{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae34a79-03b7-43c6-a1ef-71a3b432a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "418b9bb2-0826-4471-b5e0-4f5acc5fc234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_id A0A5E4HS15.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35854"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ruta del directorio que contiene los archivos .pt\n",
    "embeddings_dir = \"curated_dataset/individual_embeddings_original\"\n",
    "\n",
    "# Inicializar el diccionario para almacenar los embeddings\n",
    "embeddings_dict = {}\n",
    "count = 0\n",
    "# Iterar sobre los archivos .pt en el directorio\n",
    "for filename in os.listdir(embeddings_dir):\n",
    "    count = count + 1\n",
    "    # Obtener el ID de la secuencia desde el nombre del archivo\n",
    "    sequence_id = filename.split(\".pt\")[0]\n",
    "\n",
    "    # Cargar el tensor de embedding desde el archivo .pt\n",
    "    embedding = torch.load(os.path.join(embeddings_dir, filename))\n",
    "\n",
    "    # Agregar el embedding al diccionario con el ID de la secuencia como clave\n",
    "    \n",
    "    embeddings_dict[sequence_id] = embedding\n",
    "    if count == 2:\n",
    "        print(\"sequence_id\", sequence_id)\n",
    "\n",
    "# Ahora tienes un diccionario con los embeddings cargados y listos para su uso\n",
    "len(embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ead9f67e-25dc-489a-9db4-ed019d8b3d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0A0F6AC62.1: tensor([[ 0.2372, -0.1559,  0.1103,  ...,  0.3969, -0.5825, -0.0428],\n",
      "        [-0.3194, -0.1705, -0.0451,  ...,  0.3626,  0.0815, -0.1895],\n",
      "        [ 0.0437, -0.1727,  0.3814,  ...,  0.1214, -0.1519,  0.0835],\n",
      "        ...,\n",
      "        [-0.2321, -0.0523, -0.0148,  ...,  0.4848, -0.0748,  0.2708],\n",
      "        [ 0.1027, -0.2259,  0.1735,  ..., -0.1111, -0.0759, -0.2376],\n",
      "        [ 0.2237, -0.1295,  0.1406,  ..., -0.0047, -0.1700, -0.3562]],\n",
      "       requires_grad=True)\n",
      "len torch.Size([50, 320])\n",
      "A0A5E4HS15.1: tensor([[ 0.0776,  0.5679,  0.3548,  ...,  1.2091,  0.3872, -0.2083],\n",
      "        [ 0.0622, -0.4613,  0.2075,  ...,  0.0323, -0.0510,  0.2340],\n",
      "        [-0.0388, -0.2371, -0.1866,  ..., -0.0708,  0.2436,  0.1552],\n",
      "        ...,\n",
      "        [ 0.0591,  0.0199, -0.1469,  ..., -0.0629,  0.0126, -0.2372],\n",
      "        [ 0.2729,  0.2205, -0.2491,  ...,  0.0683,  0.0939, -0.4274],\n",
      "        [-0.0058,  0.2432,  0.0837,  ..., -0.0527, -0.3397, -0.0704]],\n",
      "       requires_grad=True)\n",
      "len torch.Size([42, 320])\n",
      "A0A6A6HHG7.1: tensor([[ 0.1974,  0.2222, -0.3026,  ...,  0.7450, -0.1879, -0.1530],\n",
      "        [-0.0037, -0.0842,  0.0468,  ...,  0.1459,  0.0680,  0.0480],\n",
      "        [-0.1016, -0.1237,  0.2762,  ...,  0.1985, -0.0535,  0.1105],\n",
      "        ...,\n",
      "        [ 0.1207, -0.0452,  0.2257,  ...,  0.2576, -0.1974, -0.1191],\n",
      "        [ 0.1963, -0.0340,  0.1456,  ...,  0.2574, -0.2179,  0.0455],\n",
      "        [-0.0038, -0.1082,  0.1399,  ..., -0.2338, -0.0718, -0.0010]],\n",
      "       requires_grad=True)\n",
      "len torch.Size([218, 320])\n"
     ]
    }
   ],
   "source": [
    "# Suponiendo que embeddings_dict es tu diccionario\n",
    "\n",
    "\n",
    "# Iterar sobre los primeros 10 elementos del diccionario\n",
    "for i, (key, value) in enumerate(embeddings_dict.items()):\n",
    "    print(f\"{key}: {value}\")\n",
    "    print(\"len\", value.shape)\n",
    "    if i >= 2:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0b388cb-fc6b-4ec3-b973-9c6cbe0a713e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, EsmModel\n",
    "import torch\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "\n",
    "# Cargar el tokenizador y el modelo\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "model = EsmModel.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "\n",
    "# Función para generar los embeddings vectors de una secuencia\n",
    "\n",
    "\n",
    "def generate_embedding(sequence):\n",
    "    inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    # Squeeze para eliminar la dimensión de lote\n",
    "    embedding = outputs.last_hidden_state.squeeze(0)\n",
    "    # Eliminar la primera y última fila\n",
    "    embedding = embedding[1:-1, :]\n",
    "    return embedding\n",
    "\n",
    "\n",
    "# Crear directorio para almacenar los embeddings\n",
    "\n",
    "# Leer el archivo fasta y procesar las secuencias\n",
    "fasta_file = \"curated_dataset/reduced_input_20000.fasta\"\n",
    "count = 0\n",
    "if False:\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        count = count + 1\n",
    "        sequence_id = record.id.split('/')[0]\n",
    "        # sequence_id = sequence_id.replace('.', '')\n",
    "        sequence_id_complement = record.id.split('/')[1]\n",
    "        sequence = str(record.seq)\n",
    "    \n",
    "        # Generar el embedding para la secuencia actual\n",
    "        embedding = generate_embedding(sequence)\n",
    "        output_file = f\"curated_dataset/individual_embeddings/{sequence_id}.pt\"\n",
    "        # os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "        # Guardar el embedding en un archivo .pt dentro del directorio de la secuencia\n",
    "        torch.save(embedding, output_file)\n",
    "    \n",
    "        print(\n",
    "            f\"Embedding {count} generado y guardado para la secuencia {sequence_id}\")\n",
    "\n",
    "    print(\"Proceso completado.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
