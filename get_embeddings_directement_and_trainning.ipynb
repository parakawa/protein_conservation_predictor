{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ae34a79-03b7-43c6-a1ef-71a3b432a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "418b9bb2-0826-4471-b5e0-4f5acc5fc234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_id A0A5E4HS15.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35854"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chemin du répertoire contenant les fichiers .pt\n",
    "embeddings_dir = \"curated_dataset/individual_embeddings_original\"\n",
    "\n",
    "# Initialiser le dictionnaire pour stocker les embeddings\n",
    "embeddings_dict = {}\n",
    "count = 0\n",
    "\n",
    "# Itérer sur les fichiers .pt dans le répertoire\n",
    "for filename in os.listdir(embeddings_dir):\n",
    "    count = count + 1\n",
    "    # Obtenir l'ID de la séquence à partir du nom du fichier\n",
    "    sequence_id = filename.split(\".pt\")[0]\n",
    "\n",
    "    # Charger le tenseur d'embedding depuis le fichier .pt\n",
    "    embedding = torch.load(os.path.join(embeddings_dir, filename))\n",
    "\n",
    "    # Ajouter l'embedding au dictionnaire avec l'ID de la séquence comme clé\n",
    "    embeddings_dict[sequence_id] = embedding\n",
    "    if count == 2:\n",
    "        print(\"sequence_id\", sequence_id)\n",
    "\n",
    "# Maintenant, tu as un dictionnaire avec les embeddings chargés et prêts à l'emploi\n",
    "len(embeddings_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "010e94e5-630c-407c-823f-266d8f4547fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defectuoso 76\n"
     ]
    }
   ],
   "source": [
    "print(\"defectuoso\", len(embeddings_dict[\"Q54EQ8.1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00135c62-d13f-4a30-a0f2-5dff32acd67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"SLFGGQTQTTTSPFGSQTSTPFGQPQQTNTGSGLFGAQQTQQTNTGGGLFGAQPTQQTSGGGLFGTQPTSGTGLFG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ead9f67e-25dc-489a-9db4-ed019d8b3d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0A0F6AC62.1: tensor([[ 0.2372, -0.1559,  0.1103,  ...,  0.3969, -0.5825, -0.0428],\n",
      "        [-0.3194, -0.1705, -0.0451,  ...,  0.3626,  0.0815, -0.1895],\n",
      "        [ 0.0437, -0.1727,  0.3814,  ...,  0.1214, -0.1519,  0.0835],\n",
      "        ...,\n",
      "        [-0.2321, -0.0523, -0.0148,  ...,  0.4848, -0.0748,  0.2708],\n",
      "        [ 0.1027, -0.2259,  0.1735,  ..., -0.1111, -0.0759, -0.2376],\n",
      "        [ 0.2237, -0.1295,  0.1406,  ..., -0.0047, -0.1700, -0.3562]],\n",
      "       requires_grad=True)\n",
      "len torch.Size([50, 320])\n",
      "A0A5E4HS15.1: tensor([[ 0.0776,  0.5679,  0.3548,  ...,  1.2091,  0.3872, -0.2083],\n",
      "        [ 0.0622, -0.4613,  0.2075,  ...,  0.0323, -0.0510,  0.2340],\n",
      "        [-0.0388, -0.2371, -0.1866,  ..., -0.0708,  0.2436,  0.1552],\n",
      "        ...,\n",
      "        [ 0.0591,  0.0199, -0.1469,  ..., -0.0629,  0.0126, -0.2372],\n",
      "        [ 0.2729,  0.2205, -0.2491,  ...,  0.0683,  0.0939, -0.4274],\n",
      "        [-0.0058,  0.2432,  0.0837,  ..., -0.0527, -0.3397, -0.0704]],\n",
      "       requires_grad=True)\n",
      "len torch.Size([42, 320])\n",
      "A0A6A6HHG7.1: tensor([[ 0.1974,  0.2222, -0.3026,  ...,  0.7450, -0.1879, -0.1530],\n",
      "        [-0.0037, -0.0842,  0.0468,  ...,  0.1459,  0.0680,  0.0480],\n",
      "        [-0.1016, -0.1237,  0.2762,  ...,  0.1985, -0.0535,  0.1105],\n",
      "        ...,\n",
      "        [ 0.1207, -0.0452,  0.2257,  ...,  0.2576, -0.1974, -0.1191],\n",
      "        [ 0.1963, -0.0340,  0.1456,  ...,  0.2574, -0.2179,  0.0455],\n",
      "        [-0.0038, -0.1082,  0.1399,  ..., -0.2338, -0.0718, -0.0010]],\n",
      "       requires_grad=True)\n",
      "len torch.Size([218, 320])\n"
     ]
    }
   ],
   "source": [
    "# Iterar sobre los primeros elementos del diccionario\n",
    "for i, (key, value) in enumerate(embeddings_dict.items()):\n",
    "    print(f\"{key}: {value}\")\n",
    "    print(\"len\", value.shape)\n",
    "    if i >= 2:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8461ce59-2053-451d-89c2-e00ef35a65a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conservation_scores(csv_file):\n",
    "    # Charger le CSV\n",
    "    df = pd.read_csv(csv_file, delimiter=',', names=[\n",
    "                     'sequence id', 'conservation score'], header=0)\n",
    "    sequences = df['sequence id'].values\n",
    "    conservation_scores = df['conservation score'].apply(lambda x: np.array(\n",
    "    [float(i) if i != 'nan' else 0.0 for i in x.split()], dtype=np.float32)).values\n",
    "    #print(\"conservation_scores\", conservation_scores)\n",
    "\n",
    "    return sequences, conservation_scores\n",
    "\n",
    "sequences, conservation_scores_array = get_conservation_scores('curated_dataset/filtered_conservation_scores_35854.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c184dd24-c138-4ab7-9a4d-c2fe7bcde04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.329834, 0.481934, 0.342285, 0.564941, 0.238525, 0.47168 ,\n",
       "       0.438721, 0.492676, 0.788574, 0.220581, 0.723633, 0.492188,\n",
       "       0.746582, 0.791016, 0.192017, 0.133179, 0.223022, 0.570312,\n",
       "       0.258057, 0.250488, 0.561523, 0.192627, 0.457764, 0.516113,\n",
       "       0.197021, 0.366455, 0.281982, 0.490234, 0.554688, 0.349121,\n",
       "       0.444824, 0.409424, 0.41748 , 0.578125, 0.206055, 0.260498,\n",
       "       0.522949, 0.725098, 0.470947, 0.601074, 0.477539, 0.161255,\n",
       "       0.461182, 0.463379, 0.349365, 0.472656, 0.257568, 0.697754,\n",
       "       0.404053, 0.223633, 0.222412, 0.219482, 0.146606, 0.22229 ,\n",
       "       0.18103 , 0.207642, 0.268555, 0.400879, 0.336914, 0.219727,\n",
       "       0.213135, 0.355713, 0.301514, 0.17981 , 0.327148, 0.360596,\n",
       "       0.368408, 0.166626, 0.146362, 0.070801, 0.104004, 0.057739,\n",
       "       0.181152, 0.062988, 0.031799, 0.063232, 0.127197, 0.136108,\n",
       "       0.109619, 0.282471, 0.36377 , 0.185791, 0.05777 , 0.430176,\n",
       "       0.244141, 0.400391, 0.170166, 0.174072, 0.413574, 0.48999 ,\n",
       "       0.256348, 0.168945, 0.454346, 0.255371, 0.205078, 0.168579,\n",
       "       0.35498 , 0.110413, 0.129883, 0.13562 , 0.151001, 0.126343,\n",
       "       0.19519 , 0.062744, 0.680664, 0.319092, 0.530762, 0.597656,\n",
       "       0.462402, 0.610352, 0.49585 , 0.639648, 0.755859, 0.736816,\n",
       "       0.304199, 0.35376 , 0.1875  , 0.295166, 0.25415 , 0.184937,\n",
       "       0.177002, 0.409424, 0.213501, 0.288086, 0.240479, 0.522461,\n",
       "       0.236328, 0.272461, 0.424561, 0.448242, 0.160767, 0.247925,\n",
       "       0.490479, 0.458496, 0.596191, 0.649414, 0.535156, 0.703125,\n",
       "       0.505371, 0.512695, 0.405518, 0.534668, 0.213989, 0.187378,\n",
       "       0.200928, 0.405029, 0.261475, 0.45459 , 0.608398, 0.339111,\n",
       "       0.267822, 0.625   , 0.601074, 0.360352, 0.383789, 0.134033,\n",
       "       0.40332 , 0.467773, 0.105835, 0.351318, 0.575195, 0.628418,\n",
       "       0.487793, 0.425049, 0.507324, 0.414307, 0.237915, 0.312012,\n",
       "       0.252686, 0.36499 , 0.251465, 0.195068, 0.167114, 0.32373 ,\n",
       "       0.352539, 0.490234, 0.227783, 0.292725, 0.519531, 0.544922,\n",
       "       0.307373, 0.203369, 0.483643, 0.40918 , 0.204468, 0.436768,\n",
       "       0.500977, 0.373535, 0.104004, 0.67041 , 0.32666 , 0.226196,\n",
       "       0.245728, 0.371094, 0.296631, 0.127441, 0.244629, 0.350586,\n",
       "       0.335205, 0.245972], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conservation_scores_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec61534f-0af4-462c-bccc-c494c9be0917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0H3YJP0.1/580-733',) y 154 y 165\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n",
      "Epoch 1/5, Validation Loss: 0.03345598168290293\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0H3YJP0.1/580-733',) y 154 y 165\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Epoch 2/5, Validation Loss: 0.03293524811729844\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0H3YJP0.1/580-733',) y 154 y 165\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Epoch 3/5, Validation Loss: 0.03318450601207141\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0H3YJP0.1/580-733',) y 154 y 165\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n",
      "Epoch 4/5, Validation Loss: 0.032708449719549886\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0H3YJP0.1/580-733',) y 154 y 165\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Epoch 5/5, Validation Loss: 0.03263311526204934\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n",
      "Test Loss: 0.033463410311560235\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define your datasets (train, validation, test)\n",
    "dataset = [(embeddings_dict[sequence.split(\"/\")[0]], conservation_scores, sequence) for sequence, conservation_scores in zip(sequences, conservation_scores_array)]\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create data loaders for train, validation, and test\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Define your model\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Define training function\n",
    "def train_model(model, optimizer, loss_fn, data_loader):\n",
    "    model.train()\n",
    "    for embedding, label, sequence in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        embedding = embedding.squeeze()\n",
    "        label = label.squeeze()\n",
    "        if embedding.size(0) != label.size(0):\n",
    "            print(f\"Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: {sequence} y {label.size(0)} y {embedding.size(0)}\" )\n",
    "            continue\n",
    "        output = model(embedding).squeeze()\n",
    "        loss = loss_fn(output, label)\n",
    "        #print(\"embedding\", embedding)\n",
    "        #print(\"embedding.shape\", embedding.shape)\n",
    "        #print(\"label\", label)\n",
    "        #print(\"labelshape\", label.shape)\n",
    "        \n",
    "        #print(\"output\", output)\n",
    "        #print(\"output.shape\", output.shape)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_model(model, loss_fn, data_loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for embedding, label, sequence in data_loader:\n",
    "            embedding = embedding.squeeze()\n",
    "            label = label.squeeze()\n",
    "            output = model(embedding).squeeze()\n",
    "            if embedding.size(0) != label.size(0):\n",
    "                print(f\"Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: {sequence} y {label.size(0)} y {embedding.size(0)}\" )\n",
    "                continue\n",
    "            #print(\"embedding.shape ev\", embedding.shape)\n",
    "            #print(\"label\", label)\n",
    "            #print(\"labelshape\", label.shape)\n",
    "            \n",
    "            #print(\"output\", output)\n",
    "            #print(\"output.shape\", output.shape)\n",
    "            loss = loss_fn(output, label)\n",
    "            running_loss += loss.item()\n",
    "    return running_loss / len(data_loader)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = LinearRegression(input_size=320)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "val_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_model(model, optimizer, loss_fn, train_loader)\n",
    "    val_loss = evaluate_model(model, loss_fn, val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Validation Loss: {val_loss}')\n",
    "\n",
    "# Plot validation loss over epochs\n",
    "plt.plot(val_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss over Epochs Regression Linear')\n",
    "plt.show()\n",
    "\n",
    "# Finally, evaluate on test set\n",
    "test_loss = evaluate_model(model, loss_fn, test_loader)\n",
    "print(f'Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4fc067f-3cf3-4799-bbee-cbff1de6622b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0H3YJP0.1/580-733',) y 154 y 165\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Epoch 1/5, Validation Loss: 0.03359931995642119\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0H3YJP0.1/580-733',) y 154 y 165\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Epoch 2/5, Validation Loss: 0.03345294034517055\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0H3YJP0.1/580-733',) y 154 y 165\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Epoch 3/5, Validation Loss: 0.03307994047740689\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0H3YJP0.1/580-733',) y 154 y 165\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Epoch 4/5, Validation Loss: 0.03331160185379097\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0H3YJP0.1/580-733',) y 154 y 165\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Epoch 5/5, Validation Loss: 0.032982373448455754\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAHHCAYAAACfqw0dAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB7dElEQVR4nO3dd1gU59oG8Ht3YXfpICCgoqgIKCLYQLASUVATgxWNUSyp9pB4LDFqippm7IkltiQaewtiQSyxYANRVLBgFwERKaLUne8P4n7ZAAoIDAv377r2OsfZd3budweyDzOzz0gEQRBARERERKUiFTsAERERkTZiEUVERERUBiyiiIiIiMqARRQRERFRGbCIIiIiIioDFlFEREREZcAiioiIiKgMWEQRERERlQGLKCIiIqIyYBFFpOVu374NiUSCtWvXqpfNmjULEomkROtLJBLMmjWrXDN16dIFXbp0KdfXJCqKRCLB2LFjxY5BNRSLKKJK1Lt3b+jr6yMjI6PYMUOGDIFcLsfjx48rMVnpXblyBbNmzcLt27fFjqJ25MgRSCQSbN26Vewo1YZEIin28dFHH4kdj0hUOmIHIKpJhgwZgr/++gs7duzAsGHDCj3/7Nkz7Nq1C35+fjA3Ny/zdqZPn44pU6a8TtRXunLlCr788kt06dIFdnZ2Gs8dOHCgQrdNlatbt25F/rw6ODiIkIao6mARRVSJevfuDSMjI2zYsKHID6Vdu3YhMzMTQ4YMea3t6OjoQEdHvF9vuVwu2rapdLKysiCXyyGVFn9iwsHBAe+++24lpiLSDjydR1SJ9PT00LdvX4SFhSEpKanQ8xs2bICRkRF69+6NlJQUfPbZZ3BxcYGhoSGMjY3Ro0cPXLhw4ZXbKeqaqOzsbHzyySewtLRUb+P+/fuF1r1z5w5Gjx4NR0dH6OnpwdzcHAMGDNA4bbd27VoMGDAAAODt7a0+vXPkyBEARV8TlZSUhFGjRsHKygpKpRKurq5Yt26dxpgX13f9+OOPWLFiBRo3bgyFQoG2bdvi7Nmzr5x3Sd28eRMDBgxArVq1oK+vj3bt2mHPnj2Fxi1evBjOzs7Q19eHmZkZ2rRpgw0bNqifz8jIwMSJE2FnZweFQoHatWujW7duiIyMfGWG8+fPo0ePHjA2NoahoSG6du2KU6dOqZ8/d+4cJBJJofcIAPbv3w+JRILg4GD1sgcPHmDkyJGwsrKCQqGAs7MzVq9erbHei9OdGzduxPTp01G3bl3o6+sjPT29RO/by3Tp0gXNmzdHREQEvLy8oKenh4YNG2LZsmWFxpbkZwEAVCoVFi5cCBcXFyiVSlhaWsLPzw/nzp0rNHbnzp1o3ry5eu779u3TeP519hVRcXgkiqiSDRkyBOvWrcPmzZs1LohNSUnB/v37MXjwYOjp6eHy5cvYuXMnBgwYgIYNGyIxMRHLly9H586dceXKFdSpU6dU233vvffwxx9/4J133oGXlxcOHTqEXr16FRp39uxZnDx5EoMGDUK9evVw+/Zt/PLLL+jSpQuuXLkCfX19dOrUCePHj8eiRYswbdo0NG3aFADU//tfz58/R5cuXXDjxg2MHTsWDRs2xJYtWzB8+HCkpqZiwoQJGuM3bNiAjIwMfPjhh5BIJPj+++/Rt29f3Lx5E7q6uqWa938lJibCy8sLz549w/jx42Fubo5169ahd+/e2Lp1K/r06QMAWLlyJcaPH4/+/ftjwoQJyMrKwsWLF3H69Gm88847AICPPvoIW7duxdixY9GsWTM8fvwYx48fR0xMDFq1alVshsuXL6Njx44wNjbG//73P+jq6mL58uXo0qULjh49Cg8PD7Rp0waNGjXC5s2bERgYqLH+pk2bYGZmBl9fX/Wc2rVrp77I2tLSEnv37sWoUaOQnp6OiRMnaqz/9ddfQy6X47PPPkN2dvYrjxxmZWUhOTm50HJjY2ONdZ88eYKePXti4MCBGDx4MDZv3oyPP/4YcrkcI0eOBFC6n4VRo0Zh7dq16NGjB9577z3k5eXh2LFjOHXqFNq0aaMed/z4cWzfvh2jR4+GkZERFi1ahH79+uHu3bvq0+Jl3VdELyUQUaXKy8sTbGxsBE9PT43ly5YtEwAI+/fvFwRBELKysoT8/HyNMbdu3RIUCoXw1VdfaSwDIKxZs0a9bObMmcK/f72joqIEAMLo0aM1Xu+dd94RAAgzZ85UL3v27FmhzOHh4QIA4bffflMv27JliwBAOHz4cKHxnTt3Fjp37qz+94IFCwQAwh9//KFelpOTI3h6egqGhoZCenq6xlzMzc2FlJQU9dhdu3YJAIS//vqr0Lb+7fDhwwIAYcuWLcWOmThxogBAOHbsmHpZRkaG0LBhQ8HOzk79nr/99tuCs7PzS7dnYmIijBkz5qVjiuLv7y/I5XIhLi5OvSw+Pl4wMjISOnXqpF42depUQVdXV+O9yM7OFkxNTYWRI0eql40aNUqwsbERkpOTNbYzaNAgwcTERL1PX7w/jRo1KnI/FwVAsY8///xTPa5z584CAGHevHkaWd3c3ITatWsLOTk5giCU/Gfh0KFDAgBh/PjxhTKpVCqNfHK5XLhx44Z62YULFwQAwuLFi9XLyrqviF6Gp/OIKplMJsOgQYMQHh6ucYpsw4YNsLKyQteuXQEACoVCfZ1Kfn4+Hj9+DENDQzg6Opb6FERISAgAYPz48RrL/3uEAig45fhCbm4uHj9+DHt7e5iampb51EdISAisra0xePBg9TJdXV2MHz8eT58+xdGjRzXGBwQEwMzMTP3vjh07Aig4Dfe6QkJC4O7ujg4dOqiXGRoa4oMPPsDt27dx5coVAICpqSnu37//0tOIpqamOH36NOLj40u8/fz8fBw4cAD+/v5o1KiRermNjQ3eeecdHD9+XH16LSAgALm5udi+fbt63IEDB5CamoqAgAAAgCAI2LZtG9566y0IgoDk5GT1w9fXF2lpaYX2W2BgoMZ+fpW3334boaGhhR7e3t4a43R0dPDhhx+q/y2Xy/Hhhx8iKSkJERERAEr+s7Bt2zZIJBLMnDmzUJ7/nqr28fFB48aN1f9u0aIFjI2NNX5eyrKviF6FRRSRCF5cOP7i+pr79+/j2LFjGDRoEGQyGYCC60Hmz5+PJk2aQKFQwMLCApaWlrh48SLS0tJKtb07d+5AKpVqfNAAgKOjY6Gxz58/x4wZM2Bra6ux3dTU1FJv99/bb9KkSaGLl1+c/rtz547G8vr162v8+0VB9eTJkzJt/79Zipr3f7NMnjwZhoaGcHd3R5MmTTBmzBicOHFCY53vv/8ely5dgq2tLdzd3TFr1qxXFnqPHj3Cs2fPis2gUqlw7949AICrqyucnJywadMm9ZhNmzbBwsICb7zxhvr1UlNTsWLFClhaWmo8RowYAQCFrr9r2LDhSzP+V7169eDj41PoYWVlpTGuTp06MDAw0Fj24ht8L/5gKOnPQlxcHOrUqYNatWq9Mt9/f16Agp+Zf/+8lGVfEb0KiygiEbRu3RpOTk74888/AQB//vknBEHQ+FbenDlzEBQUhE6dOuGPP/7A/v37ERoaCmdnZ6hUqgrLNm7cOMyePRsDBw7E5s2bceDAAYSGhsLc3LxCt/tvLwrJ/xIEoVK2DxR8qF+9ehUbN25Ehw4dsG3bNnTo0EHjyMjAgQNx8+ZNLF68GHXq1MEPP/wAZ2dn7N27t9xyBAQE4PDhw0hOTkZ2djZ2796Nfv36qb99+WKfvPvuu0UeLQoNDUX79u01XrM0R6G0QUl+XipjX1HNwwvLiUQyZMgQfPHFF7h48SI2bNiAJk2aoG3bturnt27dCm9vb6xatUpjvdTUVFhYWJRqWw0aNIBKpUJcXJzGEZCrV68WGrt161YEBgZi3rx56mVZWVlITU3VGFfSjugvtn/x4kWoVCqNIxCxsbHq5ytLgwYNipx3UVkMDAwQEBCAgIAA5OTkoG/fvpg9ezamTp0KpVIJoOA03OjRozF69GgkJSWhVatWmD17Nnr06FHk9i0tLaGvr19sBqlUCltbW/WygIAAfPnll9i2bRusrKyQnp6OQYMGabyekZER8vPz4ePjU7Y3pZzEx8cjMzNT42jUtWvXAEDdS6ykPwuNGzfG/v37kZKSUqKjUSVR2n1F9Co8EkUkkhdHnWbMmIGoqKhCvaFkMlmhIy9btmzBgwcPSr2tFx8SixYt0li+YMGCQmOL2u7ixYuRn5+vsezFB+V/i6ui9OzZEwkJCRqnpfLy8rB48WIYGhqic+fOJZlGuejZsyfOnDmD8PBw9bLMzEysWLECdnZ2aNasGQAU6hgvl8vRrFkzCIKA3Nxc5OfnFzq9Wbt2bdSpUwfZ2dnFbl8mk6F79+7YtWuXxjVxiYmJ2LBhAzp06ABjY2P18qZNm8LFxQWbNm3Cpk2bYGNjg06dOmm8Xr9+/bBt2zZcunSp0PYePXpUsjemHOTl5WH58uXqf+fk5GD58uWwtLRE69atAZT8Z6Ffv34QBAFffvlloe2U9ohkWfcV0avwSBSRSBo2bAgvLy/s2rULAAoVUW+++Sa++uorjBgxAl5eXoiOjsb69es1LkYuKTc3NwwePBg///wz0tLS4OXlhbCwMNy4caPQ2DfffBO///47TExM0KxZM4SHh+PgwYOFOqi7ublBJpPhu+++Q1paGhQKBd544w3Url270Gt+8MEHWL58OYYPH46IiAjY2dlh69atOHHiBBYsWAAjI6NSz+lltm3bpj6y8W+BgYGYMmUK/vzzT/To0QPjx49HrVq1sG7dOty6dQvbtm1THx3p3r07rK2t0b59e1hZWSEmJgZLlixBr169YGRkhNTUVNSrVw/9+/eHq6srDA0NcfDgQZw9e1bjKF5RvvnmG4SGhqJDhw4YPXo0dHR0sHz5cmRnZ+P7778vND4gIAAzZsyAUqnEqFGjCl1P9O233+Lw4cPw8PDA+++/j2bNmiElJQWRkZE4ePAgUlJSXuPdLDia9McffxRabmVlhW7duqn/XadOHXz33Xe4ffs2HBwcsGnTJkRFRWHFihXq1hQl/Vnw9vbG0KFDsWjRIly/fh1+fn5QqVQ4duwYvL29S3W/vIyMjDLvK6KXEutrgUQkCEuXLhUACO7u7oWey8rKEj799FPBxsZG0NPTE9q3by+Eh4cXah9QkhYHgiAIz58/F8aPHy+Ym5sLBgYGwltvvSXcu3evUIuDJ0+eCCNGjBAsLCwEQ0NDwdfXV4iNjRUaNGggBAYGarzmypUrhUaNGgkymUyj3cF/MwqCICQmJqpfVy6XCy4uLhqZ/z2XH374odD78d+cRXnxFf7iHi/aGsTFxQn9+/cXTE1NBaVSKbi7uwvBwcEar7V8+XKhU6dOgrm5uaBQKITGjRsLkyZNEtLS0gRBKPj6/qRJkwRXV1fByMhIMDAwEFxdXYWff/75pRlfiIyMFHx9fQVDQ0NBX19f8Pb2Fk6ePFnk2OvXr6vncPz48SLHJCYmCmPGjBFsbW0FXV1dwdraWujatauwYsWKQu/Py1pA/NfL3s9/7+POnTsLzs7Owrlz5wRPT09BqVQKDRo0EJYsWVJk1lf9LAhCQTuQH374QXBychLkcrlgaWkp9OjRQ4iIiNDIV1Trgn//vL7uviIqjkQQKvFKTSIiqpa6dOmC5OTkIk8pElVXvCaKiIiIqAxYRBERERGVAYsoIiIiojLgNVFEREREZcAjUURERERlwCKKiIiIqAzYbLMCqVQqxMfHw8jIqFS3yCAiIiLxCIKAjIwM1KlTp1Bz239jEVWB4uPjNe6BRURERNrj3r17qFevXrHPs4iqQC9uX3Dv3j2Ne2ERERFR1ZWeng5bW9tX3pKKRVQFenEKz9jYmEUUERGRlnnVpTi8sJyIiIioDFhEEREREZUBiygiIiKiMmARRURERFQGLKKIiIiIyoBFFBEREVEZsIgiIiIiKgMWUURERERlwCKKiIiIqAxEL6KWLl0KOzs7KJVKeHh44MyZMy8dv2XLFjg5OUGpVMLFxQUhISEaz8+aNQtOTk4wMDCAmZkZfHx8cPr0aY0xvXv3Rv369aFUKmFjY4OhQ4ciPj5eY4wgCPjxxx/h4OAAhUKBunXrYvbs2eUzaSIiItJ6ohZRmzZtQlBQEGbOnInIyEi4urrC19cXSUlJRY4/efIkBg8ejFGjRuH8+fPw9/eHv78/Ll26pB7j4OCAJUuWIDo6GsePH4ednR26d++OR48eqcd4e3tj8+bNuHr1KrZt24a4uDj0799fY1sTJkzAr7/+ih9//BGxsbHYvXs33N3dK+aNICIiIq0jEQRBEGvjHh4eaNu2LZYsWQIAUKlUsLW1xbhx4zBlypRC4wMCApCZmYng4GD1snbt2sHNzQ3Lli0rchvp6ekwMTHBwYMH0bVr1yLH7N69G/7+/sjOzoauri5iYmLQokULXLp0CY6OjmWe34ttp6Wl8d55REREWqKkn9+iHYnKyclBREQEfHx8/j+MVAofHx+Eh4cXuU54eLjGeADw9fUtdnxOTg5WrFgBExMTuLq6FjkmJSUF69evh5eXF3R1dQEAf/31Fxo1aoTg4GA0bNgQdnZ2eO+995CSklKWqZa7K/HpuP/kmdgxiIiIajTRiqjk5GTk5+fDyspKY7mVlRUSEhKKXCchIaFE44ODg2FoaAilUon58+cjNDQUFhYWGmMmT54MAwMDmJub4+7du9i1a5f6uZs3b+LOnTvYsmULfvvtN6xduxYRERGFTvn9V3Z2NtLT0zUe5e1pdh4+Xh+BHguPYVfUg3J/fSIiIioZ0S8srwje3t6IiorCyZMn4efnh4EDBxa6zmrSpEk4f/48Dhw4AJlMhmHDhuHFmU2VSoXs7Gz89ttv6NixI7p06YJVq1bh8OHDuHr1arHbnTt3LkxMTNQPW1vbcp/b06w8mOnLkZGVhwkbozBx43mkZ+WW+3aIiIjo5UQroiwsLCCTyZCYmKixPDExEdbW1kWuY21tXaLxBgYGsLe3R7t27bBq1Sro6Ohg1apVhbbv4OCAbt26YePGjQgJCcGpU6cAADY2NtDR0YGDg4N6fNOmTQEAd+/eLXZOU6dORVpamvpx7969V7wLpWdtosSWjzwxvmsTSCXAzqh49FhwDGduVY1TjURERDWFaEWUXC5H69atERYWpl6mUqkQFhYGT0/PItfx9PTUGA8AoaGhxY7/9+tmZ2e/9HkA6jHt27dHXl4e4uLi1GOuXbsGAGjQoEGxr6NQKGBsbKzxqAi6MimCujlgy0eesK2lhwepzzFoRTh+2B+L3HxVhWyTiIiINIn67bxNmzYhMDAQy5cvh7u7OxYsWIDNmzcjNjYWVlZWGDZsGOrWrYu5c+cCKGhx0LlzZ3z77bfo1asXNm7ciDlz5iAyMhLNmzdHZmYmZs+ejd69e8PGxgbJyclYunQpNmzYgIiICDg7O+P06dM4e/YsOnToADMzM8TFxeGLL75AYmIiLl++DIVCAZVKhbZt28LQ0BALFiyASqXCmDFjYGxsjAMHDpR4fpXx7byMrFzM2n0F2yLvAwBa1DPBggA3NLI0rJDtERERVXdV/tt5QEHLgh9//BEzZsyAm5sboqKisG/fPvXF43fv3sXDhw/V4728vLBhwwasWLECrq6u2Lp1K3bu3InmzZsDAGQyGWJjY9GvXz84ODjgrbfewuPHj3Hs2DE4OzsDAPT19bF9+3Z07doVjo6OGDVqFFq0aIGjR49CoVAAKPiW4F9//QULCwt06tQJvXr1QtOmTbFx48ZKfodezUipi3kDXbH0nVYw0dPFxftp6LXoODacvgsR62MiIqJqT9QjUdVdZfeJepj2HJ9uvoCTcY8BAN2aWeHbvi4wN1RU+LaJiIiqC604EkXly8ZED3+M8sC0nk7QlUkQeiURfguP4cjVojvAExERUdmxiKpmpFIJPujUGDvHtId9bUM8ysjG8DVnMWv3ZWTl5osdj4iIqNpgEVVNOdcxQfC4Dgj0LPg24dqTt9F7yXFciS//BqBEREQ1EYuoakypK8OXbzfHmhFtYWGowLXEp/BfegIr/74JlYqXwhEREb0OFlE1gLdjbeyb2BE+TWsjJ1+F2SExGLr6NBLSssSORkREpLVYRNUQFoYKrBzWBrP7NIdSV4oTNx7Dd8HfCIl++OqViYiIqBAWUTWIRCLBEI8G2DO+I1zqmiDteS5Gr4/EZ1su4Gl2ntjxiIiItAqLqBqosaUhtn3shdFdGkMiAbZG3EfPhccQceeJ2NGIiIi0BouoGkquI8X//Jyw8f12qGuqh7spzzBweTjmh15DHu+/R0RE9Eosomo4j0bmCJnQEW+71UG+SsDCsOsYsDwcdx5nih2NiIioSmMRRTDR08XCQS2xIMANRgodnL+bip4Lj2HLuXu8/x4REVExWESRmn/LugiZ0BHudrWQmZOPSVsvYsyGSKQ+yxE7GhERUZXDIoo02NbSx58ftMMkX0foSCUIiU6A34JjOHkjWexoREREVQqLKCpEJpVgjLc9to/2QiMLAySkZ+GdX09j9p4ryM7j/feIiIgAFlH0Ei3qmSJ4fAcMdq8PAFh57Bb8l57EtcQMkZMRERGJj0UUvZS+XAdz+7pgxdDWqGUgR8zDdLy1+DjWnbzNi86JiKhGYxFFJdLd2Rr7JnZEZwdLZOepMHP3ZYxYexZJGbz/HhER1UwsoqjEahspsXZEW8x6qxnkOlIcufoIfguO4eCVRLGjERERVToWUVQqEokEw9s3RPC4DnCyNkJKZg7e++0cpu2IxrMc3n+PiIhqDhZRVCYOVkbYNbY93u/YEACw4fRdvLnoOKLvp4mcjIiIqHKwiKIyU+jI8HmvZlj/ngesjZW4mZyJPj+fwNLDN5Cv4kXnRERUvbGIotfW3t4C+yZ2RE8Xa+SpBPyw/yoGrzyF+0+eiR2NiIiowrCIonJhqi/H0nda4Yf+LWAgl+HMrRT0WHgMu6IeiB2NiIioQrCIonIjkUgwoI0tQiZ0RMv6psjIysOEjVGYsPE80p7nih2PiIioXLGIonLXwNwAWz70xESfJpBJJdgVFY+eC4/h9M3HYkcjIiIqNyyiqELoyKSY6OOAzR96on4tfTxIfY5BK0/h+32xyMlTiR2PiIjotbGIogrVuoEZQiZ0xIDW9SAIwM9H4tDvl5OIe/RU7GhERESvhUUUVThDhQ5+GOCKn4e0gomeLqIfpOHNRcex/vQd3n+PiIi0FosoqjQ9XWywb2JHtLc3x/PcfHy+4xLe/y0Cj59mix2NiIio1FhEUaWyMdHD7yM98HnPppDLpDgYkwjfBcdw+GqS2NGIiIhKhUUUVTqpVIL3OzXCzjHt0aS2IZKfZmPEmrOYuesSsnLzxY5HRERUIiyiSDTN6hjjr3EdMNzLDgCwLvwO3lp8HJfjef89IiKq+lhEkaiUujLM6u2MtSPawsJQgetJT9Fn6Ums+DsOKt5/j4iIqjAWUVQldHGsjf0TO8KnqRVy8lWYExKLd1edxsO052JHIyIiKhKLKKoyzA0VWDmsNeb0cYGergwn4x7Db8ExhEQ/FDsaERFRISyiqEqRSCR4x6M+9ozvgBb1TJD2PBej10fisy0X8DQ7T+x4REREaiyiqEpqZGmIbR97YYx3Y0gkwNaI++i58Bgi7jwROxoREREAFlFUhenKpJjk64RNH3iirqke7qY8w8Dl4Zgfeg15+bz/HhERiYtFFFV57g1rYe/EjvB3q4N8lYCFYdcxYHk47jzOFDsaERHVYCyiSCsYK3WxYFBLLBzkBiOlDs7fTUXPhcew+dw93n+PiIhEwSKKtMrbbnWxd0JHuDeshcycfPxv60WMXh+JJ5k5YkcjIqIahkUUaZ16Zvr48/12+J+fI3SkEuy9lAC/hX/j+PVksaMREVENwiKKtJJMKsHoLvbYMbo9GlkaIDE9G++uOo1vgq8gO4/33yMioorHIoq0mks9EwSP64AhHvUBAL8ev4W3l5zAtcQMkZMREVF1VyWKqKVLl8LOzg5KpRIeHh44c+bMS8dv2bIFTk5OUCqVcHFxQUhIiMbzs2bNgpOTEwwMDGBmZgYfHx+cPn1aY0zv3r1Rv359KJVK2NjYYOjQoYiPj1c/f/v2bUgkkkKPU6dOld/EqVzoy3Uwu48Lfh3WBuYGcsQmZODNxcex5sQtXnROREQVRvQiatOmTQgKCsLMmTMRGRkJV1dX+Pr6IikpqcjxJ0+exODBgzFq1CicP38e/v7+8Pf3x6VLl9RjHBwcsGTJEkRHR+P48eOws7ND9+7d8ejRI/UYb29vbN68GVevXsW2bdsQFxeH/v37F9rewYMH8fDhQ/WjdevW5f8mULnwaWaFvRM7ooujJXLyVPjyrysIXHMWSelZYkcjIqJqSCKI/Ke6h4cH2rZtiyVLlgAAVCoVbG1tMW7cOEyZMqXQ+ICAAGRmZiI4OFi9rF27dnBzc8OyZcuK3EZ6ejpMTExw8OBBdO3atcgxu3fvhr+/P7Kzs6Grq4vbt2+jYcOGOH/+PNzc3Mo0txfbTUtLg7GxcZleg0pPEAT8fuoOZu+JQXaeCrUM5Pi2rwu6O1uLHY2IiLRAST+/RT0SlZOTg4iICPj4+KiXSaVS+Pj4IDw8vMh1wsPDNcYDgK+vb7Hjc3JysGLFCpiYmMDV1bXIMSkpKVi/fj28vLygq6ur8Vzv3r1Ru3ZtdOjQAbt3737pfLKzs5Genq7xoMonkUgwzNMOweM6oKmNMVIyc/DB7xGYuv0inuXw/ntERFQ+RC2ikpOTkZ+fDysrK43lVlZWSEhIKHKdhISEEo0PDg6GoaEhlEol5s+fj9DQUFhYWGiMmTx5MgwMDGBubo67d+9i165d6ucMDQ0xb948bNmyBXv27EGHDh3g7+//0kJq7ty5MDExUT9sbW1L9D5QxWhiZYSdY7zwQadGkEiAP8/cQ69Fx3HhXqrY0YiIqBoQ/ZqoiuLt7Y2oqCicPHkSfn5+GDhwYKHrrCZNmoTz58/jwIEDkMlkGDZsmPpCZAsLCwQFBalPN3777bd499138cMPPxS7zalTpyItLU39uHfvXoXOkV5NoSPDtJ5NsX6UB6yNlbiVnIl+v5zEkkPXka/iRedERFR2ohZRFhYWkMlkSExM1FiemJgIa+uir1+xtrYu0XgDAwPY29ujXbt2WLVqFXR0dLBq1apC23dwcEC3bt2wceNGhISEvPTbdx4eHrhx40axzysUChgbG2s8qGrwsrfAvokd0cvFBnkqAT8euIZBK8JxL+WZ2NGIiEhLiVpEyeVytG7dGmFhYeplKpUKYWFh8PT0LHIdT09PjfEAEBoaWuz4f79udnb2S58H8NIxUVFRsLGxeel2qOoy1ZdjyTst8eMAVxjIZTh7+wl6LjyGnecfiB2NiIi0kI7YAYKCghAYGIg2bdrA3d0dCxYsQGZmJkaMGAEAGDZsGOrWrYu5c+cCACZMmIDOnTtj3rx56NWrFzZu3Ihz585hxYoVAIDMzEzMnj0bvXv3ho2NDZKTk7F06VI8ePAAAwYMAACcPn0aZ8+eRYcOHWBmZoa4uDh88cUXaNy4sboYW7duHeRyOVq2bAkA2L59O1avXo1ff/21st8iKkcSiQT9W9eDu10tTNx0HpF3UzFxUxQOxSbha//mMNHTffWLEBERoQoUUQEBAXj06BFmzJiBhIQEuLm5Yd++feqLx+/evQup9P8PmHl5eWHDhg2YPn06pk2bhiZNmmDnzp1o3rw5AEAmkyE2Nhbr1q1DcnIyzM3N0bZtWxw7dgzOzs4AAH19fWzfvh0zZ85EZmYmbGxs4Ofnh+nTp0OhUKi39fXXX+POnTvQ0dGBk5MTNm3aVGQvKdI+9c31sflDTyw9HIdFh65j94V4RNx5gnkDXdGukbnY8YiISAuI3ieqOmOfKO0QefcJPtkUhTuPn0EiAT7q3Bif+DhArlNtv3dBREQvoRV9ooiqglb1zbBnfEcMbFMPggD8ciQOfX85gRtJT8WORkREVRiLKCIAhgodfN/fFcvebQVTfV1cepCONxcfwx+n7vD+e0REVCQWUUT/4tfcBvsmdEIHewtk5aowfeclvP/bOSQ/Lf5bm0REVDOxiCL6D2sTJX4b6Y7pvZpCLpPiYEwS/Bb8jcOxRd8Um4iIaiYWUURFkEoleK9jI+wa2x6OVkZIfpqDEWvPYsauS8jKzRc7HhERVQEsooheoqmNMXaNbY8R7e0AAL+F38Gbi4/jcnyauMGIiEh0LKKIXkGpK8PMt5yxbqQ7LI0UuJH0FP5LT2D50TioeP89IqIai0UUUQl1drDE/omd0L2ZFXLzBczdG4shv55GfOpzsaMREZEIWEQRlUItAzmWD22Nb/u6QE9XhvCbj+G34G8EX4wXOxoREVUyFlFEpSSRSDDIvT5CJnSEaz0TpGflYeyG8wjaHIWMrFyx4xERUSVhEUVURg0tDLD1Yy+M9baHVAJsj3yAnouOIeJOitjRiIioErCIInoNujIpPvN1xKYPPVHXVA/3Up5jwLJw/HTgKnLzVWLHIyKiCsQiiqgctLWrhb0TO6JPy7pQCcCiQzcwYFk4bidnih2NiIgqCIsoonJirNTF/AA3LBrcEkZKHUTdS0XPRcew6exd3n+PiKgaYhFFVM56u9bBvomd4NGwFp7l5GPytmh8/EcknmTmiB2NiIjKEYsoogpQ11QPG95vh8l+TtCVSbDvcgL8Fv6N49eTxY5GRETlhEUUUQWRSSX4uEtj7BjdHo0sDZCYno13V53G18FXeP89IqJqgEUUUQVrXtcEe8Z1xLvt6gMAVh2/Bf+lJ3AjKUPkZERE9DpYRBFVAj25DN/4u2BVYBuYG8gRm5CBwNVneUSKiEiLsYgiqkRdm1ph38ROsDFR4kHqc6w5cVvsSEREVEYsoogqmaWRApN8HQEAPx++gcdPs0VOREREZcEiikgE/m514VzHGBnZeVgUdl3sOEREVAYsoohEIJVK8HnPpgCA9afvIu7RU5ETERFRabGIIhKJl70FujrVRp5KwHd7Y8WOQ0REpcQiikhEU3s6QSaV4MCVRJy++VjsOEREVAosoohEZF/bCIPa2gIAZofEQKXiPfaIiLQFiygikU30cYCBXIaL99Pw18V4seMQEVEJsYgiEpmlkQIfd2kMAPh+31U24CQi0hIsooiqgFEdGqkbcK49eVvsOEREVAIsooiqAD25DJ91L2jAufTQDaRk5oiciIiIXoVFFFEV0adlXTSzYQNOIiJtwSKKqIqQSiWY3qugAecfp+7gJhtwEhFVaSyiiKoQL3sLvPGiAec+NuAkIqrKWEQRVTFTezhBKgH2X07EmVspYschIqJisIgiqmKaWBlhkHt9AMDsPVfYgJOIqIpiEUVUBU30aQIDuQwX7qchOPqh2HGIiKgILKKIqqDaRkp81LmgAed3e2PZgJOIqApiEUVURb3XsRGsjBV4kPocv4XfFjsOERH9B4sooirq3w04Fx+6gSdswElEVKWwiCKqwvq2qoemNsbIyMrDokNswElEVJWwiCKqwmRSCT7vWdCA8/fwO7iVnClyIiIieoFFFFEV16GJBbo4WiJPJeB7NuAkIqoyWEQRaYGpPZpCKgH2XkrAudtswElEVBVUiSJq6dKlsLOzg1KphIeHB86cOfPS8Vu2bIGTkxOUSiVcXFwQEhKi8fysWbPg5OQEAwMDmJmZwcfHB6dPn9YY07t3b9SvXx9KpRI2NjYYOnQo4uPji9zejRs3YGRkBFNT09eaJ1FZOVobIaCtLQDgmz0xEAQ24CQiEpvoRdSmTZsQFBSEmTNnIjIyEq6urvD19UVSUlKR40+ePInBgwdj1KhROH/+PPz9/eHv749Lly6pxzg4OGDJkiWIjo7G8ePHYWdnh+7du+PRo0fqMd7e3ti8eTOuXr2Kbdu2IS4uDv379y+0vdzcXAwePBgdO3Ys/8kTlcIn3RygL5ch6l4qgi+yAScRkdgkgsh/0np4eKBt27ZYsmQJAEClUsHW1hbjxo3DlClTCo0PCAhAZmYmgoOD1cvatWsHNzc3LFu2rMhtpKenw8TEBAcPHkTXrl2LHLN79274+/sjOzsburq66uWTJ09GfHw8unbtiokTJyI1NbXEc3ux3bS0NBgbG5d4PaLiLAq7jp9Cr6GemR7CPu0MhY5M7EhERNVOST+/RT0SlZOTg4iICPj4+KiXSaVS+Pj4IDw8vMh1wsPDNcYDgK+vb7Hjc3JysGLFCpiYmMDV1bXIMSkpKVi/fj28vLw0CqhDhw5hy5YtWLp0aYnmk52djfT0dI0HUXl6r2NDWBkrcP/Jc/x28o7YcYiIajRRi6jk5GTk5+fDyspKY7mVlRUSEhKKXCchIaFE44ODg2FoaAilUon58+cjNDQUFhYWGmMmT54MAwMDmJub4+7du9i1a5f6ucePH2P48OFYu3ZtiY8izZ07FyYmJuqHra1tidYjKil9uQ4+VTfgvM4GnEREIhL9mqiK4u3tjaioKJw8eRJ+fn4YOHBgoeusJk2ahPPnz+PAgQOQyWQYNmyY+oLd999/H++88w46depU4m1OnToVaWlp6se9e/fKdU5EANCvVT04WRshPSsPiw/dEDsOEVGNJWoRZWFhAZlMhsTERI3liYmJsLa2LnIda2vrEo03MDCAvb092rVrh1WrVkFHRwerVq0qtH0HBwd069YNGzduREhICE6dOgWg4FTejz/+CB0dHejo6GDUqFFIS0uDjo4OVq9eXWQ2hUIBY2NjjQdReZNJJfi81z8NOE/dxm024CQiEoWoRZRcLkfr1q0RFhamXqZSqRAWFgZPT88i1/H09NQYDwChoaHFjv/362ZnZ7/0eQDqMeHh4YiKilI/vvrqKxgZGSEqKgp9+vQp0fyIKkrHJpbo7GCJ3HwB3+9nA04iIjHoiB0gKCgIgYGBaNOmDdzd3bFgwQJkZmZixIgRAIBhw4ahbt26mDt3LgBgwoQJ6Ny5M+bNm4devXph48aNOHfuHFasWAEAyMzMxOzZs9G7d2/Y2NggOTkZS5cuxYMHDzBgwAAAwOnTp3H27Fl06NABZmZmiIuLwxdffIHGjRuri7GmTZtq5Dx37hykUimaN29eWW8N0UtN69kUx64/Qkh0AiLupKB1g1piRyIiqlFEvyYqICAAP/74I2bMmAE3NzdERUVh37596ovH7969i4cP/78njpeXFzZs2IAVK1bA1dUVW7duxc6dO9XFjUwmQ2xsLPr16wcHBwe89dZbePz4MY4dOwZnZ2cAgL6+PrZv346uXbvC0dERo0aNQosWLXD06FEoFIrKfxOIysDR2ggD27ABJxGRWETvE1WdsU8UVbSk9Cx0/uEInufmY+k7rdCrhY3YkYiItJ5W9IkiotdT21iJDzs3AgB8ty8W2Xn5IiciIqo5WEQRabkPOjVCbSMF7qY8w+/hbMBJRFRZWEQRabmCBpwOAIDFh24g9RkbcBIRVYZSF1H79u3D8ePH1f9eunQp3Nzc8M477+DJkyflGo6ISqZ/a1s4Whkh7XkulrABJxFRpSh1ETVp0iT1PeGio6Px6aefomfPnrh16xaCgoLKPSARvZpMKsG0fxpwrgu/jbuPn4mciIio+it1EXXr1i00a9YMALBt2za8+eabmDNnDpYuXYq9e/eWe0AiKpnODpbo2MQCufkCvmMDTiKiClfqIkoul+PZs4K/cg8ePIju3bsDAGrVqqU+QkVE4vi8V1NIJcCeiw8RcYen14mIKlKpi6gOHTogKCgIX3/9Nc6cOYNevXoBAK5du4Z69eqVe0AiKjkna2MMaF3QgHP2nitswElEVIFKXUQtWbIEOjo62Lp1K3755RfUrVsXALB37174+fmVe0AiKp2g7g7Q05Uh8m4q9l5KEDsOEVG1xY7lFYgdy0ks80OvYWHYddSvpY+DQZ0h12E3EyKikqqwjuWRkZGIjo5W/3vXrl3w9/fHtGnTkJPD/jREVcEHnRrB8kUDzlNswElEVBFKXUR9+OGHuHbtGgDg5s2bGDRoEPT19bFlyxb873//K/eARFR6BgodfNqtoAHnorDrSHuWK3IiIqLqp9RF1LVr1+Dm5gYA2LJlCzp16oQNGzZg7dq12LZtW3nnI6IyGtDmXw04D18XOw4RUbVT6iJKEASoVCoABS0OevbsCQCwtbVFcnJy+aYjojKTSSWY2tMJALDu5B024CQiKmelLqLatGmDb775Br///juOHj2qbnFw69YtWFlZlXtAIiq7Fw04c/JV+J4NOImIylWpi6gFCxYgMjISY8eOxeeffw57e3sAwNatW+Hl5VXuAYmo7CQSCab2aAqJBAi++BCRd9mAk4iovJRbi4OsrCzIZDLo6uqWx8tVC2xxQFXFpC0XsCXiPto0MMOWjzwhkUjEjkREVGWV9PNbp6wbiIiIQExMDACgWbNmaNWqVVlfiogq2KfdHfHXxXicu/ME+y8nwK+5jdiRiIi0XqmLqKSkJAQEBODo0aMwNTUFAKSmpsLb2xsbN26EpaVleWckotdkbaLEBx0bYdGhG/h2byzecLJiA04iotdU6v+Kjhs3Dk+fPsXly5eRkpKClJQUXLp0Cenp6Rg/fnxFZCSicvBB58awMFTg9uNnWH+aDTiJiF5XqYuoffv24eeff0bTpk3Vy5o1a4alS5di79695RqOiMqPoUIHQf804FwYdh1pz9mAk4jodZS6iFKpVEVePK6rq6vuH0VEVdPANvXQpLYhUp/l4ufDN8SOQ0Sk1UpdRL3xxhuYMGEC4uPj1csePHiATz75BF27di3XcERUvnRkUkzrWXAUec2J27iXwgacRERlVeoiasmSJUhPT4ednR0aN26Mxo0bo2HDhkhPT8eiRYsqIiMRlaMujpboYF/QgPOH/VfFjkNEpLXK1CdKEAQcPHgQsbEFHZCbNm0KHx+fcg+n7dgniqqqy/FpeHPxcQgCsHNMe7jZmoodiYioyijp53e5NduMjY1F7969ce3atfJ4uWqBRRRVZZ9tuYCtEffR1s4Mmz9kA04iohdK+vldbo1isrOzERcXV14vR0QV7NPuDlDqSnH29hPsv5wodhwiIq3DbntENZSNiR7e79gIAPDt3hjk5PHbtUREpcEiiqgG+7BzY1gYynH78TNsYANOIqJSYRFFVIMZKnTwCRtwEhGVSYnvnWdmZvbSC0/z8vLKJRARVa6ANrZYc+I2biQ9xc9HbmBqj6avXomIiEpeRC1YsKACYxCRWAoacDph5NpzWHPiNt71aADbWvpixyIiqvJKXEQFBgZWZA4iEpG3Y214NTbHybjH+PHAVSwc1FLsSEREVR6viSIiSCQSTOvZFBIJsCsqHhfupYodiYioymMRRUQAgOZ1TdCnZV0AwOyQGJRTH14iomqLRRQRqX3W3REKHSnO3EpB6BU24CQiehkWUUSkVsdUD+91bAgA+HZvLHLz2YCTiKg4LKKISMNHnRvD3ECOm8mZ+PPMXbHjEBFVWSX+dt4L+fn5WLt2LcLCwpCUlASVSvMv1UOHDpVbOCKqfEZKXUzs5oAvdl7CgoPX4d+yLoyVumLHIiKqckpdRE2YMAFr165Fr1690Lx5c975nagaGtzWFmtP3ELco0z8ciQOk/2cxI5ERFTlSIRSfgXHwsICv/32G3r27FlRmaqN9PR0mJiYIC0tDcbGxmLHISqVsJhEjFp3DnIdKQ5/1gV1TfXEjkRUbpLSs3At8Sna25vzYAAVUtLP71JfEyWXy2Fvb/9a4Yio6nvDqTY8G5kjJ0+FH/dfFTsOUbm5+/gZei46hndXncYfp3ndH5VdqYuoTz/9FAsXLmQPGaJqTiKR4PNeBffR23H+AS7eTxU3EFE5ePw0G8NWn0by0xwAwPd7Y5GYniVyKtJWpb4m6vjx4zh8+DD27t0LZ2dn6OpqXnC6ffv2cgtHROJqXtcEfVvWxfbzDzB7Tww2ftCOpz5Iaz3LycPItWdx+/Ez1DXVg5mBLi49SMeXf13Gz0Naix2PtFCpj0SZmpqiT58+6Ny5MywsLGBiYqLxKIulS5fCzs4OSqUSHh4eOHPmzEvHb9myBU5OTlAqlXBxcUFISIjG87NmzYKTkxMMDAxgZmYGHx8fnD59WmNM7969Ub9+fSiVStjY2GDo0KGIj49XP3/16lV4e3vDysoKSqUSjRo1wvTp05Gbm1umORJpq099Cxpwnr6VgoMxSWLHISqTvHwVxqyPxIX7aTDV18Vvo9zxfT9XyKQShEQnICyGzWWp9Ep9YXl527RpE4YNG4Zly5bBw8MDCxYswJYtW3D16lXUrl270PiTJ0+iU6dOmDt3Lt58801s2LAB3333HSIjI9G8eXMAwIYNG1C7dm00atQIz58/x/z587FlyxbcuHEDlpaWAID58+fD09MTNjY2ePDgAT777DP16wPAzZs3cfToUbRq1Qqmpqa4cOEC3n//fYwaNQpz5swp0dx4YTlVF9/vi8XPR+LQyNIA+yd2gq6MLeZIewiCgMnbLmLzuftQ6kqx/r12aN3ADAAwNyQGy/++ibqmejjwSScYKEp9goaqoZJ+fpe5iHr06BGuXi242NTR0VFdnJSWh4cH2rZtiyVLlgAAVCoVbG1tMW7cOEyZMqXQ+ICAAGRmZiI4OFi9rF27dnBzc8OyZcuK3MaLN+PgwYPo2rVrkWN2794Nf39/ZGdnFzpF+UJQUBDOnj2LY8eOlWhuLKKousjIykWXH47gcWYOvn7bGUM97cSORFRiPx24ikWHbkAqAZYPbYNuzazUzz3LyUP3+X/j/pPnGNWhIb54s5mISamqqLBv52VmZmLkyJGwsbFBp06d0KlTJ9SpUwejRo3Cs2fPSvVaOTk5iIiIgI+Pz/8Hkkrh4+OD8PDwItcJDw/XGA8Avr6+xY7PycnBihUrYGJiAldX1yLHpKSkYP369fDy8iq2gLpx4wb27duHzp07Fzuf7OxspKenazyIqgMjpS4m+jQBAMw/eB3pWTytTdph/ek7WHToBgBgdh8XjQIKAPTlOvjGv+AsxpoTtxB9P63SM5L2KnURFRQUhKNHj+Kvv/5CamoqUlNTsWvXLhw9ehSffvppqV4rOTkZ+fn5sLLS/KG2srJCQkJCkeskJCSUaHxwcDAMDQ2hVCoxf/58hIaGwsLCQmPM5MmTYWBgAHNzc9y9exe7du0qtD0vLy8olUo0adIEHTt2xFdffVXsfObOnatxfZitre1L50+kTQa510cjSwOkZOZg2ZE4seMQvdKBywn4YuclAMCErk0w2L1+keO6ONbGW651oBKAqTsuIo/3jKQSKnURtW3bNqxatQo9evSAsbExjI2N0bNnT6xcuRJbt26tiIxl4u3tjaioKJw8eRJ+fn4YOHAgkpI0L4qdNGkSzp8/jwMHDkAmk2HYsGGFWjds2rQJkZGR2LBhA/bs2YMff/yx2G1OnToVaWlp6se9e/cqZG5EYtCVSTG1R0HLg1XHb+FB6nORExEVL+JOCsb9eR4qARjU1lZ9JLU4M95sBmOlDi49SMfak7crJyRpvVIXUc+ePSt0JAgAateuXerTeRYWFpDJZEhM1PxWRGJiIqytrYtcx9raukTjDQwMYG9vj3bt2mHVqlXQ0dHBqlWrCm3fwcEB3bp1w8aNGxESEoJTp05pjLG1tUWzZs0wePBgfPvtt5g1axby8/OLzKZQKNSF5YsHUXXi07Q2PBrWQnaeCvPYgJOqqBtJTzFq3Tlk56nQ1ak2vvF/9S3KLI0UmNqz4I+En0Kv8Y8EKpFSF1Genp6YOXMmsrL+vznZ8+fP8eWXX8LT07NUryWXy9G6dWuEhYWpl6lUKoSFhRX7Wp6enhrjASA0NPSV21apVMjOzn7p8wBeOSY3N7fQTZeJaop/N+Dcfv4BLj3g9SNUtSSmZyFw9RmkPsuFm60pFr/TEjol/DZpQBtbtLUzw7OcfMzYeYlNpemVSv1dzoULF8LX1xf16tVTX6h94cIFKJVK7N+/v9QBgoKCEBgYiDZt2sDd3R0LFixAZmYmRowYAQAYNmwY6tati7lz5wIouAFy586dMW/ePPTq1QsbN27EuXPnsGLFCgAFF77Pnj0bvXv3ho2NDZKTk7F06VI8ePAAAwYMAACcPn0aZ8+eRYcOHWBmZoa4uDh88cUXaNy4sboYW79+PXR1deHi4gKFQoFz585h6tSpCAgIKPbic6KaoEU9U/i71cHOqHh8s+cK/nyfDTipakjPysXwNWfxIPU5GloYYFVgG+jLS/4xJ5VKMLevC3osPIaw2CTsvZSAni42FZiYtF2pi6jmzZvj+vXrWL9+PWJjYwEAgwcPxpAhQ6CnV/oblAYEBODRo0eYMWMGEhIS4Obmhn379qlPGd69exdS6f//FeHl5YUNGzZg+vTpmDZtGpo0aYKdO3eqe0TJZDLExsZi3bp1SE5Ohrm5Odq2bYtjx47B2dkZAKCvr4/t27dj5syZyMzMhI2NDfz8/DB9+nQoFIqCN0ZHB9999x2uXbsGQRDQoEEDjB07Fp988kmp50hU3Xzm64iQSwk4dTMFh2KT0LVp4VP8RJUpOy8fH/0egZiH6bAwVOC3ke4wN1SU+nXsaxvh486NsejQDczafRkdmljAWMk/nKloojfbrM7YJ4qqs2/3xmLZ0Tg0/qcBZ0lPmRCVN5VKwIRNUfjrQjwM5DJs+tATzeuW7Q4aAJCVm4+eC4/hZnIm3m1XH9/4u5RjWtIGJf38LtGRqN27d6NHjx7Q1dXF7t27Xzq2d+/epUtKRFpptHdjbD53D3GPMrHx7D28266B2JGohpq7NwZ/XYiHjlSCZUNbv1YBBQBKXRm+6dMc76w8jfWn76JPy3rqDudE/1aiI1FSqRQJCQmoXbu2xqm1Qi8mkRT7zbWaiEeiqLr7Lfw2Zuy6DAtDOQ5/1gVGPO1BlezXYzfxzZ4YAMD8AFf0aVmv3F77080XsC3yPhytjBA8vgNvd1SDlGvHcpVKpb6PnUqlKvbBAoqoZhnsXh+NLAyQ/DQHy4/eFDsO1TC7L8SrC6gpPZzKtYACgM97NYWZvi6uJmZg5TH+fFNhpS6rf/vttyLbAOTk5OC3334rl1BEpB10ZVJM6eEEAFh57CYeprG3DlWOkzeS8enmKADAcC87fNipUblvo5aBHNN7FdxLb+HB67jzOLPct0HardRF1IgRI5CWVrg3TEZGhrotARHVHN2aWcH9nwacP7ABJ1WCK/Hp+PD3COTmC+jpYo0v3mxWYW02+raqi/b25sjOU2E6e0fRf5S6iBIEocgf1vv378PE5PUu5iMi7SORSPD5P52ed7ABJ1Ww+0+eYfiaM8jIzoNHw1r4aaAbZNKK61MmkUjwjb8L5DpSHLuejF1R8RW2LdI+Je4T1bJlS0gkEkgkEnTt2hU6Ov+/an5+Pm7dugU/P78KCUlEVZurrSnedquDXVHxmL0nBhve92ADTip3TzJzELj6DJIysuFoZYQVw9pAqSur8O02tDDA+Dfs8eOBa/g6+Aq6OFrCVF9e4dulqq/ERZS/vz8AICoqCr6+vjA0NFQ/J5fLYWdnh379+pV7QCLSDp91d8TeSwkIv/kYh68m4Q0nNuCk8pOVm4/3fjuHuEeZsDFRYu3ItjDRq7xvg37QqTF2X4jHtcSnmBMSg+/7u1batqnqKnWzzXXr1iEgIABKpbKiMlUbbHFANc3cvTFYfvQm7GsbYt+EjmzASeUiXyXg4z8icOBKIoyVOtj6sRccrIwqPce52ynovywcALDxg3Zo18i80jNQ5SjXFgf/FhgYyAKKiIo0uos9zPR1cSPpKTaduyd2HKoGBEHAjF2XcOBKIuQ6Uvwa2FaUAgoA2tjVwjse9QEA03ZEIzuPbX1qulIXUfn5+fjxxx/h7u4Oa2tr1KpVS+NBRDWXiZ4uJnRtAgCYH3oNT7PzRE5E2m7JoRtYf/ouJBJg0SA3uDcU93Nmsp8TLI0UuPkoEz8fjhM1C4mv1EXUl19+iZ9++gkBAQFIS0tDUFAQ+vbtC6lUilmzZlVARCLSJu94NEBDdQNOfshQ2W0+dw/zQq8BAGa95Qy/5jYiJyr4Q2HmWwW9o345EocbSU9FTkRiKnURtX79eqxcuRKffvopdHR0MHjwYPz666+YMWMGTp06VREZiUiLyHWkmOzHBpz0eg7HJmHq9mgAwMddGiPQy07cQP/Sy8UG3o6WyMlXYdqOaKhU7B1VU5W6iEpISICLS8EdrQ0NDdWNN998803s2bOnfNMRkVbydbZCWzszZOWqMO/ANbHjkJaJupeK0esjka8S0LdVXfzP11HsSBokEgm+ers59HRlOHMrBVsieP1fTVXqIqpevXp4+PAhAKBx48Y4cOAAAODs2bNQKBTlm46ItJJEIsG0fxpwbou8j8vxbMBJJXMrORMj157F89x8dHKwxHf9WlTJnmO2tfQR1M0BADAnJBbJTwvfDo2qv1IXUX369EFYWBgAYNy4cfjiiy/QpEkTDBs2DCNHjiz3gESknVrWN8NbrnUgCMCckBjeLoNe6VFGNgJXn0FKZg5c6prg5yGtoFuF22SMaG8H5zrGSHuei6+Dr4gdh0RQ6j5R/xUeHo7w8HA0adIEb731VnnlqhbYJ4pqunspz9B13lHk5KuwZkRbeDvWFjsSVVGZ2XkYtOIUoh+koX4tfWz72AuWRlX/7MbF+6nwX3oCKgFYN9IdnR0sxY5E5aDC+kT9l6enJ4KCglhAEVEhtrX0MaK9HQBgzp4Y5OWrxA1EVVJuvgofr49E9IM01DKQY91Id60ooACgRT1T9UXv03dG43kOe0fVJCW67cvu3btL/IK9e/cucxgiqn5Ge9tj07l7uJ70FFsi7mOwe32xI1EVIggCJm+7iL+vPYKergyrh7dFQwsDsWOVyqfdHbHvUgLupTzHwrDrmNLDSexIVElKdDpPKtU8YCWRSApd3/Diwr/8fFbhL/B0HlGBNSdu4cu/rsDCUIGjk7rAQFHi23ZSNff9vlj8fCQOMqkEvw5rA28n7TzlG3olEe//dg4yqQTB4zqgqQ3/m6/NyvV0nkqlUj8OHDgANzc37N27F6mpqUhNTcXevXvRqlUr7Nu3r9wmQETVxxCPBrAz10fy02ws//um2HGoilh38jZ+PlLQkHVuXxetLaAAoFszK/g6WyFfJWDqdvaOqilKfU3UxIkTsXDhQvj6+sLY2BjGxsbw9fXFTz/9hPHjx1dERiLScnIdqfoUx4q/45CQliVyIhLb3uiHmPXXZQDAp90cMLCNrciJXt+XvZvDUKGDqHupWH/6jthxqBKUuoiKi4uDqalpoeUmJia4fft2OUQiourI19kabRq8aMB5Vew4JKIzt1IwYVMUBAEY4lEfY9+wFztSubA2UWLSP41Bv993FYnp/GOhuit1EdW2bVsEBQUhMTFRvSwxMRGTJk2Cu7t7uYYjoupDIpHg814FDTi3Rt7Hlfh0kRORGK4lZuC9dWeRk6dCt2ZW+Ort5lWymWZZvduuAdxsTZGRnYdZuy+LHYcqWKmLqNWrV+Phw4eoX78+7O3tYW9vj/r16+PBgwdYtWpVRWQkomqiZX0zvNnChg04a6iHac8RuPoM0rPy0LqBGRYPbgmZtPoUUAAgk0owt68LZFIJ9l5KwMEria9eibRWqb8iY29vj4sXLyI0NBSxsbEAgKZNm8LHx6da/TVBRBVjsp8TDlxOxPEbyTh67RG6sAFnjZD2PBfDV5/Fw7QsNLY0wK/D2kCpKxM7VoVoamOM9zo2xPKjNzFj1yV4NjbnN1KrqdfuWE7FY4sDoqLN3nMFK4/dgoOVIULGd4ROFb61B72+rNx8BK4+g9O3UlDbSIHto71Qz0xf7FgV6nlOProvOIp7Kc8xsn1DzHirmdiRqBRK+vldotJ40aJF+OCDD6BUKrFo0aKXjuU39IjoVcZ6N8Hmc/dxLfEptkbcxyA24Ky2VCoBn26+gNO3UmCk0MHaEe7VvoACAD25DN/4uyBw9RmsPXkLfVrWhUs9E7FjUTkr0ZGohg0b4ty5czA3N0fDhg2LfzGJBDdvsgfMCzwSRVS8Vcdv4evgK7A0UuDIZ2zAWR0JgoAv/7qCtSdvQ1cmwboR7vCytxA7VqUa/+d57L4QD+c6xtg1pj2PumqJcj0SdevWrSL/PxFRWQ1t1wC/hd/GncfPsOLvm/ikm4PYkaicLf/7JtaevA0AmDfQrcYVUADwxZvNcORqEi7Hp2Ptydt4r2MjsSNROWJJTESikOtIMdnvRQPOm+ypU83sOH8f3+4t+PLR9F5N0du1jsiJxGFppMC0ngWtPeYduIb7T56JnIjKU4mORAUFBZX4BX/66acyhyGimqVHc2u0qm+KyLup+OnANXzXv4XYkagcHLv+CJO2XAQAvNehYY0/+jKwjS22Rz7AmdspmLHrMlYFtuG32auJEhVR58+fL9GL8YeCiEqjoAFnM/T75SQ2R9zD8PZ2vHGrlrv0IA0f/R6BPJWA3q511EdhajKpVII5fZujx8JjOBSbhJDoBPRqYSN2LCoHbHFQgXhhOVHJjNkQiT0XH6KTgyV+G8k7H2ireynP0Ofnk0h+mg2vxuZYM6ItFDrVsxdUWfwUeg2Lwq7D0kiBg0GdYaKnK3YkKkZJP795TRQRiW6yrxN0ZRL8fe0Rjl57JHYcKoOUzBwMW30GyU+z4WRthGVDW7OA+o/RXRqjkYUBHmVk4/t9sWLHoXJQpu8Unzt3Dps3b8bdu3eRk5Oj8dz27dvLJRgR1Rz1zfUR6GmHX4/fwtyQGHSwt6h2twOpzp7l5GHk2rO4lZyJuqZ6WDfSHcZKHmX5L6WuDLP7uGDwylNYf/ou+raqi9YNaokdi15DqY9Ebdy4EV5eXoiJicGOHTuQm5uLy5cv49ChQzAxYSMxIiqbsW/Yw0RPF7EJGdgWcV/sOFRCefkqjNtwHlH3UmGqr4t1I91hZawUO1aV5dnYHANa1wMATN0ejZw8lciJ6HWUuoiaM2cO5s+fj7/++gtyuRwLFy5EbGwsBg4ciPr12XWYiMrGVF+OcW/YAwB+PHAVz3LyRE5EryIIAqbvvISw2CQodKRYFdgG9rUNxY5V5U3r2RS1DOS4lvgUK4+xQbU2K3URFRcXh169egEA5HI5MjMzIZFI8Mknn2DFihXlHpCIao6hng1Qv5Y+kjKysfJvNvat6hYcvI6NZ+9BKgEWD27JU1MlZGYgxxdvFnxrcVHYddxOzhQ5EZVVqYsoMzMzZGRkAADq1q2LS5cuAQBSU1Px7BmbiBFR2Sl0ZOoGnMv/jkMSG3BWWRtO38XCsOsAgK/9m6O7s7XIibSLv1tdtLc3R3aeCtN3XgK/KK+dSl1EderUCaGhoQCAAQMGYMKECXj//fcxePBgdO3atdwDElHN0tPFGi3rm+JZTj5+Cr0mdhwqQuiVREzfGQ0AGP+GPYZ4NBA5kfaRSCSY7e8ChY4Ux28kY2fUA7EjURmUuIh6ccRpyZIlGDRoEADg888/R1BQEBITE9GvXz+sWrWqYlISUY0hkUgwvVfBqY7N5+4hNiFd5ET0bxF3nmDcn5FQCcDANvV4z8PXYGdhgPFdmwAAvg6OwZPMnFesQVVNiYuoFi1awMPDA9u2bYORkVHBylIppkyZgt27d2PevHkwMzOrsKBEVHO0blALPV2soRKAuSHsp1NVxD16ivfWnUVWrgrejpaY3ceFd6p4Te93bAQHK0OkZOZgTkiM2HGolEpcRB09ehTOzs749NNPYWNjg8DAQBw7dqxcQixduhR2dnZQKpXw8PDAmTNnXjp+y5YtcHJyglKphIuLC0JCQjSenzVrFpycnGBgYAAzMzP4+Pjg9OnTGmN69+6N+vXrQ6lUwsbGBkOHDkV8fLz6+SNHjuDtt9+GjY0NDAwM4ObmhvXr15fLfIno1f73TwPOo9ce4W824BRdUnoWhq06gyfPcuFqa4qlQ1pBV8Z+za9LriPF3L4uAIAtEfcRHvdY5ERUGiX+DejYsSNWr16Nhw8fYvHixbh9+zY6d+4MBwcHfPfdd0hISChTgE2bNiEoKAgzZ85EZGQkXF1d4evri6SkpCLHnzx5EoMHD8aoUaNw/vx5+Pv7w9/fX326EQAcHBywZMkSREdH4/jx47Czs0P37t3x6NH//4fY29sbmzdvxtWrV7Ft2zbExcWhf//+Gttp0aIFtm3bhosXL2LEiBEYNmwYgoODyzRPIiodOwsDDG1nBwCYExKDfBUvvBVLRlYuhq85iwepz2Fnro/VgW2gLy9Tr2YqQusGtTDEo6BF0Oc7opGVmy9yIiqp17p33o0bN7BmzRr8/vvvSEhIgJ+fH3bv3l2q1/Dw8EDbtm2xZMkSAIBKpYKtrS3GjRuHKVOmFBofEBCAzMxMjWKmXbt2cHNzw7Jly4rcxot74Bw8eLDYi993794Nf39/ZGdnQ1e36E67vXr1gpWVFVavXl2iufHeeUSv50lmDjr/cBjpWXn4vn8LDGxjK3akGicnT4URa8/gxI3HsDCUY/vH7VHfXF/sWNVO2vNc+Px0FI8ysjG+axME8VozUVXKvfPs7e0xbdo0TJ8+HUZGRtizZ0+p1s/JyUFERAR8fHz+P5BUCh8fH4SHhxe5Tnh4uMZ4APD19S12fE5ODlasWAETExO4uroWOSYlJQXr16+Hl5dXsQUUAKSlpaFWreL7oGRnZyM9PV3jQURlZ2Ygx7g3Ci68nccGnJVOpRIwaesFnLjxGAZyGdYMd2cBVUFM9HQx6y1nAMAvR27gRlKGyImoJMpcRP39998YPnw4rK2tMWnSJPTt2xcnTpwo1WskJycjPz8fVlZWGsutrKyKPT2YkJBQovHBwcEwNDSEUqnE/PnzERoaCgsLC40xkydPhoGBAczNzXH37l3s2rWr2KybN2/G2bNnMWLEiGLHzJ07FyYmJuqHrS3/aiZ6XcO8GqCemR4S07Px6zE24KxM3+6Lxa6oeOhIJfjl3dZwqcdbe1Wkni7WeMOpNnLzBUzbfgkqnsKu8kpVRMXHx2POnDlwcHBAly5dcOPGDSxatAjx8fFYuXIl2rVrV1E5S83b2xtRUVE4efIk/Pz8MHDgwELXWU2aNAnnz5/HgQMHIJPJMGzYsCIbnh0+fBgjRozAypUr4ezsXOw2p06dirS0NPXj3r175T4voprm3w04lx2NQ1IGG3BWhlXHb2HF3wW3JPmuXwt0crAUOVH1J5FI8NXbztDTleHM7RRsPsfPkKquxEVUjx490KBBAyxevBh9+vRBTEwMjh8/jhEjRsDAwKBMG7ewsIBMJkNiYqLG8sTERFhbF9391traukTjDQwMYG9vj3bt2mHVqlXQ0dEp1MfKwsICDg4O6NatGzZu3IiQkBCcOnVKY8zRo0fx1ltvYf78+Rg2bNhL56NQKGBsbKzxIKLX92YLG7jZFjTgnB96Xew41V7wxXh8s+cKAOB/fo7o988Nc6ni1TPTx6fdC66HmhMSg0cZ2SInopcpcRGlq6uLrVu34v79+/juu+/g6Oj42huXy+Vo3bo1wsLC1MtUKhXCwsLg6elZ5Dqenp4a4wEgNDS02PH/ft3s7OJ/GFWqgjtp/3vMkSNH0KtXL3z33Xf44IMPXjkfIqoY/27AuensXVxL5PUiFeVkXDKCNl2AIACBng3wcefGYkeqcYZ72aF5XWOkZ+Xh6+ArYsehlyhxEbV79268/fbbkMlk5RogKCgIK1euxLp16xATE4OPP/4YmZmZ6muPhg0bhqlTp6rHT5gwAfv27cO8efMQGxuLWbNm4dy5cxg7diwAIDMzE9OmTcOpU6dw584dREREYOTIkXjw4AEGDBgAADh9+jSWLFmCqKgo3LlzB4cOHcLgwYPRuHFjdTF2+PBh9OrVC+PHj0e/fv2QkJCAhIQEpKSklOv8iahk2tjVQo/mLxpwsilhRYh5mI4Pf4tATr4KPZpbY8ZbzmymKQIdmRRz+7SAVALsvhCPI1eLbvlD4hO9U1pAQAB+/PFHzJgxA25uboiKisK+ffvUF4/fvXsXDx8+VI/38vLChg0bsGLFCri6umLr1q3YuXMnmjdvDgCQyWSIjY1Fv3794ODggLfeeguPHz/GsWPH1Ncz6evrY/v27ejatSscHR0xatQotGjRAkePHoVCoQAArFu3Ds+ePcPcuXNhY2OjfvTt27eS3yEiemGynxN0pBIcvvoIx68nix2nWnmQ+hzD15xBRnYe3O1qYX6AG2RSFlBicalnguFeDQEAX+y6hOc57B1VFb1Wnyh6OfaJIip/X/51GWtO3EZTG2MEj+vAD/pykPosB/2XheNG0lM4WBliy4deMNEvvt0LVY7M7Dx0++ko4tOy8GHnRpjao6nYkWqMSukTRURU2ca/0QRGSh3EPEzHjvMPxI6j9bJy8/HeunO4kfQU1sZKrB3hzgKqijBQ6OCrtwvOsvx67BauxLP3YFXDIoqItEpBA057AMCP+6/yNMdryFcJmLDxPM7deQIjpQ7WjXRHHVM9sWPRv/g0s0KP5tbIVwmYtiOatz+qYlhEEZHWGeZph3pmekhIz8Kq4zfFjqOVBEHArN2Xsf9yIuQyKVYOawNHayOxY1ERZvV2hpFCB1H3UrH+9B2x49C/sIgiIq2j1JXhf/804PzlCBtwlsXPR+Lw+6k7kEiABYPc0K6RudiRqBhWxkr8z6+grdD3+64iIY0/71UFiygi0kpvtbCBq60pMnPyseAgG3CWxpZz9/DD/qsAgJlvNkNPFxuRE9GrvOPRAG62pnianYdZuy+LHYf+wSKKiLSSRCLB5z0Lvq208cxdXGcDzhI5fDUJU7ZHAwA+7NwIw9s3FDkRlYRMKsHcvi7QkUqw73ICQq8kvnolqnAsoohIa7k3rAVfZ6uCBpx7Y8WOU+VduJeKMesjka8S0KdlXUz2dRI7EpVCUxtjvNexEQBgxq5LeJqdJ3IiYhFFRFrtRQPOQ7FJOHGDDTiLczs5EyPXnsWznHx0bGKB7/q1gJQ9trTOhK5NYFtLDw/TsjDvwFWx49R4LKKISKs1sjTEu+0aAABm74mBil8BLyT5aTYC15zB48wcONcxxi/vtoZch//510Z6chlm+7sAANadvI2L91PFDVTD8beIiLTe+K5NYKTQwRU24CwkMzsPI9eexZ3Hz2BbSw9rRrSFoUJH7Fj0Gjo5WOJttzpQCcCUbdHIy1eJHanGYhFFRFqvloEcY1404DzABpwv5OarMHp9JC7eT0MtAznWjXBHbSOl2LGoHHzxZjOY6OniysN0rDlxW+w4NRaLKCKqFoZ72aGuacG1IqtP3BI7jugEQcCUbdE4eu0RlLpSrApsg0aWhmLHonJiYajAtJ4FXwz4KfQa7qU8EzlRzcQiioiqhYIGnAUNCX8+fAOPMrJFTiSueQeuYVvkfcikEix9pxVa1jcTOxKVs4FtbOHesBae5+Zjxq5LEAReD1jZWEQRUbXxVos6cK1ngsycfCwMuyZ2HNH8fuoOlhy+AQCY7d8cXZtaiZyIKoJEIsGcPi6Qy6Q4fPUR9kQ/FDtSjcMiioiqDalUgmn/NOD888w93EiqeQ04911KwIxdlwAAn/g4YJB7fZETUUWyr22Ij7s0BgB8+dcVpD3PFTlRzcIiioiqFY9G5ujezAr5KgHf1rAGnGdvp2D8xvMQBGCwe32M72ovdiSqBKO9G6ORpQEeZWTju30162debCyiiKjamdKjoAHnwZgknIyrGQ04rydm4L1155CTp4JPUyt8/bYzJBI206wJFDoyzOlT0Dtqw+m7OHc7ReRENQeLKCKqdhpZGmKIR8FprDkh1b8BZ0JaFgJXn0Ha81y0qm+KxYNbQkfG/7zXJO0amWNgm3oAgKnbo5GTx95RlYG/ZURULb1owHnpQTp2Xai+DTjTnudi+JoziE/LQiNLA6wKbAs9uUzsWCSCaT2bwtxAjutJT7Hi7zix49QILKKIqFoyN1RgtHfBNUE/7LuKrNzq14AzOy8fH/5+DrEJGbA0UmDdCHeYGcjFjkUiMdWX44s3mwEAFh26gdvJmSInqv5YRBFRtTWifUEDzvhq2IBTpRIQtPkCTt1MgaFCB2tHtIVtLX2xY5HI3narg45NLJCTp8LnO6PZO6qCsYgiompLqSvDJN8XDTjjkPy0ejTgFAQB3+yJwZ6LD6Erk2D50NZwrmMidiyqAiQSCb7xbw6FjhQnbjzmvSQrGIsoIqrWervWgUtdEzzNzsPCg9fFjlMuVh67qT6y9uMAV7S3txA5EVUlDcwNML5rEwDAN3tikJKZI3Ki6otFFBFVa/9uwLnhzF3cSHoqcqLXsyvqAeaEFPQCmtbTCW+71RU5EVVFH3RqBEcrI6Rk5mBOSIzYcaotFlFEVO15NjaHT1Ptb8B54kYyPttyAQAwsn1DvN+xkciJqKrSlUkxp68LJBJga8T9GtMvrbKxiCKiGmFKDyfIpBIcjElEeNxjseOU2uX4NHz4ewRy8wW82cIG03s1ZTNNeqnWDczU/dI+33GpWn5DVWwsooioRrCvbYh33LWzAee9lGcYvuYsnmbnoV2jWpg30BVSKQsoerX/+TmhtpECt5Iz8fM/N6Wm8sMiiohqjAk+TWCo0EH0gzTsvhAvdpwSScnMQeDqM3iUkQ0nayOsGNYGCh0206SSMVbqYlZvZwDAL0fjcD2x5t2UuyKxiCKiGsPCUIHR3gV3vP9hf9VvwPk8Jx+j1p3FzeRM1DXVw9oR7jBW6oodi7RMj+bW6OpUG7n5AqbtiNaqo7BVHYsoIqpRRrZviDomSjxIfY41J26LHadYefkqjPszEufvpsJETxfrRraFtYlS7FikhSQSCb7ybw59uQxnbz/BpnP3xI5UbbCIIqIaRakrwyS/Fw04b+BxFWzAKQgCvth1CQdjkqDQkWJVYBvY1zYSOxZpsbqmegjq5gAAmBsSg6SMLJETVQ8sooioxnnbtS6a1zVGRnYeFoVVvQaci8Ju4M8z9yCVAAsHtUQbu1piR6JqYLiXHZrXNUZ6Vh6+DmbvqPLAIoqIapx/N+Bcf/ou4h5VnQacG8/cxfyD1wAAX77dHH7NrUVORNWFjkyKb/u2gFQC/HUhHkeuJokdSeuxiCKiGsmrsQV8mtZGnkrAd1WkAWdYTCI+33kJADDW2x5D2zUQORFVN83rmmBE+4YAgOk7L+FZTp7IibQbiygiqrFeNOA8cCURp2+K24Dz/N0nGLMhEvkqAf1b18On3R1EzUPVV1A3B9Q11cP9J8+rzf0kxcIiiohqLPvaRhjsbgtA3AacNx89xci1Z5GVq0IXR0vM7evCbuRUYQwUOvjq7YLeUb8ev4XL8WkiJ9JeLKKIqEab6OMAQ4UOLtxPw18XK78BZ1JGFoatPoMnz3LRop4Jlr7TCroy/qeZKlbXplbo6WKNfJWAadujkc/eUWXC31QiqtEsDBX4uEtBA87v91VuA86MrFyMWHMW9588RwNzfawe3hYGCp1K2z7VbDPfcobRP39A/HHqjthxtBKLKCKq8Ua2bwibfxpwrjt5u1K2mZOnwsd/ROJyfDrMDeT4baQ7LAwVlbJtIgCwMlbifz2cABR08E9IY++o0mIRRUQ1np5chs+6FzTgXHL4BlIycyp0eyqVgMnbLuL4jWToy2VYM6ItGpgbVOg2iYoyxL0+WtU3xdPsPMzcfUnsOFqHRRQREYA+LeuimY0xMrIqvgHnd/tjseP8A+hIJfh5SCu0qGdaodsjKo5UKsGcvi7QkUqw/3IiDlxOEDuSVmERRUSEgg+T6b0KGnD+ceoOblZQA841J25h+dGbAIBv+7VAF8faFbIdopJysjbG+50aAQBm7r6Mp9nsHVVSLKKIiP7hZW+BN5z+acC5r/wbcO65+BBfBV8BAEzydUT/1vXKfRtEZTGhaxPUr6WPh2lZ+HH/VbHjaA0WUURE/zL1nwac+y8n4sytlHJ73VM3H+OTTVEQBGBouwYY/c83AomqAqWuDLP7NAcArAu/jQv3UsUNpCVEL6KWLl0KOzs7KJVKeHh44MyZMy8dv2XLFjg5OUGpVMLFxQUhISEaz8+aNQtOTk4wMDCAmZkZfHx8cPr0aY0xvXv3Rv369aFUKmFjY4OhQ4ciPv7/+8NkZWVh+PDhcHFxgY6ODvz9/cttvkRUtTWxMsKgtgUNOGfvuVIuDThjE9Lx/m/nkJOvgq+zFWb1dmYzTapyOjaxhL9bHQgCMHV7NPLyVWJHqvJELaI2bdqEoKAgzJw5E5GRkXB1dYWvry+Skoq+KeLJkycxePBgjBo1CufPn4e/vz/8/f1x6dL/f6PAwcEBS5YsQXR0NI4fPw47Ozt0794djx49Uo/x9vbG5s2bcfXqVWzbtg1xcXHo37+/+vn8/Hzo6elh/Pjx8PHxqbg3gIiqpIk+DjCQy3DhfhqCox++1mvFpz7H8NVnkZGVhzYNzLBwUEvIpCygqGqa/mYzmOrr4srDdKw+cUvsOFWeRBAE0dqUenh4oG3btliyZAkAQKVSwdbWFuPGjcOUKVMKjQ8ICEBmZiaCg4PVy9q1awc3NzcsW7asyG2kp6fDxMQEBw8eRNeuXYscs3v3bvj7+yM7Oxu6uroazw0fPhypqanYuXNnqef3YttpaWkwNjYu9fpEJJ4lh67jxwPXUNdUD2GfdoZSV1bq10h7lov+y07ietJT2Nc2xNaPPGGqL6+AtETlZ/PZe/jftovQ05XhwCedYFtLX+xIla6kn9+iHYnKyclBRESExpEeqVQKHx8fhIeHF7lOeHh4oSNDvr6+xY7PycnBihUrYGJiAldX1yLHpKSkYP369fDy8ipUQJVWdnY20tPTNR5EpJ1GdWgEa+OCBpy/hd8u9fpZufl4/7dzuJ70FNbGSqwb6c4CirTCgDb14NGwFp7n5uOLXZcg4rGWKk+0Iio5ORn5+fmwsrLSWG5lZYWEhKL7VCQkJJRofHBwMAwNDaFUKjF//nyEhobCwsJCY8zkyZNhYGAAc3Nz3L17F7t27XrtOc2dOxcmJibqh62t7Wu/JhGJQ08uw2e+BQ04Fx+6gSelaMCZrxIwcWMUztxOgZFCB2tHtkVdU72KikpUriSSgt5RcpkUR64+QvDF1zulXZ2JfmF5RfD29kZUVBROnjwJPz8/DBw4sNB1VpMmTcL58+dx4MAByGQyDBs27LWr7alTpyItLU39uHfv3mu9HhGJS6MB56GSNeAUBAFf/nUZ+y4nQC6TYsWwNnCy5ul80i6NLQ0x2rvgG6Rf/nUFac9yRU5UNYlWRFlYWEAmkyExMVFjeWJiIqytrYtcx9raukTjDQwMYG9vj3bt2mHVqlXQ0dHBqlWrCm3fwcEB3bp1w8aNGxESEoJTp0691pwUCgWMjY01HkSkvWRSCT7/pwHn7+F3cCs585Xr/HI0Dr+F34FEAvwU4ArPxuYVHZOoQnzcpTEaWxog+Wk2vq2AvmnVgWhFlFwuR+vWrREWFqZeplKpEBYWBk9PzyLX8fT01BgPAKGhocWO//frZmdnv/R5AC8dQ0Q1U3t7C3g7WiJPJeD7V3yQbIu4j+/3FTQq/KJXM7zZok5lRCSqEAodGeb0cQEA/HnmLs7eLr++adWFqKfzgoKCsHLlSqxbtw4xMTH4+OOPkZmZiREjRgAAhg0bhqlTp6rHT5gwAfv27cO8efMQGxuLWbNm4dy5cxg7diwAIDMzE9OmTcOpU6dw584dREREYOTIkXjw4AEGDBgAADh9+jSWLFmCqKgo3LlzB4cOHcLgwYPRuHFjjWLsypUriIqKQkpKCtLS0hAVFYWoqKjKe3OIqMqY2rMppBJg76UEnCvmg+TI1SRM3nYRAPBhp0YY2aFhZUYkqhAejcwR0Kbg+t5p26ORk8feUf+mI+bGAwIC8OjRI8yYMQMJCQlwc3PDvn371BeP3717F1Lp/9d5Xl5e2LBhA6ZPn45p06ahSZMm2LlzJ5o3L+iyKpPJEBsbi3Xr1iE5ORnm5uZo27Ytjh07BmdnZwCAvr4+tm/fjpkzZyIzMxM2Njbw8/PD9OnToVAo1Nvq2bMn7ty5o/53y5YtAYDfUiCqgRysjBDQtj7+PHMX3+yJwY7RXhrNMqPvp2H0+kjkqQT4u9XBZD8nEdMSla+pPZ0QFpuI60lPsfxoHMZ1bSJ2pCpD1D5R1R37RBFVH0kZWejywxE8y8nHkndaqk/V3XmciX6/nETy0xx0sLfA6uFtIdeplt/ZoRpsV9QDTNgYBbmOFPsndkJDCwOxI1WoKt8niohIm9Q2UuKjzgXfVvpuXyyy8/KR/DQbgavPIPlpDprZGOOXd1uxgKJqqbdrHXRsYoGcPBU+3xHNszL/4G87EVEJvdexIayMFbiX8hzLjtzEqLVncfvxM9Qz08PaEW1hpHy9hr1EVZVEIsFsfxcodaU4GfcY2yMfiB2pSmARRURUQvpyHXzavaAB5/yD13DhfhrM9HWxbqQ7ahsrRU5HVLHqm+tjQlcHAMA3e64gpRQNaKsrFlFERKXQr1U9OFkbAQCUulKsGt4WjS0NRU5FVDne69gQTtZGePIsF7P3xIgdR3QsooiISkEmleD7/i3g3rAWlg9tg1b1zcSORFRpdGVSzOnrAokE2BZ5HydvJIsdSVQsooiISqlFPVNs/tATnR0sxY5CVOla1TfDux4NAACf77yErNx8kROJh0UUERERlcokP0fUNlLgVnImlh6+IXYc0bCIIiIiolIxVuriy94FTayXHY3D9cQMkROJg0UUERERlZpfc2v4NK2N3HwBU7dHQ6Wqeb2jWEQRERFRqUkkEnz5dnPoy2U4d+cJNp69J3akSsciioiIiMqkrqmeunfa3L0xSMrIEjlR5WIRRURERGU23MsOLnVNkJGVh6/+uiJ2nErFIoqIiIjKTCaVYG5fF0glQPDFhzh8NUnsSJWGRRQRERG9luZ1TTCyfUMAwPQdl/AsJ0/kRJWDRRQRERG9tk+6OaCuqR4epD7HgoPXxY5TKVhEERER0WszUOjga/+C3lGrjt/C5fg0kRNVPBZRREREVC7ecLJCLxcb5KsKekflV/PeUSyiiIiIqNzMfKsZjJQ6uHg/Db+H3xY7ToViEUVERETlpraxEpP9nAAAP+y/iodpz0VOVHFYRBEREVG5ese9Plo3MENmTj5m7rosdpwKwyKKiIiIypVUKsGcPi7QkUpw4Eoi9l9OEDtShWARRUREROXO0doIH3ZuBACYuesyMrJyRU5U/lhEERERUYUY90YT2JnrIyE9C/MOXBM7TrljEUVEREQVQqkrwzf+LgCAdeG3EXUvVdxA5YxFFBEREVWYDk0s0KdlXQgCMHV7NHLzVWJHKjcsooiIiKhCTe/VFKb6uoh5mI7Vx2+JHafcsIgiIiKiCmVuqMC0nk0BAPMPXsO9lGciJyofLKKIiIiowg1oXQ/tGtVCVq4K03degiBo/y1hWEQRERFRhZNIJJjdxwVymRRHrz3CXxcfih3ptbGIIiIiokrR2NIQY7ztAQBf/XUZac+0u3cUiygiIiKqNB91aYTGlgZIfpqDb/fFiB3ntbCIIiIiokqj0JFhbt8WAIA/z9zDmVspIicqOxZRREREVKncG9bCoLa2AIBpO6KRnZcvcqKyYRFFRERElW5qj6awMJTjRtJTLD96U+w4ZcIiioiIiCqdib4uvnizGQBgyeEbuPnoqciJSo9FFBEREYmit2sddHKwRE6eCp/v0L7eUSyiiIiISBQSiQSz/ZtDqStF+M3H2Bb5QOxIpcIiioiIiERjW0sfE30cAACz91xBSmaOyIlKjkUUERERiWpUh4ZwsjbCk2e5+GbPFbHjlBiLKCIiIhKVrkyKb/u1gEQCbI98gBM3ksWOVCIsooiIiEh0bramGNauAQDg8x3RyMqt+r2jWEQRERFRlfCZryOsjZW4/fgZlhy6IXacV2IRRURERFWCkVIXs3o7AwCWHY3DtcQMkRO9XJUoopYuXQo7OzsolUp4eHjgzJkzLx2/ZcsWODk5QalUwsXFBSEhIRrPz5o1C05OTjAwMICZmRl8fHxw+vRpjTG9e/dG/fr1oVQqYWNjg6FDhyI+Pl5jzMWLF9GxY0colUrY2tri+++/L58JExERUZF8na3g09QKeSoBU7dHQ6Wqur2jRC+iNm3ahKCgIMycORORkZFwdXWFr68vkpKSihx/8uRJDB48GKNGjcL58+fh7+8Pf39/XLp0ST3GwcEBS5YsQXR0NI4fPw47Ozt0794djx49Uo/x9vbG5s2bcfXqVWzbtg1xcXHo37+/+vn09HR0794dDRo0QEREBH744QfMmjULK1asqLg3g4iIqIaTSCT46m1nGMhliLjzBH+evSt2pGJJBJHbg3p4eKBt27ZYsmQJAEClUsHW1hbjxo3DlClTCo0PCAhAZmYmgoOD1cvatWsHNzc3LFu2rMhtpKenw8TEBAcPHkTXrl2LHLN79274+/sjOzsburq6+OWXX/D5558jISEBcrkcADBlyhTs3LkTsbGxJZrbi+2mpaXB2Ni4ROsQERERsPr4LXwVfAVGSh2EBXVGbWNlpW27pJ/foh6JysnJQUREBHx8fNTLpFIpfHx8EB4eXuQ64eHhGuMBwNfXt9jxOTk5WLFiBUxMTODq6lrkmJSUFKxfvx5eXl7Q1dVVb6dTp07qAurFdq5evYonT54U+TrZ2dlIT0/XeBAREVHpBXrZoUU9E2Rk5eHL4KrZO0rUIio5ORn5+fmwsrLSWG5lZYWEhIQi10lISCjR+ODgYBgaGkKpVGL+/PkIDQ2FhYWFxpjJkyfDwMAA5ubmuHv3Lnbt2vXK7bx4rihz586FiYmJ+mFra/uS2RMREVFxZFIJ5vRxgUwqwZ6LD3E4tujLfMQk+jVRFcXb2xtRUVE4efIk/Pz8MHDgwELXWU2aNAnnz5/HgQMHIJPJMGzYsNe6+eHUqVORlpamfty7d+91p0FERFRjNa9rgpHt7QAA03dewrOcPHED/YeoRZSFhQVkMhkSExM1licmJsLa2rrIdaytrUs03sDAAPb29mjXrh1WrVoFHR0drFq1qtD2HRwc0K1bN2zcuBEhISE4derUS7fz4rmiKBQKGBsbazyIiIio7D7p5oC6pnp4kPoc80OviR1Hg6hFlFwuR+vWrREWFqZeplKpEBYWBk9PzyLX8fT01BgPAKGhocWO//frZmdnv/R5AOoxnp6e+Pvvv5Gbm6uxHUdHR5iZmb18YkRERFQu9OU6+Ma/OQBg9YnbuPQgTeRE/0/003lBQUFYuXIl1q1bh5iYGHz88cfIzMzEiBEjAADDhg3D1KlT1eMnTJiAffv2Yd68eYiNjcWsWbNw7tw5jB07FgCQmZmJadOm4dSpU7hz5w4iIiIwcuRIPHjwAAMGDAAAnD59GkuWLEFUVBTu3LmDQ4cOYfDgwWjcuLG6GHvnnXcgl8sxatQoXL58GZs2bcLChQsRFBRUye8QERFRzebtVBu9WtggXyVg2o5o5FeV3lFCFbB48WKhfv36glwuF9zd3YVTp06pn+vcubMQGBioMX7z5s2Cg4ODIJfLBWdnZ2HPnj3q554/fy706dNHqFOnjiCXywUbGxuhd+/ewpkzZ9RjLl68KHh7ewu1atUSFAqFYGdnJ3z00UfC/fv3NbZz4cIFoUOHDoJCoRDq1q0rfPvtt6WaV1pamgBASEtLK9V6REREpCkx/bnQfOY+ocHkYGH18ZsVuq2Sfn6L3ieqOmOfKCIiovKz/vQdfL7jEgzkMoQGdUYdU70K2Y5W9IkiIiIiKqnBbeujTQMzZObkY+buy2LHYRFFRERE2kEqlWBOXxfoyiQIvZKIfZeK7ttYaXlE3ToRERFRKThYGeHDTo0BALN2X0ZGVu4r1qg4LKKIiIhIq4x9wx525vowM5Dj8dMc0XLoiLZlIiIiojJQ6srw+ygPWJsooSsT73gQiygiIiLSOra19MWOwNN5RERERGXBIoqIiIioDFhEEREREZUBiygiIiKiMmARRURERFQGLKKIiIiIyoBFFBEREVEZsIgiIiIiKgMWUURERERlwCKKiIiIqAxYRBERERGVAYsoIiIiojJgEUVERERUBjpiB6jOBEEAAKSnp4uchIiIiErqxef2i8/x4rCIqkAZGRkAAFtbW5GTEBERUWllZGTAxMSk2OclwqvKLCozlUqF+Ph4GBkZQSKRlNvrpqenw9bWFvfu3YOxsXG5vW5VUd3nB1T/OVb3+QHVf46cn/ar7nOsyPkJgoCMjAzUqVMHUmnxVz7xSFQFkkqlqFevXoW9vrGxcbX8xXihus8PqP5zrO7zA6r/HDk/7Vfd51hR83vZEagXeGE5ERERURmwiCIiIiIqAxZRWkihUGDmzJlQKBRiR6kQ1X1+QPWfY3WfH1D958j5ab/qPseqMD9eWE5ERERUBjwSRURERFQGLKKIiIiIyoBFFBEREVEZsIgiIiIiKgMWUVXU0qVLYWdnB6VSCQ8PD5w5c+al47ds2QInJycolUq4uLggJCSkkpKWTWnmt3btWkgkEo2HUqmsxLSl8/fff+Ott95CnTp1IJFIsHPnzleuc+TIEbRq1QoKhQL29vZYu3Zthed8HaWd45EjRwrtQ4lEgoSEhMoJXEpz585F27ZtYWRkhNq1a8Pf3x9Xr1595Xra8ntYlvlp0+/hL7/8ghYtWqibMHp6emLv3r0vXUdb9t0LpZ2jNu2/onz77beQSCSYOHHiS8dV9n5kEVUFbdq0CUFBQZg5cyYiIyPh6uoKX19fJCUlFTn+5MmTGDx4MEaNGoXz58/D398f/v7+uHTpUiUnL5nSzg8o6Ej78OFD9ePOnTuVmLh0MjMz4erqiqVLl5Zo/K1bt9CrVy94e3sjKioKEydOxHvvvYf9+/dXcNKyK+0cX7h69arGfqxdu3YFJXw9R48exZgxY3Dq1CmEhoYiNzcX3bt3R2ZmZrHraNPvYVnmB2jP72G9evXw7bffIiIiAufOncMbb7yBt99+G5cvXy5yvDbtuxdKO0dAe/bff509exbLly9HixYtXjpOlP0oUJXj7u4ujBkzRv3v/Px8oU6dOsLcuXOLHD9w4EChV69eGss8PDyEDz/8sEJzllVp57dmzRrBxMSkktKVLwDCjh07Xjrmf//7n+Ds7KyxLCAgQPD19a3AZOWnJHM8fPiwAEB48uRJpWQqb0lJSQIA4ejRo8WO0bbfw38ryfy0+fdQEATBzMxM+PXXX4t8Tpv33b+9bI7auv8yMjKEJk2aCKGhoULnzp2FCRMmFDtWjP3II1FVTE5ODiIiIuDj46NeJpVK4ePjg/Dw8CLXCQ8P1xgPAL6+vsWOF1NZ5gcAT58+RYMGDWBra/vKv7a0jTbtv9fl5uYGGxsbdOvWDSdOnBA7TomlpaUBAGrVqlXsGG3ejyWZH6Cdv4f5+fnYuHEjMjMz4enpWeQYbd53QMnmCGjn/hszZgx69epVaP8URYz9yCKqiklOTkZ+fj6srKw0lltZWRV7/UhCQkKpxoupLPNzdHTE6tWrsWvXLvzxxx9QqVTw8vLC/fv3KyNyhStu/6Wnp+P58+cipSpfNjY2WLZsGbZt24Zt27bB1tYWXbp0QWRkpNjRXkmlUmHixIlo3749mjdvXuw4bfo9/LeSzk/bfg+jo6NhaGgIhUKBjz76CDt27ECzZs2KHKut+640c9S2/QcAGzduRGRkJObOnVui8WLsR50Ke2WicuLp6anx15WXlxeaNm2K5cuX4+uvvxYxGZWUo6MjHB0d1f/28vJCXFwc5s+fj99//13EZK82ZswYXLp0CcePHxc7SoUo6fy07ffQ0dERUVFRSEtLw9atWxEYGIijR48WW2Roo9LMUdv237179zBhwgSEhoZW6QvgWURVMRYWFpDJZEhMTNRYnpiYCGtr6yLXsba2LtV4MZVlfv+lq6uLli1b4saNGxURsdIVt/+MjY2hp6cnUqqK5+7uXuULk7FjxyI4OBh///036tWr99Kx2vR7+EJp5vdfVf33UC6Xw97eHgDQunVrnD17FgsXLsTy5csLjdXGfQeUbo7/VdX3X0REBJKSktCqVSv1svz8fPz9999YsmQJsrOzIZPJNNYRYz/ydF4VI5fL0bp1a4SFhamXqVQqhIWFFXuu29PTU2M8AISGhr703LhYyjK//8rPz0d0dDRsbGwqKmal0qb9V56ioqKq7D4UBAFjx47Fjh07cOjQITRs2PCV62jTfizL/P5L234PVSoVsrOzi3xOm/bdy7xsjv9V1fdf165dER0djaioKPWjTZs2GDJkCKKiogoVUIBI+7HCLlmnMtu4caOgUCiEtWvXCleuXBE++OADwdTUVEhISBAEQRCGDh0qTJkyRT3+xIkTgo6OjvDjjz8KMTExwsyZMwVdXV0hOjparCm8VGnn9+WXXwr79+8X4uLihIiICGHQoEGCUqkULl++LNYUXiojI0M4f/68cP78eQGA8NNPPwnnz58X7ty5IwiCIEyZMkUYOnSoevzNmzcFfX19YdKkSUJMTIywdOlSQSaTCfv27RNrCq9U2jnOnz9f2Llzp3D9+nUhOjpamDBhgiCVSoWDBw+KNYWX+vjjjwUTExPhyJEjwsOHD9WPZ8+eqcdo8+9hWeanTb+HU6ZMEY4ePSrcunVLuHjxojBlyhRBIpEIBw4cEARBu/fdC6Wdozbtv+L899t5VWE/soiqohYvXizUr19fkMvlgru7u3Dq1Cn1c507dxYCAwM1xm/evFlwcHAQ5HK54OzsLOzZs6eSE5dOaeY3ceJE9VgrKyuhZ8+eQmRkpAipS+bF1/n/+3gxp8DAQKFz586F1nFzcxPkcrnQqFEjYc2aNZWeuzRKO8fvvvtOaNy4saBUKoVatWoJXbp0EQ4dOiRO+BIoam4ANPaLNv8elmV+2vR7OHLkSKFBgwaCXC4XLC0tha5du6qLC0HQ7n33QmnnqE37rzj/LaKqwn6UCIIgVNxxLiIiIqLqiddEEREREZUBiygiIiKiMmARRURERFQGLKKIiIiIyoBFFBEREVEZsIgiIiIiKgMWUURERERlwCKKiKgSSSQS7Ny5U+wYRFQOWEQRUY0xfPhwSCSSQg8/Pz+xoxGRFtIROwARUWXy8/PDmjVrNJYpFAqR0hCRNuORKCKqURQKBaytrTUeZmZmAApOtf3yyy/o0aMH9PT00KhRI2zdulVj/ejoaLzxxhvQ09ODubk5PvjgAzx9+lRjzOrVq+Hs7AyFQgEbGxuMHTtW4/nk5GT06dMH+vr6aNKkCXbv3l2xkyaiCsEiiojoX7744gv069cPFy5cwJAhQzBo0CDExMQAADIzM+Hr6wszMzOcPXsWW7ZswcGDBzWKpF9++QVjxozBBx98gOjoaOzevRv29vYa2/jyyy8xcOBAXLx4ET179sSQIUOQkpJSqfMkonJQobc3JiKqQgIDAwWZTCYYGBhoPGbPni0IgiAAED766CONdTw8PISPP/5YEARBWLFihWBmZiY8ffpU/fyePXsEqVQqJCQkCIIgCHXq1BE+//zzYjMAEKZPn67+99OnTwUAwt69e8ttnkRUOXhNFBHVKN7e3vjll180ltWqVUv9/z09PTWe8/T0RFRUFAAgJiYGrq6uMDAwUD/fvn17qFQqXL16FRKJBPHx8ejatetLM7Ro0UL9/w0MDGBsbIykpKSyTomIRMIiiohqFAMDg0Kn18qLnp5eicbp6upq/FsikUClUlVEJCKqQLwmiojoX06dOlXo302bNgUANG3aFBcuXEBmZqb6+RMnTkAqlcLR0RFGRkaws7NDWFhYpWYmInHwSBQR1SjZ2dlISEjQWKajowMLCwsAwJYtW9CmTRt06NAB69evx5kzZ7Bq1SoAwJAhQzBz5kwEBgZi1qxZePToEcaNG4ehQ4fCysoKADBr1ix89NFHqF27Nnr06IGMjAycOHEC48aNq9yJElGFYxFFRDXKvn37YGNjo7HM0dERsbGxAAq+Obdx40aMHj0aNjY2+PPPP9GsWTMAgL6+Pvbv348JEyagbdu20NfXR79+/fDTTz+pXyswMBBZWVmYP38+PvvsM1hYWKB///6VN0EiqjQSQRAEsUMQEVUFEokEO3bsgL+/v9hRiEgL8JooIiIiojJgEUVERERUBrwmiojoH7y6gYhKg0eiiIiIiMqARRQRERFRGbCIIiIiIioDFlFEREREZcAiioiIiKgMWEQRERERlQGLKCIiIqIyYBFFREREVAYsooiIiIjK4P8AM39TpcGSZoAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n",
      "Test Loss: 0.033025779902577865\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# datasets (train, validation, test)\n",
    "dataset = [(embeddings_dict[sequence.split(\"/\")[0]], conservation_scores, sequence) for sequence, conservation_scores in zip(sequences, conservation_scores_array)]\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Creation data loaders for train, validation, and test\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Definition model\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# the training function\n",
    "def train_model(model, optimizer, loss_fn, data_loader):\n",
    "    model.train()\n",
    "    for embedding, label, sequence in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        embedding = embedding.squeeze()\n",
    "        label = label.squeeze()\n",
    "        if embedding.size(0) != label.size(0):\n",
    "            print(f\"Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: {sequence} y {label.size(0)} y {embedding.size(0)}\" )\n",
    "            continue\n",
    "        output = model(embedding).squeeze()\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_model(model, loss_fn, data_loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for embedding, label, sequence in data_loader:\n",
    "            embedding = embedding.squeeze()\n",
    "            label = label.squeeze()\n",
    "            output = model(embedding).squeeze()\n",
    "            if embedding.size(0) != label.size(0):\n",
    "                print(f\"Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: {sequence} y {label.size(0)} y {embedding.size(0)}\" )\n",
    "                continue\n",
    "            loss = loss_fn(output, label)\n",
    "            running_loss += loss.item()\n",
    "    return running_loss / len(data_loader)\n",
    "\n",
    "# On initialize the model, loss function, and optimizer with L2 regularization\n",
    "model = LinearRegression(input_size=320)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, weight_decay=0.01)  # Add weight_decay for L2 regularization\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "val_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_model(model, optimizer, loss_fn, train_loader)\n",
    "    val_loss = evaluate_model(model, loss_fn, val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Validation Loss: {val_loss}')\n",
    "\n",
    "# Plot validation loss over epochs\n",
    "plt.plot(val_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "# Finally, on evalue on test set\n",
    "test_loss = evaluate_model(model, loss_fn, test_loader)\n",
    "print(f'Test Loss: {test_loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63b683c-ad1d-4cf6-b885-2de938bcfdba",
   "metadata": {},
   "source": [
    "este es el codigo anterior con solo 1000 secuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ceb225b-584a-4af0-8ab0-ff15bce8307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Fonction pour calculer le coefficient de corrélation de Pearson\n",
    "def pearson_correlation(true_scores, predicted_scores):\n",
    "    # Calculer les moyennes des scores réels et prédits\n",
    "    mean_true = torch.mean(true_scores)\n",
    "    mean_pred = torch.mean(predicted_scores)\n",
    "\n",
    "    # Calculer les différences par rapport à la moyenne\n",
    "    diff_true = true_scores - mean_true\n",
    "    diff_pred = predicted_scores - mean_pred\n",
    "\n",
    "    # Calculer la covariance\n",
    "    cov = torch.sum(diff_true * diff_pred) / len(true_scores)\n",
    "\n",
    "    # Calculer les écarts-types\n",
    "    std_true = torch.sqrt(torch.sum(diff_true ** 2) / len(true_scores))\n",
    "    std_pred = torch.sqrt(torch.sum(diff_pred ** 2) / len(predicted_scores))\n",
    "\n",
    "    # Calculer le coefficient de corrélation de Pearson\n",
    "    pearson_corr = cov / (std_true * std_pred)\n",
    "\n",
    "    return pearson_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60f66478-3f0d-495b-9d95-97d512ae4db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label tensor([0.4919, 0.2313, 0.3818, 0.1685, 0.2695, 0.1858, 0.1532, 0.3962, 0.2444,\n",
      "        0.3074, 0.4836, 0.1338, 0.2737, 0.1707, 0.1571, 0.1104, 0.3152, 0.4802,\n",
      "        0.6621, 0.3076, 0.4839, 0.1354, 0.3293, 0.2324, 0.5620, 0.4451, 0.3264,\n",
      "        0.2832, 0.2832, 0.2651, 0.3567, 0.1647, 0.4163, 0.1479, 0.5259, 0.1555,\n",
      "        0.8252, 0.1001, 0.3469, 0.3096, 0.2908, 0.3000, 0.2380, 0.2910, 0.4534,\n",
      "        0.1236, 0.3079, 0.1798, 0.2715, 0.2357, 0.3049, 0.5562, 0.1978, 0.5918,\n",
      "        0.4438, 0.1338, 0.3433, 0.6260, 0.1481, 0.3833, 0.2917, 0.5898, 0.1414,\n",
      "        0.1331, 0.1196, 0.1395, 0.0895, 0.1908, 0.0676, 0.2715, 0.1299, 0.2428,\n",
      "        0.2170, 0.2045, 0.1802, 0.2048, 0.3608, 0.2034, 0.2668, 0.3818, 0.3162,\n",
      "        0.2413, 0.1004, 0.2300, 0.0997, 0.0000, 0.2040, 0.2426, 0.4724, 0.3118,\n",
      "        0.5571, 0.3569, 0.4958, 0.3198, 0.3701, 0.2830, 0.2871, 0.1715, 0.4336,\n",
      "        0.2192, 0.4048, 0.2581, 0.4888, 0.3167, 0.4009, 0.7368, 0.2781, 0.2632,\n",
      "        0.1716, 0.2920, 0.2834, 0.7456, 0.2217, 0.3782, 0.2964, 0.6377, 0.5679,\n",
      "        0.5215, 0.2021, 0.3589, 0.1915])\n",
      "output tensor([0.3985, 0.3038, 0.3732, 0.2408, 0.3597, 0.2182, 0.3072, 0.2912, 0.2560,\n",
      "        0.3143, 0.2271, 0.2492, 0.2661, 0.2870, 0.2322, 0.2811, 0.2603, 0.3143,\n",
      "        0.3487, 0.3017, 0.3222, 0.1964, 0.3562, 0.2043, 0.3003, 0.2517, 0.2680,\n",
      "        0.1347, 0.3622, 0.1711, 0.3686, 0.2413, 0.4012, 0.2212, 0.4158, 0.2168,\n",
      "        0.4660, 0.2181, 0.3296, 0.2751, 0.1554, 0.1290, 0.3299, 0.1652, 0.4176,\n",
      "        0.2828, 0.3357, 0.2999, 0.3671, 0.3589, 0.3608, 0.2960, 0.3563, 0.2296,\n",
      "        0.2087, 0.1708, 0.2051, 0.4145, 0.1913, 0.2614, 0.2172, 0.3384, 0.2625,\n",
      "        0.2470, 0.2783, 0.2458, 0.2136, 0.2234, 0.3072, 0.2607, 0.2289, 0.1999,\n",
      "        0.2946, 0.2202, 0.3433, 0.2342, 0.2979, 0.2272, 0.3103, 0.2888, 0.2379,\n",
      "        0.2220, 0.2549, 0.2288, 0.2836, 0.1999, 0.2869, 0.2543, 0.3781, 0.1095,\n",
      "        0.4315, 0.2998, 0.3269, 0.3997, 0.2886, 0.1749, 0.3685, 0.1559, 0.3615,\n",
      "        0.2163, 0.4282, 0.1568, 0.4630, 0.1554, 0.3973, 0.3724, 0.2157, 0.1811,\n",
      "        0.4261, 0.4008, 0.3081, 0.4283, 0.2877, 0.3967, 0.3782, 0.5240, 0.3547,\n",
      "        0.6103, 0.3941, 0.4843, 0.3576])\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Coefficient de corrélation de Pearson: 0.3994137644767761\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de données de test et obtenir les scores réels\n",
    "model.eval()\n",
    "true_scores = []\n",
    "predicted_scores = []\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for embedding, label, sequence in test_loader:\n",
    "        count = count + 1\n",
    "        embedding = embedding.squeeze()\n",
    "        label = label.squeeze()\n",
    "        output = model(embedding).squeeze()\n",
    "        if embedding.size(0) != label.size(0):\n",
    "            print(f\"Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: {sequence} y {label.size(0)} y {embedding.size(0)}\" )\n",
    "            continue\n",
    "        if count == 2:\n",
    "            print(\"label\", label)\n",
    "            print(\"output\", output)\n",
    "        true_scores.append(label)\n",
    "        predicted_scores.append(output)\n",
    "\n",
    "# Convertir les listes en tenseurs PyTorch\n",
    "true_scores_tensor = torch.cat(true_scores)\n",
    "predicted_scores_tensor = torch.cat(predicted_scores)\n",
    "\n",
    "# Calculer le coefficient de corrélation de Pearson\n",
    "pearson_corr = pearson_correlation(true_scores_tensor, predicted_scores_tensor)\n",
    "print(f\"Coefficient de corrélation de Pearson: {pearson_corr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66b28d90-86d0-4a23-b59e-2006cf68ca5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Epoch 1/5, Validation Loss: 0.035997305871558735\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Epoch 2/5, Validation Loss: 0.03463816545301266\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Epoch 3/5, Validation Loss: 0.03400361717654371\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Epoch 4/5, Validation Loss: 0.0336584592518504\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Epoch 5/5, Validation Loss: 0.033421303814131643\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0H3YJP0.1/580-733',) y 154 y 165\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n",
      "Test Loss: 0.03364353817730134\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# datasets (train, validation, test)\n",
    "dataset = [(embeddings_dict[sequence.split(\"/\")[0]], conservation_scores, sequence) for sequence, conservation_scores in zip(sequences, conservation_scores_array)]\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Creation data loaders for train, validation, and test\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Definition model\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "# the training function\n",
    "def train_model(model, optimizer, loss_fn, data_loader):\n",
    "    model.train()\n",
    "    for embedding, label, sequence in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        embedding = embedding.squeeze()\n",
    "        label = label.squeeze()\n",
    "        if embedding.size(0) != label.size(0):\n",
    "            print(f\"Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: {sequence} y {label.size(0)} y {embedding.size(0)}\" )\n",
    "            continue\n",
    "        output = model(embedding).squeeze()\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_model(model, loss_fn, data_loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for embedding, label, sequence in data_loader:\n",
    "            embedding = embedding.squeeze()\n",
    "            label = label.squeeze()\n",
    "            output = model(embedding).squeeze()\n",
    "            if embedding.size(0) != label.size(0):\n",
    "                print(f\"Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: {sequence} y {label.size(0)} y {embedding.size(0)}\" )\n",
    "                continue\n",
    "            loss = loss_fn(output, label)\n",
    "            running_loss += loss.item()\n",
    "    return running_loss / len(data_loader)\n",
    "\n",
    "# On initialize the model, loss function, and optimizer with L2 regularization\n",
    "model = LogisticRegression(input_size=320)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)  # Add weight_decay for L2 regularization\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "val_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_model(model, optimizer, loss_fn, train_loader)\n",
    "    val_loss = evaluate_model(model, loss_fn, val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Validation Loss: {val_loss}')\n",
    "\n",
    "# Plot validation loss over epochs\n",
    "plt.plot(val_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "# Finally, on evalue on test set\n",
    "test_loss = evaluate_model(model, loss_fn, test_loader)\n",
    "print(f'Test Loss: {test_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0ba9f7a-669a-4a80-8472-ffb99bb9f9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot validation loss over epochs\n",
    "plt.plot(val_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss over Epochs - Logistic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "011f476d-bbd2-4a3b-af30-e12c5292f6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label tensor([0.4951, 0.5132, 0.6763, 0.3291, 0.2091, 0.7407, 0.4521, 0.3337, 0.7129,\n",
      "        0.7520, 0.2849, 0.2842, 0.4734, 0.4189, 0.8223, 0.1920, 0.2603, 0.3767,\n",
      "        0.3726, 0.5928, 0.4092, 0.6001, 0.5430, 0.5303, 0.5596, 0.1327, 0.4102,\n",
      "        0.6626, 0.5283, 0.5825, 0.4880, 0.5791, 0.6719, 0.5522, 0.4407, 0.6875,\n",
      "        0.6958, 0.7617, 0.4207, 0.5991, 0.6499, 0.5586, 0.4331, 0.3870, 0.5464,\n",
      "        0.3660, 0.5566, 0.1310, 0.1760, 0.1912, 0.3792, 0.2091, 0.2278, 0.2615,\n",
      "        0.5815, 0.4297, 0.4778, 0.4634, 0.3865, 0.8691, 0.5557, 0.7705, 0.4736,\n",
      "        0.8306, 0.4265, 0.2854, 0.8262, 0.5879, 0.6045, 0.4167, 0.7251, 0.7642,\n",
      "        0.2151, 0.6084, 0.2095, 0.4958, 0.8789, 0.4417, 0.7534, 0.5571, 0.8301,\n",
      "        0.6685, 0.8989, 0.5752, 0.7158, 0.7114, 0.7515, 0.6909, 0.6387, 0.6245,\n",
      "        0.5278, 0.8184, 0.6997, 0.7046, 0.3496, 0.4934, 0.5146, 0.5874, 0.1415,\n",
      "        0.5771, 0.4153, 0.6357, 0.4900, 0.6006, 0.4624, 0.5435, 0.3237, 0.2469,\n",
      "        0.4685, 0.3865, 0.5249, 0.4912, 0.2847, 0.3977, 0.4326, 0.5723, 0.4185,\n",
      "        0.4558, 0.5771, 0.5117, 0.5708, 0.1194, 0.3853, 0.5142, 0.2815, 0.5684,\n",
      "        0.5210, 0.2179, 0.2139, 0.3225, 0.7236, 0.2095, 0.2333, 0.1338, 0.2001,\n",
      "        0.2532, 0.3423, 0.2927, 0.2620, 0.2292, 0.4600, 0.5244, 0.1840, 0.2654,\n",
      "        0.2732, 0.3633, 0.2047, 0.3459, 0.4668, 0.6919, 0.7134, 0.7705, 0.2423,\n",
      "        0.3826, 0.5410, 0.2460, 0.5532, 0.6094, 0.6099, 0.6733, 0.6904, 0.5532,\n",
      "        0.5703, 0.7100, 0.5938, 0.5786, 0.5073, 0.5425, 0.2198, 0.4419, 0.1793,\n",
      "        0.2235, 0.1127, 0.1216, 0.1578, 0.1447, 0.0735, 0.1321, 0.1350, 0.1804,\n",
      "        0.0612, 0.1740, 0.1598, 0.1636, 0.3403, 0.3562, 0.2947, 0.3772, 0.5322,\n",
      "        0.3176, 0.6812, 0.4958, 0.6577, 0.6948, 0.3389, 0.6646, 0.6743, 0.4604,\n",
      "        0.5610, 0.5454, 0.3210, 0.3645, 0.1600, 0.1718, 0.2505, 0.3376, 0.1647,\n",
      "        0.3137, 0.1451, 0.3079, 0.6504, 0.4150, 0.2664, 0.3914, 0.4600, 0.5454,\n",
      "        0.6689, 0.6094, 0.7021, 0.4912, 0.6245, 0.4907, 0.6196, 0.7046, 0.3230,\n",
      "        0.3191, 0.3108, 0.3667, 0.3745, 0.5273, 0.3774, 0.2739, 0.1486, 0.4382,\n",
      "        0.3589, 0.6309, 0.3804, 0.4546, 0.5693, 0.3386, 0.4609, 0.1425, 0.3367,\n",
      "        0.4033, 0.3330, 0.2225, 0.1290, 0.2634, 0.2188, 0.2030, 0.2079, 0.2620,\n",
      "        0.2947, 0.1219, 0.1500, 0.4048, 0.1170, 0.0774, 0.1277, 0.1082, 0.1105,\n",
      "        0.0748, 0.1520, 0.1488, 0.3145, 0.3076, 0.5991, 0.5059, 0.5684, 0.4849,\n",
      "        0.8042, 0.9028, 0.3240, 0.7441, 0.5122, 0.3105, 0.3625, 0.6001, 0.4302,\n",
      "        0.5039, 0.3401, 0.7026, 0.6436, 0.4351, 0.2125, 0.7715, 0.5596, 0.7207,\n",
      "        0.3340, 0.4470, 0.5205, 0.6377, 0.8169, 0.5576, 0.4824, 0.8320, 0.5903,\n",
      "        0.5679, 0.5327, 0.8296, 0.7827, 0.5107, 0.3110, 0.4341, 0.3831, 0.3367,\n",
      "        0.2468, 0.1481, 0.4768, 0.4495, 0.1885, 0.2412, 0.1489, 0.2468, 0.3708,\n",
      "        0.4216, 0.1648, 0.2224, 0.4136, 0.3379, 0.2196, 0.1049, 0.3728, 0.2637,\n",
      "        0.2542, 0.1093, 0.5103, 0.2808, 0.1989, 0.1532, 0.6519, 0.4993, 0.4321,\n",
      "        0.4810, 0.0836, 0.2244, 0.2498, 0.1863, 0.2296, 0.1203, 0.5576, 0.1156,\n",
      "        0.2247, 0.3076, 0.4324, 0.1432, 0.0926, 0.8081, 0.5371, 0.2581, 0.3706,\n",
      "        0.7876, 0.1059, 0.2600, 0.5771, 0.5234, 0.2532, 0.2505, 0.6279, 0.2593,\n",
      "        0.1919, 0.2583, 0.4893, 0.2749, 0.2539, 0.1501, 0.2239, 0.1687, 0.1816,\n",
      "        0.1401, 0.1241, 0.1245, 0.1927, 0.1205, 0.4756, 0.3755, 0.4490, 0.2727,\n",
      "        0.1796, 0.4443, 0.6460, 0.2286, 0.6606, 0.6270, 0.5527, 0.6743, 0.5942,\n",
      "        0.7759, 0.6138, 0.6953, 0.2966, 0.6646, 0.4702, 0.5200, 0.2053, 0.3853,\n",
      "        0.3628, 0.4377, 0.2279, 0.4395, 0.2544, 0.4534, 0.2876, 0.1686, 0.4580,\n",
      "        0.5464, 0.1696, 0.2424, 0.3176, 0.5928, 0.2634, 0.1902, 0.2477, 0.4399,\n",
      "        0.2411, 0.2712, 0.5332, 0.4954, 0.2734, 0.2820, 0.4580, 0.4822, 0.2069,\n",
      "        0.2289, 0.1893, 0.1600, 0.1351, 0.1185, 0.0964, 0.0000, 0.0000, 0.0477,\n",
      "        0.0544, 0.0749, 0.0490, 0.0822, 0.0684, 0.0591, 0.0572, 0.1249, 0.0415,\n",
      "        0.1133, 0.0806, 0.0554, 0.0741, 0.1085, 0.2795, 0.1425, 0.3911, 0.1545,\n",
      "        0.3870, 0.5693, 0.2397, 0.0891, 0.1204, 0.1351, 0.0685, 0.1514, 0.2344,\n",
      "        0.1431, 0.3547, 0.1310, 0.1448, 0.2598, 0.1290, 0.0741, 0.1340, 0.1328,\n",
      "        0.1138, 0.0736, 0.1436, 0.1141, 0.1108, 0.1664, 0.0536, 0.1092, 0.1964,\n",
      "        0.1564, 0.0969, 0.1177, 0.0793, 0.3853, 0.3599, 0.3906, 0.3398, 0.2189,\n",
      "        0.5825, 0.4031, 0.6108, 0.6733, 0.3894, 0.4956, 0.3682, 0.6035, 0.6177,\n",
      "        0.6748, 0.2688, 0.3640, 0.6602, 0.1962, 0.6113, 0.1185, 0.4009, 0.0786,\n",
      "        0.1010, 0.1296, 0.1738, 0.0807, 0.1072, 0.2394, 0.1272, 0.5269, 0.0914,\n",
      "        0.3818, 0.4338, 0.2280, 0.2747, 0.0561, 0.0937, 0.2480, 0.1212, 0.2708,\n",
      "        0.2339, 0.5879, 0.1204, 0.2725, 0.1422, 0.1370, 0.0801, 0.1027, 0.2810,\n",
      "        0.0789, 0.2590, 0.1201, 0.1351, 0.3303, 0.2255, 0.0876, 0.3345, 0.0980,\n",
      "        0.2426, 0.1045, 0.4238, 0.4497, 0.0593, 0.1678])\n",
      "output tensor([0.3130, 0.4486, 0.4046, 0.2734, 0.3408, 0.5844, 0.3298, 0.2593, 0.3979,\n",
      "        0.5300, 0.2853, 0.2069, 0.2864, 0.3637, 0.3742, 0.3431, 0.3339, 0.3665,\n",
      "        0.3461, 0.3510, 0.4474, 0.3167, 0.3966, 0.3262, 0.3947, 0.3275, 0.2716,\n",
      "        0.3168, 0.3090, 0.3468, 0.3924, 0.4257, 0.4076, 0.4127, 0.3940, 0.3717,\n",
      "        0.4178, 0.3545, 0.3390, 0.4111, 0.3436, 0.3221, 0.4024, 0.4219, 0.3854,\n",
      "        0.3239, 0.3673, 0.3015, 0.2721, 0.2960, 0.3222, 0.3290, 0.2793, 0.3200,\n",
      "        0.3559, 0.3597, 0.3503, 0.3570, 0.5028, 0.3308, 0.3607, 0.5239, 0.3764,\n",
      "        0.3509, 0.3335, 0.3945, 0.3588, 0.3162, 0.3179, 0.3205, 0.3257, 0.3522,\n",
      "        0.3407, 0.3646, 0.3364, 0.3577, 0.4106, 0.3896, 0.3595, 0.4631, 0.4188,\n",
      "        0.3754, 0.3796, 0.4027, 0.3767, 0.3613, 0.3995, 0.3103, 0.4159, 0.3425,\n",
      "        0.3390, 0.3759, 0.4083, 0.3463, 0.2854, 0.3281, 0.3787, 0.3889, 0.2412,\n",
      "        0.3840, 0.4404, 0.4352, 0.2777, 0.4135, 0.5083, 0.2706, 0.2382, 0.2842,\n",
      "        0.3599, 0.3448, 0.3563, 0.2487, 0.2638, 0.2760, 0.2667, 0.3897, 0.3964,\n",
      "        0.3074, 0.3265, 0.3734, 0.4296, 0.3532, 0.3356, 0.3776, 0.2801, 0.2894,\n",
      "        0.3618, 0.2875, 0.2576, 0.3128, 0.4746, 0.3400, 0.2801, 0.3463, 0.3551,\n",
      "        0.3630, 0.3564, 0.2879, 0.3599, 0.3142, 0.3781, 0.3859, 0.3095, 0.3393,\n",
      "        0.3548, 0.3767, 0.3048, 0.2932, 0.3329, 0.3377, 0.3905, 0.4365, 0.3762,\n",
      "        0.3975, 0.3965, 0.4206, 0.4298, 0.4060, 0.5308, 0.4092, 0.4079, 0.5448,\n",
      "        0.3742, 0.3694, 0.4172, 0.4643, 0.3658, 0.3503, 0.3475, 0.4042, 0.3409,\n",
      "        0.3318, 0.4074, 0.3789, 0.4977, 0.3806, 0.4467, 0.4504, 0.3385, 0.4986,\n",
      "        0.3822, 0.3708, 0.4168, 0.4675, 0.3847, 0.5278, 0.3739, 0.3943, 0.5029,\n",
      "        0.3534, 0.3533, 0.3875, 0.4617, 0.3666, 0.3986, 0.3980, 0.4268, 0.3165,\n",
      "        0.3485, 0.4165, 0.3665, 0.3148, 0.4124, 0.1765, 0.2323, 0.3796, 0.2921,\n",
      "        0.3556, 0.3127, 0.3064, 0.3342, 0.3157, 0.3887, 0.3799, 0.3264, 0.3484,\n",
      "        0.3448, 0.3484, 0.3224, 0.3138, 0.3991, 0.3663, 0.3416, 0.3479, 0.4290,\n",
      "        0.3277, 0.2574, 0.4283, 0.3586, 0.2948, 0.3129, 0.3115, 0.3297, 0.2932,\n",
      "        0.2960, 0.3294, 0.3504, 0.2898, 0.3154, 0.3428, 0.4201, 0.3151, 0.3511,\n",
      "        0.4686, 0.4156, 0.3310, 0.4403, 0.4692, 0.4033, 0.2601, 0.3307, 0.3428,\n",
      "        0.3560, 0.2952, 0.2541, 0.4010, 0.3250, 0.2937, 0.2418, 0.2479, 0.2598,\n",
      "        0.3376, 0.3320, 0.2906, 0.3500, 0.3673, 0.3480, 0.3455, 0.4394, 0.3784,\n",
      "        0.4023, 0.4217, 0.4364, 0.4013, 0.3467, 0.3895, 0.3798, 0.3986, 0.3696,\n",
      "        0.3413, 0.2958, 0.3785, 0.3719, 0.3175, 0.3691, 0.2862, 0.2796, 0.2824,\n",
      "        0.3241, 0.3701, 0.3703, 0.3624, 0.3706, 0.3801, 0.4367, 0.3523, 0.3932,\n",
      "        0.4536, 0.4687, 0.3521, 0.4080, 0.4072, 0.3866, 0.3069, 0.3920, 0.3875,\n",
      "        0.3274, 0.3424, 0.3312, 0.3682, 0.3445, 0.3363, 0.3347, 0.3291, 0.3925,\n",
      "        0.3785, 0.3131, 0.3287, 0.3841, 0.3667, 0.2765, 0.3242, 0.4288, 0.3617,\n",
      "        0.2709, 0.3242, 0.3362, 0.3589, 0.2947, 0.2950, 0.3997, 0.2882, 0.2485,\n",
      "        0.3423, 0.2875, 0.2649, 0.3459, 0.3861, 0.2664, 0.2979, 0.4069, 0.3513,\n",
      "        0.2956, 0.3659, 0.3559, 0.3105, 0.3211, 0.3564, 0.2585, 0.2228, 0.2702,\n",
      "        0.4178, 0.2396, 0.2014, 0.3240, 0.3508, 0.2234, 0.2623, 0.4358, 0.3360,\n",
      "        0.2069, 0.3276, 0.4236, 0.3406, 0.2689, 0.4420, 0.3685, 0.2181, 0.2848,\n",
      "        0.3273, 0.2849, 0.3127, 0.3428, 0.2625, 0.2900, 0.3375, 0.3495, 0.2944,\n",
      "        0.3815, 0.3287, 0.3476, 0.2833, 0.3668, 0.4339, 0.3506, 0.2606, 0.3841,\n",
      "        0.3712, 0.3968, 0.4104, 0.3030, 0.2713, 0.3229, 0.3678, 0.2907, 0.2505,\n",
      "        0.3558, 0.4523, 0.2572, 0.2309, 0.3034, 0.3912, 0.3702, 0.2198, 0.3131,\n",
      "        0.3192, 0.2307, 0.2346, 0.2875, 0.4599, 0.2748, 0.2330, 0.3376, 0.3787,\n",
      "        0.2384, 0.2643, 0.3957, 0.3363, 0.2757, 0.3021, 0.3627, 0.2813, 0.2396,\n",
      "        0.2558, 0.2980, 0.2667, 0.2600, 0.2689, 0.3075, 0.3059, 0.2527, 0.2593,\n",
      "        0.3749, 0.3055, 0.3100, 0.3349, 0.3467, 0.2763, 0.2779, 0.4006, 0.3860,\n",
      "        0.2538, 0.2737, 0.3263, 0.3478, 0.2574, 0.2758, 0.2729, 0.3287, 0.2461,\n",
      "        0.3192, 0.3713, 0.2933, 0.2658, 0.2785, 0.2513, 0.2826, 0.2907, 0.3316,\n",
      "        0.3194, 0.3207, 0.3403, 0.3363, 0.3511, 0.3108, 0.3038, 0.3080, 0.2944,\n",
      "        0.2883, 0.3030, 0.3117, 0.3402, 0.3159, 0.3569, 0.2377, 0.2730, 0.3681,\n",
      "        0.3109, 0.3385, 0.4641, 0.3671, 0.3901, 0.3758, 0.4281, 0.3684, 0.3363,\n",
      "        0.3138, 0.3940, 0.4163, 0.3714, 0.3250, 0.2852, 0.2859, 0.3446, 0.3700,\n",
      "        0.3107, 0.3255, 0.3738, 0.3777, 0.3250, 0.3650, 0.2598, 0.2675, 0.2443,\n",
      "        0.2653, 0.3180, 0.2392, 0.3168, 0.2992, 0.4060, 0.2714, 0.3804, 0.2955,\n",
      "        0.3236, 0.3163, 0.2686, 0.2497, 0.2301, 0.2784, 0.2689, 0.2350, 0.3529,\n",
      "        0.2401, 0.4127, 0.3176, 0.3808, 0.3128, 0.3899, 0.2771, 0.2920, 0.3434,\n",
      "        0.2415, 0.3017, 0.2411, 0.2417, 0.3182, 0.2947, 0.2432, 0.4172, 0.2316,\n",
      "        0.3648, 0.2629, 0.3672, 0.2975, 0.3471, 0.3137])\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0H3YJP0.1/580-733',) y 154 y 165\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n",
      "Coefficient de corrélation de Pearson Logistic Regression: 0.3884710967540741\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "true_scores = []\n",
    "predicted_scores = []\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for embedding, label, sequence in test_loader:\n",
    "        count = count + 1\n",
    "        embedding = embedding.squeeze()\n",
    "        label = label.squeeze()\n",
    "        output = model(embedding).squeeze()\n",
    "        if embedding.size(0) != label.size(0):\n",
    "            print(f\"Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: {sequence} y {label.size(0)} y {embedding.size(0)}\" )\n",
    "            continue\n",
    "        if count == 2:\n",
    "            print(\"label\", label)\n",
    "            print(\"output\", output)\n",
    "        true_scores.append(label)\n",
    "        predicted_scores.append(output)\n",
    "\n",
    "# Convertir les listes en tenseurs PyTorch\n",
    "true_scores_tensor = torch.cat(true_scores)\n",
    "predicted_scores_tensor = torch.cat(predicted_scores)\n",
    "\n",
    "# Calculer le coefficient de corrélation de Pearson\n",
    "pearson_corr = pearson_correlation(true_scores_tensor, predicted_scores_tensor)\n",
    "print(f\"Coefficient de corrélation de Pearson Logistic Regression: {pearson_corr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a37acb7-89fb-4344-9cd1-4989dd2e5603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0H3YJP0.1/580-733',) y 154 y 165\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Epoch 1/5, Validation Loss: 0.03451649049473546\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0H3YJP0.1/580-733',) y 154 y 165\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Epoch 2/5, Validation Loss: 0.03340156760558375\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0H3YJP0.1/580-733',) y 154 y 165\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Epoch 3/5, Validation Loss: 0.033144861373004805\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0H3YJP0.1/580-733',) y 154 y 165\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Epoch 4/5, Validation Loss: 0.033083229331943624\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0H3YJP0.1/580-733',) y 154 y 165\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Epoch 5/5, Validation Loss: 0.032923103586967935\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Test Loss: 0.033302739102169125\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "# datasets (train, validation, test)\n",
    "dataset = [(embeddings_dict[sequence.split(\"/\")[0]], conservation_scores, sequence) for sequence, conservation_scores in zip(sequences, conservation_scores_array)]\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Création des data loaders pour train, validation et test\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Définition du modèle MLP\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_size, hidden_size))\n",
    "        layers.append(nn.ReLU())\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(hidden_size, 1))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Fonction de formation\n",
    "def train_model(model, optimizer, loss_fn, data_loader):\n",
    "    model.train()\n",
    "    for embedding, label, sequence in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        embedding = embedding.squeeze()\n",
    "        label = label.squeeze()\n",
    "        if embedding.size(0) != label.size(0):\n",
    "            print(f\"La taille des tenseurs de sortie et d'étiquette ne correspond pas pour la séquence: {sequence} y {label.size(0)} y {embedding.size(0)}\")\n",
    "            continue\n",
    "        output = model(embedding).squeeze()\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Fonction d'évaluation\n",
    "def evaluate_model(model, loss_fn, data_loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for embedding, label, sequence in data_loader:\n",
    "            embedding = embedding.squeeze()\n",
    "            label = label.squeeze()\n",
    "            output = model(embedding).squeeze()\n",
    "            if embedding.size(0) != label.size(0):\n",
    "                print(f\"La taille des tenseurs de sortie et d'étiquette ne correspond pas pour la séquence: {sequence} y {label.size(0)} y {embedding.size(0)}\")\n",
    "                continue\n",
    "            loss = loss_fn(output, label)\n",
    "            running_loss += loss.item()\n",
    "    return running_loss / len(data_loader)\n",
    "\n",
    "# Initialiser le modèle, la fonction de perte et l'optimiseur avec régularisation L2\n",
    "input_size = 320  # taille d'entrée\n",
    "hidden_size = 128  # Taille des couches cachées\n",
    "num_layers = 1  # Nombre de couches cachées\n",
    "\n",
    "model = MLP(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, weight_decay=0.01)  # Ajout de weight_decay pour la régularisation L2\n",
    "\n",
    "# Entraîner le modèle\n",
    "num_epochs = 5\n",
    "val_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_model(model, optimizer, loss_fn, train_loader)\n",
    "    val_loss = evaluate_model(model, loss_fn, val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Validation Loss: {val_loss}')\n",
    "\n",
    "# Tracer la perte de validation au fil des époques\n",
    "plt.plot(val_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss over Epochs - MLP (1 hidden layer)')\n",
    "plt.show()\n",
    "\n",
    "# Évaluer finalement sur l'ensemble de test\n",
    "test_loss = evaluate_model(model, loss_fn, test_loader)\n",
    "print(f'Test Loss: {test_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e98f6df-6992-4206-8b2a-376aa8b6e57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Test Loss: 0.033302739102169125\n"
     ]
    }
   ],
   "source": [
    "# Tracer la perte de validation au fil des époques\n",
    "plt.plot(val_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss over Epochs - MLP (1 hidden layer)')\n",
    "plt.show()\n",
    "\n",
    "# Évaluer finalement sur l'ensemble de test\n",
    "test_loss = evaluate_model(model, loss_fn, test_loader)\n",
    "print(f'Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "992fb6d0-c1b5-4052-b9e9-9c43e6b6a559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label tensor([0.1895, 0.1392, 0.4331, 0.7090, 0.1962, 0.3525, 0.2404, 0.1301, 0.5806,\n",
      "        0.4275, 0.4441, 0.0877, 0.0408, 0.1643, 0.0712, 0.1196, 0.1483, 0.2057,\n",
      "        0.0948, 0.1344, 0.4429, 0.1787, 0.1471, 0.2106, 0.5684, 0.1528, 0.1416,\n",
      "        0.3682, 0.6294, 0.7212, 0.1595, 0.3403, 0.1484, 0.1157, 0.0976, 0.0660,\n",
      "        0.1108, 0.1343, 0.1460, 0.1271, 0.1802, 0.3042, 0.3430, 0.1412, 0.1547,\n",
      "        0.1012, 0.0536, 0.0513, 0.0679, 0.0481, 0.0463, 0.1147, 0.0698, 0.1017,\n",
      "        0.2759, 0.4614, 0.2451, 0.2542, 0.2045, 0.7930, 0.5654, 0.1191, 0.3953,\n",
      "        0.7373, 0.3713, 0.2377, 0.2100, 0.2649, 0.2125, 0.3452, 0.3601, 0.3538,\n",
      "        0.1548, 0.1709, 0.1646, 0.5078])\n",
      "output tensor([0.3387, 0.3373, 0.3595, 0.3900, 0.3826, 0.3893, 0.3793, 0.3510, 0.4330,\n",
      "        0.4937, 0.3617, 0.3462, 0.3688, 0.3233, 0.3268, 0.3256, 0.3543, 0.3830,\n",
      "        0.2320, 0.2483, 0.4298, 0.3625, 0.2577, 0.2964, 0.4186, 0.2653, 0.2621,\n",
      "        0.3027, 0.3959, 0.4652, 0.2655, 0.3416, 0.3186, 0.2917, 0.3749, 0.2993,\n",
      "        0.3321, 0.3144, 0.3122, 0.4006, 0.3949, 0.3613, 0.3504, 0.3018, 0.3542,\n",
      "        0.3380, 0.2939, 0.2710, 0.2377, 0.2687, 0.2863, 0.3408, 0.3212, 0.2763,\n",
      "        0.2787, 0.3495, 0.3447, 0.4897, 0.3770, 0.4681, 0.3738, 0.3801, 0.4233,\n",
      "        0.3809, 0.3120, 0.3167, 0.4195, 0.4222, 0.5059, 0.3799, 0.3318, 0.3726,\n",
      "        0.3074, 0.3646, 0.3581, 0.4410])\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Coefficient de corrélation de Pearson MLP (1 hidden layer): 0.40633106231689453\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "true_scores = []\n",
    "predicted_scores = []\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for embedding, label, sequence in test_loader:\n",
    "        count = count + 1\n",
    "        embedding = embedding.squeeze()\n",
    "        label = label.squeeze()\n",
    "        output = model(embedding).squeeze()\n",
    "        if embedding.size(0) != label.size(0):\n",
    "            print(f\"La taille des tenseurs de sortie et d'étiquette ne correspond pas pour la séquence: {sequence} y {label.size(0)} y {embedding.size(0)}\" )\n",
    "            continue\n",
    "        if count == 2:\n",
    "            print(\"label\", label)\n",
    "            print(\"output\", output)\n",
    "        true_scores.append(label)\n",
    "        predicted_scores.append(output)\n",
    "\n",
    "# Convertir les listes en tenseurs PyTorch\n",
    "true_scores_tensor = torch.cat(true_scores)\n",
    "predicted_scores_tensor = torch.cat(predicted_scores)\n",
    "\n",
    "# Calculer le coefficient de corrélation de Pearson\n",
    "pearson_corr = pearson_correlation(true_scores_tensor, predicted_scores_tensor)\n",
    "print(f\"Coefficient de corrélation de Pearson MLP (1 hidden layer): {pearson_corr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5431826-a41c-401b-86f3-09d667b21a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n",
      "Epoch 1/5, Validation Loss: 0.03617481018025359\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n",
      "Epoch 2/5, Validation Loss: 0.03486373418990564\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n",
      "Epoch 3/5, Validation Loss: 0.03424345324522224\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n",
      "Epoch 4/5, Validation Loss: 0.03393290871806221\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n",
      "Epoch 5/5, Validation Loss: 0.03382121213247868\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0H3YJP0.1/580-733',) y 154 y 165\n",
      "Test Loss: 0.03377675895559432\n"
     ]
    }
   ],
   "source": [
    "# datasets (train, validation, test)\n",
    "dataset = [(embeddings_dict[sequence.split(\"/\")[0]], conservation_scores, sequence) for sequence, conservation_scores in zip(sequences, conservation_scores_array)]\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Création des data loaders pour train, validation et test\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Définition du modèle MLP 2 couches\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_size, hidden_size))\n",
    "        layers.append(nn.ReLU())\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(hidden_size, 1))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Fonction de formation\n",
    "def train_model(model, optimizer, loss_fn, data_loader):\n",
    "    model.train()\n",
    "    for embedding, label, sequence in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        embedding = embedding.squeeze()\n",
    "        label = label.squeeze()\n",
    "        if embedding.size(0) != label.size(0):\n",
    "            print(f\"La taille des tenseurs de sortie et d'étiquette ne correspond pas pour la séquence: {sequence} y {label.size(0)} y {embedding.size(0)}\")\n",
    "            continue\n",
    "        output = model(embedding).squeeze()\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Fonction d'évaluation\n",
    "def evaluate_model(model, loss_fn, data_loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for embedding, label, sequence in data_loader:\n",
    "            embedding = embedding.squeeze()\n",
    "            label = label.squeeze()\n",
    "            output = model(embedding).squeeze()\n",
    "            if embedding.size(0) != label.size(0):\n",
    "                print(f\"La taille des tenseurs de sortie et d'étiquette ne correspond pas pour la séquence: {sequence} y {label.size(0)} y {embedding.size(0)}\")\n",
    "                continue\n",
    "            loss = loss_fn(output, label)\n",
    "            running_loss += loss.item()\n",
    "    return running_loss / len(data_loader)\n",
    "\n",
    "# Initialiser le modèle, la fonction de perte et l'optimiseur avec régularisation L2\n",
    "input_size = 320  # taille d'entrée\n",
    "hidden_size = 128  # Taille des couches cachées\n",
    "num_layers = 2  # Nombre de couches cachées\n",
    "\n",
    "model = MLP(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, weight_decay=0.01)  # Ajout de weight_decay pour la régularisation L2\n",
    "\n",
    "# Entraîner le modèle\n",
    "num_epochs = 5\n",
    "val_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_model(model, optimizer, loss_fn, train_loader)\n",
    "    val_loss = evaluate_model(model, loss_fn, val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Validation Loss: {val_loss}')\n",
    "\n",
    "# Tracer la perte de validation au fil des époques\n",
    "plt.plot(val_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss over Epochs - MLP (2 hidden layer)')\n",
    "plt.show()\n",
    "\n",
    "# Évaluer finalement sur l'ensemble de test\n",
    "test_loss = evaluate_model(model, loss_fn, test_loader)\n",
    "print(f'Test Loss: {test_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e42cf466-6ab0-4f88-a344-9daaf3599b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label tensor([0.1192, 0.2942, 0.2644, 0.2759, 0.2583, 0.6729, 0.3403, 0.2949, 0.2776,\n",
      "        0.3772, 0.2229, 0.3069, 0.5059, 0.1797, 0.2725, 0.4180, 0.6069, 0.1851,\n",
      "        0.3726, 0.5220, 0.2366, 0.5786, 0.7217, 0.6221, 0.5518, 0.6655, 0.7808,\n",
      "        0.3953, 0.6025, 0.5591, 0.3220, 0.3760, 0.3032, 0.1036, 0.2534, 0.3162,\n",
      "        0.1393, 0.2373, 0.0892, 0.0717, 0.2301, 0.5576, 0.3276, 0.4390, 0.3542,\n",
      "        0.5142, 0.4094, 0.4402, 0.6978, 0.3301, 0.3635, 0.7520, 0.1649, 0.2974,\n",
      "        0.4355, 0.4287, 0.6250, 0.3628, 0.5947, 0.7178, 0.1687, 0.2561, 0.2485,\n",
      "        0.6318, 0.3960, 0.3008, 0.2256, 0.2515, 0.5752, 0.4617, 0.5840, 0.3450,\n",
      "        0.7671, 0.4602, 0.4456, 0.3684, 0.7104, 0.3367, 0.3176, 0.2932, 0.2145,\n",
      "        0.2015])\n",
      "output tensor([0.4310, 0.4090, 0.3828, 0.4218, 0.3753, 0.3890, 0.3782, 0.3600, 0.3780,\n",
      "        0.3638, 0.3733, 0.3649, 0.3629, 0.3326, 0.3800, 0.3170, 0.3177, 0.3032,\n",
      "        0.3134, 0.2826, 0.2436, 0.2910, 0.3437, 0.3048, 0.2671, 0.3041, 0.3230,\n",
      "        0.2603, 0.3236, 0.3275, 0.3195, 0.3178, 0.3601, 0.3524, 0.3198, 0.3067,\n",
      "        0.3483, 0.3620, 0.3839, 0.3879, 0.3993, 0.4337, 0.3978, 0.3554, 0.3841,\n",
      "        0.4242, 0.3727, 0.3387, 0.4392, 0.3753, 0.3784, 0.3594, 0.3109, 0.3178,\n",
      "        0.3522, 0.3148, 0.2940, 0.3256, 0.3476, 0.3427, 0.2445, 0.2605, 0.3138,\n",
      "        0.3422, 0.3056, 0.3135, 0.3508, 0.3639, 0.3796, 0.4181, 0.4300, 0.3633,\n",
      "        0.4348, 0.4259, 0.3971, 0.3725, 0.4237, 0.3572, 0.3482, 0.3926, 0.4288,\n",
      "        0.4051])\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0H3YJP0.1/580-733',) y 154 y 165\n",
      "Coefficient de corrélation de Pearson MLP (2 hidden layer): 0.39481592178344727\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "true_scores = []\n",
    "predicted_scores = []\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for embedding, label, sequence in test_loader:\n",
    "        count = count + 1\n",
    "        embedding = embedding.squeeze()\n",
    "        label = label.squeeze()\n",
    "        output = model(embedding).squeeze()\n",
    "        if embedding.size(0) != label.size(0):\n",
    "            print(f\"La taille des tenseurs de sortie et d'étiquette ne correspond pas pour la séquence: {sequence} y {label.size(0)} y {embedding.size(0)}\" )\n",
    "            continue\n",
    "        if count == 2:\n",
    "            print(\"label\", label)\n",
    "            print(\"output\", output)\n",
    "        true_scores.append(label)\n",
    "        predicted_scores.append(output)\n",
    "\n",
    "# Convertir les listes en tenseurs PyTorch\n",
    "true_scores_tensor = torch.cat(true_scores)\n",
    "predicted_scores_tensor = torch.cat(predicted_scores)\n",
    "\n",
    "# Calculer le coefficient de corrélation de Pearson\n",
    "pearson_corr = pearson_correlation(true_scores_tensor, predicted_scores_tensor)\n",
    "print(f\"Coefficient de corrélation de Pearson MLP (2 hidden layer): {pearson_corr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89f26e8c-16c5-4057-be2e-1ea57f12d66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([105])) that is different to the input size (torch.Size([105, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([94])) that is different to the input size (torch.Size([94, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([36])) that is different to the input size (torch.Size([36, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([160])) that is different to the input size (torch.Size([160, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([203])) that is different to the input size (torch.Size([203, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([229])) that is different to the input size (torch.Size([229, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([70])) that is different to the input size (torch.Size([70, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([97])) that is different to the input size (torch.Size([97, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([72])) that is different to the input size (torch.Size([72, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([84])) that is different to the input size (torch.Size([84, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([30])) that is different to the input size (torch.Size([30, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([55])) that is different to the input size (torch.Size([55, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([106])) that is different to the input size (torch.Size([106, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([121])) that is different to the input size (torch.Size([121, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([117])) that is different to the input size (torch.Size([117, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([60])) that is different to the input size (torch.Size([60, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([78])) that is different to the input size (torch.Size([78, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([133])) that is different to the input size (torch.Size([133, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([217])) that is different to the input size (torch.Size([217, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([23])) that is different to the input size (torch.Size([23, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([363])) that is different to the input size (torch.Size([363, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([183])) that is different to the input size (torch.Size([183, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([47])) that is different to the input size (torch.Size([47, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([390])) that is different to the input size (torch.Size([390, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([75])) that is different to the input size (torch.Size([75, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([124])) that is different to the input size (torch.Size([124, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([299])) that is different to the input size (torch.Size([299, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([236])) that is different to the input size (torch.Size([236, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([144])) that is different to the input size (torch.Size([144, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([221])) that is different to the input size (torch.Size([221, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([155])) that is different to the input size (torch.Size([155, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([115])) that is different to the input size (torch.Size([115, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([266])) that is different to the input size (torch.Size([266, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([91])) that is different to the input size (torch.Size([91, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([326])) that is different to the input size (torch.Size([326, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([192])) that is different to the input size (torch.Size([192, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([48])) that is different to the input size (torch.Size([48, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([59])) that is different to the input size (torch.Size([59, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([210])) that is different to the input size (torch.Size([210, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([22])) that is different to the input size (torch.Size([22, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([333])) that is different to the input size (torch.Size([333, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([208])) that is different to the input size (torch.Size([208, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([101])) that is different to the input size (torch.Size([101, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([79])) that is different to the input size (torch.Size([79, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([798])) that is different to the input size (torch.Size([798, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([834])) that is different to the input size (torch.Size([834, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([46])) that is different to the input size (torch.Size([46, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([464])) that is different to the input size (torch.Size([464, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([177])) that is different to the input size (torch.Size([177, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([142])) that is different to the input size (torch.Size([142, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([156])) that is different to the input size (torch.Size([156, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([824])) that is different to the input size (torch.Size([824, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([112])) that is different to the input size (torch.Size([112, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([170])) that is different to the input size (torch.Size([170, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([53])) that is different to the input size (torch.Size([53, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([81])) that is different to the input size (torch.Size([81, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([189])) that is different to the input size (torch.Size([189, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([116])) that is different to the input size (torch.Size([116, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([469])) that is different to the input size (torch.Size([469, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([316])) that is different to the input size (torch.Size([316, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([24])) that is different to the input size (torch.Size([24, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([99])) that is different to the input size (torch.Size([99, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([154])) that is different to the input size (torch.Size([154, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([324])) that is different to the input size (torch.Size([324, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([49])) that is different to the input size (torch.Size([49, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([195])) that is different to the input size (torch.Size([195, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([289])) that is different to the input size (torch.Size([289, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([134])) that is different to the input size (torch.Size([134, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([257])) that is different to the input size (torch.Size([257, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([62])) that is different to the input size (torch.Size([62, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([95])) that is different to the input size (torch.Size([95, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([73])) that is different to the input size (torch.Size([73, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([26])) that is different to the input size (torch.Size([26, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([149])) that is different to the input size (torch.Size([149, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([442])) that is different to the input size (torch.Size([442, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([244])) that is different to the input size (torch.Size([244, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([143])) that is different to the input size (torch.Size([143, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([103])) that is different to the input size (torch.Size([103, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([209])) that is different to the input size (torch.Size([209, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([85])) that is different to the input size (torch.Size([85, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([470])) that is different to the input size (torch.Size([470, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([230])) that is different to the input size (torch.Size([230, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([83])) that is different to the input size (torch.Size([83, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([114])) that is different to the input size (torch.Size([114, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([147])) that is different to the input size (torch.Size([147, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([169])) that is different to the input size (torch.Size([169, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([123])) that is different to the input size (torch.Size([123, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([258])) that is different to the input size (torch.Size([258, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([130])) that is different to the input size (torch.Size([130, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([168])) that is different to the input size (torch.Size([168, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([304])) that is different to the input size (torch.Size([304, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([146])) that is different to the input size (torch.Size([146, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([87])) that is different to the input size (torch.Size([87, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([58])) that is different to the input size (torch.Size([58, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([40])) that is different to the input size (torch.Size([40, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([197])) that is different to the input size (torch.Size([197, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([71])) that is different to the input size (torch.Size([71, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([296])) that is different to the input size (torch.Size([296, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([39])) that is different to the input size (torch.Size([39, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([185])) that is different to the input size (torch.Size([185, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([372])) that is different to the input size (torch.Size([372, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([45])) that is different to the input size (torch.Size([45, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([126])) that is different to the input size (torch.Size([126, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([89])) that is different to the input size (torch.Size([89, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([325])) that is different to the input size (torch.Size([325, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([163])) that is different to the input size (torch.Size([163, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([227])) that is different to the input size (torch.Size([227, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([69])) that is different to the input size (torch.Size([69, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([268])) that is different to the input size (torch.Size([268, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([190])) that is different to the input size (torch.Size([190, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([651])) that is different to the input size (torch.Size([651, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([504])) that is different to the input size (torch.Size([504, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([540])) that is different to the input size (torch.Size([540, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([161])) that is different to the input size (torch.Size([161, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([88])) that is different to the input size (torch.Size([88, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([498])) that is different to the input size (torch.Size([498, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([383])) that is different to the input size (torch.Size([383, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([239])) that is different to the input size (torch.Size([239, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([113])) that is different to the input size (torch.Size([113, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([76])) that is different to the input size (torch.Size([76, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([232])) that is different to the input size (torch.Size([232, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([111])) that is different to the input size (torch.Size([111, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([173])) that is different to the input size (torch.Size([173, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([248])) that is different to the input size (torch.Size([248, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200])) that is different to the input size (torch.Size([200, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([57])) that is different to the input size (torch.Size([57, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([37])) that is different to the input size (torch.Size([37, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([405])) that is different to the input size (torch.Size([405, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([38])) that is different to the input size (torch.Size([38, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([202])) that is different to the input size (torch.Size([202, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([120])) that is different to the input size (torch.Size([120, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([50])) that is different to the input size (torch.Size([50, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([220])) that is different to the input size (torch.Size([220, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([223])) that is different to the input size (torch.Size([223, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([281])) that is different to the input size (torch.Size([281, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([199])) that is different to the input size (torch.Size([199, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([276])) that is different to the input size (torch.Size([276, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([252])) that is different to the input size (torch.Size([252, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([648])) that is different to the input size (torch.Size([648, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([201])) that is different to the input size (torch.Size([201, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([151])) that is different to the input size (torch.Size([151, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([294])) that is different to the input size (torch.Size([294, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([157])) that is different to the input size (torch.Size([157, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([342])) that is different to the input size (torch.Size([342, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([90])) that is different to the input size (torch.Size([90, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([466])) that is different to the input size (torch.Size([466, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([511])) that is different to the input size (torch.Size([511, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([219])) that is different to the input size (torch.Size([219, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([180])) that is different to the input size (torch.Size([180, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([178])) that is different to the input size (torch.Size([178, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([319])) that is different to the input size (torch.Size([319, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([102])) that is different to the input size (torch.Size([102, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([98])) that is different to the input size (torch.Size([98, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([213])) that is different to the input size (torch.Size([213, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([67])) that is different to the input size (torch.Size([67, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([557])) that is different to the input size (torch.Size([557, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([182])) that is different to the input size (torch.Size([182, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([288])) that is different to the input size (torch.Size([288, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([243])) that is different to the input size (torch.Size([243, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([271])) that is different to the input size (torch.Size([271, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([159])) that is different to the input size (torch.Size([159, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([92])) that is different to the input size (torch.Size([92, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([440])) that is different to the input size (torch.Size([440, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([306])) that is different to the input size (torch.Size([306, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([158])) that is different to the input size (torch.Size([158, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([414])) that is different to the input size (torch.Size([414, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([110])) that is different to the input size (torch.Size([110, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([825])) that is different to the input size (torch.Size([825, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([516])) that is different to the input size (torch.Size([516, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([418])) that is different to the input size (torch.Size([418, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([242])) that is different to the input size (torch.Size([242, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([579])) that is different to the input size (torch.Size([579, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([245])) that is different to the input size (torch.Size([245, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([107])) that is different to the input size (torch.Size([107, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([43])) that is different to the input size (torch.Size([43, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([164])) that is different to the input size (torch.Size([164, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([132])) that is different to the input size (torch.Size([132, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([238])) that is different to the input size (torch.Size([238, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([416])) that is different to the input size (torch.Size([416, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([137])) that is different to the input size (torch.Size([137, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([413])) that is different to the input size (torch.Size([413, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([66])) that is different to the input size (torch.Size([66, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([303])) that is different to the input size (torch.Size([303, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([246])) that is different to the input size (torch.Size([246, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([77])) that is different to the input size (torch.Size([77, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([352])) that is different to the input size (torch.Size([352, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([108])) that is different to the input size (torch.Size([108, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([368])) that is different to the input size (torch.Size([368, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([135])) that is different to the input size (torch.Size([135, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([15])) that is different to the input size (torch.Size([15, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([44])) that is different to the input size (torch.Size([44, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([82])) that is different to the input size (torch.Size([82, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([80])) that is different to the input size (torch.Size([80, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([140])) that is different to the input size (torch.Size([140, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([349])) that is different to the input size (torch.Size([349, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([129])) that is different to the input size (torch.Size([129, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([222])) that is different to the input size (torch.Size([222, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([424])) that is different to the input size (torch.Size([424, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([300])) that is different to the input size (torch.Size([300, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([35])) that is different to the input size (torch.Size([35, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([394])) that is different to the input size (torch.Size([394, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([63])) that is different to the input size (torch.Size([63, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([274])) that is different to the input size (torch.Size([274, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([68])) that is different to the input size (torch.Size([68, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([272])) that is different to the input size (torch.Size([272, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([153])) that is different to the input size (torch.Size([153, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([206])) that is different to the input size (torch.Size([206, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([439])) that is different to the input size (torch.Size([439, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([51])) that is different to the input size (torch.Size([51, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([307])) that is different to the input size (torch.Size([307, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([460])) that is different to the input size (torch.Size([460, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([273])) that is different to the input size (torch.Size([273, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([131])) that is different to the input size (torch.Size([131, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([396])) that is different to the input size (torch.Size([396, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([264])) that is different to the input size (torch.Size([264, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([184])) that is different to the input size (torch.Size([184, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([353])) that is different to the input size (torch.Size([353, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([366])) that is different to the input size (torch.Size([366, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([86])) that is different to the input size (torch.Size([86, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([386])) that is different to the input size (torch.Size([386, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([194])) that is different to the input size (torch.Size([194, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([435])) that is different to the input size (torch.Size([435, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([323])) that is different to the input size (torch.Size([323, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([193])) that is different to the input size (torch.Size([193, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([665])) that is different to the input size (torch.Size([665, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([127])) that is different to the input size (torch.Size([127, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([175])) that is different to the input size (torch.Size([175, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([269])) that is different to the input size (torch.Size([269, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([52])) that is different to the input size (torch.Size([52, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([96])) that is different to the input size (torch.Size([96, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([925])) that is different to the input size (torch.Size([925, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([292])) that is different to the input size (torch.Size([292, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([237])) that is different to the input size (torch.Size([237, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([136])) that is different to the input size (torch.Size([136, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([148])) that is different to the input size (torch.Size([148, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([28])) that is different to the input size (torch.Size([28, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([204])) that is different to the input size (torch.Size([204, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([179])) that is different to the input size (torch.Size([179, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([224])) that is different to the input size (torch.Size([224, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([186])) that is different to the input size (torch.Size([186, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([93])) that is different to the input size (torch.Size([93, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([118])) that is different to the input size (torch.Size([118, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([74])) that is different to the input size (torch.Size([74, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([291])) that is different to the input size (torch.Size([291, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([344])) that is different to the input size (torch.Size([344, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([42])) that is different to the input size (torch.Size([42, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([139])) that is different to the input size (torch.Size([139, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([235])) that is different to the input size (torch.Size([235, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([341])) that is different to the input size (torch.Size([341, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([247])) that is different to the input size (torch.Size([247, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([280])) that is different to the input size (torch.Size([280, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([172])) that is different to the input size (torch.Size([172, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([226])) that is different to the input size (torch.Size([226, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([188])) that is different to the input size (torch.Size([188, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([216])) that is different to the input size (torch.Size([216, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([181])) that is different to the input size (torch.Size([181, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([760])) that is different to the input size (torch.Size([760, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([251])) that is different to the input size (torch.Size([251, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([119])) that is different to the input size (torch.Size([119, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([65])) that is different to the input size (torch.Size([65, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([864])) that is different to the input size (torch.Size([864, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([312])) that is different to the input size (torch.Size([312, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([317])) that is different to the input size (torch.Size([317, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([29])) that is different to the input size (torch.Size([29, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([145])) that is different to the input size (torch.Size([145, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([109])) that is different to the input size (torch.Size([109, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([380])) that is different to the input size (torch.Size([380, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([441])) that is different to the input size (torch.Size([441, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([104])) that is different to the input size (torch.Size([104, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([371])) that is different to the input size (torch.Size([371, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([635])) that is different to the input size (torch.Size([635, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([187])) that is different to the input size (torch.Size([187, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([941])) that is different to the input size (torch.Size([941, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([351])) that is different to the input size (torch.Size([351, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([428])) that is different to the input size (torch.Size([428, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([165])) that is different to the input size (torch.Size([165, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([253])) that is different to the input size (torch.Size([253, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([152])) that is different to the input size (torch.Size([152, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([263])) that is different to the input size (torch.Size([263, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([284])) that is different to the input size (torch.Size([284, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([25])) that is different to the input size (torch.Size([25, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([162])) that is different to the input size (torch.Size([162, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([331])) that is different to the input size (torch.Size([331, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([125])) that is different to the input size (torch.Size([125, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([191])) that is different to the input size (torch.Size([191, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([141])) that is different to the input size (torch.Size([141, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([479])) that is different to the input size (torch.Size([479, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([355])) that is different to the input size (torch.Size([355, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([310])) that is different to the input size (torch.Size([310, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([430])) that is different to the input size (torch.Size([430, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([313])) that is different to the input size (torch.Size([313, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([250])) that is different to the input size (torch.Size([250, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([211])) that is different to the input size (torch.Size([211, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([354])) that is different to the input size (torch.Size([354, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([212])) that is different to the input size (torch.Size([212, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([196])) that is different to the input size (torch.Size([196, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([512])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([241])) that is different to the input size (torch.Size([241, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([41])) that is different to the input size (torch.Size([41, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([726])) that is different to the input size (torch.Size([726, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([260])) that is different to the input size (torch.Size([260, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([176])) that is different to the input size (torch.Size([176, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([522])) that is different to the input size (torch.Size([522, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([295])) that is different to the input size (torch.Size([295, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([846])) that is different to the input size (torch.Size([846, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([668])) that is different to the input size (torch.Size([668, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([309])) that is different to the input size (torch.Size([309, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([279])) that is different to the input size (torch.Size([279, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([27])) that is different to the input size (torch.Size([27, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([174])) that is different to the input size (torch.Size([174, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([376])) that is different to the input size (torch.Size([376, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([421])) that is different to the input size (torch.Size([421, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([240])) that is different to the input size (torch.Size([240, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([61])) that is different to the input size (torch.Size([61, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([225])) that is different to the input size (torch.Size([225, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([215])) that is different to the input size (torch.Size([215, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([286])) that is different to the input size (torch.Size([286, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([138])) that is different to the input size (torch.Size([138, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([327])) that is different to the input size (torch.Size([327, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([166])) that is different to the input size (torch.Size([166, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([278])) that is different to the input size (torch.Size([278, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([167])) that is different to the input size (torch.Size([167, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([54])) that is different to the input size (torch.Size([54, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([275])) that is different to the input size (torch.Size([275, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([234])) that is different to the input size (torch.Size([234, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([122])) that is different to the input size (torch.Size([122, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([207])) that is different to the input size (torch.Size([207, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([398])) that is different to the input size (torch.Size([398, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([346])) that is different to the input size (torch.Size([346, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([270])) that is different to the input size (torch.Size([270, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([33])) that is different to the input size (torch.Size([33, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([311])) that is different to the input size (torch.Size([311, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([536])) that is different to the input size (torch.Size([536, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([879])) that is different to the input size (torch.Size([879, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([231])) that is different to the input size (torch.Size([231, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([198])) that is different to the input size (torch.Size([198, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([298])) that is different to the input size (torch.Size([298, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([262])) that is different to the input size (torch.Size([262, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([518])) that is different to the input size (torch.Size([518, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([361])) that is different to the input size (torch.Size([361, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([419])) that is different to the input size (torch.Size([419, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([843])) that is different to the input size (torch.Size([843, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([301])) that is different to the input size (torch.Size([301, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([337])) that is different to the input size (torch.Size([337, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([431])) that is different to the input size (torch.Size([431, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([285])) that is different to the input size (torch.Size([285, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([388])) that is different to the input size (torch.Size([388, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([282])) that is different to the input size (torch.Size([282, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([34])) that is different to the input size (torch.Size([34, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([233])) that is different to the input size (torch.Size([233, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([259])) that is different to the input size (torch.Size([259, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([730])) that is different to the input size (torch.Size([730, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([384])) that is different to the input size (torch.Size([384, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([528])) that is different to the input size (torch.Size([528, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([586])) that is different to the input size (torch.Size([586, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([332])) that is different to the input size (torch.Size([332, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([395])) that is different to the input size (torch.Size([395, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([265])) that is different to the input size (torch.Size([265, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([367])) that is different to the input size (torch.Size([367, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([254])) that is different to the input size (torch.Size([254, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([359])) that is different to the input size (torch.Size([359, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([336])) that is different to the input size (torch.Size([336, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([402])) that is different to the input size (torch.Size([402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([436])) that is different to the input size (torch.Size([436, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([267])) that is different to the input size (torch.Size([267, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([445])) that is different to the input size (torch.Size([445, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([468])) that is different to the input size (torch.Size([468, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([214])) that is different to the input size (torch.Size([214, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([505])) that is different to the input size (torch.Size([505, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([381])) that is different to the input size (torch.Size([381, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([495])) that is different to the input size (torch.Size([495, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([362])) that is different to the input size (torch.Size([362, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([443])) that is different to the input size (torch.Size([443, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([438])) that is different to the input size (torch.Size([438, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([297])) that is different to the input size (torch.Size([297, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([467])) that is different to the input size (torch.Size([467, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([423])) that is different to the input size (torch.Size([423, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([338])) that is different to the input size (torch.Size([338, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([283])) that is different to the input size (torch.Size([283, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([287])) that is different to the input size (torch.Size([287, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([249])) that is different to the input size (torch.Size([249, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([558])) that is different to the input size (torch.Size([558, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([378])) that is different to the input size (torch.Size([378, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([205])) that is different to the input size (torch.Size([205, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([463])) that is different to the input size (torch.Size([463, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([261])) that is different to the input size (torch.Size([261, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([387])) that is different to the input size (torch.Size([387, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([302])) that is different to the input size (torch.Size([302, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([425])) that is different to the input size (torch.Size([425, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([31])) that is different to the input size (torch.Size([31, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([347])) that is different to the input size (torch.Size([347, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([218])) that is different to the input size (torch.Size([218, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([364])) that is different to the input size (torch.Size([364, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([369])) that is different to the input size (torch.Size([369, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([487])) that is different to the input size (torch.Size([487, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([534])) that is different to the input size (torch.Size([534, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([348])) that is different to the input size (torch.Size([348, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([455])) that is different to the input size (torch.Size([455, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([293])) that is different to the input size (torch.Size([293, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([661])) that is different to the input size (torch.Size([661, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([322])) that is different to the input size (torch.Size([322, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([330])) that is different to the input size (torch.Size([330, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([663])) that is different to the input size (torch.Size([663, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([404])) that is different to the input size (torch.Size([404, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([365])) that is different to the input size (torch.Size([365, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([639])) that is different to the input size (torch.Size([639, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([339])) that is different to the input size (torch.Size([339, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([308])) that is different to the input size (torch.Size([308, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([703])) that is different to the input size (torch.Size([703, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([409])) that is different to the input size (torch.Size([409, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([472])) that is different to the input size (torch.Size([472, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([377])) that is different to the input size (torch.Size([377, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([707])) that is different to the input size (torch.Size([707, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([290])) that is different to the input size (torch.Size([290, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([320])) that is different to the input size (torch.Size([320, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([379])) that is different to the input size (torch.Size([379, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([462])) that is different to the input size (torch.Size([462, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([328])) that is different to the input size (torch.Size([328, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([358])) that is different to the input size (torch.Size([358, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([551])) that is different to the input size (torch.Size([551, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([503])) that is different to the input size (torch.Size([503, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([447])) that is different to the input size (torch.Size([447, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([717])) that is different to the input size (torch.Size([717, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([318])) that is different to the input size (torch.Size([318, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([494])) that is different to the input size (torch.Size([494, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([450])) that is different to the input size (torch.Size([450, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([434])) that is different to the input size (torch.Size([434, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([437])) that is different to the input size (torch.Size([437, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([535])) that is different to the input size (torch.Size([535, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([19])) that is different to the input size (torch.Size([19, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([655])) that is different to the input size (torch.Size([655, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([488])) that is different to the input size (torch.Size([488, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([863])) that is different to the input size (torch.Size([863, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([406])) that is different to the input size (torch.Size([406, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([499])) that is different to the input size (torch.Size([499, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([399])) that is different to the input size (torch.Size([399, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([373])) that is different to the input size (torch.Size([373, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([851])) that is different to the input size (torch.Size([851, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([486])) that is different to the input size (torch.Size([486, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([403])) that is different to the input size (torch.Size([403, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([277])) that is different to the input size (torch.Size([277, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([617])) that is different to the input size (torch.Size([617, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([370])) that is different to the input size (torch.Size([370, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([643])) that is different to the input size (torch.Size([643, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([484])) that is different to the input size (torch.Size([484, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([517])) that is different to the input size (torch.Size([517, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([570])) that is different to the input size (torch.Size([570, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([595])) that is different to the input size (torch.Size([595, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([427])) that is different to the input size (torch.Size([427, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([411])) that is different to the input size (torch.Size([411, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([426])) that is different to the input size (torch.Size([426, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([544])) that is different to the input size (torch.Size([544, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([315])) that is different to the input size (torch.Size([315, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([452])) that is different to the input size (torch.Size([452, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([497])) that is different to the input size (torch.Size([497, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([791])) that is different to the input size (torch.Size([791, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([389])) that is different to the input size (torch.Size([389, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([638])) that is different to the input size (torch.Size([638, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([947])) that is different to the input size (torch.Size([947, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([432])) that is different to the input size (torch.Size([432, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([335])) that is different to the input size (torch.Size([335, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([255])) that is different to the input size (torch.Size([255, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([506])) that is different to the input size (torch.Size([506, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([453])) that is different to the input size (torch.Size([453, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([401])) that is different to the input size (torch.Size([401, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([650])) that is different to the input size (torch.Size([650, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([853])) that is different to the input size (torch.Size([853, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([382])) that is different to the input size (torch.Size([382, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([415])) that is different to the input size (torch.Size([415, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([489])) that is different to the input size (torch.Size([489, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([356])) that is different to the input size (torch.Size([356, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([343])) that is different to the input size (torch.Size([343, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([228])) that is different to the input size (torch.Size([228, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([305])) that is different to the input size (torch.Size([305, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([446])) that is different to the input size (torch.Size([446, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([475])) that is different to the input size (torch.Size([475, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([473])) that is different to the input size (torch.Size([473, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([444])) that is different to the input size (torch.Size([444, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([547])) that is different to the input size (torch.Size([547, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([457])) that is different to the input size (torch.Size([457, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([559])) that is different to the input size (torch.Size([559, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([673])) that is different to the input size (torch.Size([673, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([374])) that is different to the input size (torch.Size([374, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([400])) that is different to the input size (torch.Size([400, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1009])) that is different to the input size (torch.Size([1009, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([465])) that is different to the input size (torch.Size([465, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([408])) that is different to the input size (torch.Size([408, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([357])) that is different to the input size (torch.Size([357, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([483])) that is different to the input size (torch.Size([483, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([449])) that is different to the input size (torch.Size([449, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([616])) that is different to the input size (torch.Size([616, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([482])) that is different to the input size (torch.Size([482, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([901])) that is different to the input size (torch.Size([901, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([490])) that is different to the input size (torch.Size([490, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([422])) that is different to the input size (torch.Size([422, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([708])) that is different to the input size (torch.Size([708, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([599])) that is different to the input size (torch.Size([599, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([393])) that is different to the input size (torch.Size([393, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([716])) that is different to the input size (torch.Size([716, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([613])) that is different to the input size (torch.Size([613, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([420])) that is different to the input size (torch.Size([420, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([672])) that is different to the input size (torch.Size([672, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([502])) that is different to the input size (torch.Size([502, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([546])) that is different to the input size (torch.Size([546, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([721])) that is different to the input size (torch.Size([721, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([689])) that is different to the input size (torch.Size([689, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([345])) that is different to the input size (torch.Size([345, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([576])) that is different to the input size (torch.Size([576, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([480])) that is different to the input size (torch.Size([480, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([880])) that is different to the input size (torch.Size([880, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([566])) that is different to the input size (torch.Size([566, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1022])) that is different to the input size (torch.Size([1022, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([691])) that is different to the input size (torch.Size([691, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([744])) that is different to the input size (torch.Size([744, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([631])) that is different to the input size (torch.Size([631, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([391])) that is different to the input size (torch.Size([391, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([360])) that is different to the input size (torch.Size([360, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([587])) that is different to the input size (torch.Size([587, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([456])) that is different to the input size (torch.Size([456, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([611])) that is different to the input size (torch.Size([611, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([481])) that is different to the input size (torch.Size([481, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([681])) that is different to the input size (torch.Size([681, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([804])) that is different to the input size (torch.Size([804, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([451])) that is different to the input size (torch.Size([451, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([612])) that is different to the input size (torch.Size([612, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([454])) that is different to the input size (torch.Size([454, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([636])) that is different to the input size (torch.Size([636, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([477])) that is different to the input size (torch.Size([477, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([392])) that is different to the input size (torch.Size([392, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([340])) that is different to the input size (torch.Size([340, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([757])) that is different to the input size (torch.Size([757, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([397])) that is different to the input size (torch.Size([397, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([526])) that is different to the input size (torch.Size([526, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([908])) that is different to the input size (torch.Size([908, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([660])) that is different to the input size (torch.Size([660, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([385])) that is different to the input size (torch.Size([385, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([496])) that is different to the input size (torch.Size([496, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([329])) that is different to the input size (torch.Size([329, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([375])) that is different to the input size (torch.Size([375, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([513])) that is different to the input size (torch.Size([513, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([658])) that is different to the input size (torch.Size([658, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([585])) that is different to the input size (torch.Size([585, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([555])) that is different to the input size (torch.Size([555, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([433])) that is different to the input size (torch.Size([433, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([580])) that is different to the input size (torch.Size([580, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([417])) that is different to the input size (torch.Size([417, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([750])) that is different to the input size (torch.Size([750, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([684])) that is different to the input size (torch.Size([684, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([448])) that is different to the input size (torch.Size([448, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([492])) that is different to the input size (torch.Size([492, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([458])) that is different to the input size (torch.Size([458, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([510])) that is different to the input size (torch.Size([510, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([831])) that is different to the input size (torch.Size([831, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([857])) that is different to the input size (torch.Size([857, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([476])) that is different to the input size (torch.Size([476, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([562])) that is different to the input size (torch.Size([562, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([574])) that is different to the input size (torch.Size([574, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([509])) that is different to the input size (torch.Size([509, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([575])) that is different to the input size (torch.Size([575, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([429])) that is different to the input size (torch.Size([429, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([412])) that is different to the input size (torch.Size([412, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([321])) that is different to the input size (torch.Size([321, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([501])) that is different to the input size (torch.Size([501, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([627])) that is different to the input size (torch.Size([627, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([474])) that is different to the input size (torch.Size([474, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([548])) that is different to the input size (torch.Size([548, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([525])) that is different to the input size (torch.Size([525, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([583])) that is different to the input size (torch.Size([583, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([529])) that is different to the input size (torch.Size([529, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([869])) that is different to the input size (torch.Size([869, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([671])) that is different to the input size (torch.Size([671, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([628])) that is different to the input size (torch.Size([628, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([9])) that is different to the input size (torch.Size([9, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([524])) that is different to the input size (torch.Size([524, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([410])) that is different to the input size (torch.Size([410, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([670])) that is different to the input size (torch.Size([670, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([553])) that is different to the input size (torch.Size([553, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([532])) that is different to the input size (torch.Size([532, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([519])) that is different to the input size (torch.Size([519, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([605])) that is different to the input size (torch.Size([605, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([623])) that is different to the input size (torch.Size([623, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([514])) that is different to the input size (torch.Size([514, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([17])) that is different to the input size (torch.Size([17, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([314])) that is different to the input size (torch.Size([314, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([632])) that is different to the input size (torch.Size([632, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([873])) that is different to the input size (torch.Size([873, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([776])) that is different to the input size (torch.Size([776, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([629])) that is different to the input size (torch.Size([629, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([543])) that is different to the input size (torch.Size([543, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([407])) that is different to the input size (torch.Size([407, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([350])) that is different to the input size (torch.Size([350, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([563])) that is different to the input size (torch.Size([563, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([624])) that is different to the input size (torch.Size([624, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([645])) that is different to the input size (torch.Size([645, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([527])) that is different to the input size (torch.Size([527, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([520])) that is different to the input size (torch.Size([520, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([334])) that is different to the input size (torch.Size([334, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([461])) that is different to the input size (torch.Size([461, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([764])) that is different to the input size (torch.Size([764, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([556])) that is different to the input size (torch.Size([556, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([549])) that is different to the input size (torch.Size([549, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([545])) that is different to the input size (torch.Size([545, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([759])) that is different to the input size (torch.Size([759, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([789])) that is different to the input size (torch.Size([789, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([589])) that is different to the input size (torch.Size([589, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([539])) that is different to the input size (torch.Size([539, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([608])) that is different to the input size (torch.Size([608, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([591])) that is different to the input size (torch.Size([591, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([662])) that is different to the input size (torch.Size([662, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([459])) that is different to the input size (torch.Size([459, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([657])) that is different to the input size (torch.Size([657, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([821])) that is different to the input size (torch.Size([821, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1001])) that is different to the input size (torch.Size([1001, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([701])) that is different to the input size (torch.Size([701, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([727])) that is different to the input size (torch.Size([727, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([833])) that is different to the input size (torch.Size([833, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([493])) that is different to the input size (torch.Size([493, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([538])) that is different to the input size (torch.Size([538, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([633])) that is different to the input size (torch.Size([633, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([835])) that is different to the input size (torch.Size([835, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([619])) that is different to the input size (torch.Size([619, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([584])) that is different to the input size (torch.Size([584, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([507])) that is different to the input size (torch.Size([507, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([922])) that is different to the input size (torch.Size([922, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([565])) that is different to the input size (torch.Size([565, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([912])) that is different to the input size (torch.Size([912, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([924])) that is different to the input size (torch.Size([924, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([614])) that is different to the input size (torch.Size([614, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([644])) that is different to the input size (torch.Size([644, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([842])) that is different to the input size (torch.Size([842, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([723])) that is different to the input size (torch.Size([723, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([688])) that is different to the input size (torch.Size([688, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([748])) that is different to the input size (torch.Size([748, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([552])) that is different to the input size (torch.Size([552, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([828])) that is different to the input size (torch.Size([828, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([866])) that is different to the input size (torch.Size([866, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([999])) that is different to the input size (torch.Size([999, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([531])) that is different to the input size (torch.Size([531, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([569])) that is different to the input size (torch.Size([569, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([706])) that is different to the input size (torch.Size([706, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([609])) that is different to the input size (torch.Size([609, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([808])) that is different to the input size (torch.Size([808, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([523])) that is different to the input size (torch.Size([523, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1012])) that is different to the input size (torch.Size([1012, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([830])) that is different to the input size (torch.Size([830, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([704])) that is different to the input size (torch.Size([704, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([508])) that is different to the input size (torch.Size([508, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([714])) that is different to the input size (torch.Size([714, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([618])) that is different to the input size (torch.Size([618, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([485])) that is different to the input size (torch.Size([485, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([994])) that is different to the input size (torch.Size([994, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([710])) that is different to the input size (torch.Size([710, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([530])) that is different to the input size (torch.Size([530, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([654])) that is different to the input size (torch.Size([654, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([816])) that is different to the input size (torch.Size([816, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([659])) that is different to the input size (torch.Size([659, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([478])) that is different to the input size (torch.Size([478, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([885])) that is different to the input size (torch.Size([885, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([991])) that is different to the input size (torch.Size([991, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1004])) that is different to the input size (torch.Size([1004, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([709])) that is different to the input size (torch.Size([709, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([491])) that is different to the input size (torch.Size([491, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([537])) that is different to the input size (torch.Size([537, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([785])) that is different to the input size (torch.Size([785, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([606])) that is different to the input size (torch.Size([606, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([961])) that is different to the input size (torch.Size([961, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([597])) that is different to the input size (torch.Size([597, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([542])) that is different to the input size (torch.Size([542, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([849])) that is different to the input size (torch.Size([849, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([515])) that is different to the input size (torch.Size([515, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1007])) that is different to the input size (torch.Size([1007, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([739])) that is different to the input size (torch.Size([739, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([693])) that is different to the input size (torch.Size([693, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([653])) that is different to the input size (torch.Size([653, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([749])) that is different to the input size (torch.Size([749, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([752])) that is different to the input size (torch.Size([752, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([823])) that is different to the input size (torch.Size([823, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([18])) that is different to the input size (torch.Size([18, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([567])) that is different to the input size (torch.Size([567, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([753])) that is different to the input size (torch.Size([753, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([568])) that is different to the input size (torch.Size([568, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([943])) that is different to the input size (torch.Size([943, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([640])) that is different to the input size (torch.Size([640, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([571])) that is different to the input size (torch.Size([571, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([560])) that is different to the input size (torch.Size([560, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([592])) that is different to the input size (torch.Size([592, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([854])) that is different to the input size (torch.Size([854, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([500])) that is different to the input size (torch.Size([500, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([603])) that is different to the input size (torch.Size([603, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([788])) that is different to the input size (torch.Size([788, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([577])) that is different to the input size (torch.Size([577, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([13])) that is different to the input size (torch.Size([13, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([471])) that is different to the input size (torch.Size([471, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([806])) that is different to the input size (torch.Size([806, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([699])) that is different to the input size (torch.Size([699, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([666])) that is different to the input size (torch.Size([666, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([915])) that is different to the input size (torch.Size([915, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([634])) that is different to the input size (torch.Size([634, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([521])) that is different to the input size (torch.Size([521, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1013])) that is different to the input size (torch.Size([1013, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([832])) that is different to the input size (torch.Size([832, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([667])) that is different to the input size (torch.Size([667, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([720])) that is different to the input size (torch.Size([720, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([590])) that is different to the input size (torch.Size([590, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([731])) that is different to the input size (torch.Size([731, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([573])) that is different to the input size (torch.Size([573, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([581])) that is different to the input size (torch.Size([581, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([578])) that is different to the input size (torch.Size([578, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([797])) that is different to the input size (torch.Size([797, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([809])) that is different to the input size (torch.Size([809, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([795])) that is different to the input size (torch.Size([795, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([572])) that is different to the input size (torch.Size([572, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([596])) that is different to the input size (torch.Size([596, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([675])) that is different to the input size (torch.Size([675, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([827])) that is different to the input size (torch.Size([827, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([736])) that is different to the input size (torch.Size([736, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([700])) that is different to the input size (torch.Size([700, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([819])) that is different to the input size (torch.Size([819, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([641])) that is different to the input size (torch.Size([641, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([919])) that is different to the input size (torch.Size([919, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([772])) that is different to the input size (torch.Size([772, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([729])) that is different to the input size (torch.Size([729, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([868])) that is different to the input size (torch.Size([868, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([610])) that is different to the input size (torch.Size([610, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([620])) that is different to the input size (torch.Size([620, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([952])) that is different to the input size (torch.Size([952, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([931])) that is different to the input size (torch.Size([931, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([734])) that is different to the input size (torch.Size([734, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([946])) that is different to the input size (torch.Size([946, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([826])) that is different to the input size (torch.Size([826, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([761])) that is different to the input size (torch.Size([761, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([554])) that is different to the input size (torch.Size([554, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([993])) that is different to the input size (torch.Size([993, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([607])) that is different to the input size (torch.Size([607, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([713])) that is different to the input size (torch.Size([713, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([642])) that is different to the input size (torch.Size([642, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([765])) that is different to the input size (torch.Size([765, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([564])) that is different to the input size (torch.Size([564, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([917])) that is different to the input size (torch.Size([917, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([763])) that is different to the input size (torch.Size([763, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([686])) that is different to the input size (torch.Size([686, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([621])) that is different to the input size (torch.Size([621, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([541])) that is different to the input size (torch.Size([541, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1017])) that is different to the input size (torch.Size([1017, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([588])) that is different to the input size (torch.Size([588, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([649])) that is different to the input size (torch.Size([649, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([732])) that is different to the input size (torch.Size([732, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([561])) that is different to the input size (torch.Size([561, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([725])) that is different to the input size (torch.Size([725, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([615])) that is different to the input size (torch.Size([615, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([719])) that is different to the input size (torch.Size([719, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([847])) that is different to the input size (torch.Size([847, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([937])) that is different to the input size (torch.Size([937, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([550])) that is different to the input size (torch.Size([550, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([737])) that is different to the input size (torch.Size([737, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([630])) that is different to the input size (torch.Size([630, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([687])) that is different to the input size (torch.Size([687, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([801])) that is different to the input size (torch.Size([801, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([856])) that is different to the input size (torch.Size([856, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([598])) that is different to the input size (torch.Size([598, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([970])) that is different to the input size (torch.Size([970, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([897])) that is different to the input size (torch.Size([897, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([695])) that is different to the input size (torch.Size([695, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([784])) that is different to the input size (torch.Size([784, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([841])) that is different to the input size (torch.Size([841, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([647])) that is different to the input size (torch.Size([647, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([747])) that is different to the input size (torch.Size([747, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([935])) that is different to the input size (torch.Size([935, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1010])) that is different to the input size (torch.Size([1010, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([814])) that is different to the input size (torch.Size([814, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([892])) that is different to the input size (torch.Size([892, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([844])) that is different to the input size (torch.Size([844, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Validation Loss: 0.04031432110757383\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Epoch 2/5, Validation Loss: 0.04024215667321586\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Epoch 3/5, Validation Loss: 0.040244984060879035\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Epoch 4/5, Validation Loss: 0.04016624741294321\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6V2YLE5.1/558-674',) y 117 y 60\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I0R687.1/331-428',) y 98 y 44\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('I6NEA7.1/22-332',) y 311 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0L0SP69.1/898-991',) y 94 y 267\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('Q54EQ8.1/622-713',) y 92 y 76\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P8HMM9.1/556-662',) y 107 y 108\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('K2IS43.1/381-491',) y 111 y 198\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A7M7P1K2.1/230-388',) y 159 y 190\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('R4K6S0.1/243-358',) y 116 y 81\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A6P7YWC7.1/4085-4167',) y 83 y 84\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A4Q8C0E3.1/247-363',) y 117 y 140\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A259HE10.1/43-148',) y 106 y 208\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('V3Z1U4.1/125-374',) y 250 y 44\n",
      "Epoch 5/5, Validation Loss: 0.040134266780717055\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([860])) that is different to the input size (torch.Size([860, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([746])) that is different to the input size (torch.Size([746, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([905])) that is different to the input size (torch.Size([905, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([718])) that is different to the input size (torch.Size([718, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([858])) that is different to the input size (torch.Size([858, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1018])) that is different to the input size (torch.Size([1018, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1002])) that is different to the input size (torch.Size([1002, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([751])) that is different to the input size (torch.Size([751, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([637])) that is different to the input size (torch.Size([637, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([692])) that is different to the input size (torch.Size([692, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([600])) that is different to the input size (torch.Size([600, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([676])) that is different to the input size (torch.Size([676, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([593])) that is different to the input size (torch.Size([593, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([787])) that is different to the input size (torch.Size([787, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([874])) that is different to the input size (torch.Size([874, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([965])) that is different to the input size (torch.Size([965, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([930])) that is different to the input size (torch.Size([930, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([893])) that is different to the input size (torch.Size([893, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0H3YJP0.1/580-733',) y 154 y 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([626])) that is different to the input size (torch.Size([626, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([807])) that is different to the input size (torch.Size([807, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([680])) that is different to the input size (torch.Size([680, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([711])) that is different to the input size (torch.Size([711, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([652])) that is different to the input size (torch.Size([652, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/patyarakawa/mi_entorno/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([837])) that is different to the input size (torch.Size([837, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.04017674030624648\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Chargement des données (train, validation, test)\n",
    "dataset = [(embeddings_dict[sequence.split(\"/\")[0]], conservation_scores, sequence) for sequence, conservation_scores in zip(sequences, conservation_scores_array)]\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Création des data loaders pour train, validation et test\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Définition du modèle CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=9)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=9)\n",
    "        \n",
    "        # Calcule la taille de sortie des convolutions\n",
    "        self._to_linear = None\n",
    "        self.convs(torch.randn(1, 1, 320))  # tensor d'entrée de taille (batch_size, in_channels, input_length)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self._to_linear, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def convs(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x.shape[1] * x.shape[2]\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Ajoute une dimension pour le canal\n",
    "        x = self.convs(x)\n",
    "        x = x.view(x.size(0), -1)  # Aplatissement\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Fonction de formation\n",
    "def train_model(model, optimizer, loss_fn, data_loader):\n",
    "    model.train()\n",
    "    for embedding, label, sequence in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        embedding = embedding.squeeze()\n",
    "        label = label.squeeze()\n",
    "        if embedding.size(0) != label.size(0):\n",
    "            print(f\"La taille des tenseurs de sortie et d'étiquette ne correspond pas pour la séquence: {sequence} y {label.size(0)} y {embedding.size(0)}\")\n",
    "            continue\n",
    "        output = model(embedding)\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Fonction d'évaluation\n",
    "def evaluate_model(model, loss_fn, data_loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for embedding, label, sequence in data_loader:\n",
    "            embedding = embedding.squeeze()\n",
    "            label = label.squeeze()\n",
    "            output = model(embedding)\n",
    "            if embedding.size(0) != label.size(0):\n",
    "                print(f\"La taille des tenseurs de sortie et d'étiquette ne correspond pas pour la séquence: {sequence} y {label.size(0)} y {embedding.size(0)}\")\n",
    "                continue\n",
    "            loss = loss_fn(output, label)\n",
    "            running_loss += loss.item()\n",
    "    return running_loss / len(data_loader)\n",
    "\n",
    "# Initialiser le modèle, la fonction de perte et l'optimiseur avec régularisation L2\n",
    "model = CNN()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, weight_decay=0.01)  # Réduisez lr pour une stabilisation\n",
    "\n",
    "# Entraîner le modèle\n",
    "num_epochs = 5\n",
    "val_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_model(model, optimizer, loss_fn, train_loader)\n",
    "    val_loss = evaluate_model(model, loss_fn, val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Validation Loss: {val_loss}')\n",
    "\n",
    "# Tracer la perte de validation au fil des époques\n",
    "plt.plot(val_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss over Epochs - CNN')\n",
    "plt.show()\n",
    "\n",
    "# Évaluer finalement sur l'ensemble de test\n",
    "test_loss = evaluate_model(model, loss_fn, test_loader)\n",
    "print(f'Test Loss: {test_loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5796117-c1a9-46aa-8a6c-fe2d7c47d842",
   "metadata": {},
   "source": [
    "## 2 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cabb1cd8-06ea-4c0e-8401-80ce62dbe3f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tailleSeq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_loader)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Initialiser le modèle, la fonction de perte et l'optimiseur avec régularisation L2\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m     67\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)  \u001b[38;5;66;03m# Ajout de weight_decay pour la régularisation L2\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m, in \u001b[0;36mCNN.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv1d(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv1d(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m64\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[43mtailleSeq\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m4\u001b[39m), \u001b[38;5;241m128\u001b[39m)  \u001b[38;5;66;03m# Remplacez 64 * (tailleSeq - 4) par la taille après aplatissement\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m320\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tailleSeq' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Chargement des données (train, validation, test)\n",
    "dataset = [(embeddings_dict[sequence.split(\"/\")[0]], conservation_scores, sequence) for sequence, conservation_scores in zip(sequences, conservation_scores_array)]\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Création des data loaders pour train, validation et test\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Définition du modèle CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(64 * (320 - 4), 128)  # Remplacez 64 * (tailleSeq - 4) par la taille après aplatissement\n",
    "        self.fc2 = nn.Linear(128, 320)  # La sortie est un vecteur de taille 320\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Ajoute une dimension pour le canal\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # Aplatissement\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Fonction de formation\n",
    "def train_model(model, optimizer, loss_fn, data_loader):\n",
    "    model.train()\n",
    "    for embedding, label, sequence in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        embedding = embedding.squeeze()\n",
    "        label = label.squeeze()\n",
    "        output = model(embedding)\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Fonction d'évaluation\n",
    "def evaluate_model(model, loss_fn, data_loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for embedding, label, sequence in data_loader:\n",
    "            embedding = embedding.squeeze()\n",
    "            label = label.squeeze()\n",
    "            output = model(embedding)\n",
    "            loss = loss_fn(output, label)\n",
    "            running_loss += loss.item()\n",
    "    return running_loss / len(data_loader)\n",
    "\n",
    "# Initialiser le modèle, la fonction de perte et l'optimiseur avec régularisation L2\n",
    "model = CNN()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, weight_decay=0.01)  # Ajout de weight_decay pour la régularisation L2\n",
    "\n",
    "# Entraîner le modèle\n",
    "num_epochs = 5\n",
    "val_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_model(model, optimizer, loss_fn, train_loader)\n",
    "    val_loss = evaluate_model(model, loss_fn, val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Validation Loss: {val_loss}')\n",
    "\n",
    "# Tracer la perte de validation au fil des époques\n",
    "plt.plot(val_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss over Epochs - CNN')\n",
    "plt.show()\n",
    "\n",
    "# Évaluer finalement sur l'ensemble de test\n",
    "test_loss = evaluate_model(model, loss_fn, test_loader)\n",
    "print(f'Test Loss: {test_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88b7755d-6b62-4f04-aee8-caa69d46baa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0H3YJP0.1/580-733',) y 154 y 165\n",
      "Test Loss: 0.04017674030624648\n"
     ]
    }
   ],
   "source": [
    "# Tracer la perte de validation au fil des époques\n",
    "plt.plot(val_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss over Epochs - CNN')\n",
    "plt.show()\n",
    "\n",
    "# Évaluer finalement sur l'ensemble de test\n",
    "test_loss = evaluate_model(model, loss_fn, test_loader)\n",
    "print(f'Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee861790-f69b-4b89-b9ff-f99a47800246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label tensor([0.2382, 0.2698, 0.2325, 0.2319, 0.1912, 0.2350, 0.2157, 0.2134, 0.1652,\n",
      "        0.4375, 0.3711, 0.4460, 0.3601, 0.5029, 0.5835, 0.3574, 0.4172, 0.5703,\n",
      "        0.3882, 0.3254, 0.3430, 0.2810, 0.3521, 0.6079, 0.3127, 0.5283, 0.5986,\n",
      "        0.8018, 0.4656, 0.4661, 0.5078, 0.6294, 0.6494, 0.3188, 0.7900, 0.4951,\n",
      "        0.6060, 0.4810, 0.7036, 0.5308, 0.6470, 0.3459, 0.2927, 0.2817, 0.3184,\n",
      "        0.4409, 0.3145, 0.7686, 0.8027, 0.6406, 0.6001, 0.6948, 0.5298, 0.6382,\n",
      "        0.4951, 0.4111, 0.2477, 0.5063, 0.8838, 0.7817, 0.6841, 0.4036, 0.5068,\n",
      "        0.4602, 0.2385, 0.4651, 0.1425, 0.2052, 0.3018, 0.7378, 0.5752, 0.3027,\n",
      "        0.3740, 0.8110, 0.3689, 0.2725, 0.6440, 0.4160, 0.3716, 0.6118, 0.5332,\n",
      "        0.1941, 0.2991, 0.6602, 0.6333, 0.4111, 0.2542, 0.5645, 0.4744, 0.5127,\n",
      "        0.4558, 0.3684, 0.3999, 0.6387, 0.4182, 0.6377, 0.5229, 0.4417, 0.3647,\n",
      "        0.3340, 0.3213, 0.4236, 0.5024, 0.2788, 0.4954, 0.3628, 0.2349, 0.4036,\n",
      "        0.4761, 0.3093, 0.5693, 0.4749, 0.2710, 0.3774, 0.6323, 0.5718, 0.3665,\n",
      "        0.6616, 0.4297, 0.3328, 0.2844, 0.3589, 0.4614, 0.3337, 0.6704, 0.3657,\n",
      "        0.3337, 0.2896, 0.4695, 0.2920, 0.3127, 0.3713, 0.6050, 0.4097, 0.4590,\n",
      "        0.2476, 0.5122, 0.2771, 0.5610, 0.3826, 0.2542, 0.3525, 0.6089, 0.3140,\n",
      "        0.2549, 0.5923, 0.3867, 0.2070, 0.3716, 0.3962, 0.5020, 0.2600, 0.5923,\n",
      "        0.6763, 0.3079, 0.2917, 0.4089, 0.4165, 0.4197, 0.5176, 0.5967, 0.3403,\n",
      "        0.2483, 0.6733, 0.5259, 0.3042, 0.4280, 0.2986])\n",
      "output tensor([0.3289, 0.3324, 0.3322, 0.3297, 0.3334, 0.3314, 0.3294, 0.3319, 0.3256,\n",
      "        0.3286, 0.3345, 0.3319, 0.3272, 0.3331, 0.3353, 0.3248, 0.3235, 0.3309,\n",
      "        0.3282, 0.3322, 0.3242, 0.3414, 0.3297, 0.3329, 0.3289, 0.3363, 0.3321,\n",
      "        0.3318, 0.3363, 0.3337, 0.3348, 0.3283, 0.3320, 0.3341, 0.3296, 0.3332,\n",
      "        0.3316, 0.3327, 0.3309, 0.3303, 0.3325, 0.3336, 0.3358, 0.3285, 0.3366,\n",
      "        0.3342, 0.3342, 0.3328, 0.3323, 0.3311, 0.3368, 0.3285, 0.3307, 0.3273,\n",
      "        0.3270, 0.3277, 0.3331, 0.3277, 0.3322, 0.3296, 0.3293, 0.3298, 0.3287,\n",
      "        0.3317, 0.3306, 0.3312, 0.3385, 0.3329, 0.3280, 0.3287, 0.3313, 0.3299,\n",
      "        0.3358, 0.3318, 0.3237, 0.3275, 0.3326, 0.3248, 0.3285, 0.3264, 0.3312,\n",
      "        0.3297, 0.3317, 0.3292, 0.3318, 0.3276, 0.3214, 0.3262, 0.3226, 0.3252,\n",
      "        0.3204, 0.3232, 0.3257, 0.3288, 0.3267, 0.3192, 0.3284, 0.3255, 0.3301,\n",
      "        0.3297, 0.3233, 0.3226, 0.3213, 0.3294, 0.3283, 0.3296, 0.3277, 0.3187,\n",
      "        0.3199, 0.3296, 0.3250, 0.3191, 0.3260, 0.3313, 0.3149, 0.3211, 0.3225,\n",
      "        0.3285, 0.3201, 0.3293, 0.3297, 0.3162, 0.3273, 0.3283, 0.3263, 0.3303,\n",
      "        0.3311, 0.3259, 0.3257, 0.3311, 0.3223, 0.3152, 0.3181, 0.3353, 0.3233,\n",
      "        0.3275, 0.3194, 0.3302, 0.3187, 0.3203, 0.3299, 0.3275, 0.3284, 0.3263,\n",
      "        0.3256, 0.3157, 0.3216, 0.3261, 0.3274, 0.3193, 0.3099, 0.3226, 0.3190,\n",
      "        0.3188, 0.3260, 0.3261, 0.3147, 0.3067, 0.3196, 0.3253, 0.3118, 0.3275,\n",
      "        0.3249, 0.3280, 0.3195, 0.3277, 0.3294, 0.3383])\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A553PFE8.1/1433-1850',) y 418 y 69\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A1Y1Y8X0.1/333-680',) y 348 y 117\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A2E2XEI3.1/363-477',) y 115 y 114\n",
      "Tamaño de los tensores de salida y etiqueta no coinciden para la secuencia: ('A0A0H3YJP0.1/580-733',) y 154 y 165\n",
      "Coefficient de corrélation de Pearson CNN: -0.003656493965536356\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "true_scores = []\n",
    "predicted_scores = []\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for embedding, label, sequence in test_loader:\n",
    "        count = count + 1\n",
    "        embedding = embedding.squeeze()\n",
    "        label = label.squeeze()\n",
    "        output = model(embedding).squeeze()\n",
    "        if embedding.size(0) != label.size(0):\n",
    "            print(f\"La taille des tenseurs de sortie et d'étiquette ne correspond pas pour la séquence: {sequence} y {label.size(0)} y {embedding.size(0)}\" )\n",
    "            continue\n",
    "        if count == 2:\n",
    "            print(\"label\", label)\n",
    "            print(\"output\", output)\n",
    "        true_scores.append(label)\n",
    "        predicted_scores.append(output)\n",
    "\n",
    "# Convertir les listes en tenseurs PyTorch\n",
    "true_scores_tensor = torch.cat(true_scores)\n",
    "predicted_scores_tensor = torch.cat(predicted_scores)\n",
    "\n",
    "# Calculer le coefficient de corrélation de Pearson\n",
    "pearson_corr = pearson_correlation(true_scores_tensor, predicted_scores_tensor)\n",
    "print(f\"Coefficient de corrélation de Pearson CNN: {pearson_corr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b020598-226a-43b1-a3a6-d36033c195cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "if False:\n",
    "    # Lire le fichier CSV\n",
    "    csv_file = \"curated_dataset/conservation_scores_formated.csv\"\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Filtrer les lignes du DataFrame en fonction des clés du dictionnaire\n",
    "    filtered_rows = []\n",
    "    for index, row in df.iterrows():\n",
    "        sequence_id = row[\"sequence id\"].split(\"/\")[0]  # Obtenir le préfixe de l'ID de séquence\n",
    "        if sequence_id in embeddings_dict:\n",
    "            print(\"Correspondance trouvée\", sequence_id)\n",
    "            filtered_rows.append(row)\n",
    "    \n",
    "    # Créer un nouveau DataFrame avec les lignes filtrées\n",
    "    filtered_df = pd.DataFrame(filtered_rows)\n",
    "    \n",
    "    # Enregistrer le DataFrame filtré dans un nouveau fichier CSV\n",
    "    filtered_csv_file = \"curated_dataset/filtered_conservation_scores.csv\"\n",
    "    filtered_df.to_csv(filtered_csv_file, index=False)\n",
    "    \n",
    "    print(\"Filtrage terminé. Le fichier filtré a été enregistré sous :\", filtered_csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b388cb-fc6b-4ec3-b973-9c6cbe0a713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, EsmModel\n",
    "import torch\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "\n",
    "# Charger le tokenizer et le modèle\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "model = EsmModel.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "\n",
    "# Fonction pour générer les vecteurs d'embedding d'une séquence\n",
    "def generate_embedding(sequence):\n",
    "    inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    # Squeeze pour enlever la dimension de lot\n",
    "    embedding = outputs.last_hidden_state.squeeze(0)\n",
    "    # Enlever la première et la dernière ligne\n",
    "    embedding = embedding[1:-1, :]\n",
    "    return embedding\n",
    "\n",
    "# Créer un répertoire pour stocker les embeddings\n",
    "\n",
    "# Lire le fichier fasta et traiter les séquences\n",
    "fasta_file = \"curated_dataset/reduced_input_20000.fasta\"\n",
    "count = 0\n",
    "if False:\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        count = count + 1\n",
    "        sequence_id = record.id.split('/')[0]\n",
    "        # sequence_id = sequence_id.replace('.', '')\n",
    "        sequence_id_complement = record.id.split('/')[1]\n",
    "        sequence = str(record.seq)\n",
    "    \n",
    "        # Générer l'embedding pour la séquence actuelle\n",
    "        embedding = generate_embedding(sequence)\n",
    "        output_file = f\"curated_dataset/individual_embeddings/{sequence_id}.pt\"\n",
    "        # os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "        # Enregistrer l'embedding dans un fichier .pt dans le répertoire de la séquence\n",
    "        torch.save(embedding, output_file)\n",
    "    \n",
    "        print(\n",
    "            f\"Embedding {count} généré et sauvegardé pour la séquence {sequence_id}\")\n",
    "\n",
    "    print(\"Processus terminé.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0b6bca8-8bf1-4093-8666-1e603bb5c33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, EsmModel\n",
    "import torch\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "\n",
    "# Charger le tokenizer et le modèle\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "model = EsmModel.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "\n",
    "def generate_embedding(sequence):\n",
    "    inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    # Squeeze pour enlever la dimension de lot\n",
    "    embedding = outputs.last_hidden_state.squeeze(0)\n",
    "    # Enlever la première et la dernière ligne\n",
    "    embedding = embedding[1:-1, :]\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e35ed35-9e4c-4a30-9cae-9abe7f04209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_1btk = generate_embedding(\"AAVILESIFLKRSQQKKKTSPLNFKKCLFLLTVHKLSYYEYDFERGRRGSKKGSIDVEKITCVETVVPEKNPPPERQIPRRGEESSEMEQISIIERFPYPFQVVYDEGPLYVFSPTEELRKRWIHQLKNVIRYNSDLVQKYHPCFWIDGQYLCCSQTAKNAMGCQILEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27ab6a3e-a105-4f40-aa1a-68014b7ab9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1246,  0.2177, -0.0609,  ...,  0.1311,  0.2336, -0.0956],\n",
       "        [ 0.0979, -0.0464, -0.0279,  ..., -0.0412,  0.1485,  0.0365],\n",
       "        [ 0.0046, -0.1843,  0.3125,  ...,  0.3578,  0.2835,  0.1302],\n",
       "        ...,\n",
       "        [ 0.1103, -0.2611,  0.3035,  ..., -0.0811, -0.0425,  0.0694],\n",
       "        [-0.0162, -0.6340,  0.3425,  ..., -0.1947,  0.1116,  0.3056],\n",
       "        [ 0.1330, -0.1816,  0.2326,  ..., -0.1703, -0.2321, -0.0649]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_1btk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "249a24e1-5d16-4cfe-9036-652e73020982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_1btk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09b6855a-e64e-4db1-9f71-df51dbb1eff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.034, 1.584, 2.128, -0.496, -0.895, -0.654, -0.327, 0.884, -0.806, -0.203, -1.255, -0.956, -1.275, -1.262, -1.216, -1.129, -0.653, -0.653, -0.587, -1.153, -1.052, 0.584, -1.137, -0.547, -1.199, -0.515, -1.144, -0.019, -1.231, -0.131, -1.066, -1.09, 0.647, 1.188, 0.741, -0.52, -0.083, -1.226, -0.865, -0.322, 0.736, -0.276, 1.574, 0.716, -0.123, 0.522, -0.293, -0.051, 0.221, 1.105, 0.541, -0.462, -1.055, -0.198, -0.571, 0.301, 1.017, 0.742, -0.154, -0.642, 0.187, -0.698, -0.827, -0.735, 0.66, -1.181, 2.529, 0.857, 0.27, 2.583, 2.015, -0.141, -1.089, 1.253, 0.747, -0.409, -0.238, 1.987, 2.598, 0.86, 0.392, 0.171, 2.135, 0.879, 2.613, 0.88, 1.827, 1.391, -0.086, -0.632, -0.126, -0.129, -0.064, -0.779, -0.827, -0.839, -0.298, -0.411, 0.333, -0.776, -0.581, -1.038, -0.185, 0.0, -0.31, -0.802, 0.988, 0.191, -0.098, -1.07, -1.043, 0.272, -0.779, -0.894, -0.164, 0.187, 0.394, 1.087, -0.29, -0.972, 2.4, 2.018, -1.157, -0.526, 1.101, 0.639, -0.288, -0.329, 2.612, 0.253, -0.534, 0.703, 1.257, -0.997, 1.509, 1.164, -0.577, 1.014, 1.248, -0.929, -0.374, -1.227, -0.267, 1.001, -0.501, -0.159, 1.74, -0.047, -1.152, 1.073, -0.584, 0.159, -1.222, -1.222, 0.5, -1.216, 0.099, -0.583, -0.994, 0.544, -1.182, 0.407, -1.152, -1.222, 0.725, 1.303, -0.499, -0.033, -0.977]\n"
     ]
    }
   ],
   "source": [
    "def read_conservation_scores(file):\n",
    "    conservation_scores = []\n",
    "\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()[29:198]  # Lire de la ligne 30 à la 198\n",
    "        for line in lines:\n",
    "            score_str = line[18:24].strip().rstrip(',')  # Extraire les scores de conservation, enlever les espaces blancs et les virgules\n",
    "            # if score_str.startswith('-'):\n",
    "\n",
    "            if score_str.strip():  \n",
    "                score = float(score_str) \n",
    "                conservation_scores.append(score)\n",
    "\n",
    "    return conservation_scores\n",
    "\n",
    "\n",
    "scores_1btk = read_conservation_scores(\"Consurf_Outputs_1716245811/1BTK_A_consurf_grades.txt\")\n",
    "print(scores_1btk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87ceaf8a-1c99-4eec-951b-174fe5cd4090",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores_1btk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m min_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[43mscores_1btk\u001b[49m)\n\u001b[1;32m      2\u001b[0m max_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(scores_1btk)\n\u001b[1;32m      4\u001b[0m normalized_scores_1btk \u001b[38;5;241m=\u001b[39m [(score \u001b[38;5;241m-\u001b[39m min_score) \u001b[38;5;241m/\u001b[39m (max_score \u001b[38;5;241m-\u001b[39m min_score) \u001b[38;5;28;01mfor\u001b[39;00m score \u001b[38;5;129;01min\u001b[39;00m scores_1btk]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scores_1btk' is not defined"
     ]
    }
   ],
   "source": [
    "min_score = min(scores_1btk)\n",
    "max_score = max(scores_1btk)\n",
    "\n",
    "normalized_scores_1btk = [(score - min_score) / (max_score - min_score) for score in scores_1btk]\n",
    "\n",
    "print(normalized_scores_1btk)\n",
    "len(normalized_scores_1btk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec76d97e-3581-42f0-8de5-89402523f87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Conservation Scores: tensor([[0.3157],\n",
      "        [0.2815],\n",
      "        [0.3039],\n",
      "        [0.3406],\n",
      "        [0.3480],\n",
      "        [0.3223],\n",
      "        [0.3181],\n",
      "        [0.3686],\n",
      "        [0.4091],\n",
      "        [0.3230],\n",
      "        [0.2986],\n",
      "        [0.3082],\n",
      "        [0.3047],\n",
      "        [0.2577],\n",
      "        [0.2479],\n",
      "        [0.2697],\n",
      "        [0.2767],\n",
      "        [0.2532],\n",
      "        [0.2249],\n",
      "        [0.2779],\n",
      "        [0.3256],\n",
      "        [0.2776],\n",
      "        [0.3079],\n",
      "        [0.3785],\n",
      "        [0.3213],\n",
      "        [0.3516],\n",
      "        [0.5597],\n",
      "        [0.4152],\n",
      "        [0.5192],\n",
      "        [0.4102],\n",
      "        [0.4308],\n",
      "        [0.3898],\n",
      "        [0.3709],\n",
      "        [0.3935],\n",
      "        [0.3477],\n",
      "        [0.3531],\n",
      "        [0.3490],\n",
      "        [0.4878],\n",
      "        [0.4960],\n",
      "        [0.3649],\n",
      "        [0.4835],\n",
      "        [0.4257],\n",
      "        [0.3413],\n",
      "        [0.3124],\n",
      "        [0.3090],\n",
      "        [0.4117],\n",
      "        [0.3377],\n",
      "        [0.3163],\n",
      "        [0.3770],\n",
      "        [0.2869],\n",
      "        [0.2839],\n",
      "        [0.2382],\n",
      "        [0.3175],\n",
      "        [0.2464],\n",
      "        [0.2745],\n",
      "        [0.2768],\n",
      "        [0.2872],\n",
      "        [0.3137],\n",
      "        [0.2596],\n",
      "        [0.3636],\n",
      "        [0.3130],\n",
      "        [0.4909],\n",
      "        [0.3046],\n",
      "        [0.3309],\n",
      "        [0.2417],\n",
      "        [0.2183],\n",
      "        [0.1865],\n",
      "        [0.2695],\n",
      "        [0.1950],\n",
      "        [0.1588],\n",
      "        [0.1860],\n",
      "        [0.2571],\n",
      "        [0.2362],\n",
      "        [0.2169],\n",
      "        [0.2282],\n",
      "        [0.2069],\n",
      "        [0.2186],\n",
      "        [0.2071],\n",
      "        [0.3232],\n",
      "        [0.2129],\n",
      "        [0.2167],\n",
      "        [0.2547],\n",
      "        [0.1970],\n",
      "        [0.1657],\n",
      "        [0.1714],\n",
      "        [0.1915],\n",
      "        [0.2255],\n",
      "        [0.2021],\n",
      "        [0.2438],\n",
      "        [0.2289],\n",
      "        [0.2511],\n",
      "        [0.2851],\n",
      "        [0.2754],\n",
      "        [0.3017],\n",
      "        [0.3324],\n",
      "        [0.2839],\n",
      "        [0.3428],\n",
      "        [0.3264],\n",
      "        [0.3866],\n",
      "        [0.3617],\n",
      "        [0.4488],\n",
      "        [0.3686],\n",
      "        [0.4259],\n",
      "        [0.3129],\n",
      "        [0.4169],\n",
      "        [0.3227],\n",
      "        [0.2564],\n",
      "        [0.3206],\n",
      "        [0.3322],\n",
      "        [0.3640],\n",
      "        [0.4682],\n",
      "        [0.4084],\n",
      "        [0.4415],\n",
      "        [0.5655],\n",
      "        [0.3605],\n",
      "        [0.3261],\n",
      "        [0.1762],\n",
      "        [0.2616],\n",
      "        [0.4760],\n",
      "        [0.5247],\n",
      "        [0.2096],\n",
      "        [0.2285],\n",
      "        [0.6131],\n",
      "        [0.3842],\n",
      "        [0.3136],\n",
      "        [0.3520],\n",
      "        [0.5174],\n",
      "        [0.3082],\n",
      "        [0.2757],\n",
      "        [0.3526],\n",
      "        [0.3913],\n",
      "        [0.2721],\n",
      "        [0.3261],\n",
      "        [0.3332],\n",
      "        [0.2529],\n",
      "        [0.2767],\n",
      "        [0.2709],\n",
      "        [0.2670],\n",
      "        [0.2499],\n",
      "        [0.2622],\n",
      "        [0.3897],\n",
      "        [0.3741],\n",
      "        [0.4401],\n",
      "        [0.4924],\n",
      "        [0.3881],\n",
      "        [0.4785],\n",
      "        [0.3149],\n",
      "        [0.3923],\n",
      "        [0.3933],\n",
      "        [0.2904],\n",
      "        [0.4286],\n",
      "        [0.3498],\n",
      "        [0.5687],\n",
      "        [0.5282],\n",
      "        [0.3692],\n",
      "        [0.3278],\n",
      "        [0.2913],\n",
      "        [0.3144],\n",
      "        [0.2764],\n",
      "        [0.3040],\n",
      "        [0.2816],\n",
      "        [0.3163],\n",
      "        [0.3871],\n",
      "        [0.5198],\n",
      "        [0.3259],\n",
      "        [0.3232],\n",
      "        [0.3133],\n",
      "        [0.3019],\n",
      "        [0.3144]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "if not isinstance(embedding_1btk, torch.Tensor):\n",
    "    embedding_1btk = torch.tensor(embedding_1btk, dtype=torch.float32)\n",
    "\n",
    "\n",
    "if len(embedding_1btk.shape) == 1:\n",
    "    embedding_1btk = embedding_1btk.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted_scores_1btk = model(embedding_1btk)\n",
    "\n",
    "print(\"Scores de conservation prédits :\", predicted_scores_1btk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5587bb8e-b095-4256-ac64-496a152435a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diferencia entre scores originales y predichos: tensor([[-1.3497,  1.2683,  1.8123,  ..., -0.8147, -0.3487, -1.2927],\n",
      "        [-1.3155,  1.3025,  1.8465,  ..., -0.7805, -0.3145, -1.2585],\n",
      "        [-1.3379,  1.2801,  1.8241,  ..., -0.8029, -0.3369, -1.2809],\n",
      "        ...,\n",
      "        [-1.3473,  1.2707,  1.8147,  ..., -0.8123, -0.3463, -1.2903],\n",
      "        [-1.3359,  1.2821,  1.8261,  ..., -0.8009, -0.3349, -1.2789],\n",
      "        [-1.3484,  1.2696,  1.8136,  ..., -0.8134, -0.3474, -1.2914]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "diff_score_1btk = torch.tensor(scores_1btk) - predicted_scores_1btk\n",
    "\n",
    "print(\"diff_score_1btk:\", diff_score_1btk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93aee4da-63be-4893-b932-560cb1648055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1240, 0.7269, 0.8522,  ..., 0.2472, 0.3545, 0.1371],\n",
      "        [0.1319, 0.7348, 0.8601,  ..., 0.2551, 0.3624, 0.1450],\n",
      "        [0.1267, 0.7296, 0.8549,  ..., 0.2499, 0.3572, 0.1398],\n",
      "        ...,\n",
      "        [0.1245, 0.7274, 0.8527,  ..., 0.2477, 0.3551, 0.1377],\n",
      "        [0.1272, 0.7301, 0.8554,  ..., 0.2504, 0.3577, 0.1403],\n",
      "        [0.1243, 0.7272, 0.8525,  ..., 0.2475, 0.3548, 0.1374]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def min_max_normalize(data):\n",
    "    min_val = torch.min(data)\n",
    "    max_val = torch.max(data)\n",
    "    normalized_data = (data - min_val) / (max_val - min_val)\n",
    "    return normalized_data\n",
    "\n",
    "\n",
    "diff_score_1btk_normalized = min_max_normalize(diff_score_1btk)\n",
    "print(diff_score_1btk_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d832fea-29fb-4d47-8988-8439ef8dfe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_scores_in_pdb(pdb_file, scores_array, normalized_tensor, output_file):\n",
    "    # Ouvre le fichier PDB original en lecture\n",
    "    with open(pdb_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Indice pour parcourir le tenseur normalisé\n",
    "    tensor_index = 0\n",
    "\n",
    "    # Parcours chaque ligne du fichier PDB\n",
    "    for i, line in enumerate(lines):\n",
    "        # Vérifie si la ligne contient les scores à remplacer\n",
    "        if 506 <= i + 1 <= 1823:\n",
    "            # Obtient le nombre de la colonne 61 à 66\n",
    "            original_score = float(line[60:66])\n",
    "\n",
    "            # Compare le score original avec les scores du tableau\n",
    "            if original_score == scores_array[tensor_index]:\n",
    "                # Remplace le score original par la valeur du tenseur normalisé\n",
    "                new_score = normalized_tensor[tensor_index].tolist()  # Convertit le tenseur en liste\n",
    "                lines[i] = line[:60] + f\"{new_score[0]:6.2f}\" + line[66:]\n",
    "                tensor_index += 1\n",
    "\n",
    "        # Vérifie si tous les scores ont déjà été traités\n",
    "        if tensor_index >= len(normalized_tensor):\n",
    "            break\n",
    "\n",
    "    # Écrit le fichier modifié\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "\n",
    "# Exemple d'utilisation\n",
    "replace_scores_in_pdb(\"Consurf_Outputs_1716245811/1BTK_A_With_Conservation_Scores.pdb\", scores_1btk, diff_score_1btk_normalized, \"Consurf_Outputs_1716245811/1BTK_A_Modified.pdb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9fa6c67-3947-4ece-91c6-245dfc24010f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1240, 0.7269, 0.8522,  ..., 0.2472, 0.3545, 0.1371],\n",
      "        [0.1319, 0.7348, 0.8601,  ..., 0.2551, 0.3624, 0.1450],\n",
      "        [0.1267, 0.7296, 0.8549,  ..., 0.2499, 0.3572, 0.1398],\n",
      "        ...,\n",
      "        [0.1245, 0.7274, 0.8527,  ..., 0.2477, 0.3551, 0.1377],\n",
      "        [0.1272, 0.7301, 0.8554,  ..., 0.2504, 0.3577, 0.1403],\n",
      "        [0.1243, 0.7272, 0.8525,  ..., 0.2475, 0.3548, 0.1374]])\n"
     ]
    }
   ],
   "source": [
    "print(diff_score_1btk_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0f851788-bd8a-40ff-b863-2fdf69613fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save('diff_score_1btk_normalized.npy', diff_score_1btk_normalized)\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('diff_score_1btk_normalized.pkl', 'wb') as f:\n",
    "    pickle.dump(diff_score_1btk_normalized, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3dc3e171-e03b-459d-9593-86e111e9b438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements of diff_score_1btk_normalized:\n",
      "0.124\n",
      "0.727\n",
      "0.852\n",
      "0.248\n",
      "0.156\n",
      "0.211\n",
      "0.287\n",
      "0.566\n",
      "0.176\n",
      "0.315\n",
      "0.073\n",
      "0.142\n",
      "0.068\n",
      "0.071\n",
      "0.082\n",
      "0.102\n",
      "0.212\n",
      "0.212\n",
      "0.227\n",
      "0.097\n",
      "0.120\n",
      "0.497\n",
      "0.100\n",
      "0.236\n",
      "0.086\n",
      "0.244\n",
      "0.099\n",
      "0.358\n",
      "0.079\n",
      "0.332\n",
      "0.117\n",
      "0.111\n",
      "0.511\n",
      "0.636\n",
      "0.533\n",
      "0.242\n",
      "0.343\n",
      "0.080\n",
      "0.163\n",
      "0.288\n",
      "0.532\n",
      "0.299\n",
      "0.725\n",
      "0.527\n",
      "0.334\n",
      "0.482\n",
      "0.295\n",
      "0.350\n",
      "0.413\n",
      "0.617\n",
      "0.487\n",
      "0.256\n",
      "0.119\n",
      "0.317\n",
      "0.231\n",
      "0.431\n",
      "0.596\n",
      "0.533\n",
      "0.327\n",
      "0.214\n",
      "0.405\n",
      "0.201\n",
      "0.172\n",
      "0.193\n",
      "0.514\n",
      "0.090\n",
      "0.945\n",
      "0.559\n",
      "0.424\n",
      "0.957\n",
      "0.826\n",
      "0.330\n",
      "0.111\n",
      "0.651\n",
      "0.534\n",
      "0.268\n",
      "0.307\n",
      "0.820\n",
      "0.960\n",
      "0.560\n",
      "0.452\n",
      "0.401\n",
      "0.854\n",
      "0.565\n",
      "0.964\n",
      "0.565\n",
      "0.783\n",
      "0.682\n",
      "0.342\n",
      "0.217\n",
      "0.333\n",
      "0.332\n",
      "0.347\n",
      "0.183\n",
      "0.172\n",
      "0.169\n",
      "0.293\n",
      "0.267\n",
      "0.439\n",
      "0.183\n",
      "0.228\n",
      "0.123\n",
      "0.320\n",
      "0.362\n",
      "0.291\n",
      "0.177\n",
      "0.590\n",
      "0.406\n",
      "0.340\n",
      "0.116\n",
      "0.122\n",
      "0.425\n",
      "0.183\n",
      "0.156\n",
      "0.324\n",
      "0.405\n",
      "0.453\n",
      "0.612\n",
      "0.295\n",
      "0.138\n",
      "0.915\n",
      "0.827\n",
      "0.096\n",
      "0.241\n",
      "0.616\n",
      "0.509\n",
      "0.296\n",
      "0.286\n",
      "0.964\n",
      "0.420\n",
      "0.239\n",
      "0.524\n",
      "0.652\n",
      "0.133\n",
      "0.710\n",
      "0.630\n",
      "0.229\n",
      "0.596\n",
      "0.650\n",
      "0.148\n",
      "0.276\n",
      "0.080\n",
      "0.301\n",
      "0.593\n",
      "0.247\n",
      "0.325\n",
      "0.763\n",
      "0.351\n",
      "0.097\n",
      "0.609\n",
      "0.228\n",
      "0.399\n",
      "0.081\n",
      "0.081\n",
      "0.477\n",
      "0.082\n",
      "0.385\n",
      "0.228\n",
      "0.133\n",
      "0.487\n",
      "0.090\n",
      "0.456\n",
      "0.097\n",
      "0.081\n",
      "0.529\n",
      "0.662\n",
      "0.247\n",
      "0.355\n",
      "0.137\n",
      "0.132\n",
      "0.735\n",
      "0.860\n",
      "0.256\n",
      "0.164\n",
      "0.219\n",
      "0.295\n",
      "0.574\n",
      "0.184\n",
      "0.323\n",
      "0.081\n",
      "0.150\n",
      "0.076\n",
      "0.079\n",
      "0.090\n",
      "0.110\n",
      "0.220\n",
      "0.220\n",
      "0.235\n",
      "0.104\n",
      "0.128\n",
      "0.504\n",
      "0.108\n",
      "0.244\n",
      "0.094\n",
      "0.251\n",
      "0.107\n",
      "0.366\n",
      "0.087\n",
      "0.340\n",
      "0.125\n",
      "0.119\n",
      "0.519\n",
      "0.644\n",
      "0.541\n",
      "0.250\n",
      "0.351\n",
      "0.088\n",
      "0.171\n",
      "0.296\n",
      "0.539\n",
      "0.306\n",
      "0.732\n",
      "0.535\n",
      "0.342\n",
      "0.490\n",
      "0.303\n",
      "0.358\n",
      "0.421\n",
      "0.624\n",
      "0.495\n",
      "0.264\n",
      "0.127\n",
      "0.324\n",
      "0.238\n",
      "0.439\n",
      "0.604\n",
      "0.541\n",
      "0.335\n",
      "0.222\n",
      "0.413\n",
      "0.209\n",
      "0.180\n",
      "0.201\n",
      "0.522\n",
      "0.098\n",
      "0.952\n",
      "0.567\n",
      "0.432\n",
      "0.965\n",
      "0.834\n",
      "0.338\n",
      "0.119\n",
      "0.659\n",
      "0.542\n",
      "0.276\n",
      "0.315\n",
      "0.828\n",
      "0.968\n",
      "0.568\n",
      "0.460\n",
      "0.409\n",
      "0.862\n",
      "0.572\n",
      "0.972\n",
      "0.573\n",
      "0.791\n",
      "0.690\n",
      "0.350\n",
      "0.224\n",
      "0.341\n",
      "0.340\n",
      "0.355\n",
      "0.191\n",
      "0.180\n",
      "0.177\n",
      "0.301\n",
      "0.275\n",
      "0.447\n",
      "0.191\n",
      "0.236\n",
      "0.131\n",
      "0.327\n",
      "0.370\n",
      "0.299\n",
      "0.185\n",
      "0.598\n",
      "0.414\n",
      "0.347\n",
      "0.124\n",
      "0.130\n",
      "0.433\n",
      "0.191\n",
      "0.164\n",
      "0.332\n",
      "0.413\n",
      "0.461\n",
      "0.620\n",
      "0.303\n",
      "0.146\n",
      "0.923\n",
      "0.835\n",
      "0.104\n",
      "0.249\n",
      "0.624\n",
      "0.517\n",
      "0.304\n",
      "0.294\n",
      "0.972\n",
      "0.428\n",
      "0.247\n",
      "0.532\n",
      "0.659\n",
      "0.140\n",
      "0.718\n",
      "0.638\n",
      "0.237\n",
      "0.604\n",
      "0.657\n",
      "0.156\n",
      "0.284\n",
      "0.087\n",
      "0.309\n",
      "0.601\n",
      "0.255\n",
      "0.333\n",
      "0.771\n",
      "0.359\n",
      "0.105\n",
      "0.617\n",
      "0.236\n",
      "0.407\n",
      "0.089\n",
      "0.089\n",
      "0.485\n",
      "0.090\n",
      "0.393\n",
      "0.236\n",
      "0.141\n",
      "0.495\n",
      "0.098\n",
      "0.464\n",
      "0.105\n",
      "0.089\n",
      "0.537\n",
      "0.670\n",
      "0.255\n",
      "0.362\n",
      "0.145\n",
      "0.127\n",
      "0.730\n",
      "0.855\n",
      "0.251\n",
      "0.159\n",
      "0.214\n",
      "0.290\n",
      "0.568\n",
      "0.179\n",
      "0.318\n",
      "0.076\n",
      "0.145\n",
      "0.071\n",
      "0.074\n",
      "0.085\n",
      "0.105\n",
      "0.214\n",
      "0.214\n",
      "0.230\n",
      "0.099\n",
      "0.123\n",
      "0.499\n",
      "0.103\n",
      "0.239\n",
      "0.089\n",
      "0.246\n",
      "0.101\n",
      "0.360\n",
      "0.081\n",
      "0.335\n",
      "0.119\n",
      "0.114\n",
      "0.514\n",
      "0.638\n",
      "0.535\n",
      "0.245\n",
      "0.346\n",
      "0.082\n",
      "0.166\n",
      "0.291\n",
      "0.534\n",
      "0.301\n",
      "0.727\n",
      "0.530\n",
      "0.337\n",
      "0.485\n",
      "0.297\n",
      "0.353\n",
      "0.416\n",
      "0.619\n",
      "0.489\n",
      "0.258\n",
      "0.122\n",
      "0.319\n",
      "0.233\n",
      "0.434\n",
      "0.599\n",
      "0.536\n",
      "0.329\n",
      "0.217\n",
      "0.408\n",
      "0.204\n",
      "0.174\n",
      "0.196\n",
      "0.517\n",
      "0.093\n",
      "0.947\n",
      "0.562\n",
      "0.427\n",
      "0.960\n",
      "0.829\n",
      "0.332\n",
      "0.114\n",
      "0.653\n",
      "0.537\n",
      "0.271\n",
      "0.310\n",
      "0.822\n",
      "0.963\n",
      "0.563\n",
      "0.455\n",
      "0.404\n",
      "0.857\n",
      "0.567\n",
      "0.967\n",
      "0.567\n",
      "0.786\n",
      "0.685\n",
      "0.345\n",
      "0.219\n",
      "0.336\n",
      "0.335\n",
      "0.350\n",
      "0.185\n",
      "0.174\n",
      "0.172\n",
      "0.296\n",
      "0.270\n",
      "0.442\n",
      "0.186\n",
      "0.231\n",
      "0.126\n",
      "0.322\n",
      "0.365\n",
      "0.293\n",
      "0.180\n",
      "0.592\n",
      "0.409\n",
      "0.342\n",
      "0.118\n",
      "0.125\n",
      "0.427\n",
      "0.185\n",
      "0.159\n",
      "0.327\n",
      "0.408\n",
      "0.456\n",
      "0.615\n",
      "0.298\n",
      "0.141\n",
      "0.918\n",
      "0.830\n",
      "0.098\n",
      "0.244\n",
      "0.618\n",
      "0.512\n",
      "0.299\n",
      "0.289\n",
      "0.966\n",
      "0.423\n",
      "0.242\n",
      "0.527\n",
      "0.654\n",
      "0.135\n",
      "0.712\n",
      "0.633\n",
      "0.232\n",
      "0.598\n",
      "0.652\n",
      "0.151\n",
      "0.279\n",
      "0.082\n",
      "0.303\n",
      "0.595\n",
      "0.249\n",
      "0.328\n",
      "0.766\n",
      "0.354\n",
      "0.100\n",
      "0.612\n",
      "0.230\n",
      "0.401\n",
      "0.083\n",
      "0.083\n",
      "0.480\n",
      "0.085\n",
      "0.388\n",
      "0.231\n",
      "0.136\n",
      "0.490\n",
      "0.093\n",
      "0.459\n",
      "0.100\n",
      "0.083\n",
      "0.532\n",
      "0.665\n",
      "0.250\n",
      "0.357\n",
      "0.140\n",
      "0.118\n",
      "0.721\n",
      "0.846\n",
      "0.242\n",
      "0.150\n",
      "0.206\n",
      "0.281\n",
      "0.560\n",
      "0.171\n",
      "0.310\n",
      "0.067\n",
      "0.136\n",
      "0.063\n",
      "0.066\n",
      "0.076\n",
      "0.096\n",
      "0.206\n",
      "0.206\n",
      "0.221\n",
      "0.091\n",
      "0.114\n",
      "0.491\n",
      "0.095\n",
      "0.230\n",
      "0.080\n",
      "0.238\n",
      "0.093\n",
      "0.352\n",
      "0.073\n",
      "0.326\n",
      "0.111\n",
      "0.105\n",
      "0.505\n",
      "0.630\n",
      "0.527\n",
      "0.237\n",
      "0.337\n",
      "0.074\n",
      "0.157\n",
      "0.282\n",
      "0.526\n",
      "0.293\n",
      "0.719\n",
      "0.521\n",
      "0.328\n",
      "0.477\n",
      "0.289\n",
      "0.345\n",
      "0.407\n",
      "0.611\n",
      "0.481\n",
      "0.250\n",
      "0.113\n",
      "0.311\n",
      "0.225\n",
      "0.426\n",
      "0.591\n",
      "0.527\n",
      "0.321\n",
      "0.209\n",
      "0.399\n",
      "0.196\n",
      "0.166\n",
      "0.187\n",
      "0.508\n",
      "0.084\n",
      "0.939\n",
      "0.554\n",
      "0.419\n",
      "0.951\n",
      "0.820\n",
      "0.324\n",
      "0.106\n",
      "0.645\n",
      "0.528\n",
      "0.262\n",
      "0.302\n",
      "0.814\n",
      "0.955\n",
      "0.554\n",
      "0.447\n",
      "0.396\n",
      "0.848\n",
      "0.559\n",
      "0.958\n",
      "0.559\n",
      "0.777\n",
      "0.677\n",
      "0.337\n",
      "0.211\n",
      "0.327\n",
      "0.327\n",
      "0.342\n",
      "0.177\n",
      "0.166\n",
      "0.163\n",
      "0.288\n",
      "0.262\n",
      "0.433\n",
      "0.178\n",
      "0.223\n",
      "0.117\n",
      "0.314\n",
      "0.356\n",
      "0.285\n",
      "0.172\n",
      "0.584\n",
      "0.400\n",
      "0.334\n",
      "0.110\n",
      "0.116\n",
      "0.419\n",
      "0.177\n",
      "0.151\n",
      "0.319\n",
      "0.399\n",
      "0.447\n",
      "0.607\n",
      "0.290\n",
      "0.133\n",
      "0.909\n",
      "0.821\n",
      "0.090\n",
      "0.235\n",
      "0.610\n",
      "0.504\n",
      "0.290\n",
      "0.281\n",
      "0.958\n",
      "0.415\n",
      "0.233\n",
      "0.518\n",
      "0.646\n",
      "0.127\n",
      "0.704\n",
      "0.624\n",
      "0.224\n",
      "0.590\n",
      "0.644\n",
      "0.142\n",
      "0.270\n",
      "0.074\n",
      "0.295\n",
      "0.587\n",
      "0.241\n",
      "0.320\n",
      "0.757\n",
      "0.346\n",
      "0.091\n",
      "0.603\n",
      "0.222\n",
      "0.393\n",
      "0.075\n",
      "0.075\n",
      "0.472\n",
      "0.076\n",
      "0.379\n",
      "0.222\n",
      "0.127\n",
      "0.482\n",
      "0.084\n",
      "0.450\n",
      "0.091\n",
      "0.075\n",
      "0.523\n",
      "0.656\n",
      "0.241\n",
      "0.349\n",
      "0.131\n",
      "0.117\n",
      "0.719\n",
      "0.845\n",
      "0.240\n",
      "0.149\n",
      "0.204\n",
      "0.279\n",
      "0.558\n",
      "0.169\n",
      "0.308\n",
      "0.066\n",
      "0.135\n",
      "0.061\n",
      "0.064\n",
      "0.075\n",
      "0.095\n",
      "0.204\n",
      "0.204\n",
      "0.219\n",
      "0.089\n",
      "0.112\n",
      "0.489\n",
      "0.093\n",
      "0.229\n",
      "0.079\n",
      "0.236\n",
      "0.091\n",
      "0.350\n",
      "0.071\n",
      "0.325\n",
      "0.109\n",
      "0.104\n",
      "0.504\n",
      "0.628\n",
      "0.525\n",
      "0.235\n",
      "0.336\n",
      "0.072\n",
      "0.155\n",
      "0.281\n",
      "0.524\n",
      "0.291\n",
      "0.717\n",
      "0.520\n",
      "0.326\n",
      "0.475\n",
      "0.287\n",
      "0.343\n",
      "0.406\n",
      "0.609\n",
      "0.479\n",
      "0.248\n",
      "0.112\n",
      "0.309\n",
      "0.223\n",
      "0.424\n",
      "0.589\n",
      "0.526\n",
      "0.319\n",
      "0.207\n",
      "0.398\n",
      "0.194\n",
      "0.164\n",
      "0.185\n",
      "0.507\n",
      "0.083\n",
      "0.937\n",
      "0.552\n",
      "0.417\n",
      "0.950\n",
      "0.819\n",
      "0.322\n",
      "0.104\n",
      "0.643\n",
      "0.527\n",
      "0.260\n",
      "0.300\n",
      "0.812\n",
      "0.953\n",
      "0.553\n",
      "0.445\n",
      "0.394\n",
      "0.846\n",
      "0.557\n",
      "0.956\n",
      "0.557\n",
      "0.775\n",
      "0.675\n",
      "0.335\n",
      "0.209\n",
      "0.326\n",
      "0.325\n",
      "0.340\n",
      "0.175\n",
      "0.164\n",
      "0.161\n",
      "0.286\n",
      "0.260\n",
      "0.431\n",
      "0.176\n",
      "0.221\n",
      "0.116\n",
      "0.312\n",
      "0.355\n",
      "0.283\n",
      "0.170\n",
      "0.582\n",
      "0.399\n",
      "0.332\n",
      "0.108\n",
      "0.114\n",
      "0.417\n",
      "0.175\n",
      "0.149\n",
      "0.317\n",
      "0.398\n",
      "0.445\n",
      "0.605\n",
      "0.288\n",
      "0.131\n",
      "0.907\n",
      "0.819\n",
      "0.088\n",
      "0.234\n",
      "0.608\n",
      "0.502\n",
      "0.288\n",
      "0.279\n",
      "0.956\n",
      "0.413\n",
      "0.232\n",
      "0.517\n",
      "0.644\n",
      "0.125\n",
      "0.702\n",
      "0.623\n",
      "0.222\n",
      "0.588\n",
      "0.642\n",
      "0.141\n",
      "0.269\n",
      "0.072\n",
      "0.293\n",
      "0.585\n",
      "0.239\n",
      "0.318\n",
      "0.755\n",
      "0.344\n",
      "0.089\n",
      "0.602\n",
      "0.220\n",
      "0.391\n",
      "0.073\n",
      "0.073\n",
      "0.470\n",
      "0.075\n",
      "0.377\n",
      "0.220\n",
      "0.126\n",
      "0.480\n",
      "0.082\n",
      "0.448\n",
      "0.089\n",
      "0.073\n",
      "0.522\n",
      "0.655\n",
      "0.240\n",
      "0.347\n",
      "0.130\n",
      "0.122\n",
      "0.725\n",
      "0.851\n",
      "0.246\n",
      "0.154\n",
      "0.210\n",
      "0.285\n",
      "0.564\n",
      "0.175\n",
      "0.314\n",
      "0.072\n",
      "0.140\n",
      "0.067\n",
      "0.070\n",
      "0.081\n",
      "0.101\n",
      "0.210\n",
      "0.210\n",
      "0.225\n",
      "0.095\n",
      "0.118\n",
      "0.495\n",
      "0.099\n",
      "0.235\n",
      "0.084\n",
      "0.242\n",
      "0.097\n",
      "0.356\n",
      "0.077\n",
      "0.330\n",
      "0.115\n",
      "0.110\n",
      "0.510\n",
      "0.634\n",
      "0.531\n",
      "0.241\n",
      "0.341\n",
      "0.078\n",
      "0.161\n",
      "0.286\n",
      "0.530\n",
      "0.297\n",
      "0.723\n",
      "0.525\n",
      "0.332\n",
      "0.481\n",
      "0.293\n",
      "0.349\n",
      "0.411\n",
      "0.615\n",
      "0.485\n",
      "0.254\n",
      "0.118\n",
      "0.315\n",
      "0.229\n",
      "0.430\n",
      "0.595\n",
      "0.531\n",
      "0.325\n",
      "0.213\n",
      "0.404\n",
      "0.200\n",
      "0.170\n",
      "0.191\n",
      "0.513\n",
      "0.089\n",
      "0.943\n",
      "0.558\n",
      "0.423\n",
      "0.955\n",
      "0.825\n",
      "0.328\n",
      "0.110\n",
      "0.649\n",
      "0.533\n",
      "0.266\n",
      "0.306\n",
      "0.818\n",
      "0.959\n",
      "0.559\n",
      "0.451\n",
      "0.400\n",
      "0.852\n",
      "0.563\n",
      "0.962\n",
      "0.563\n",
      "0.781\n",
      "0.681\n",
      "0.341\n",
      "0.215\n",
      "0.332\n",
      "0.331\n",
      "0.346\n",
      "0.181\n",
      "0.170\n",
      "0.167\n",
      "0.292\n",
      "0.266\n",
      "0.437\n",
      "0.182\n",
      "0.227\n",
      "0.122\n",
      "0.318\n",
      "0.361\n",
      "0.289\n",
      "0.176\n",
      "0.588\n",
      "0.405\n",
      "0.338\n",
      "0.114\n",
      "0.120\n",
      "0.423\n",
      "0.181\n",
      "0.155\n",
      "0.323\n",
      "0.404\n",
      "0.451\n",
      "0.611\n",
      "0.294\n",
      "0.137\n",
      "0.913\n",
      "0.825\n",
      "0.094\n",
      "0.239\n",
      "0.614\n",
      "0.508\n",
      "0.294\n",
      "0.285\n",
      "0.962\n",
      "0.419\n",
      "0.238\n",
      "0.522\n",
      "0.650\n",
      "0.131\n",
      "0.708\n",
      "0.629\n",
      "0.228\n",
      "0.594\n",
      "0.648\n",
      "0.147\n",
      "0.274\n",
      "0.078\n",
      "0.299\n",
      "0.591\n",
      "0.245\n",
      "0.324\n",
      "0.761\n",
      "0.350\n",
      "0.095\n",
      "0.608\n",
      "0.226\n",
      "0.397\n",
      "0.079\n",
      "0.079\n",
      "0.476\n",
      "0.081\n",
      "0.383\n",
      "0.226\n",
      "0.132\n",
      "0.486\n",
      "0.088\n",
      "0.454\n",
      "0.095\n",
      "0.079\n",
      "0.528\n",
      "0.661\n",
      "0.246\n",
      "0.353\n",
      "0.136\n",
      "0.123\n",
      "0.726\n",
      "0.852\n",
      "0.247\n",
      "0.155\n",
      "0.211\n",
      "0.286\n",
      "0.565\n",
      "0.176\n",
      "0.315\n",
      "0.073\n",
      "0.141\n",
      "0.068\n",
      "0.071\n",
      "0.082\n",
      "0.102\n",
      "0.211\n",
      "0.211\n",
      "0.226\n",
      "0.096\n",
      "0.119\n",
      "0.496\n",
      "0.100\n",
      "0.236\n",
      "0.085\n",
      "0.243\n",
      "0.098\n",
      "0.357\n",
      "0.078\n",
      "0.331\n",
      "0.116\n",
      "0.111\n",
      "0.511\n",
      "0.635\n",
      "0.532\n",
      "0.242\n",
      "0.342\n",
      "0.079\n",
      "0.162\n",
      "0.287\n",
      "0.531\n",
      "0.298\n",
      "0.724\n",
      "0.526\n",
      "0.333\n",
      "0.482\n",
      "0.294\n",
      "0.350\n",
      "0.412\n",
      "0.616\n",
      "0.486\n",
      "0.255\n",
      "0.119\n",
      "0.316\n",
      "0.230\n",
      "0.431\n",
      "0.596\n",
      "0.532\n",
      "0.326\n",
      "0.214\n",
      "0.405\n",
      "0.201\n",
      "0.171\n",
      "0.192\n",
      "0.514\n",
      "0.090\n",
      "0.944\n",
      "0.559\n",
      "0.424\n",
      "0.956\n",
      "0.826\n",
      "0.329\n",
      "0.111\n",
      "0.650\n",
      "0.534\n",
      "0.267\n",
      "0.307\n",
      "0.819\n",
      "0.960\n",
      "0.560\n",
      "0.452\n",
      "0.401\n",
      "0.853\n",
      "0.564\n",
      "0.963\n",
      "0.564\n",
      "0.782\n",
      "0.682\n",
      "0.342\n",
      "0.216\n",
      "0.333\n",
      "0.332\n",
      "0.347\n",
      "0.182\n",
      "0.171\n",
      "0.168\n",
      "0.293\n",
      "0.267\n",
      "0.438\n",
      "0.183\n",
      "0.228\n",
      "0.123\n",
      "0.319\n",
      "0.362\n",
      "0.290\n",
      "0.177\n",
      "0.589\n",
      "0.406\n",
      "0.339\n",
      "0.115\n",
      "0.121\n",
      "0.424\n",
      "0.182\n",
      "0.156\n",
      "0.324\n",
      "0.405\n",
      "0.452\n",
      "0.612\n",
      "0.295\n",
      "0.138\n",
      "0.914\n",
      "0.826\n",
      "0.095\n",
      "0.240\n",
      "0.615\n",
      "0.509\n",
      "0.295\n",
      "0.286\n",
      "0.963\n",
      "0.420\n",
      "0.239\n",
      "0.523\n",
      "0.651\n",
      "0.132\n",
      "0.709\n",
      "0.630\n",
      "0.229\n",
      "0.595\n",
      "0.649\n",
      "0.148\n",
      "0.275\n",
      "0.079\n",
      "0.300\n",
      "0.592\n",
      "0.246\n",
      "0.325\n",
      "0.762\n",
      "0.351\n",
      "0.096\n",
      "0.609\n",
      "0.227\n",
      "0.398\n",
      "0.080\n",
      "0.080\n",
      "0.477\n",
      "0.082\n",
      "0.384\n",
      "0.227\n",
      "0.133\n",
      "0.487\n",
      "0.089\n",
      "0.455\n",
      "0.096\n",
      "0.080\n",
      "0.529\n",
      "0.662\n",
      "0.247\n",
      "0.354\n",
      "0.137\n",
      "0.112\n",
      "0.715\n",
      "0.840\n",
      "0.236\n",
      "0.144\n",
      "0.199\n",
      "0.275\n",
      "0.554\n",
      "0.164\n",
      "0.303\n",
      "0.061\n",
      "0.130\n",
      "0.056\n",
      "0.059\n",
      "0.070\n",
      "0.090\n",
      "0.200\n",
      "0.200\n",
      "0.215\n",
      "0.084\n",
      "0.108\n",
      "0.484\n",
      "0.088\n",
      "0.224\n",
      "0.074\n",
      "0.231\n",
      "0.086\n",
      "0.346\n",
      "0.066\n",
      "0.320\n",
      "0.104\n",
      "0.099\n",
      "0.499\n",
      "0.624\n",
      "0.521\n",
      "0.230\n",
      "0.331\n",
      "0.068\n",
      "0.151\n",
      "0.276\n",
      "0.519\n",
      "0.286\n",
      "0.712\n",
      "0.515\n",
      "0.322\n",
      "0.470\n",
      "0.282\n",
      "0.338\n",
      "0.401\n",
      "0.604\n",
      "0.475\n",
      "0.244\n",
      "0.107\n",
      "0.304\n",
      "0.218\n",
      "0.419\n",
      "0.584\n",
      "0.521\n",
      "0.314\n",
      "0.202\n",
      "0.393\n",
      "0.189\n",
      "0.159\n",
      "0.181\n",
      "0.502\n",
      "0.078\n",
      "0.932\n",
      "0.547\n",
      "0.412\n",
      "0.945\n",
      "0.814\n",
      "0.317\n",
      "0.099\n",
      "0.638\n",
      "0.522\n",
      "0.256\n",
      "0.295\n",
      "0.808\n",
      "0.948\n",
      "0.548\n",
      "0.440\n",
      "0.389\n",
      "0.842\n",
      "0.552\n",
      "0.952\n",
      "0.553\n",
      "0.771\n",
      "0.670\n",
      "0.330\n",
      "0.204\n",
      "0.321\n",
      "0.320\n",
      "0.335\n",
      "0.171\n",
      "0.159\n",
      "0.157\n",
      "0.281\n",
      "0.255\n",
      "0.427\n",
      "0.171\n",
      "0.216\n",
      "0.111\n",
      "0.307\n",
      "0.350\n",
      "0.279\n",
      "0.165\n",
      "0.577\n",
      "0.394\n",
      "0.327\n",
      "0.104\n",
      "0.110\n",
      "0.413\n",
      "0.171\n",
      "0.144\n",
      "0.312\n",
      "0.393\n",
      "0.441\n",
      "0.600\n",
      "0.283\n",
      "0.126\n",
      "0.903\n",
      "0.815\n",
      "0.083\n",
      "0.229\n",
      "0.603\n",
      "0.497\n",
      "0.284\n",
      "0.274\n",
      "0.951\n",
      "0.408\n",
      "0.227\n",
      "0.512\n",
      "0.639\n",
      "0.120\n",
      "0.697\n",
      "0.618\n",
      "0.217\n",
      "0.583\n",
      "0.637\n",
      "0.136\n",
      "0.264\n",
      "0.067\n",
      "0.288\n",
      "0.580\n",
      "0.235\n",
      "0.313\n",
      "0.751\n",
      "0.339\n",
      "0.085\n",
      "0.597\n",
      "0.215\n",
      "0.387\n",
      "0.069\n",
      "0.069\n",
      "0.465\n",
      "0.070\n",
      "0.373\n",
      "0.216\n",
      "0.121\n",
      "0.475\n",
      "0.078\n",
      "0.444\n",
      "0.085\n",
      "0.069\n",
      "0.517\n",
      "0.650\n",
      "0.235\n",
      "0.342\n",
      "0.125\n",
      "0.102\n",
      "0.705\n",
      "0.831\n",
      "0.226\n",
      "0.134\n",
      "0.190\n",
      "0.265\n",
      "0.544\n",
      "0.155\n",
      "0.294\n",
      "0.052\n",
      "0.120\n",
      "0.047\n",
      "0.050\n",
      "0.061\n",
      "0.081\n",
      "0.190\n",
      "0.190\n",
      "0.205\n",
      "0.075\n",
      "0.098\n",
      "0.475\n",
      "0.079\n",
      "0.215\n",
      "0.064\n",
      "0.222\n",
      "0.077\n",
      "0.336\n",
      "0.057\n",
      "0.310\n",
      "0.095\n",
      "0.090\n",
      "0.490\n",
      "0.614\n",
      "0.511\n",
      "0.221\n",
      "0.321\n",
      "0.058\n",
      "0.141\n",
      "0.266\n",
      "0.510\n",
      "0.277\n",
      "0.703\n",
      "0.505\n",
      "0.312\n",
      "0.461\n",
      "0.273\n",
      "0.329\n",
      "0.391\n",
      "0.595\n",
      "0.465\n",
      "0.234\n",
      "0.098\n",
      "0.295\n",
      "0.209\n",
      "0.410\n",
      "0.575\n",
      "0.511\n",
      "0.305\n",
      "0.193\n",
      "0.384\n",
      "0.180\n",
      "0.150\n",
      "0.171\n",
      "0.493\n",
      "0.069\n",
      "0.923\n",
      "0.538\n",
      "0.403\n",
      "0.935\n",
      "0.805\n",
      "0.308\n",
      "0.090\n",
      "0.629\n",
      "0.513\n",
      "0.246\n",
      "0.286\n",
      "0.798\n",
      "0.939\n",
      "0.539\n",
      "0.431\n",
      "0.380\n",
      "0.832\n",
      "0.543\n",
      "0.942\n",
      "0.543\n",
      "0.761\n",
      "0.661\n",
      "0.321\n",
      "0.195\n",
      "0.312\n",
      "0.311\n",
      "0.326\n",
      "0.161\n",
      "0.150\n",
      "0.147\n",
      "0.272\n",
      "0.246\n",
      "0.417\n",
      "0.162\n",
      "0.207\n",
      "0.102\n",
      "0.298\n",
      "0.341\n",
      "0.269\n",
      "0.156\n",
      "0.568\n",
      "0.385\n",
      "0.318\n",
      "0.094\n",
      "0.100\n",
      "0.403\n",
      "0.161\n",
      "0.135\n",
      "0.303\n",
      "0.384\n",
      "0.431\n",
      "0.591\n",
      "0.274\n",
      "0.117\n",
      "0.893\n",
      "0.805\n",
      "0.074\n",
      "0.219\n",
      "0.594\n",
      "0.488\n",
      "0.274\n",
      "0.265\n",
      "0.942\n",
      "0.399\n",
      "0.218\n",
      "0.502\n",
      "0.630\n",
      "0.111\n",
      "0.688\n",
      "0.609\n",
      "0.208\n",
      "0.574\n",
      "0.628\n",
      "0.127\n",
      "0.254\n",
      "0.058\n",
      "0.279\n",
      "0.571\n",
      "0.225\n",
      "0.304\n",
      "0.741\n",
      "0.330\n",
      "0.075\n",
      "0.588\n",
      "0.206\n",
      "0.377\n",
      "0.059\n",
      "0.059\n",
      "0.456\n",
      "0.061\n",
      "0.363\n",
      "0.206\n",
      "0.112\n",
      "0.466\n",
      "0.068\n",
      "0.434\n",
      "0.075\n",
      "0.059\n",
      "0.508\n",
      "0.641\n",
      "0.226\n",
      "0.333\n",
      "0.116\n",
      "0.122\n",
      "0.725\n",
      "0.850\n",
      "0.246\n",
      "0.154\n",
      "0.210\n",
      "0.285\n",
      "0.564\n",
      "0.175\n",
      "0.314\n",
      "0.071\n",
      "0.140\n",
      "0.067\n",
      "0.070\n",
      "0.080\n",
      "0.100\n",
      "0.210\n",
      "0.210\n",
      "0.225\n",
      "0.095\n",
      "0.118\n",
      "0.495\n",
      "0.099\n",
      "0.234\n",
      "0.084\n",
      "0.242\n",
      "0.097\n",
      "0.356\n",
      "0.077\n",
      "0.330\n",
      "0.115\n",
      "0.109\n",
      "0.509\n",
      "0.634\n",
      "0.531\n",
      "0.241\n",
      "0.341\n",
      "0.078\n",
      "0.161\n",
      "0.286\n",
      "0.530\n",
      "0.297\n",
      "0.723\n",
      "0.525\n",
      "0.332\n",
      "0.481\n",
      "0.293\n",
      "0.349\n",
      "0.411\n",
      "0.615\n",
      "0.485\n",
      "0.254\n",
      "0.117\n",
      "0.315\n",
      "0.229\n",
      "0.430\n",
      "0.595\n",
      "0.531\n",
      "0.325\n",
      "0.213\n",
      "0.404\n",
      "0.200\n",
      "0.170\n",
      "0.191\n",
      "0.512\n",
      "0.088\n",
      "0.943\n",
      "0.558\n",
      "0.423\n",
      "0.955\n",
      "0.824\n",
      "0.328\n",
      "0.110\n",
      "0.649\n",
      "0.532\n",
      "0.266\n",
      "0.306\n",
      "0.818\n",
      "0.959\n",
      "0.558\n",
      "0.451\n",
      "0.400\n",
      "0.852\n",
      "0.563\n",
      "0.962\n",
      "0.563\n",
      "0.781\n",
      "0.681\n",
      "0.341\n",
      "0.215\n",
      "0.331\n",
      "0.331\n",
      "0.346\n",
      "0.181\n",
      "0.170\n",
      "0.167\n",
      "0.292\n",
      "0.266\n",
      "0.437\n",
      "0.182\n",
      "0.227\n",
      "0.121\n",
      "0.318\n",
      "0.360\n",
      "0.289\n",
      "0.176\n",
      "0.588\n",
      "0.404\n",
      "0.338\n",
      "0.114\n",
      "0.120\n",
      "0.423\n",
      "0.181\n",
      "0.155\n",
      "0.323\n",
      "0.404\n",
      "0.451\n",
      "0.611\n",
      "0.294\n",
      "0.137\n",
      "0.913\n",
      "0.825\n",
      "0.094\n",
      "0.239\n",
      "0.614\n",
      "0.508\n",
      "0.294\n",
      "0.285\n",
      "0.962\n",
      "0.419\n",
      "0.237\n",
      "0.522\n",
      "0.650\n",
      "0.131\n",
      "0.708\n",
      "0.628\n",
      "0.228\n",
      "0.594\n",
      "0.648\n",
      "0.146\n",
      "0.274\n",
      "0.078\n",
      "0.299\n",
      "0.591\n",
      "0.245\n",
      "0.324\n",
      "0.761\n",
      "0.350\n",
      "0.095\n",
      "0.608\n",
      "0.226\n",
      "0.397\n",
      "0.079\n",
      "0.079\n",
      "0.476\n",
      "0.080\n",
      "0.383\n",
      "0.226\n",
      "0.132\n",
      "0.486\n",
      "0.088\n",
      "0.454\n",
      "0.095\n",
      "0.079\n",
      "0.527\n",
      "0.661\n",
      "0.246\n",
      "0.353\n",
      "0.135\n",
      "0.128\n",
      "0.731\n",
      "0.856\n",
      "0.252\n",
      "0.160\n",
      "0.215\n",
      "0.291\n",
      "0.570\n",
      "0.180\n",
      "0.319\n",
      "0.077\n",
      "0.146\n",
      "0.072\n",
      "0.075\n",
      "0.086\n",
      "0.106\n",
      "0.216\n",
      "0.216\n",
      "0.231\n",
      "0.101\n",
      "0.124\n",
      "0.501\n",
      "0.104\n",
      "0.240\n",
      "0.090\n",
      "0.247\n",
      "0.103\n",
      "0.362\n",
      "0.083\n",
      "0.336\n",
      "0.121\n",
      "0.115\n",
      "0.515\n",
      "0.640\n",
      "0.537\n",
      "0.246\n",
      "0.347\n",
      "0.084\n",
      "0.167\n",
      "0.292\n",
      "0.536\n",
      "0.302\n",
      "0.729\n",
      "0.531\n",
      "0.338\n",
      "0.486\n",
      "0.299\n",
      "0.354\n",
      "0.417\n",
      "0.621\n",
      "0.491\n",
      "0.260\n",
      "0.123\n",
      "0.320\n",
      "0.235\n",
      "0.435\n",
      "0.600\n",
      "0.537\n",
      "0.331\n",
      "0.218\n",
      "0.409\n",
      "0.205\n",
      "0.176\n",
      "0.197\n",
      "0.518\n",
      "0.094\n",
      "0.948\n",
      "0.563\n",
      "0.428\n",
      "0.961\n",
      "0.830\n",
      "0.334\n",
      "0.115\n",
      "0.655\n",
      "0.538\n",
      "0.272\n",
      "0.311\n",
      "0.824\n",
      "0.964\n",
      "0.564\n",
      "0.456\n",
      "0.405\n",
      "0.858\n",
      "0.568\n",
      "0.968\n",
      "0.569\n",
      "0.787\n",
      "0.686\n",
      "0.346\n",
      "0.221\n",
      "0.337\n",
      "0.336\n",
      "0.351\n",
      "0.187\n",
      "0.176\n",
      "0.173\n",
      "0.297\n",
      "0.271\n",
      "0.443\n",
      "0.187\n",
      "0.232\n",
      "0.127\n",
      "0.323\n",
      "0.366\n",
      "0.295\n",
      "0.181\n",
      "0.594\n",
      "0.410\n",
      "0.343\n",
      "0.120\n",
      "0.126\n",
      "0.429\n",
      "0.187\n",
      "0.160\n",
      "0.328\n",
      "0.409\n",
      "0.457\n",
      "0.616\n",
      "0.299\n",
      "0.142\n",
      "0.919\n",
      "0.831\n",
      "0.100\n",
      "0.245\n",
      "0.620\n",
      "0.513\n",
      "0.300\n",
      "0.290\n",
      "0.968\n",
      "0.424\n",
      "0.243\n",
      "0.528\n",
      "0.656\n",
      "0.136\n",
      "0.714\n",
      "0.634\n",
      "0.233\n",
      "0.600\n",
      "0.653\n",
      "0.152\n",
      "0.280\n",
      "0.083\n",
      "0.305\n",
      "0.597\n",
      "0.251\n",
      "0.329\n",
      "0.767\n",
      "0.355\n",
      "0.101\n",
      "0.613\n",
      "0.232\n",
      "0.403\n",
      "0.085\n",
      "0.085\n",
      "0.481\n",
      "0.086\n",
      "0.389\n",
      "0.232\n",
      "0.137\n",
      "0.491\n",
      "0.094\n",
      "0.460\n",
      "0.101\n",
      "0.085\n",
      "0.533\n",
      "0.666\n",
      "0.251\n",
      "0.358\n",
      "0.141\n",
      "0.126\n",
      "0.729\n",
      "0.854\n",
      "0.250\n",
      "0.158\n",
      "0.213\n",
      "0.289\n",
      "0.567\n",
      "0.178\n",
      "0.317\n",
      "0.075\n",
      "0.144\n",
      "0.070\n",
      "0.073\n",
      "0.084\n",
      "0.104\n",
      "0.213\n",
      "0.213\n",
      "0.229\n",
      "0.098\n",
      "0.122\n",
      "0.498\n",
      "0.102\n",
      "0.238\n",
      "0.088\n",
      "0.245\n",
      "0.100\n",
      "0.359\n",
      "0.080\n",
      "0.334\n",
      "0.118\n",
      "0.113\n",
      "0.513\n",
      "0.637\n",
      "0.534\n",
      "0.244\n",
      "0.345\n",
      "0.082\n",
      "0.165\n",
      "0.290\n",
      "0.533\n",
      "0.300\n",
      "0.726\n",
      "0.529\n",
      "0.336\n",
      "0.484\n",
      "0.296\n",
      "0.352\n",
      "0.415\n",
      "0.618\n",
      "0.488\n",
      "0.257\n",
      "0.121\n",
      "0.318\n",
      "0.232\n",
      "0.433\n",
      "0.598\n",
      "0.535\n",
      "0.328\n",
      "0.216\n",
      "0.407\n",
      "0.203\n",
      "0.173\n",
      "0.195\n",
      "0.516\n",
      "0.092\n",
      "0.946\n",
      "0.561\n",
      "0.426\n",
      "0.959\n",
      "0.828\n",
      "0.331\n",
      "0.113\n",
      "0.652\n",
      "0.536\n",
      "0.270\n",
      "0.309\n",
      "0.821\n",
      "0.962\n",
      "0.562\n",
      "0.454\n",
      "0.403\n",
      "0.856\n",
      "0.566\n",
      "0.966\n",
      "0.567\n",
      "0.785\n",
      "0.684\n",
      "0.344\n",
      "0.218\n",
      "0.335\n",
      "0.334\n",
      "0.349\n",
      "0.184\n",
      "0.173\n",
      "0.171\n",
      "0.295\n",
      "0.269\n",
      "0.441\n",
      "0.185\n",
      "0.230\n",
      "0.125\n",
      "0.321\n",
      "0.364\n",
      "0.292\n",
      "0.179\n",
      "0.591\n",
      "0.408\n",
      "0.341\n",
      "0.117\n",
      "0.124\n",
      "0.426\n",
      "0.184\n",
      "0.158\n",
      "0.326\n",
      "0.407\n",
      "0.455\n",
      "0.614\n",
      "0.297\n",
      "0.140\n",
      "0.917\n",
      "0.829\n",
      "0.097\n",
      "0.243\n",
      "0.617\n",
      "0.511\n",
      "0.298\n",
      "0.288\n",
      "0.965\n",
      "0.422\n",
      "0.241\n",
      "0.526\n",
      "0.653\n",
      "0.134\n",
      "0.711\n",
      "0.632\n",
      "0.231\n",
      "0.597\n",
      "0.651\n",
      "0.150\n",
      "0.278\n",
      "0.081\n",
      "0.302\n",
      "0.594\n",
      "0.248\n",
      "0.327\n",
      "0.765\n",
      "0.353\n",
      "0.099\n",
      "0.611\n",
      "0.229\n",
      "0.400\n",
      "0.082\n",
      "0.082\n",
      "0.479\n",
      "0.084\n",
      "0.387\n",
      "0.230\n",
      "0.135\n",
      "0.489\n",
      "0.092\n",
      "0.458\n",
      "0.099\n",
      "0.082\n",
      "0.531\n",
      "0.664\n",
      "0.249\n",
      "0.356\n",
      "0.139\n",
      "0.127\n",
      "0.729\n",
      "0.855\n",
      "0.250\n",
      "0.159\n",
      "0.214\n",
      "0.289\n",
      "0.568\n",
      "0.179\n",
      "0.318\n",
      "0.076\n",
      "0.144\n",
      "0.071\n",
      "0.074\n",
      "0.085\n",
      "0.105\n",
      "0.214\n",
      "0.214\n",
      "0.229\n",
      "0.099\n",
      "0.122\n",
      "0.499\n",
      "0.103\n",
      "0.239\n",
      "0.089\n",
      "0.246\n",
      "0.101\n",
      "0.360\n",
      "0.081\n",
      "0.334\n",
      "0.119\n",
      "0.114\n",
      "0.514\n",
      "0.638\n",
      "0.535\n",
      "0.245\n",
      "0.346\n",
      "0.082\n",
      "0.165\n",
      "0.290\n",
      "0.534\n",
      "0.301\n",
      "0.727\n",
      "0.530\n",
      "0.336\n",
      "0.485\n",
      "0.297\n",
      "0.353\n",
      "0.416\n",
      "0.619\n",
      "0.489\n",
      "0.258\n",
      "0.122\n",
      "0.319\n",
      "0.233\n",
      "0.434\n",
      "0.599\n",
      "0.536\n",
      "0.329\n",
      "0.217\n",
      "0.408\n",
      "0.204\n",
      "0.174\n",
      "0.195\n",
      "0.517\n",
      "0.093\n",
      "0.947\n",
      "0.562\n",
      "0.427\n",
      "0.959\n",
      "0.829\n",
      "0.332\n",
      "0.114\n",
      "0.653\n",
      "0.537\n",
      "0.270\n",
      "0.310\n",
      "0.822\n",
      "0.963\n",
      "0.563\n",
      "0.455\n",
      "0.404\n",
      "0.856\n",
      "0.567\n",
      "0.966\n",
      "0.567\n",
      "0.785\n",
      "0.685\n",
      "0.345\n",
      "0.219\n",
      "0.336\n",
      "0.335\n",
      "0.350\n",
      "0.185\n",
      "0.174\n",
      "0.171\n",
      "0.296\n",
      "0.270\n",
      "0.441\n",
      "0.186\n",
      "0.231\n",
      "0.126\n",
      "0.322\n",
      "0.365\n",
      "0.293\n",
      "0.180\n",
      "0.592\n",
      "0.409\n",
      "0.342\n",
      "0.118\n",
      "0.124\n",
      "0.427\n",
      "0.185\n",
      "0.159\n",
      "0.327\n",
      "0.408\n",
      "0.455\n",
      "0.615\n",
      "0.298\n",
      "0.141\n",
      "0.917\n",
      "0.829\n",
      "0.098\n",
      "0.244\n",
      "0.618\n",
      "0.512\n",
      "0.298\n",
      "0.289\n",
      "0.966\n",
      "0.423\n",
      "0.242\n",
      "0.527\n",
      "0.654\n",
      "0.135\n",
      "0.712\n",
      "0.633\n",
      "0.232\n",
      "0.598\n",
      "0.652\n",
      "0.151\n",
      "0.279\n",
      "0.082\n",
      "0.303\n",
      "0.595\n",
      "0.249\n",
      "0.328\n",
      "0.765\n",
      "0.354\n",
      "0.099\n",
      "0.612\n",
      "0.230\n",
      "0.401\n",
      "0.083\n",
      "0.083\n",
      "0.480\n",
      "0.085\n",
      "0.387\n",
      "0.230\n",
      "0.136\n",
      "0.490\n",
      "0.092\n",
      "0.458\n",
      "0.099\n",
      "0.083\n",
      "0.532\n",
      "0.665\n",
      "0.250\n",
      "0.357\n",
      "0.140\n",
      "0.137\n",
      "0.740\n",
      "0.866\n",
      "0.261\n",
      "0.169\n",
      "0.225\n",
      "0.300\n",
      "0.579\n",
      "0.190\n",
      "0.329\n",
      "0.086\n",
      "0.155\n",
      "0.082\n",
      "0.085\n",
      "0.095\n",
      "0.115\n",
      "0.225\n",
      "0.225\n",
      "0.240\n",
      "0.110\n",
      "0.133\n",
      "0.510\n",
      "0.114\n",
      "0.249\n",
      "0.099\n",
      "0.257\n",
      "0.112\n",
      "0.371\n",
      "0.092\n",
      "0.345\n",
      "0.130\n",
      "0.124\n",
      "0.524\n",
      "0.649\n",
      "0.546\n",
      "0.256\n",
      "0.356\n",
      "0.093\n",
      "0.176\n",
      "0.301\n",
      "0.545\n",
      "0.312\n",
      "0.738\n",
      "0.540\n",
      "0.347\n",
      "0.496\n",
      "0.308\n",
      "0.364\n",
      "0.426\n",
      "0.630\n",
      "0.500\n",
      "0.269\n",
      "0.133\n",
      "0.330\n",
      "0.244\n",
      "0.445\n",
      "0.610\n",
      "0.546\n",
      "0.340\n",
      "0.228\n",
      "0.419\n",
      "0.215\n",
      "0.185\n",
      "0.206\n",
      "0.527\n",
      "0.103\n",
      "0.958\n",
      "0.573\n",
      "0.438\n",
      "0.970\n",
      "0.840\n",
      "0.343\n",
      "0.125\n",
      "0.664\n",
      "0.547\n",
      "0.281\n",
      "0.321\n",
      "0.833\n",
      "0.974\n",
      "0.574\n",
      "0.466\n",
      "0.415\n",
      "0.867\n",
      "0.578\n",
      "0.977\n",
      "0.578\n",
      "0.796\n",
      "0.696\n",
      "0.356\n",
      "0.230\n",
      "0.346\n",
      "0.346\n",
      "0.361\n",
      "0.196\n",
      "0.185\n",
      "0.182\n",
      "0.307\n",
      "0.281\n",
      "0.452\n",
      "0.197\n",
      "0.242\n",
      "0.136\n",
      "0.333\n",
      "0.375\n",
      "0.304\n",
      "0.191\n",
      "0.603\n",
      "0.419\n",
      "0.353\n",
      "0.129\n",
      "0.135\n",
      "0.438\n",
      "0.196\n",
      "0.170\n",
      "0.338\n",
      "0.419\n",
      "0.466\n",
      "0.626\n",
      "0.309\n",
      "0.152\n",
      "0.928\n",
      "0.840\n",
      "0.109\n",
      "0.254\n",
      "0.629\n",
      "0.523\n",
      "0.309\n",
      "0.300\n",
      "0.977\n",
      "0.434\n",
      "0.252\n",
      "0.537\n",
      "0.665\n",
      "0.146\n",
      "0.723\n",
      "0.644\n",
      "0.243\n",
      "0.609\n",
      "0.663\n",
      "0.162\n",
      "0.289\n",
      "0.093\n",
      "0.314\n",
      "0.606\n",
      "0.260\n",
      "0.339\n",
      "0.776\n",
      "0.365\n",
      "0.110\n",
      "0.623\n",
      "0.241\n",
      "0.412\n",
      "0.094\n",
      "0.094\n",
      "0.491\n",
      "0.095\n",
      "0.398\n",
      "0.241\n",
      "0.147\n",
      "0.501\n",
      "0.103\n",
      "0.469\n",
      "0.110\n",
      "0.094\n",
      "0.542\n",
      "0.676\n",
      "0.261\n",
      "0.368\n",
      "0.150\n",
      "0.140\n",
      "0.743\n",
      "0.868\n",
      "0.264\n",
      "0.172\n",
      "0.227\n",
      "0.302\n",
      "0.581\n",
      "0.192\n",
      "0.331\n",
      "0.089\n",
      "0.158\n",
      "0.084\n",
      "0.087\n",
      "0.098\n",
      "0.118\n",
      "0.227\n",
      "0.227\n",
      "0.243\n",
      "0.112\n",
      "0.135\n",
      "0.512\n",
      "0.116\n",
      "0.252\n",
      "0.102\n",
      "0.259\n",
      "0.114\n",
      "0.373\n",
      "0.094\n",
      "0.348\n",
      "0.132\n",
      "0.127\n",
      "0.527\n",
      "0.651\n",
      "0.548\n",
      "0.258\n",
      "0.359\n",
      "0.095\n",
      "0.179\n",
      "0.304\n",
      "0.547\n",
      "0.314\n",
      "0.740\n",
      "0.543\n",
      "0.349\n",
      "0.498\n",
      "0.310\n",
      "0.366\n",
      "0.429\n",
      "0.632\n",
      "0.502\n",
      "0.271\n",
      "0.135\n",
      "0.332\n",
      "0.246\n",
      "0.447\n",
      "0.612\n",
      "0.549\n",
      "0.342\n",
      "0.230\n",
      "0.421\n",
      "0.217\n",
      "0.187\n",
      "0.208\n",
      "0.530\n",
      "0.106\n",
      "0.960\n",
      "0.575\n",
      "0.440\n",
      "0.973\n",
      "0.842\n",
      "0.345\n",
      "0.127\n",
      "0.666\n",
      "0.550\n",
      "0.284\n",
      "0.323\n",
      "0.835\n",
      "0.976\n",
      "0.576\n",
      "0.468\n",
      "0.417\n",
      "0.869\n",
      "0.580\n",
      "0.979\n",
      "0.580\n",
      "0.798\n",
      "0.698\n",
      "0.358\n",
      "0.232\n",
      "0.349\n",
      "0.348\n",
      "0.363\n",
      "0.198\n",
      "0.187\n",
      "0.185\n",
      "0.309\n",
      "0.283\n",
      "0.454\n",
      "0.199\n",
      "0.244\n",
      "0.139\n",
      "0.335\n",
      "0.378\n",
      "0.306\n",
      "0.193\n",
      "0.605\n",
      "0.422\n",
      "0.355\n",
      "0.131\n",
      "0.138\n",
      "0.440\n",
      "0.198\n",
      "0.172\n",
      "0.340\n",
      "0.421\n",
      "0.468\n",
      "0.628\n",
      "0.311\n",
      "0.154\n",
      "0.930\n",
      "0.842\n",
      "0.111\n",
      "0.257\n",
      "0.631\n",
      "0.525\n",
      "0.311\n",
      "0.302\n",
      "0.979\n",
      "0.436\n",
      "0.255\n",
      "0.540\n",
      "0.667\n",
      "0.148\n",
      "0.725\n",
      "0.646\n",
      "0.245\n",
      "0.611\n",
      "0.665\n",
      "0.164\n",
      "0.292\n",
      "0.095\n",
      "0.316\n",
      "0.608\n",
      "0.262\n",
      "0.341\n",
      "0.778\n",
      "0.367\n",
      "0.112\n",
      "0.625\n",
      "0.243\n",
      "0.414\n",
      "0.096\n",
      "0.096\n",
      "0.493\n",
      "0.098\n",
      "0.401\n",
      "0.243\n",
      "0.149\n",
      "0.503\n",
      "0.106\n",
      "0.471\n",
      "0.112\n",
      "0.096\n",
      "0.545\n",
      "0.678\n",
      "0.263\n",
      "0.370\n",
      "0.153\n",
      "0.135\n",
      "0.737\n",
      "0.863\n",
      "0.258\n",
      "0.167\n",
      "0.222\n",
      "0.297\n",
      "0.576\n",
      "0.187\n",
      "0.326\n",
      "0.084\n",
      "0.153\n",
      "0.079\n",
      "0.082\n",
      "0.093\n",
      "0.113\n",
      "0.222\n",
      "0.222\n",
      "0.238\n",
      "0.107\n",
      "0.130\n",
      "0.507\n",
      "0.111\n",
      "0.247\n",
      "0.097\n",
      "0.254\n",
      "0.109\n",
      "0.368\n",
      "0.089\n",
      "0.343\n",
      "0.127\n",
      "0.122\n",
      "0.522\n",
      "0.646\n",
      "0.543\n",
      "0.253\n",
      "0.354\n",
      "0.090\n",
      "0.174\n",
      "0.299\n",
      "0.542\n",
      "0.309\n",
      "0.735\n",
      "0.538\n",
      "0.344\n",
      "0.493\n",
      "0.305\n",
      "0.361\n",
      "0.424\n",
      "0.627\n",
      "0.497\n",
      "0.266\n",
      "0.130\n",
      "0.327\n",
      "0.241\n",
      "0.442\n",
      "0.607\n",
      "0.544\n",
      "0.337\n",
      "0.225\n",
      "0.416\n",
      "0.212\n",
      "0.182\n",
      "0.203\n",
      "0.525\n",
      "0.101\n",
      "0.955\n",
      "0.570\n",
      "0.435\n",
      "0.968\n",
      "0.837\n",
      "0.340\n",
      "0.122\n",
      "0.661\n",
      "0.545\n",
      "0.279\n",
      "0.318\n",
      "0.830\n",
      "0.971\n",
      "0.571\n",
      "0.463\n",
      "0.412\n",
      "0.864\n",
      "0.575\n",
      "0.974\n",
      "0.575\n",
      "0.793\n",
      "0.693\n",
      "0.353\n",
      "0.227\n",
      "0.344\n",
      "0.343\n",
      "0.358\n",
      "0.193\n",
      "0.182\n",
      "0.179\n",
      "0.304\n",
      "0.278\n",
      "0.449\n",
      "0.194\n",
      "0.239\n",
      "0.134\n",
      "0.330\n",
      "0.373\n",
      "0.301\n",
      "0.188\n",
      "0.600\n",
      "0.417\n",
      "0.350\n",
      "0.126\n",
      "0.133\n",
      "0.435\n",
      "0.193\n",
      "0.167\n",
      "0.335\n",
      "0.416\n",
      "0.463\n",
      "0.623\n",
      "0.306\n",
      "0.149\n",
      "0.925\n",
      "0.837\n",
      "0.106\n",
      "0.252\n",
      "0.626\n",
      "0.520\n",
      "0.306\n",
      "0.297\n",
      "0.974\n",
      "0.431\n",
      "0.250\n",
      "0.535\n",
      "0.662\n",
      "0.143\n",
      "0.720\n",
      "0.641\n",
      "0.240\n",
      "0.606\n",
      "0.660\n",
      "0.159\n",
      "0.287\n",
      "0.090\n",
      "0.311\n",
      "0.603\n",
      "0.257\n",
      "0.336\n",
      "0.773\n",
      "0.362\n",
      "0.107\n",
      "0.620\n",
      "0.238\n",
      "0.409\n",
      "0.091\n",
      "0.091\n",
      "0.488\n",
      "0.093\n",
      "0.396\n",
      "0.238\n",
      "0.144\n",
      "0.498\n",
      "0.101\n",
      "0.466\n",
      "0.107\n",
      "0.091\n",
      "0.540\n",
      "0.673\n",
      "0.258\n",
      "0.365\n",
      "0.148\n",
      "0.133\n",
      "0.736\n",
      "0.861\n",
      "0.257\n",
      "0.165\n",
      "0.220\n",
      "0.296\n",
      "0.575\n",
      "0.185\n",
      "0.324\n",
      "0.082\n",
      "0.151\n",
      "0.077\n",
      "0.080\n",
      "0.091\n",
      "0.111\n",
      "0.221\n",
      "0.221\n",
      "0.236\n",
      "0.106\n",
      "0.129\n",
      "0.506\n",
      "0.109\n",
      "0.245\n",
      "0.095\n",
      "0.252\n",
      "0.108\n",
      "0.367\n",
      "0.088\n",
      "0.341\n",
      "0.126\n",
      "0.120\n",
      "0.520\n",
      "0.645\n",
      "0.542\n",
      "0.251\n",
      "0.352\n",
      "0.089\n",
      "0.172\n",
      "0.297\n",
      "0.541\n",
      "0.308\n",
      "0.734\n",
      "0.536\n",
      "0.343\n",
      "0.491\n",
      "0.304\n",
      "0.359\n",
      "0.422\n",
      "0.626\n",
      "0.496\n",
      "0.265\n",
      "0.128\n",
      "0.325\n",
      "0.240\n",
      "0.440\n",
      "0.605\n",
      "0.542\n",
      "0.336\n",
      "0.223\n",
      "0.414\n",
      "0.210\n",
      "0.181\n",
      "0.202\n",
      "0.523\n",
      "0.099\n",
      "0.954\n",
      "0.568\n",
      "0.433\n",
      "0.966\n",
      "0.835\n",
      "0.339\n",
      "0.120\n",
      "0.660\n",
      "0.543\n",
      "0.277\n",
      "0.316\n",
      "0.829\n",
      "0.969\n",
      "0.569\n",
      "0.461\n",
      "0.410\n",
      "0.863\n",
      "0.574\n",
      "0.973\n",
      "0.574\n",
      "0.792\n",
      "0.691\n",
      "0.351\n",
      "0.226\n",
      "0.342\n",
      "0.341\n",
      "0.356\n",
      "0.192\n",
      "0.181\n",
      "0.178\n",
      "0.302\n",
      "0.276\n",
      "0.448\n",
      "0.192\n",
      "0.237\n",
      "0.132\n",
      "0.328\n",
      "0.371\n",
      "0.300\n",
      "0.186\n",
      "0.599\n",
      "0.415\n",
      "0.349\n",
      "0.125\n",
      "0.131\n",
      "0.434\n",
      "0.192\n",
      "0.165\n",
      "0.333\n",
      "0.414\n",
      "0.462\n",
      "0.621\n",
      "0.304\n",
      "0.147\n",
      "0.924\n",
      "0.836\n",
      "0.105\n",
      "0.250\n",
      "0.625\n",
      "0.518\n",
      "0.305\n",
      "0.295\n",
      "0.973\n",
      "0.429\n",
      "0.248\n",
      "0.533\n",
      "0.661\n",
      "0.141\n",
      "0.719\n",
      "0.639\n",
      "0.238\n",
      "0.605\n",
      "0.659\n",
      "0.157\n",
      "0.285\n",
      "0.089\n",
      "0.310\n",
      "0.602\n",
      "0.256\n",
      "0.334\n",
      "0.772\n",
      "0.360\n",
      "0.106\n",
      "0.618\n",
      "0.237\n",
      "0.408\n",
      "0.090\n",
      "0.090\n",
      "0.486\n",
      "0.091\n",
      "0.394\n",
      "0.237\n",
      "0.142\n",
      "0.496\n",
      "0.099\n",
      "0.465\n",
      "0.106\n",
      "0.090\n",
      "0.538\n",
      "0.671\n",
      "0.256\n",
      "0.363\n",
      "0.146\n",
      "0.138\n",
      "0.741\n",
      "0.867\n",
      "0.262\n",
      "0.170\n",
      "0.226\n",
      "0.301\n",
      "0.580\n",
      "0.191\n",
      "0.330\n",
      "0.087\n",
      "0.156\n",
      "0.083\n",
      "0.086\n",
      "0.096\n",
      "0.116\n",
      "0.226\n",
      "0.226\n",
      "0.241\n",
      "0.111\n",
      "0.134\n",
      "0.511\n",
      "0.115\n",
      "0.251\n",
      "0.100\n",
      "0.258\n",
      "0.113\n",
      "0.372\n",
      "0.093\n",
      "0.346\n",
      "0.131\n",
      "0.125\n",
      "0.525\n",
      "0.650\n",
      "0.547\n",
      "0.257\n",
      "0.357\n",
      "0.094\n",
      "0.177\n",
      "0.302\n",
      "0.546\n",
      "0.313\n",
      "0.739\n",
      "0.541\n",
      "0.348\n",
      "0.497\n",
      "0.309\n",
      "0.365\n",
      "0.427\n",
      "0.631\n",
      "0.501\n",
      "0.270\n",
      "0.134\n",
      "0.331\n",
      "0.245\n",
      "0.446\n",
      "0.611\n",
      "0.547\n",
      "0.341\n",
      "0.229\n",
      "0.420\n",
      "0.216\n",
      "0.186\n",
      "0.207\n",
      "0.528\n",
      "0.105\n",
      "0.959\n",
      "0.574\n",
      "0.439\n",
      "0.971\n",
      "0.841\n",
      "0.344\n",
      "0.126\n",
      "0.665\n",
      "0.549\n",
      "0.282\n",
      "0.322\n",
      "0.834\n",
      "0.975\n",
      "0.575\n",
      "0.467\n",
      "0.416\n",
      "0.868\n",
      "0.579\n",
      "0.978\n",
      "0.579\n",
      "0.797\n",
      "0.697\n",
      "0.357\n",
      "0.231\n",
      "0.347\n",
      "0.347\n",
      "0.362\n",
      "0.197\n",
      "0.186\n",
      "0.183\n",
      "0.308\n",
      "0.282\n",
      "0.453\n",
      "0.198\n",
      "0.243\n",
      "0.137\n",
      "0.334\n",
      "0.376\n",
      "0.305\n",
      "0.192\n",
      "0.604\n",
      "0.420\n",
      "0.354\n",
      "0.130\n",
      "0.136\n",
      "0.439\n",
      "0.197\n",
      "0.171\n",
      "0.339\n",
      "0.420\n",
      "0.467\n",
      "0.627\n",
      "0.310\n",
      "0.153\n",
      "0.929\n",
      "0.841\n",
      "0.110\n",
      "0.255\n",
      "0.630\n",
      "0.524\n",
      "0.310\n",
      "0.301\n",
      "0.978\n",
      "0.435\n",
      "0.254\n",
      "0.538\n",
      "0.666\n",
      "0.147\n",
      "0.724\n",
      "0.645\n",
      "0.244\n",
      "0.610\n",
      "0.664\n",
      "0.163\n",
      "0.290\n",
      "0.094\n",
      "0.315\n",
      "0.607\n",
      "0.261\n",
      "0.340\n",
      "0.777\n",
      "0.366\n",
      "0.111\n",
      "0.624\n",
      "0.242\n",
      "0.413\n",
      "0.095\n",
      "0.095\n",
      "0.492\n",
      "0.096\n",
      "0.399\n",
      "0.242\n",
      "0.148\n",
      "0.502\n",
      "0.104\n",
      "0.470\n",
      "0.111\n",
      "0.095\n",
      "0.543\n",
      "0.677\n",
      "0.262\n",
      "0.369\n",
      "0.152\n",
      "0.145\n",
      "0.748\n",
      "0.873\n",
      "0.269\n",
      "0.177\n",
      "0.232\n",
      "0.308\n",
      "0.587\n",
      "0.197\n",
      "0.336\n",
      "0.094\n",
      "0.163\n",
      "0.089\n",
      "0.092\n",
      "0.103\n",
      "0.123\n",
      "0.233\n",
      "0.233\n",
      "0.248\n",
      "0.117\n",
      "0.141\n",
      "0.518\n",
      "0.121\n",
      "0.257\n",
      "0.107\n",
      "0.264\n",
      "0.120\n",
      "0.379\n",
      "0.100\n",
      "0.353\n",
      "0.138\n",
      "0.132\n",
      "0.532\n",
      "0.657\n",
      "0.554\n",
      "0.263\n",
      "0.364\n",
      "0.101\n",
      "0.184\n",
      "0.309\n",
      "0.553\n",
      "0.319\n",
      "0.745\n",
      "0.548\n",
      "0.355\n",
      "0.503\n",
      "0.316\n",
      "0.371\n",
      "0.434\n",
      "0.637\n",
      "0.508\n",
      "0.277\n",
      "0.140\n",
      "0.337\n",
      "0.252\n",
      "0.452\n",
      "0.617\n",
      "0.554\n",
      "0.348\n",
      "0.235\n",
      "0.426\n",
      "0.222\n",
      "0.193\n",
      "0.214\n",
      "0.535\n",
      "0.111\n",
      "0.965\n",
      "0.580\n",
      "0.445\n",
      "0.978\n",
      "0.847\n",
      "0.351\n",
      "0.132\n",
      "0.672\n",
      "0.555\n",
      "0.289\n",
      "0.328\n",
      "0.841\n",
      "0.981\n",
      "0.581\n",
      "0.473\n",
      "0.422\n",
      "0.875\n",
      "0.585\n",
      "0.985\n",
      "0.586\n",
      "0.804\n",
      "0.703\n",
      "0.363\n",
      "0.237\n",
      "0.354\n",
      "0.353\n",
      "0.368\n",
      "0.204\n",
      "0.193\n",
      "0.190\n",
      "0.314\n",
      "0.288\n",
      "0.460\n",
      "0.204\n",
      "0.249\n",
      "0.144\n",
      "0.340\n",
      "0.383\n",
      "0.312\n",
      "0.198\n",
      "0.611\n",
      "0.427\n",
      "0.360\n",
      "0.137\n",
      "0.143\n",
      "0.446\n",
      "0.204\n",
      "0.177\n",
      "0.345\n",
      "0.426\n",
      "0.474\n",
      "0.633\n",
      "0.316\n",
      "0.159\n",
      "0.936\n",
      "0.848\n",
      "0.117\n",
      "0.262\n",
      "0.637\n",
      "0.530\n",
      "0.317\n",
      "0.307\n",
      "0.985\n",
      "0.441\n",
      "0.260\n",
      "0.545\n",
      "0.672\n",
      "0.153\n",
      "0.731\n",
      "0.651\n",
      "0.250\n",
      "0.617\n",
      "0.670\n",
      "0.169\n",
      "0.297\n",
      "0.100\n",
      "0.322\n",
      "0.614\n",
      "0.268\n",
      "0.346\n",
      "0.784\n",
      "0.372\n",
      "0.118\n",
      "0.630\n",
      "0.249\n",
      "0.420\n",
      "0.102\n",
      "0.102\n",
      "0.498\n",
      "0.103\n",
      "0.406\n",
      "0.249\n",
      "0.154\n",
      "0.508\n",
      "0.111\n",
      "0.477\n",
      "0.118\n",
      "0.102\n",
      "0.550\n",
      "0.683\n",
      "0.268\n",
      "0.375\n",
      "0.158\n",
      "0.133\n",
      "0.736\n",
      "0.861\n",
      "0.257\n",
      "0.165\n",
      "0.220\n",
      "0.296\n",
      "0.574\n",
      "0.185\n",
      "0.324\n",
      "0.082\n",
      "0.151\n",
      "0.077\n",
      "0.080\n",
      "0.091\n",
      "0.111\n",
      "0.220\n",
      "0.220\n",
      "0.236\n",
      "0.105\n",
      "0.129\n",
      "0.505\n",
      "0.109\n",
      "0.245\n",
      "0.095\n",
      "0.252\n",
      "0.107\n",
      "0.366\n",
      "0.087\n",
      "0.341\n",
      "0.125\n",
      "0.120\n",
      "0.520\n",
      "0.644\n",
      "0.541\n",
      "0.251\n",
      "0.352\n",
      "0.088\n",
      "0.172\n",
      "0.297\n",
      "0.540\n",
      "0.307\n",
      "0.733\n",
      "0.536\n",
      "0.342\n",
      "0.491\n",
      "0.303\n",
      "0.359\n",
      "0.422\n",
      "0.625\n",
      "0.495\n",
      "0.264\n",
      "0.128\n",
      "0.325\n",
      "0.239\n",
      "0.440\n",
      "0.605\n",
      "0.542\n",
      "0.335\n",
      "0.223\n",
      "0.414\n",
      "0.210\n",
      "0.180\n",
      "0.202\n",
      "0.523\n",
      "0.099\n",
      "0.953\n",
      "0.568\n",
      "0.433\n",
      "0.966\n",
      "0.835\n",
      "0.338\n",
      "0.120\n",
      "0.659\n",
      "0.543\n",
      "0.277\n",
      "0.316\n",
      "0.828\n",
      "0.969\n",
      "0.569\n",
      "0.461\n",
      "0.410\n",
      "0.863\n",
      "0.573\n",
      "0.973\n",
      "0.573\n",
      "0.792\n",
      "0.691\n",
      "0.351\n",
      "0.225\n",
      "0.342\n",
      "0.341\n",
      "0.356\n",
      "0.191\n",
      "0.180\n",
      "0.178\n",
      "0.302\n",
      "0.276\n",
      "0.448\n",
      "0.192\n",
      "0.237\n",
      "0.132\n",
      "0.328\n",
      "0.371\n",
      "0.299\n",
      "0.186\n",
      "0.598\n",
      "0.415\n",
      "0.348\n",
      "0.124\n",
      "0.131\n",
      "0.433\n",
      "0.191\n",
      "0.165\n",
      "0.333\n",
      "0.414\n",
      "0.462\n",
      "0.621\n",
      "0.304\n",
      "0.147\n",
      "0.924\n",
      "0.836\n",
      "0.104\n",
      "0.250\n",
      "0.624\n",
      "0.518\n",
      "0.305\n",
      "0.295\n",
      "0.972\n",
      "0.429\n",
      "0.248\n",
      "0.533\n",
      "0.660\n",
      "0.141\n",
      "0.718\n",
      "0.639\n",
      "0.238\n",
      "0.604\n",
      "0.658\n",
      "0.157\n",
      "0.285\n",
      "0.088\n",
      "0.309\n",
      "0.601\n",
      "0.255\n",
      "0.334\n",
      "0.772\n",
      "0.360\n",
      "0.106\n",
      "0.618\n",
      "0.236\n",
      "0.407\n",
      "0.089\n",
      "0.089\n",
      "0.486\n",
      "0.091\n",
      "0.394\n",
      "0.237\n",
      "0.142\n",
      "0.496\n",
      "0.099\n",
      "0.465\n",
      "0.106\n",
      "0.089\n",
      "0.538\n",
      "0.671\n",
      "0.256\n",
      "0.363\n",
      "0.146\n",
      "0.122\n",
      "0.725\n",
      "0.850\n",
      "0.246\n",
      "0.154\n",
      "0.209\n",
      "0.285\n",
      "0.563\n",
      "0.174\n",
      "0.313\n",
      "0.071\n",
      "0.140\n",
      "0.066\n",
      "0.069\n",
      "0.080\n",
      "0.100\n",
      "0.209\n",
      "0.209\n",
      "0.225\n",
      "0.094\n",
      "0.118\n",
      "0.494\n",
      "0.098\n",
      "0.234\n",
      "0.084\n",
      "0.241\n",
      "0.096\n",
      "0.355\n",
      "0.076\n",
      "0.330\n",
      "0.114\n",
      "0.109\n",
      "0.509\n",
      "0.633\n",
      "0.530\n",
      "0.240\n",
      "0.341\n",
      "0.078\n",
      "0.161\n",
      "0.286\n",
      "0.529\n",
      "0.296\n",
      "0.722\n",
      "0.525\n",
      "0.332\n",
      "0.480\n",
      "0.292\n",
      "0.348\n",
      "0.411\n",
      "0.614\n",
      "0.484\n",
      "0.253\n",
      "0.117\n",
      "0.314\n",
      "0.228\n",
      "0.429\n",
      "0.594\n",
      "0.531\n",
      "0.324\n",
      "0.212\n",
      "0.403\n",
      "0.199\n",
      "0.169\n",
      "0.191\n",
      "0.512\n",
      "0.088\n",
      "0.942\n",
      "0.557\n",
      "0.422\n",
      "0.955\n",
      "0.824\n",
      "0.327\n",
      "0.109\n",
      "0.648\n",
      "0.532\n",
      "0.266\n",
      "0.305\n",
      "0.817\n",
      "0.958\n",
      "0.558\n",
      "0.450\n",
      "0.399\n",
      "0.852\n",
      "0.562\n",
      "0.962\n",
      "0.562\n",
      "0.781\n",
      "0.680\n",
      "0.340\n",
      "0.214\n",
      "0.331\n",
      "0.330\n",
      "0.345\n",
      "0.180\n",
      "0.169\n",
      "0.167\n",
      "0.291\n",
      "0.265\n",
      "0.437\n",
      "0.181\n",
      "0.226\n",
      "0.121\n",
      "0.317\n",
      "0.360\n",
      "0.288\n",
      "0.175\n",
      "0.587\n",
      "0.404\n",
      "0.337\n",
      "0.113\n",
      "0.120\n",
      "0.422\n",
      "0.180\n",
      "0.154\n",
      "0.322\n",
      "0.403\n",
      "0.451\n",
      "0.610\n",
      "0.293\n",
      "0.136\n",
      "0.913\n",
      "0.825\n",
      "0.093\n",
      "0.239\n",
      "0.613\n",
      "0.507\n",
      "0.294\n",
      "0.284\n",
      "0.961\n",
      "0.418\n",
      "0.237\n",
      "0.522\n",
      "0.649\n",
      "0.130\n",
      "0.707\n",
      "0.628\n",
      "0.227\n",
      "0.593\n",
      "0.647\n",
      "0.146\n",
      "0.274\n",
      "0.077\n",
      "0.298\n",
      "0.590\n",
      "0.244\n",
      "0.323\n",
      "0.761\n",
      "0.349\n",
      "0.095\n",
      "0.607\n",
      "0.225\n",
      "0.396\n",
      "0.078\n",
      "0.078\n",
      "0.475\n",
      "0.080\n",
      "0.383\n",
      "0.226\n",
      "0.131\n",
      "0.485\n",
      "0.088\n",
      "0.454\n",
      "0.095\n",
      "0.078\n",
      "0.527\n",
      "0.660\n",
      "0.245\n",
      "0.352\n",
      "0.135\n",
      "0.133\n",
      "0.736\n",
      "0.861\n",
      "0.257\n",
      "0.165\n",
      "0.220\n",
      "0.296\n",
      "0.574\n",
      "0.185\n",
      "0.324\n",
      "0.082\n",
      "0.151\n",
      "0.077\n",
      "0.080\n",
      "0.091\n",
      "0.111\n",
      "0.221\n",
      "0.221\n",
      "0.236\n",
      "0.105\n",
      "0.129\n",
      "0.505\n",
      "0.109\n",
      "0.245\n",
      "0.095\n",
      "0.252\n",
      "0.107\n",
      "0.367\n",
      "0.087\n",
      "0.341\n",
      "0.125\n",
      "0.120\n",
      "0.520\n",
      "0.644\n",
      "0.542\n",
      "0.251\n",
      "0.352\n",
      "0.089\n",
      "0.172\n",
      "0.297\n",
      "0.540\n",
      "0.307\n",
      "0.733\n",
      "0.536\n",
      "0.343\n",
      "0.491\n",
      "0.303\n",
      "0.359\n",
      "0.422\n",
      "0.625\n",
      "0.495\n",
      "0.264\n",
      "0.128\n",
      "0.325\n",
      "0.239\n",
      "0.440\n",
      "0.605\n",
      "0.542\n",
      "0.335\n",
      "0.223\n",
      "0.414\n",
      "0.210\n",
      "0.180\n",
      "0.202\n",
      "0.523\n",
      "0.099\n",
      "0.953\n",
      "0.568\n",
      "0.433\n",
      "0.966\n",
      "0.835\n",
      "0.338\n",
      "0.120\n",
      "0.659\n",
      "0.543\n",
      "0.277\n",
      "0.316\n",
      "0.828\n",
      "0.969\n",
      "0.569\n",
      "0.461\n",
      "0.410\n",
      "0.863\n",
      "0.573\n",
      "0.973\n",
      "0.574\n",
      "0.792\n",
      "0.691\n",
      "0.351\n",
      "0.225\n",
      "0.342\n",
      "0.341\n",
      "0.356\n",
      "0.191\n",
      "0.180\n",
      "0.178\n",
      "0.302\n",
      "0.276\n",
      "0.448\n",
      "0.192\n",
      "0.237\n",
      "0.132\n",
      "0.328\n",
      "0.371\n",
      "0.299\n",
      "0.186\n",
      "0.598\n",
      "0.415\n",
      "0.348\n",
      "0.124\n",
      "0.131\n",
      "0.434\n",
      "0.191\n",
      "0.165\n",
      "0.333\n",
      "0.414\n",
      "0.462\n",
      "0.621\n",
      "0.304\n",
      "0.147\n",
      "0.924\n",
      "0.836\n",
      "0.104\n",
      "0.250\n",
      "0.624\n",
      "0.518\n",
      "0.305\n",
      "0.295\n",
      "0.972\n",
      "0.429\n",
      "0.248\n",
      "0.533\n",
      "0.660\n",
      "0.141\n",
      "0.718\n",
      "0.639\n",
      "0.238\n",
      "0.604\n",
      "0.658\n",
      "0.157\n",
      "0.285\n",
      "0.088\n",
      "0.309\n",
      "0.601\n",
      "0.256\n",
      "0.334\n",
      "0.772\n",
      "0.360\n",
      "0.106\n",
      "0.618\n",
      "0.236\n",
      "0.408\n",
      "0.089\n",
      "0.089\n",
      "0.486\n",
      "0.091\n",
      "0.394\n",
      "0.237\n",
      "0.142\n",
      "0.496\n",
      "0.099\n",
      "0.465\n",
      "0.106\n",
      "0.089\n",
      "0.538\n",
      "0.671\n",
      "0.256\n",
      "0.363\n",
      "0.146\n",
      "0.126\n",
      "0.729\n",
      "0.854\n",
      "0.250\n",
      "0.158\n",
      "0.213\n",
      "0.289\n",
      "0.567\n",
      "0.178\n",
      "0.317\n",
      "0.075\n",
      "0.144\n",
      "0.070\n",
      "0.073\n",
      "0.084\n",
      "0.104\n",
      "0.214\n",
      "0.214\n",
      "0.229\n",
      "0.098\n",
      "0.122\n",
      "0.498\n",
      "0.102\n",
      "0.238\n",
      "0.088\n",
      "0.245\n",
      "0.100\n",
      "0.360\n",
      "0.080\n",
      "0.334\n",
      "0.118\n",
      "0.113\n",
      "0.513\n",
      "0.637\n",
      "0.535\n",
      "0.244\n",
      "0.345\n",
      "0.082\n",
      "0.165\n",
      "0.290\n",
      "0.533\n",
      "0.300\n",
      "0.726\n",
      "0.529\n",
      "0.336\n",
      "0.484\n",
      "0.296\n",
      "0.352\n",
      "0.415\n",
      "0.618\n",
      "0.488\n",
      "0.258\n",
      "0.121\n",
      "0.318\n",
      "0.232\n",
      "0.433\n",
      "0.598\n",
      "0.535\n",
      "0.328\n",
      "0.216\n",
      "0.407\n",
      "0.203\n",
      "0.173\n",
      "0.195\n",
      "0.516\n",
      "0.092\n",
      "0.946\n",
      "0.561\n",
      "0.426\n",
      "0.959\n",
      "0.828\n",
      "0.331\n",
      "0.113\n",
      "0.652\n",
      "0.536\n",
      "0.270\n",
      "0.309\n",
      "0.822\n",
      "0.962\n",
      "0.562\n",
      "0.454\n",
      "0.403\n",
      "0.856\n",
      "0.566\n",
      "0.966\n",
      "0.567\n",
      "0.785\n",
      "0.684\n",
      "0.344\n",
      "0.218\n",
      "0.335\n",
      "0.334\n",
      "0.349\n",
      "0.185\n",
      "0.173\n",
      "0.171\n",
      "0.295\n",
      "0.269\n",
      "0.441\n",
      "0.185\n",
      "0.230\n",
      "0.125\n",
      "0.321\n",
      "0.364\n",
      "0.293\n",
      "0.179\n",
      "0.591\n",
      "0.408\n",
      "0.341\n",
      "0.117\n",
      "0.124\n",
      "0.427\n",
      "0.185\n",
      "0.158\n",
      "0.326\n",
      "0.407\n",
      "0.455\n",
      "0.614\n",
      "0.297\n",
      "0.140\n",
      "0.917\n",
      "0.829\n",
      "0.097\n",
      "0.243\n",
      "0.617\n",
      "0.511\n",
      "0.298\n",
      "0.288\n",
      "0.965\n",
      "0.422\n",
      "0.241\n",
      "0.526\n",
      "0.653\n",
      "0.134\n",
      "0.711\n",
      "0.632\n",
      "0.231\n",
      "0.597\n",
      "0.651\n",
      "0.150\n",
      "0.278\n",
      "0.081\n",
      "0.302\n",
      "0.594\n",
      "0.249\n",
      "0.327\n",
      "0.765\n",
      "0.353\n",
      "0.099\n",
      "0.611\n",
      "0.229\n",
      "0.401\n",
      "0.082\n",
      "0.082\n",
      "0.479\n",
      "0.084\n",
      "0.387\n",
      "0.230\n",
      "0.135\n",
      "0.489\n",
      "0.092\n",
      "0.458\n",
      "0.099\n",
      "0.082\n",
      "0.531\n",
      "0.664\n",
      "0.249\n",
      "0.356\n",
      "0.139\n",
      "0.110\n",
      "0.712\n",
      "0.838\n",
      "0.233\n",
      "0.142\n",
      "0.197\n",
      "0.272\n",
      "0.551\n",
      "0.162\n",
      "0.301\n",
      "0.059\n",
      "0.127\n",
      "0.054\n",
      "0.057\n",
      "0.068\n",
      "0.088\n",
      "0.197\n",
      "0.197\n",
      "0.212\n",
      "0.082\n",
      "0.105\n",
      "0.482\n",
      "0.086\n",
      "0.222\n",
      "0.072\n",
      "0.229\n",
      "0.084\n",
      "0.343\n",
      "0.064\n",
      "0.317\n",
      "0.102\n",
      "0.097\n",
      "0.497\n",
      "0.621\n",
      "0.518\n",
      "0.228\n",
      "0.329\n",
      "0.065\n",
      "0.148\n",
      "0.274\n",
      "0.517\n",
      "0.284\n",
      "0.710\n",
      "0.513\n",
      "0.319\n",
      "0.468\n",
      "0.280\n",
      "0.336\n",
      "0.399\n",
      "0.602\n",
      "0.472\n",
      "0.241\n",
      "0.105\n",
      "0.302\n",
      "0.216\n",
      "0.417\n",
      "0.582\n",
      "0.519\n",
      "0.312\n",
      "0.200\n",
      "0.391\n",
      "0.187\n",
      "0.157\n",
      "0.178\n",
      "0.500\n",
      "0.076\n",
      "0.930\n",
      "0.545\n",
      "0.410\n",
      "0.943\n",
      "0.812\n",
      "0.315\n",
      "0.097\n",
      "0.636\n",
      "0.520\n",
      "0.253\n",
      "0.293\n",
      "0.805\n",
      "0.946\n",
      "0.546\n",
      "0.438\n",
      "0.387\n",
      "0.839\n",
      "0.550\n",
      "0.949\n",
      "0.550\n",
      "0.768\n",
      "0.668\n",
      "0.328\n",
      "0.202\n",
      "0.319\n",
      "0.318\n",
      "0.333\n",
      "0.168\n",
      "0.157\n",
      "0.154\n",
      "0.279\n",
      "0.253\n",
      "0.424\n",
      "0.169\n",
      "0.214\n",
      "0.109\n",
      "0.305\n",
      "0.348\n",
      "0.276\n",
      "0.163\n",
      "0.575\n",
      "0.392\n",
      "0.325\n",
      "0.101\n",
      "0.107\n",
      "0.410\n",
      "0.168\n",
      "0.142\n",
      "0.310\n",
      "0.391\n",
      "0.438\n",
      "0.598\n",
      "0.281\n",
      "0.124\n",
      "0.900\n",
      "0.812\n",
      "0.081\n",
      "0.227\n",
      "0.601\n",
      "0.495\n",
      "0.281\n",
      "0.272\n",
      "0.949\n",
      "0.406\n",
      "0.225\n",
      "0.510\n",
      "0.637\n",
      "0.118\n",
      "0.695\n",
      "0.616\n",
      "0.215\n",
      "0.581\n",
      "0.635\n",
      "0.134\n",
      "0.262\n",
      "0.065\n",
      "0.286\n",
      "0.578\n",
      "0.232\n",
      "0.311\n",
      "0.748\n",
      "0.337\n",
      "0.082\n",
      "0.595\n",
      "0.213\n",
      "0.384\n",
      "0.066\n",
      "0.066\n",
      "0.463\n",
      "0.068\n",
      "0.370\n",
      "0.213\n",
      "0.119\n",
      "0.473\n",
      "0.075\n",
      "0.441\n",
      "0.082\n",
      "0.066\n",
      "0.515\n",
      "0.648\n",
      "0.233\n",
      "0.340\n",
      "0.123\n",
      "0.123\n",
      "0.726\n",
      "0.851\n",
      "0.247\n",
      "0.155\n",
      "0.210\n",
      "0.286\n",
      "0.564\n",
      "0.175\n",
      "0.314\n",
      "0.072\n",
      "0.141\n",
      "0.067\n",
      "0.070\n",
      "0.081\n",
      "0.101\n",
      "0.210\n",
      "0.210\n",
      "0.226\n",
      "0.095\n",
      "0.119\n",
      "0.495\n",
      "0.099\n",
      "0.235\n",
      "0.085\n",
      "0.242\n",
      "0.097\n",
      "0.356\n",
      "0.077\n",
      "0.331\n",
      "0.115\n",
      "0.110\n",
      "0.510\n",
      "0.634\n",
      "0.531\n",
      "0.241\n",
      "0.342\n",
      "0.078\n",
      "0.162\n",
      "0.287\n",
      "0.530\n",
      "0.297\n",
      "0.723\n",
      "0.526\n",
      "0.332\n",
      "0.481\n",
      "0.293\n",
      "0.349\n",
      "0.412\n",
      "0.615\n",
      "0.485\n",
      "0.254\n",
      "0.118\n",
      "0.315\n",
      "0.229\n",
      "0.430\n",
      "0.595\n",
      "0.532\n",
      "0.325\n",
      "0.213\n",
      "0.404\n",
      "0.200\n",
      "0.170\n",
      "0.192\n",
      "0.513\n",
      "0.089\n",
      "0.943\n",
      "0.558\n",
      "0.423\n",
      "0.956\n",
      "0.825\n",
      "0.328\n",
      "0.110\n",
      "0.649\n",
      "0.533\n",
      "0.267\n",
      "0.306\n",
      "0.818\n",
      "0.959\n",
      "0.559\n",
      "0.451\n",
      "0.400\n",
      "0.852\n",
      "0.563\n",
      "0.963\n",
      "0.563\n",
      "0.782\n",
      "0.681\n",
      "0.341\n",
      "0.215\n",
      "0.332\n",
      "0.331\n",
      "0.346\n",
      "0.181\n",
      "0.170\n",
      "0.168\n",
      "0.292\n",
      "0.266\n",
      "0.438\n",
      "0.182\n",
      "0.227\n",
      "0.122\n",
      "0.318\n",
      "0.361\n",
      "0.289\n",
      "0.176\n",
      "0.588\n",
      "0.405\n",
      "0.338\n",
      "0.114\n",
      "0.121\n",
      "0.423\n",
      "0.181\n",
      "0.155\n",
      "0.323\n",
      "0.404\n",
      "0.452\n",
      "0.611\n",
      "0.294\n",
      "0.137\n",
      "0.914\n",
      "0.826\n",
      "0.094\n",
      "0.240\n",
      "0.614\n",
      "0.508\n",
      "0.294\n",
      "0.285\n",
      "0.962\n",
      "0.419\n",
      "0.238\n",
      "0.523\n",
      "0.650\n",
      "0.131\n",
      "0.708\n",
      "0.629\n",
      "0.228\n",
      "0.594\n",
      "0.648\n",
      "0.147\n",
      "0.275\n",
      "0.078\n",
      "0.299\n",
      "0.591\n",
      "0.245\n",
      "0.324\n",
      "0.762\n",
      "0.350\n",
      "0.096\n",
      "0.608\n",
      "0.226\n",
      "0.397\n",
      "0.079\n",
      "0.079\n",
      "0.476\n",
      "0.081\n",
      "0.384\n",
      "0.227\n",
      "0.132\n",
      "0.486\n",
      "0.089\n",
      "0.455\n",
      "0.096\n",
      "0.079\n",
      "0.528\n",
      "0.661\n",
      "0.246\n",
      "0.353\n",
      "0.136\n",
      "0.116\n",
      "0.719\n",
      "0.844\n",
      "0.240\n",
      "0.148\n",
      "0.203\n",
      "0.279\n",
      "0.557\n",
      "0.168\n",
      "0.307\n",
      "0.065\n",
      "0.134\n",
      "0.060\n",
      "0.063\n",
      "0.074\n",
      "0.094\n",
      "0.203\n",
      "0.203\n",
      "0.219\n",
      "0.088\n",
      "0.112\n",
      "0.488\n",
      "0.092\n",
      "0.228\n",
      "0.078\n",
      "0.235\n",
      "0.090\n",
      "0.349\n",
      "0.070\n",
      "0.324\n",
      "0.108\n",
      "0.103\n",
      "0.503\n",
      "0.627\n",
      "0.524\n",
      "0.234\n",
      "0.335\n",
      "0.071\n",
      "0.155\n",
      "0.280\n",
      "0.523\n",
      "0.290\n",
      "0.716\n",
      "0.519\n",
      "0.326\n",
      "0.474\n",
      "0.286\n",
      "0.342\n",
      "0.405\n",
      "0.608\n",
      "0.478\n",
      "0.247\n",
      "0.111\n",
      "0.308\n",
      "0.222\n",
      "0.423\n",
      "0.588\n",
      "0.525\n",
      "0.318\n",
      "0.206\n",
      "0.397\n",
      "0.193\n",
      "0.163\n",
      "0.185\n",
      "0.506\n",
      "0.082\n",
      "0.936\n",
      "0.551\n",
      "0.416\n",
      "0.949\n",
      "0.818\n",
      "0.321\n",
      "0.103\n",
      "0.642\n",
      "0.526\n",
      "0.260\n",
      "0.299\n",
      "0.811\n",
      "0.952\n",
      "0.552\n",
      "0.444\n",
      "0.393\n",
      "0.846\n",
      "0.556\n",
      "0.956\n",
      "0.556\n",
      "0.775\n",
      "0.674\n",
      "0.334\n",
      "0.208\n",
      "0.325\n",
      "0.324\n",
      "0.339\n",
      "0.174\n",
      "0.163\n",
      "0.161\n",
      "0.285\n",
      "0.259\n",
      "0.431\n",
      "0.175\n",
      "0.220\n",
      "0.115\n",
      "0.311\n",
      "0.354\n",
      "0.282\n",
      "0.169\n",
      "0.581\n",
      "0.398\n",
      "0.331\n",
      "0.107\n",
      "0.114\n",
      "0.416\n",
      "0.174\n",
      "0.148\n",
      "0.316\n",
      "0.397\n",
      "0.445\n",
      "0.604\n",
      "0.287\n",
      "0.130\n",
      "0.907\n",
      "0.819\n",
      "0.087\n",
      "0.233\n",
      "0.607\n",
      "0.501\n",
      "0.288\n",
      "0.278\n",
      "0.955\n",
      "0.412\n",
      "0.231\n",
      "0.516\n",
      "0.643\n",
      "0.124\n",
      "0.701\n",
      "0.622\n",
      "0.221\n",
      "0.587\n",
      "0.641\n",
      "0.140\n",
      "0.268\n",
      "0.071\n",
      "0.292\n",
      "0.584\n",
      "0.238\n",
      "0.317\n",
      "0.755\n",
      "0.343\n",
      "0.089\n",
      "0.601\n",
      "0.219\n",
      "0.390\n",
      "0.072\n",
      "0.072\n",
      "0.469\n",
      "0.074\n",
      "0.377\n",
      "0.220\n",
      "0.125\n",
      "0.479\n",
      "0.082\n",
      "0.448\n",
      "0.089\n",
      "0.072\n",
      "0.521\n",
      "0.654\n",
      "0.239\n",
      "0.346\n",
      "0.129\n",
      "0.068\n",
      "0.671\n",
      "0.796\n",
      "0.192\n",
      "0.100\n",
      "0.155\n",
      "0.231\n",
      "0.510\n",
      "0.120\n",
      "0.259\n",
      "0.017\n",
      "0.086\n",
      "0.012\n",
      "0.015\n",
      "0.026\n",
      "0.046\n",
      "0.156\n",
      "0.156\n",
      "0.171\n",
      "0.040\n",
      "0.064\n",
      "0.440\n",
      "0.044\n",
      "0.180\n",
      "0.030\n",
      "0.187\n",
      "0.042\n",
      "0.302\n",
      "0.022\n",
      "0.276\n",
      "0.060\n",
      "0.055\n",
      "0.455\n",
      "0.580\n",
      "0.477\n",
      "0.186\n",
      "0.287\n",
      "0.024\n",
      "0.107\n",
      "0.232\n",
      "0.475\n",
      "0.242\n",
      "0.668\n",
      "0.471\n",
      "0.278\n",
      "0.426\n",
      "0.238\n",
      "0.294\n",
      "0.357\n",
      "0.560\n",
      "0.431\n",
      "0.200\n",
      "0.063\n",
      "0.260\n",
      "0.174\n",
      "0.375\n",
      "0.540\n",
      "0.477\n",
      "0.270\n",
      "0.158\n",
      "0.349\n",
      "0.145\n",
      "0.115\n",
      "0.137\n",
      "0.458\n",
      "0.034\n",
      "0.888\n",
      "0.503\n",
      "0.368\n",
      "0.901\n",
      "0.770\n",
      "0.273\n",
      "0.055\n",
      "0.594\n",
      "0.478\n",
      "0.212\n",
      "0.251\n",
      "0.764\n",
      "0.904\n",
      "0.504\n",
      "0.396\n",
      "0.345\n",
      "0.798\n",
      "0.508\n",
      "0.908\n",
      "0.509\n",
      "0.727\n",
      "0.626\n",
      "0.286\n",
      "0.160\n",
      "0.277\n",
      "0.276\n",
      "0.291\n",
      "0.127\n",
      "0.115\n",
      "0.113\n",
      "0.237\n",
      "0.211\n",
      "0.383\n",
      "0.127\n",
      "0.172\n",
      "0.067\n",
      "0.263\n",
      "0.306\n",
      "0.235\n",
      "0.121\n",
      "0.533\n",
      "0.350\n",
      "0.283\n",
      "0.060\n",
      "0.066\n",
      "0.369\n",
      "0.127\n",
      "0.100\n",
      "0.268\n",
      "0.349\n",
      "0.397\n",
      "0.556\n",
      "0.239\n",
      "0.082\n",
      "0.859\n",
      "0.771\n",
      "0.039\n",
      "0.185\n",
      "0.559\n",
      "0.453\n",
      "0.240\n",
      "0.230\n",
      "0.907\n",
      "0.364\n",
      "0.183\n",
      "0.468\n",
      "0.595\n",
      "0.076\n",
      "0.653\n",
      "0.574\n",
      "0.173\n",
      "0.539\n",
      "0.593\n",
      "0.092\n",
      "0.220\n",
      "0.023\n",
      "0.244\n",
      "0.536\n",
      "0.191\n",
      "0.269\n",
      "0.707\n",
      "0.295\n",
      "0.041\n",
      "0.553\n",
      "0.171\n",
      "0.343\n",
      "0.025\n",
      "0.025\n",
      "0.421\n",
      "0.026\n",
      "0.329\n",
      "0.172\n",
      "0.077\n",
      "0.431\n",
      "0.034\n",
      "0.400\n",
      "0.041\n",
      "0.025\n",
      "0.473\n",
      "0.606\n",
      "0.191\n",
      "0.298\n",
      "0.081\n",
      "0.101\n",
      "0.704\n",
      "0.829\n",
      "0.225\n",
      "0.133\n",
      "0.189\n",
      "0.264\n",
      "0.543\n",
      "0.154\n",
      "0.292\n",
      "0.050\n",
      "0.119\n",
      "0.046\n",
      "0.049\n",
      "0.059\n",
      "0.079\n",
      "0.189\n",
      "0.189\n",
      "0.204\n",
      "0.074\n",
      "0.097\n",
      "0.474\n",
      "0.077\n",
      "0.213\n",
      "0.063\n",
      "0.221\n",
      "0.076\n",
      "0.335\n",
      "0.056\n",
      "0.309\n",
      "0.094\n",
      "0.088\n",
      "0.488\n",
      "0.613\n",
      "0.510\n",
      "0.219\n",
      "0.320\n",
      "0.057\n",
      "0.140\n",
      "0.265\n",
      "0.509\n",
      "0.276\n",
      "0.702\n",
      "0.504\n",
      "0.311\n",
      "0.459\n",
      "0.272\n",
      "0.327\n",
      "0.390\n",
      "0.594\n",
      "0.464\n",
      "0.233\n",
      "0.096\n",
      "0.294\n",
      "0.208\n",
      "0.409\n",
      "0.573\n",
      "0.510\n",
      "0.304\n",
      "0.191\n",
      "0.382\n",
      "0.178\n",
      "0.149\n",
      "0.170\n",
      "0.491\n",
      "0.067\n",
      "0.922\n",
      "0.537\n",
      "0.401\n",
      "0.934\n",
      "0.803\n",
      "0.307\n",
      "0.088\n",
      "0.628\n",
      "0.511\n",
      "0.245\n",
      "0.284\n",
      "0.797\n",
      "0.938\n",
      "0.537\n",
      "0.429\n",
      "0.379\n",
      "0.831\n",
      "0.542\n",
      "0.941\n",
      "0.542\n",
      "0.760\n",
      "0.660\n",
      "0.319\n",
      "0.194\n",
      "0.310\n",
      "0.309\n",
      "0.324\n",
      "0.160\n",
      "0.149\n",
      "0.146\n",
      "0.271\n",
      "0.245\n",
      "0.416\n",
      "0.160\n",
      "0.205\n",
      "0.100\n",
      "0.297\n",
      "0.339\n",
      "0.268\n",
      "0.155\n",
      "0.567\n",
      "0.383\n",
      "0.317\n",
      "0.093\n",
      "0.099\n",
      "0.402\n",
      "0.160\n",
      "0.133\n",
      "0.301\n",
      "0.382\n",
      "0.430\n",
      "0.590\n",
      "0.272\n",
      "0.115\n",
      "0.892\n",
      "0.804\n",
      "0.073\n",
      "0.218\n",
      "0.593\n",
      "0.486\n",
      "0.273\n",
      "0.263\n",
      "0.941\n",
      "0.397\n",
      "0.216\n",
      "0.501\n",
      "0.629\n",
      "0.110\n",
      "0.687\n",
      "0.607\n",
      "0.206\n",
      "0.573\n",
      "0.627\n",
      "0.125\n",
      "0.253\n",
      "0.057\n",
      "0.278\n",
      "0.570\n",
      "0.224\n",
      "0.303\n",
      "0.740\n",
      "0.328\n",
      "0.074\n",
      "0.586\n",
      "0.205\n",
      "0.376\n",
      "0.058\n",
      "0.058\n",
      "0.454\n",
      "0.059\n",
      "0.362\n",
      "0.205\n",
      "0.110\n",
      "0.464\n",
      "0.067\n",
      "0.433\n",
      "0.074\n",
      "0.058\n",
      "0.506\n",
      "0.639\n",
      "0.224\n",
      "0.332\n",
      "0.114\n",
      "0.077\n",
      "0.680\n",
      "0.805\n",
      "0.201\n",
      "0.109\n",
      "0.165\n",
      "0.240\n",
      "0.519\n",
      "0.130\n",
      "0.269\n",
      "0.026\n",
      "0.095\n",
      "0.022\n",
      "0.025\n",
      "0.035\n",
      "0.055\n",
      "0.165\n",
      "0.165\n",
      "0.180\n",
      "0.050\n",
      "0.073\n",
      "0.450\n",
      "0.053\n",
      "0.189\n",
      "0.039\n",
      "0.197\n",
      "0.052\n",
      "0.311\n",
      "0.032\n",
      "0.285\n",
      "0.070\n",
      "0.064\n",
      "0.464\n",
      "0.589\n",
      "0.486\n",
      "0.195\n",
      "0.296\n",
      "0.033\n",
      "0.116\n",
      "0.241\n",
      "0.485\n",
      "0.252\n",
      "0.678\n",
      "0.480\n",
      "0.287\n",
      "0.435\n",
      "0.248\n",
      "0.304\n",
      "0.366\n",
      "0.570\n",
      "0.440\n",
      "0.209\n",
      "0.072\n",
      "0.270\n",
      "0.184\n",
      "0.385\n",
      "0.549\n",
      "0.486\n",
      "0.280\n",
      "0.167\n",
      "0.358\n",
      "0.155\n",
      "0.125\n",
      "0.146\n",
      "0.467\n",
      "0.043\n",
      "0.898\n",
      "0.513\n",
      "0.377\n",
      "0.910\n",
      "0.779\n",
      "0.283\n",
      "0.064\n",
      "0.604\n",
      "0.487\n",
      "0.221\n",
      "0.260\n",
      "0.773\n",
      "0.914\n",
      "0.513\n",
      "0.406\n",
      "0.355\n",
      "0.807\n",
      "0.518\n",
      "0.917\n",
      "0.518\n",
      "0.736\n",
      "0.636\n",
      "0.295\n",
      "0.170\n",
      "0.286\n",
      "0.286\n",
      "0.301\n",
      "0.136\n",
      "0.125\n",
      "0.122\n",
      "0.247\n",
      "0.221\n",
      "0.392\n",
      "0.137\n",
      "0.181\n",
      "0.076\n",
      "0.273\n",
      "0.315\n",
      "0.244\n",
      "0.131\n",
      "0.543\n",
      "0.359\n",
      "0.293\n",
      "0.069\n",
      "0.075\n",
      "0.378\n",
      "0.136\n",
      "0.109\n",
      "0.277\n",
      "0.358\n",
      "0.406\n",
      "0.566\n",
      "0.248\n",
      "0.091\n",
      "0.868\n",
      "0.780\n",
      "0.049\n",
      "0.194\n",
      "0.569\n",
      "0.462\n",
      "0.249\n",
      "0.239\n",
      "0.917\n",
      "0.374\n",
      "0.192\n",
      "0.477\n",
      "0.605\n",
      "0.086\n",
      "0.663\n",
      "0.583\n",
      "0.182\n",
      "0.549\n",
      "0.603\n",
      "0.101\n",
      "0.229\n",
      "0.033\n",
      "0.254\n",
      "0.546\n",
      "0.200\n",
      "0.279\n",
      "0.716\n",
      "0.304\n",
      "0.050\n",
      "0.562\n",
      "0.181\n",
      "0.352\n",
      "0.034\n",
      "0.034\n",
      "0.430\n",
      "0.035\n",
      "0.338\n",
      "0.181\n",
      "0.086\n",
      "0.441\n",
      "0.043\n",
      "0.409\n",
      "0.050\n",
      "0.034\n",
      "0.482\n",
      "0.615\n",
      "0.200\n",
      "0.308\n",
      "0.090\n",
      "0.102\n",
      "0.705\n",
      "0.830\n",
      "0.226\n",
      "0.134\n",
      "0.190\n",
      "0.265\n",
      "0.544\n",
      "0.155\n",
      "0.294\n",
      "0.051\n",
      "0.120\n",
      "0.047\n",
      "0.050\n",
      "0.060\n",
      "0.080\n",
      "0.190\n",
      "0.190\n",
      "0.205\n",
      "0.075\n",
      "0.098\n",
      "0.475\n",
      "0.079\n",
      "0.214\n",
      "0.064\n",
      "0.222\n",
      "0.077\n",
      "0.336\n",
      "0.057\n",
      "0.310\n",
      "0.095\n",
      "0.089\n",
      "0.489\n",
      "0.614\n",
      "0.511\n",
      "0.221\n",
      "0.321\n",
      "0.058\n",
      "0.141\n",
      "0.266\n",
      "0.510\n",
      "0.277\n",
      "0.703\n",
      "0.505\n",
      "0.312\n",
      "0.461\n",
      "0.273\n",
      "0.329\n",
      "0.391\n",
      "0.595\n",
      "0.465\n",
      "0.234\n",
      "0.097\n",
      "0.295\n",
      "0.209\n",
      "0.410\n",
      "0.575\n",
      "0.511\n",
      "0.305\n",
      "0.193\n",
      "0.383\n",
      "0.180\n",
      "0.150\n",
      "0.171\n",
      "0.492\n",
      "0.068\n",
      "0.923\n",
      "0.538\n",
      "0.403\n",
      "0.935\n",
      "0.804\n",
      "0.308\n",
      "0.090\n",
      "0.629\n",
      "0.512\n",
      "0.246\n",
      "0.286\n",
      "0.798\n",
      "0.939\n",
      "0.538\n",
      "0.431\n",
      "0.380\n",
      "0.832\n",
      "0.543\n",
      "0.942\n",
      "0.543\n",
      "0.761\n",
      "0.661\n",
      "0.321\n",
      "0.195\n",
      "0.311\n",
      "0.311\n",
      "0.326\n",
      "0.161\n",
      "0.150\n",
      "0.147\n",
      "0.272\n",
      "0.246\n",
      "0.417\n",
      "0.162\n",
      "0.207\n",
      "0.101\n",
      "0.298\n",
      "0.340\n",
      "0.269\n",
      "0.156\n",
      "0.568\n",
      "0.384\n",
      "0.318\n",
      "0.094\n",
      "0.100\n",
      "0.403\n",
      "0.161\n",
      "0.134\n",
      "0.303\n",
      "0.383\n",
      "0.431\n",
      "0.591\n",
      "0.274\n",
      "0.117\n",
      "0.893\n",
      "0.805\n",
      "0.074\n",
      "0.219\n",
      "0.594\n",
      "0.488\n",
      "0.274\n",
      "0.265\n",
      "0.942\n",
      "0.399\n",
      "0.217\n",
      "0.502\n",
      "0.630\n",
      "0.111\n",
      "0.688\n",
      "0.608\n",
      "0.207\n",
      "0.574\n",
      "0.628\n",
      "0.126\n",
      "0.254\n",
      "0.058\n",
      "0.279\n",
      "0.571\n",
      "0.225\n",
      "0.304\n",
      "0.741\n",
      "0.330\n",
      "0.075\n",
      "0.587\n",
      "0.206\n",
      "0.377\n",
      "0.059\n",
      "0.059\n",
      "0.455\n",
      "0.060\n",
      "0.363\n",
      "0.206\n",
      "0.111\n",
      "0.466\n",
      "0.068\n",
      "0.434\n",
      "0.075\n",
      "0.059\n",
      "0.507\n",
      "0.640\n",
      "0.225\n",
      "0.333\n",
      "0.115\n",
      "0.097\n",
      "0.700\n",
      "0.826\n",
      "0.221\n",
      "0.129\n",
      "0.185\n",
      "0.260\n",
      "0.539\n",
      "0.150\n",
      "0.289\n",
      "0.047\n",
      "0.115\n",
      "0.042\n",
      "0.045\n",
      "0.056\n",
      "0.076\n",
      "0.185\n",
      "0.185\n",
      "0.200\n",
      "0.070\n",
      "0.093\n",
      "0.470\n",
      "0.074\n",
      "0.210\n",
      "0.059\n",
      "0.217\n",
      "0.072\n",
      "0.331\n",
      "0.052\n",
      "0.305\n",
      "0.090\n",
      "0.085\n",
      "0.485\n",
      "0.609\n",
      "0.506\n",
      "0.216\n",
      "0.316\n",
      "0.053\n",
      "0.136\n",
      "0.261\n",
      "0.505\n",
      "0.272\n",
      "0.698\n",
      "0.500\n",
      "0.307\n",
      "0.456\n",
      "0.268\n",
      "0.324\n",
      "0.387\n",
      "0.590\n",
      "0.460\n",
      "0.229\n",
      "0.093\n",
      "0.290\n",
      "0.204\n",
      "0.405\n",
      "0.570\n",
      "0.506\n",
      "0.300\n",
      "0.188\n",
      "0.379\n",
      "0.175\n",
      "0.145\n",
      "0.166\n",
      "0.488\n",
      "0.064\n",
      "0.918\n",
      "0.533\n",
      "0.398\n",
      "0.930\n",
      "0.800\n",
      "0.303\n",
      "0.085\n",
      "0.624\n",
      "0.508\n",
      "0.241\n",
      "0.281\n",
      "0.793\n",
      "0.934\n",
      "0.534\n",
      "0.426\n",
      "0.375\n",
      "0.827\n",
      "0.538\n",
      "0.937\n",
      "0.538\n",
      "0.756\n",
      "0.656\n",
      "0.316\n",
      "0.190\n",
      "0.307\n",
      "0.306\n",
      "0.321\n",
      "0.156\n",
      "0.145\n",
      "0.142\n",
      "0.267\n",
      "0.241\n",
      "0.412\n",
      "0.157\n",
      "0.202\n",
      "0.097\n",
      "0.293\n",
      "0.336\n",
      "0.264\n",
      "0.151\n",
      "0.563\n",
      "0.380\n",
      "0.313\n",
      "0.089\n",
      "0.095\n",
      "0.398\n",
      "0.156\n",
      "0.130\n",
      "0.298\n",
      "0.379\n",
      "0.426\n",
      "0.586\n",
      "0.269\n",
      "0.112\n",
      "0.888\n",
      "0.800\n",
      "0.069\n",
      "0.214\n",
      "0.589\n",
      "0.483\n",
      "0.269\n",
      "0.260\n",
      "0.937\n",
      "0.394\n",
      "0.213\n",
      "0.498\n",
      "0.625\n",
      "0.106\n",
      "0.683\n",
      "0.604\n",
      "0.203\n",
      "0.569\n",
      "0.623\n",
      "0.122\n",
      "0.249\n",
      "0.053\n",
      "0.274\n",
      "0.566\n",
      "0.220\n",
      "0.299\n",
      "0.736\n",
      "0.325\n",
      "0.070\n",
      "0.583\n",
      "0.201\n",
      "0.372\n",
      "0.054\n",
      "0.054\n",
      "0.451\n",
      "0.056\n",
      "0.358\n",
      "0.201\n",
      "0.107\n",
      "0.461\n",
      "0.063\n",
      "0.429\n",
      "0.070\n",
      "0.054\n",
      "0.503\n",
      "0.636\n",
      "0.221\n",
      "0.328\n",
      "0.111\n",
      "0.107\n",
      "0.710\n",
      "0.835\n",
      "0.231\n",
      "0.139\n",
      "0.194\n",
      "0.270\n",
      "0.549\n",
      "0.159\n",
      "0.298\n",
      "0.056\n",
      "0.125\n",
      "0.051\n",
      "0.054\n",
      "0.065\n",
      "0.085\n",
      "0.195\n",
      "0.195\n",
      "0.210\n",
      "0.080\n",
      "0.103\n",
      "0.480\n",
      "0.083\n",
      "0.219\n",
      "0.069\n",
      "0.226\n",
      "0.082\n",
      "0.341\n",
      "0.062\n",
      "0.315\n",
      "0.100\n",
      "0.094\n",
      "0.494\n",
      "0.619\n",
      "0.516\n",
      "0.225\n",
      "0.326\n",
      "0.063\n",
      "0.146\n",
      "0.271\n",
      "0.515\n",
      "0.281\n",
      "0.708\n",
      "0.510\n",
      "0.317\n",
      "0.465\n",
      "0.278\n",
      "0.333\n",
      "0.396\n",
      "0.600\n",
      "0.470\n",
      "0.239\n",
      "0.102\n",
      "0.299\n",
      "0.214\n",
      "0.414\n",
      "0.579\n",
      "0.516\n",
      "0.310\n",
      "0.197\n",
      "0.388\n",
      "0.184\n",
      "0.155\n",
      "0.176\n",
      "0.497\n",
      "0.073\n",
      "0.927\n",
      "0.542\n",
      "0.407\n",
      "0.940\n",
      "0.809\n",
      "0.313\n",
      "0.094\n",
      "0.634\n",
      "0.517\n",
      "0.251\n",
      "0.290\n",
      "0.803\n",
      "0.943\n",
      "0.543\n",
      "0.435\n",
      "0.384\n",
      "0.837\n",
      "0.547\n",
      "0.947\n",
      "0.548\n",
      "0.766\n",
      "0.665\n",
      "0.325\n",
      "0.200\n",
      "0.316\n",
      "0.315\n",
      "0.330\n",
      "0.166\n",
      "0.155\n",
      "0.152\n",
      "0.276\n",
      "0.250\n",
      "0.422\n",
      "0.166\n",
      "0.211\n",
      "0.106\n",
      "0.302\n",
      "0.345\n",
      "0.274\n",
      "0.160\n",
      "0.573\n",
      "0.389\n",
      "0.322\n",
      "0.099\n",
      "0.105\n",
      "0.408\n",
      "0.166\n",
      "0.139\n",
      "0.307\n",
      "0.388\n",
      "0.436\n",
      "0.595\n",
      "0.278\n",
      "0.121\n",
      "0.898\n",
      "0.810\n",
      "0.079\n",
      "0.224\n",
      "0.599\n",
      "0.492\n",
      "0.279\n",
      "0.269\n",
      "0.947\n",
      "0.403\n",
      "0.222\n",
      "0.507\n",
      "0.635\n",
      "0.115\n",
      "0.693\n",
      "0.613\n",
      "0.212\n",
      "0.579\n",
      "0.632\n",
      "0.131\n",
      "0.259\n",
      "0.062\n",
      "0.284\n",
      "0.576\n",
      "0.230\n",
      "0.308\n",
      "0.746\n",
      "0.334\n",
      "0.080\n",
      "0.592\n",
      "0.211\n",
      "0.382\n",
      "0.064\n",
      "0.064\n",
      "0.460\n",
      "0.065\n",
      "0.368\n",
      "0.211\n",
      "0.116\n",
      "0.470\n",
      "0.073\n",
      "0.439\n",
      "0.080\n",
      "0.064\n",
      "0.512\n",
      "0.645\n",
      "0.230\n",
      "0.337\n",
      "0.120\n",
      "0.111\n",
      "0.714\n",
      "0.839\n",
      "0.235\n",
      "0.143\n",
      "0.199\n",
      "0.274\n",
      "0.553\n",
      "0.164\n",
      "0.303\n",
      "0.060\n",
      "0.129\n",
      "0.056\n",
      "0.059\n",
      "0.069\n",
      "0.089\n",
      "0.199\n",
      "0.199\n",
      "0.214\n",
      "0.084\n",
      "0.107\n",
      "0.484\n",
      "0.088\n",
      "0.223\n",
      "0.073\n",
      "0.231\n",
      "0.086\n",
      "0.345\n",
      "0.066\n",
      "0.319\n",
      "0.104\n",
      "0.098\n",
      "0.498\n",
      "0.623\n",
      "0.520\n",
      "0.230\n",
      "0.330\n",
      "0.067\n",
      "0.150\n",
      "0.275\n",
      "0.519\n",
      "0.286\n",
      "0.712\n",
      "0.514\n",
      "0.321\n",
      "0.470\n",
      "0.282\n",
      "0.338\n",
      "0.400\n",
      "0.604\n",
      "0.474\n",
      "0.243\n",
      "0.106\n",
      "0.304\n",
      "0.218\n",
      "0.419\n",
      "0.584\n",
      "0.520\n",
      "0.314\n",
      "0.202\n",
      "0.392\n",
      "0.189\n",
      "0.159\n",
      "0.180\n",
      "0.501\n",
      "0.077\n",
      "0.932\n",
      "0.547\n",
      "0.412\n",
      "0.944\n",
      "0.813\n",
      "0.317\n",
      "0.099\n",
      "0.638\n",
      "0.521\n",
      "0.255\n",
      "0.295\n",
      "0.807\n",
      "0.948\n",
      "0.547\n",
      "0.440\n",
      "0.389\n",
      "0.841\n",
      "0.552\n",
      "0.951\n",
      "0.552\n",
      "0.770\n",
      "0.670\n",
      "0.330\n",
      "0.204\n",
      "0.320\n",
      "0.320\n",
      "0.335\n",
      "0.170\n",
      "0.159\n",
      "0.156\n",
      "0.281\n",
      "0.255\n",
      "0.426\n",
      "0.171\n",
      "0.216\n",
      "0.110\n",
      "0.307\n",
      "0.349\n",
      "0.278\n",
      "0.165\n",
      "0.577\n",
      "0.393\n",
      "0.327\n",
      "0.103\n",
      "0.109\n",
      "0.412\n",
      "0.170\n",
      "0.144\n",
      "0.312\n",
      "0.392\n",
      "0.440\n",
      "0.600\n",
      "0.283\n",
      "0.126\n",
      "0.902\n",
      "0.814\n",
      "0.083\n",
      "0.228\n",
      "0.603\n",
      "0.497\n",
      "0.283\n",
      "0.274\n",
      "0.951\n",
      "0.408\n",
      "0.226\n",
      "0.511\n",
      "0.639\n",
      "0.120\n",
      "0.697\n",
      "0.617\n",
      "0.217\n",
      "0.583\n",
      "0.637\n",
      "0.135\n",
      "0.263\n",
      "0.067\n",
      "0.288\n",
      "0.580\n",
      "0.234\n",
      "0.313\n",
      "0.750\n",
      "0.339\n",
      "0.084\n",
      "0.597\n",
      "0.215\n",
      "0.386\n",
      "0.068\n",
      "0.068\n",
      "0.465\n",
      "0.069\n",
      "0.372\n",
      "0.215\n",
      "0.120\n",
      "0.475\n",
      "0.077\n",
      "0.443\n",
      "0.084\n",
      "0.068\n",
      "0.516\n",
      "0.649\n",
      "0.234\n",
      "0.342\n",
      "0.124\n",
      "0.106\n",
      "0.709\n",
      "0.834\n",
      "0.230\n",
      "0.138\n",
      "0.194\n",
      "0.269\n",
      "0.548\n",
      "0.159\n",
      "0.297\n",
      "0.055\n",
      "0.124\n",
      "0.051\n",
      "0.054\n",
      "0.064\n",
      "0.084\n",
      "0.194\n",
      "0.194\n",
      "0.209\n",
      "0.079\n",
      "0.102\n",
      "0.479\n",
      "0.082\n",
      "0.218\n",
      "0.068\n",
      "0.226\n",
      "0.081\n",
      "0.340\n",
      "0.061\n",
      "0.314\n",
      "0.099\n",
      "0.093\n",
      "0.493\n",
      "0.618\n",
      "0.515\n",
      "0.224\n",
      "0.325\n",
      "0.062\n",
      "0.145\n",
      "0.270\n",
      "0.514\n",
      "0.281\n",
      "0.707\n",
      "0.509\n",
      "0.316\n",
      "0.464\n",
      "0.277\n",
      "0.332\n",
      "0.395\n",
      "0.599\n",
      "0.469\n",
      "0.238\n",
      "0.101\n",
      "0.299\n",
      "0.213\n",
      "0.414\n",
      "0.578\n",
      "0.515\n",
      "0.309\n",
      "0.196\n",
      "0.387\n",
      "0.183\n",
      "0.154\n",
      "0.175\n",
      "0.496\n",
      "0.072\n",
      "0.927\n",
      "0.542\n",
      "0.406\n",
      "0.939\n",
      "0.808\n",
      "0.312\n",
      "0.093\n",
      "0.633\n",
      "0.516\n",
      "0.250\n",
      "0.289\n",
      "0.802\n",
      "0.943\n",
      "0.542\n",
      "0.434\n",
      "0.384\n",
      "0.836\n",
      "0.547\n",
      "0.946\n",
      "0.547\n",
      "0.765\n",
      "0.665\n",
      "0.324\n",
      "0.199\n",
      "0.315\n",
      "0.314\n",
      "0.329\n",
      "0.165\n",
      "0.154\n",
      "0.151\n",
      "0.276\n",
      "0.250\n",
      "0.421\n",
      "0.165\n",
      "0.210\n",
      "0.105\n",
      "0.302\n",
      "0.344\n",
      "0.273\n",
      "0.160\n",
      "0.572\n",
      "0.388\n",
      "0.322\n",
      "0.098\n",
      "0.104\n",
      "0.407\n",
      "0.165\n",
      "0.138\n",
      "0.306\n",
      "0.387\n",
      "0.435\n",
      "0.595\n",
      "0.277\n",
      "0.120\n",
      "0.897\n",
      "0.809\n",
      "0.078\n",
      "0.223\n",
      "0.598\n",
      "0.491\n",
      "0.278\n",
      "0.268\n",
      "0.946\n",
      "0.402\n",
      "0.221\n",
      "0.506\n",
      "0.634\n",
      "0.115\n",
      "0.692\n",
      "0.612\n",
      "0.211\n",
      "0.578\n",
      "0.632\n",
      "0.130\n",
      "0.258\n",
      "0.062\n",
      "0.283\n",
      "0.575\n",
      "0.229\n",
      "0.308\n",
      "0.745\n",
      "0.333\n",
      "0.079\n",
      "0.591\n",
      "0.210\n",
      "0.381\n",
      "0.063\n",
      "0.063\n",
      "0.459\n",
      "0.064\n",
      "0.367\n",
      "0.210\n",
      "0.115\n",
      "0.469\n",
      "0.072\n",
      "0.438\n",
      "0.079\n",
      "0.063\n",
      "0.511\n",
      "0.644\n",
      "0.229\n",
      "0.337\n",
      "0.119\n",
      "0.117\n",
      "0.720\n",
      "0.845\n",
      "0.241\n",
      "0.149\n",
      "0.204\n",
      "0.279\n",
      "0.558\n",
      "0.169\n",
      "0.308\n",
      "0.066\n",
      "0.135\n",
      "0.061\n",
      "0.064\n",
      "0.075\n",
      "0.095\n",
      "0.204\n",
      "0.204\n",
      "0.220\n",
      "0.089\n",
      "0.112\n",
      "0.489\n",
      "0.093\n",
      "0.229\n",
      "0.079\n",
      "0.236\n",
      "0.091\n",
      "0.350\n",
      "0.071\n",
      "0.325\n",
      "0.109\n",
      "0.104\n",
      "0.504\n",
      "0.628\n",
      "0.525\n",
      "0.235\n",
      "0.336\n",
      "0.072\n",
      "0.156\n",
      "0.281\n",
      "0.524\n",
      "0.291\n",
      "0.717\n",
      "0.520\n",
      "0.326\n",
      "0.475\n",
      "0.287\n",
      "0.343\n",
      "0.406\n",
      "0.609\n",
      "0.479\n",
      "0.248\n",
      "0.112\n",
      "0.309\n",
      "0.223\n",
      "0.424\n",
      "0.589\n",
      "0.526\n",
      "0.319\n",
      "0.207\n",
      "0.398\n",
      "0.194\n",
      "0.164\n",
      "0.185\n",
      "0.507\n",
      "0.083\n",
      "0.937\n",
      "0.552\n",
      "0.417\n",
      "0.950\n",
      "0.819\n",
      "0.322\n",
      "0.104\n",
      "0.643\n",
      "0.527\n",
      "0.261\n",
      "0.300\n",
      "0.812\n",
      "0.953\n",
      "0.553\n",
      "0.445\n",
      "0.394\n",
      "0.846\n",
      "0.557\n",
      "0.957\n",
      "0.557\n",
      "0.775\n",
      "0.675\n",
      "0.335\n",
      "0.209\n",
      "0.326\n",
      "0.325\n",
      "0.340\n",
      "0.175\n",
      "0.164\n",
      "0.162\n",
      "0.286\n",
      "0.260\n",
      "0.431\n",
      "0.176\n",
      "0.221\n",
      "0.116\n",
      "0.312\n",
      "0.355\n",
      "0.283\n",
      "0.170\n",
      "0.582\n",
      "0.399\n",
      "0.332\n",
      "0.108\n",
      "0.115\n",
      "0.417\n",
      "0.175\n",
      "0.149\n",
      "0.317\n",
      "0.398\n",
      "0.445\n",
      "0.605\n",
      "0.288\n",
      "0.131\n",
      "0.907\n",
      "0.819\n",
      "0.088\n",
      "0.234\n",
      "0.608\n",
      "0.502\n",
      "0.288\n",
      "0.279\n",
      "0.956\n",
      "0.413\n",
      "0.232\n",
      "0.517\n",
      "0.644\n",
      "0.125\n",
      "0.702\n",
      "0.623\n",
      "0.222\n",
      "0.588\n",
      "0.642\n",
      "0.141\n",
      "0.269\n",
      "0.072\n",
      "0.293\n",
      "0.585\n",
      "0.239\n",
      "0.318\n",
      "0.755\n",
      "0.344\n",
      "0.089\n",
      "0.602\n",
      "0.220\n",
      "0.391\n",
      "0.073\n",
      "0.073\n",
      "0.470\n",
      "0.075\n",
      "0.378\n",
      "0.220\n",
      "0.126\n",
      "0.480\n",
      "0.083\n",
      "0.448\n",
      "0.089\n",
      "0.073\n",
      "0.522\n",
      "0.655\n",
      "0.240\n",
      "0.347\n",
      "0.130\n",
      "0.115\n",
      "0.718\n",
      "0.844\n",
      "0.239\n",
      "0.147\n",
      "0.203\n",
      "0.278\n",
      "0.557\n",
      "0.168\n",
      "0.307\n",
      "0.064\n",
      "0.133\n",
      "0.060\n",
      "0.063\n",
      "0.073\n",
      "0.094\n",
      "0.203\n",
      "0.203\n",
      "0.218\n",
      "0.088\n",
      "0.111\n",
      "0.488\n",
      "0.092\n",
      "0.228\n",
      "0.077\n",
      "0.235\n",
      "0.090\n",
      "0.349\n",
      "0.070\n",
      "0.323\n",
      "0.108\n",
      "0.102\n",
      "0.503\n",
      "0.627\n",
      "0.524\n",
      "0.234\n",
      "0.334\n",
      "0.071\n",
      "0.154\n",
      "0.279\n",
      "0.523\n",
      "0.290\n",
      "0.716\n",
      "0.518\n",
      "0.325\n",
      "0.474\n",
      "0.286\n",
      "0.342\n",
      "0.404\n",
      "0.608\n",
      "0.478\n",
      "0.247\n",
      "0.111\n",
      "0.308\n",
      "0.222\n",
      "0.423\n",
      "0.588\n",
      "0.524\n",
      "0.318\n",
      "0.206\n",
      "0.397\n",
      "0.193\n",
      "0.163\n",
      "0.184\n",
      "0.505\n",
      "0.082\n",
      "0.936\n",
      "0.551\n",
      "0.416\n",
      "0.948\n",
      "0.818\n",
      "0.321\n",
      "0.103\n",
      "0.642\n",
      "0.526\n",
      "0.259\n",
      "0.299\n",
      "0.811\n",
      "0.952\n",
      "0.552\n",
      "0.444\n",
      "0.393\n",
      "0.845\n",
      "0.556\n",
      "0.955\n",
      "0.556\n",
      "0.774\n",
      "0.674\n",
      "0.334\n",
      "0.208\n",
      "0.324\n",
      "0.324\n",
      "0.339\n",
      "0.174\n",
      "0.163\n",
      "0.160\n",
      "0.285\n",
      "0.259\n",
      "0.430\n",
      "0.175\n",
      "0.220\n",
      "0.114\n",
      "0.311\n",
      "0.354\n",
      "0.282\n",
      "0.169\n",
      "0.581\n",
      "0.397\n",
      "0.331\n",
      "0.107\n",
      "0.113\n",
      "0.416\n",
      "0.174\n",
      "0.148\n",
      "0.316\n",
      "0.397\n",
      "0.444\n",
      "0.604\n",
      "0.287\n",
      "0.130\n",
      "0.906\n",
      "0.818\n",
      "0.087\n",
      "0.232\n",
      "0.607\n",
      "0.501\n",
      "0.287\n",
      "0.278\n",
      "0.955\n",
      "0.412\n",
      "0.231\n",
      "0.515\n",
      "0.643\n",
      "0.124\n",
      "0.701\n",
      "0.622\n",
      "0.221\n",
      "0.587\n",
      "0.641\n",
      "0.140\n",
      "0.267\n",
      "0.071\n",
      "0.292\n",
      "0.584\n",
      "0.238\n",
      "0.317\n",
      "0.754\n",
      "0.343\n",
      "0.088\n",
      "0.601\n",
      "0.219\n",
      "0.390\n",
      "0.072\n",
      "0.072\n",
      "0.469\n",
      "0.073\n",
      "0.376\n",
      "0.219\n",
      "0.125\n",
      "0.479\n",
      "0.081\n",
      "0.447\n",
      "0.088\n",
      "0.072\n",
      "0.520\n",
      "0.654\n",
      "0.239\n",
      "0.346\n",
      "0.129\n",
      "0.116\n",
      "0.719\n",
      "0.845\n",
      "0.240\n",
      "0.148\n",
      "0.204\n",
      "0.279\n",
      "0.558\n",
      "0.169\n",
      "0.308\n",
      "0.065\n",
      "0.134\n",
      "0.061\n",
      "0.064\n",
      "0.074\n",
      "0.094\n",
      "0.204\n",
      "0.204\n",
      "0.219\n",
      "0.089\n",
      "0.112\n",
      "0.489\n",
      "0.093\n",
      "0.228\n",
      "0.078\n",
      "0.236\n",
      "0.091\n",
      "0.350\n",
      "0.071\n",
      "0.324\n",
      "0.109\n",
      "0.103\n",
      "0.503\n",
      "0.628\n",
      "0.525\n",
      "0.235\n",
      "0.335\n",
      "0.072\n",
      "0.155\n",
      "0.280\n",
      "0.524\n",
      "0.291\n",
      "0.717\n",
      "0.519\n",
      "0.326\n",
      "0.475\n",
      "0.287\n",
      "0.343\n",
      "0.405\n",
      "0.609\n",
      "0.479\n",
      "0.248\n",
      "0.111\n",
      "0.309\n",
      "0.223\n",
      "0.424\n",
      "0.589\n",
      "0.525\n",
      "0.319\n",
      "0.207\n",
      "0.398\n",
      "0.194\n",
      "0.164\n",
      "0.185\n",
      "0.506\n",
      "0.082\n",
      "0.937\n",
      "0.552\n",
      "0.417\n",
      "0.949\n",
      "0.818\n",
      "0.322\n",
      "0.104\n",
      "0.643\n",
      "0.526\n",
      "0.260\n",
      "0.300\n",
      "0.812\n",
      "0.953\n",
      "0.552\n",
      "0.445\n",
      "0.394\n",
      "0.846\n",
      "0.557\n",
      "0.956\n",
      "0.557\n",
      "0.775\n",
      "0.675\n",
      "0.335\n",
      "0.209\n",
      "0.325\n",
      "0.325\n",
      "0.340\n",
      "0.175\n",
      "0.164\n",
      "0.161\n",
      "0.286\n",
      "0.260\n",
      "0.431\n",
      "0.176\n",
      "0.221\n",
      "0.115\n",
      "0.312\n",
      "0.354\n",
      "0.283\n",
      "0.170\n",
      "0.582\n",
      "0.398\n",
      "0.332\n",
      "0.108\n",
      "0.114\n",
      "0.417\n",
      "0.175\n",
      "0.149\n",
      "0.317\n",
      "0.398\n",
      "0.445\n",
      "0.605\n",
      "0.288\n",
      "0.131\n",
      "0.907\n",
      "0.819\n",
      "0.088\n",
      "0.233\n",
      "0.608\n",
      "0.502\n",
      "0.288\n",
      "0.279\n",
      "0.956\n",
      "0.413\n",
      "0.231\n",
      "0.516\n",
      "0.644\n",
      "0.125\n",
      "0.702\n",
      "0.623\n",
      "0.222\n",
      "0.588\n",
      "0.642\n",
      "0.141\n",
      "0.268\n",
      "0.072\n",
      "0.293\n",
      "0.585\n",
      "0.239\n",
      "0.318\n",
      "0.755\n",
      "0.344\n",
      "0.089\n",
      "0.602\n",
      "0.220\n",
      "0.391\n",
      "0.073\n",
      "0.073\n",
      "0.470\n",
      "0.074\n",
      "0.377\n",
      "0.220\n",
      "0.126\n",
      "0.480\n",
      "0.082\n",
      "0.448\n",
      "0.089\n",
      "0.073\n",
      "0.521\n",
      "0.655\n",
      "0.240\n",
      "0.347\n",
      "0.129\n",
      "0.084\n",
      "0.687\n",
      "0.813\n",
      "0.208\n",
      "0.116\n",
      "0.172\n",
      "0.247\n",
      "0.526\n",
      "0.137\n",
      "0.276\n",
      "0.033\n",
      "0.102\n",
      "0.029\n",
      "0.032\n",
      "0.042\n",
      "0.062\n",
      "0.172\n",
      "0.172\n",
      "0.187\n",
      "0.057\n",
      "0.080\n",
      "0.457\n",
      "0.061\n",
      "0.197\n",
      "0.046\n",
      "0.204\n",
      "0.059\n",
      "0.318\n",
      "0.039\n",
      "0.292\n",
      "0.077\n",
      "0.071\n",
      "0.471\n",
      "0.596\n",
      "0.493\n",
      "0.203\n",
      "0.303\n",
      "0.040\n",
      "0.123\n",
      "0.248\n",
      "0.492\n",
      "0.259\n",
      "0.685\n",
      "0.487\n",
      "0.294\n",
      "0.443\n",
      "0.255\n",
      "0.311\n",
      "0.373\n",
      "0.577\n",
      "0.447\n",
      "0.216\n",
      "0.080\n",
      "0.277\n",
      "0.191\n",
      "0.392\n",
      "0.557\n",
      "0.493\n",
      "0.287\n",
      "0.175\n",
      "0.366\n",
      "0.162\n",
      "0.132\n",
      "0.153\n",
      "0.474\n",
      "0.051\n",
      "0.905\n",
      "0.520\n",
      "0.385\n",
      "0.917\n",
      "0.787\n",
      "0.290\n",
      "0.072\n",
      "0.611\n",
      "0.495\n",
      "0.228\n",
      "0.268\n",
      "0.780\n",
      "0.921\n",
      "0.521\n",
      "0.413\n",
      "0.362\n",
      "0.814\n",
      "0.525\n",
      "0.924\n",
      "0.525\n",
      "0.743\n",
      "0.643\n",
      "0.303\n",
      "0.177\n",
      "0.293\n",
      "0.293\n",
      "0.308\n",
      "0.143\n",
      "0.132\n",
      "0.129\n",
      "0.254\n",
      "0.228\n",
      "0.399\n",
      "0.144\n",
      "0.189\n",
      "0.083\n",
      "0.280\n",
      "0.322\n",
      "0.251\n",
      "0.138\n",
      "0.550\n",
      "0.366\n",
      "0.300\n",
      "0.076\n",
      "0.082\n",
      "0.385\n",
      "0.143\n",
      "0.117\n",
      "0.285\n",
      "0.366\n",
      "0.413\n",
      "0.573\n",
      "0.256\n",
      "0.099\n",
      "0.875\n",
      "0.787\n",
      "0.056\n",
      "0.201\n",
      "0.576\n",
      "0.470\n",
      "0.256\n",
      "0.247\n",
      "0.924\n",
      "0.381\n",
      "0.200\n",
      "0.484\n",
      "0.612\n",
      "0.093\n",
      "0.670\n",
      "0.591\n",
      "0.190\n",
      "0.556\n",
      "0.610\n",
      "0.109\n",
      "0.236\n",
      "0.040\n",
      "0.261\n",
      "0.553\n",
      "0.207\n",
      "0.286\n",
      "0.723\n",
      "0.312\n",
      "0.057\n",
      "0.570\n",
      "0.188\n",
      "0.359\n",
      "0.041\n",
      "0.041\n",
      "0.438\n",
      "0.042\n",
      "0.345\n",
      "0.188\n",
      "0.094\n",
      "0.448\n",
      "0.050\n",
      "0.416\n",
      "0.057\n",
      "0.041\n",
      "0.489\n",
      "0.623\n",
      "0.208\n",
      "0.315\n",
      "0.097\n",
      "0.082\n",
      "0.685\n",
      "0.811\n",
      "0.206\n",
      "0.114\n",
      "0.170\n",
      "0.245\n",
      "0.524\n",
      "0.135\n",
      "0.274\n",
      "0.032\n",
      "0.100\n",
      "0.027\n",
      "0.030\n",
      "0.041\n",
      "0.061\n",
      "0.170\n",
      "0.170\n",
      "0.185\n",
      "0.055\n",
      "0.078\n",
      "0.455\n",
      "0.059\n",
      "0.195\n",
      "0.044\n",
      "0.202\n",
      "0.057\n",
      "0.316\n",
      "0.037\n",
      "0.290\n",
      "0.075\n",
      "0.070\n",
      "0.470\n",
      "0.594\n",
      "0.491\n",
      "0.201\n",
      "0.301\n",
      "0.038\n",
      "0.121\n",
      "0.246\n",
      "0.490\n",
      "0.257\n",
      "0.683\n",
      "0.485\n",
      "0.292\n",
      "0.441\n",
      "0.253\n",
      "0.309\n",
      "0.371\n",
      "0.575\n",
      "0.445\n",
      "0.214\n",
      "0.078\n",
      "0.275\n",
      "0.189\n",
      "0.390\n",
      "0.555\n",
      "0.491\n",
      "0.285\n",
      "0.173\n",
      "0.364\n",
      "0.160\n",
      "0.130\n",
      "0.151\n",
      "0.473\n",
      "0.049\n",
      "0.903\n",
      "0.518\n",
      "0.383\n",
      "0.915\n",
      "0.785\n",
      "0.288\n",
      "0.070\n",
      "0.609\n",
      "0.493\n",
      "0.226\n",
      "0.266\n",
      "0.778\n",
      "0.919\n",
      "0.519\n",
      "0.411\n",
      "0.360\n",
      "0.812\n",
      "0.523\n",
      "0.922\n",
      "0.523\n",
      "0.741\n",
      "0.641\n",
      "0.301\n",
      "0.175\n",
      "0.292\n",
      "0.291\n",
      "0.306\n",
      "0.141\n",
      "0.130\n",
      "0.127\n",
      "0.252\n",
      "0.226\n",
      "0.397\n",
      "0.142\n",
      "0.187\n",
      "0.082\n",
      "0.278\n",
      "0.321\n",
      "0.249\n",
      "0.136\n",
      "0.548\n",
      "0.365\n",
      "0.298\n",
      "0.074\n",
      "0.080\n",
      "0.383\n",
      "0.141\n",
      "0.115\n",
      "0.283\n",
      "0.364\n",
      "0.411\n",
      "0.571\n",
      "0.254\n",
      "0.097\n",
      "0.873\n",
      "0.785\n",
      "0.054\n",
      "0.199\n",
      "0.574\n",
      "0.468\n",
      "0.254\n",
      "0.245\n",
      "0.922\n",
      "0.379\n",
      "0.198\n",
      "0.482\n",
      "0.610\n",
      "0.091\n",
      "0.668\n",
      "0.589\n",
      "0.188\n",
      "0.554\n",
      "0.608\n",
      "0.107\n",
      "0.234\n",
      "0.038\n",
      "0.259\n",
      "0.551\n",
      "0.205\n",
      "0.284\n",
      "0.721\n",
      "0.310\n",
      "0.055\n",
      "0.568\n",
      "0.186\n",
      "0.357\n",
      "0.039\n",
      "0.039\n",
      "0.436\n",
      "0.041\n",
      "0.343\n",
      "0.186\n",
      "0.092\n",
      "0.446\n",
      "0.048\n",
      "0.414\n",
      "0.055\n",
      "0.039\n",
      "0.488\n",
      "0.621\n",
      "0.206\n",
      "0.313\n",
      "0.096\n",
      "0.113\n",
      "0.716\n",
      "0.841\n",
      "0.237\n",
      "0.145\n",
      "0.200\n",
      "0.275\n",
      "0.554\n",
      "0.165\n",
      "0.304\n",
      "0.062\n",
      "0.131\n",
      "0.057\n",
      "0.060\n",
      "0.071\n",
      "0.091\n",
      "0.200\n",
      "0.200\n",
      "0.216\n",
      "0.085\n",
      "0.109\n",
      "0.485\n",
      "0.089\n",
      "0.225\n",
      "0.075\n",
      "0.232\n",
      "0.087\n",
      "0.346\n",
      "0.067\n",
      "0.321\n",
      "0.105\n",
      "0.100\n",
      "0.500\n",
      "0.624\n",
      "0.521\n",
      "0.231\n",
      "0.332\n",
      "0.068\n",
      "0.152\n",
      "0.277\n",
      "0.520\n",
      "0.287\n",
      "0.713\n",
      "0.516\n",
      "0.322\n",
      "0.471\n",
      "0.283\n",
      "0.339\n",
      "0.402\n",
      "0.605\n",
      "0.475\n",
      "0.244\n",
      "0.108\n",
      "0.305\n",
      "0.219\n",
      "0.420\n",
      "0.585\n",
      "0.522\n",
      "0.315\n",
      "0.203\n",
      "0.394\n",
      "0.190\n",
      "0.160\n",
      "0.182\n",
      "0.503\n",
      "0.079\n",
      "0.933\n",
      "0.548\n",
      "0.413\n",
      "0.946\n",
      "0.815\n",
      "0.318\n",
      "0.100\n",
      "0.639\n",
      "0.523\n",
      "0.257\n",
      "0.296\n",
      "0.808\n",
      "0.949\n",
      "0.549\n",
      "0.441\n",
      "0.390\n",
      "0.842\n",
      "0.553\n",
      "0.953\n",
      "0.553\n",
      "0.772\n",
      "0.671\n",
      "0.331\n",
      "0.205\n",
      "0.322\n",
      "0.321\n",
      "0.336\n",
      "0.171\n",
      "0.160\n",
      "0.158\n",
      "0.282\n",
      "0.256\n",
      "0.427\n",
      "0.172\n",
      "0.217\n",
      "0.112\n",
      "0.308\n",
      "0.351\n",
      "0.279\n",
      "0.166\n",
      "0.578\n",
      "0.395\n",
      "0.328\n",
      "0.104\n",
      "0.111\n",
      "0.413\n",
      "0.171\n",
      "0.145\n",
      "0.313\n",
      "0.394\n",
      "0.442\n",
      "0.601\n",
      "0.284\n",
      "0.127\n",
      "0.903\n",
      "0.816\n",
      "0.084\n",
      "0.230\n",
      "0.604\n",
      "0.498\n",
      "0.284\n",
      "0.275\n",
      "0.952\n",
      "0.409\n",
      "0.228\n",
      "0.513\n",
      "0.640\n",
      "0.121\n",
      "0.698\n",
      "0.619\n",
      "0.218\n",
      "0.584\n",
      "0.638\n",
      "0.137\n",
      "0.265\n",
      "0.068\n",
      "0.289\n",
      "0.581\n",
      "0.235\n",
      "0.314\n",
      "0.751\n",
      "0.340\n",
      "0.085\n",
      "0.598\n",
      "0.216\n",
      "0.387\n",
      "0.069\n",
      "0.069\n",
      "0.466\n",
      "0.071\n",
      "0.374\n",
      "0.217\n",
      "0.122\n",
      "0.476\n",
      "0.079\n",
      "0.445\n",
      "0.085\n",
      "0.069\n",
      "0.518\n",
      "0.651\n",
      "0.236\n",
      "0.343\n",
      "0.126\n",
      "0.085\n",
      "0.688\n",
      "0.814\n",
      "0.209\n",
      "0.117\n",
      "0.173\n",
      "0.248\n",
      "0.527\n",
      "0.138\n",
      "0.277\n",
      "0.034\n",
      "0.103\n",
      "0.030\n",
      "0.033\n",
      "0.043\n",
      "0.063\n",
      "0.173\n",
      "0.173\n",
      "0.188\n",
      "0.058\n",
      "0.081\n",
      "0.458\n",
      "0.062\n",
      "0.197\n",
      "0.047\n",
      "0.205\n",
      "0.060\n",
      "0.319\n",
      "0.040\n",
      "0.293\n",
      "0.078\n",
      "0.072\n",
      "0.472\n",
      "0.597\n",
      "0.494\n",
      "0.204\n",
      "0.304\n",
      "0.041\n",
      "0.124\n",
      "0.249\n",
      "0.493\n",
      "0.260\n",
      "0.686\n",
      "0.488\n",
      "0.295\n",
      "0.444\n",
      "0.256\n",
      "0.312\n",
      "0.374\n",
      "0.578\n",
      "0.448\n",
      "0.217\n",
      "0.081\n",
      "0.278\n",
      "0.192\n",
      "0.393\n",
      "0.558\n",
      "0.494\n",
      "0.288\n",
      "0.176\n",
      "0.367\n",
      "0.163\n",
      "0.133\n",
      "0.154\n",
      "0.475\n",
      "0.051\n",
      "0.906\n",
      "0.521\n",
      "0.386\n",
      "0.918\n",
      "0.788\n",
      "0.291\n",
      "0.073\n",
      "0.612\n",
      "0.495\n",
      "0.229\n",
      "0.269\n",
      "0.781\n",
      "0.922\n",
      "0.522\n",
      "0.414\n",
      "0.363\n",
      "0.815\n",
      "0.526\n",
      "0.925\n",
      "0.526\n",
      "0.744\n",
      "0.644\n",
      "0.304\n",
      "0.178\n",
      "0.294\n",
      "0.294\n",
      "0.309\n",
      "0.144\n",
      "0.133\n",
      "0.130\n",
      "0.255\n",
      "0.229\n",
      "0.400\n",
      "0.145\n",
      "0.190\n",
      "0.084\n",
      "0.281\n",
      "0.323\n",
      "0.252\n",
      "0.139\n",
      "0.551\n",
      "0.367\n",
      "0.301\n",
      "0.077\n",
      "0.083\n",
      "0.386\n",
      "0.144\n",
      "0.118\n",
      "0.286\n",
      "0.367\n",
      "0.414\n",
      "0.574\n",
      "0.257\n",
      "0.100\n",
      "0.876\n",
      "0.788\n",
      "0.057\n",
      "0.202\n",
      "0.577\n",
      "0.471\n",
      "0.257\n",
      "0.248\n",
      "0.925\n",
      "0.382\n",
      "0.200\n",
      "0.485\n",
      "0.613\n",
      "0.094\n",
      "0.671\n",
      "0.592\n",
      "0.191\n",
      "0.557\n",
      "0.611\n",
      "0.110\n",
      "0.237\n",
      "0.041\n",
      "0.262\n",
      "0.554\n",
      "0.208\n",
      "0.287\n",
      "0.724\n",
      "0.313\n",
      "0.058\n",
      "0.571\n",
      "0.189\n",
      "0.360\n",
      "0.042\n",
      "0.042\n",
      "0.439\n",
      "0.043\n",
      "0.346\n",
      "0.189\n",
      "0.095\n",
      "0.449\n",
      "0.051\n",
      "0.417\n",
      "0.058\n",
      "0.042\n",
      "0.490\n",
      "0.624\n",
      "0.209\n",
      "0.316\n",
      "0.098\n",
      "0.099\n",
      "0.702\n",
      "0.827\n",
      "0.223\n",
      "0.131\n",
      "0.186\n",
      "0.261\n",
      "0.540\n",
      "0.151\n",
      "0.290\n",
      "0.048\n",
      "0.117\n",
      "0.043\n",
      "0.046\n",
      "0.057\n",
      "0.077\n",
      "0.186\n",
      "0.186\n",
      "0.202\n",
      "0.071\n",
      "0.095\n",
      "0.471\n",
      "0.075\n",
      "0.211\n",
      "0.061\n",
      "0.218\n",
      "0.073\n",
      "0.332\n",
      "0.053\n",
      "0.307\n",
      "0.091\n",
      "0.086\n",
      "0.486\n",
      "0.610\n",
      "0.507\n",
      "0.217\n",
      "0.318\n",
      "0.054\n",
      "0.138\n",
      "0.263\n",
      "0.506\n",
      "0.273\n",
      "0.699\n",
      "0.502\n",
      "0.308\n",
      "0.457\n",
      "0.269\n",
      "0.325\n",
      "0.388\n",
      "0.591\n",
      "0.461\n",
      "0.230\n",
      "0.094\n",
      "0.291\n",
      "0.205\n",
      "0.406\n",
      "0.571\n",
      "0.508\n",
      "0.301\n",
      "0.189\n",
      "0.380\n",
      "0.176\n",
      "0.146\n",
      "0.168\n",
      "0.489\n",
      "0.065\n",
      "0.919\n",
      "0.534\n",
      "0.399\n",
      "0.932\n",
      "0.801\n",
      "0.304\n",
      "0.086\n",
      "0.625\n",
      "0.509\n",
      "0.243\n",
      "0.282\n",
      "0.794\n",
      "0.935\n",
      "0.535\n",
      "0.427\n",
      "0.376\n",
      "0.828\n",
      "0.539\n",
      "0.939\n",
      "0.539\n",
      "0.758\n",
      "0.657\n",
      "0.317\n",
      "0.191\n",
      "0.308\n",
      "0.307\n",
      "0.322\n",
      "0.157\n",
      "0.146\n",
      "0.144\n",
      "0.268\n",
      "0.242\n",
      "0.413\n",
      "0.158\n",
      "0.203\n",
      "0.098\n",
      "0.294\n",
      "0.337\n",
      "0.265\n",
      "0.152\n",
      "0.564\n",
      "0.381\n",
      "0.314\n",
      "0.090\n",
      "0.097\n",
      "0.399\n",
      "0.157\n",
      "0.131\n",
      "0.299\n",
      "0.380\n",
      "0.428\n",
      "0.587\n",
      "0.270\n",
      "0.113\n",
      "0.889\n",
      "0.802\n",
      "0.070\n",
      "0.216\n",
      "0.590\n",
      "0.484\n",
      "0.270\n",
      "0.261\n",
      "0.938\n",
      "0.395\n",
      "0.214\n",
      "0.499\n",
      "0.626\n",
      "0.107\n",
      "0.684\n",
      "0.605\n",
      "0.204\n",
      "0.570\n",
      "0.624\n",
      "0.123\n",
      "0.251\n",
      "0.054\n",
      "0.275\n",
      "0.567\n",
      "0.221\n",
      "0.300\n",
      "0.737\n",
      "0.326\n",
      "0.071\n",
      "0.584\n",
      "0.202\n",
      "0.373\n",
      "0.055\n",
      "0.055\n",
      "0.452\n",
      "0.057\n",
      "0.360\n",
      "0.203\n",
      "0.108\n",
      "0.462\n",
      "0.065\n",
      "0.431\n",
      "0.071\n",
      "0.055\n",
      "0.504\n",
      "0.637\n",
      "0.222\n",
      "0.329\n",
      "0.112\n",
      "0.118\n",
      "0.721\n",
      "0.846\n",
      "0.242\n",
      "0.150\n",
      "0.206\n",
      "0.281\n",
      "0.560\n",
      "0.171\n",
      "0.309\n",
      "0.067\n",
      "0.136\n",
      "0.063\n",
      "0.066\n",
      "0.076\n",
      "0.096\n",
      "0.206\n",
      "0.206\n",
      "0.221\n",
      "0.091\n",
      "0.114\n",
      "0.491\n",
      "0.094\n",
      "0.230\n",
      "0.080\n",
      "0.238\n",
      "0.093\n",
      "0.352\n",
      "0.073\n",
      "0.326\n",
      "0.111\n",
      "0.105\n",
      "0.505\n",
      "0.630\n",
      "0.527\n",
      "0.236\n",
      "0.337\n",
      "0.074\n",
      "0.157\n",
      "0.282\n",
      "0.526\n",
      "0.293\n",
      "0.719\n",
      "0.521\n",
      "0.328\n",
      "0.476\n",
      "0.289\n",
      "0.344\n",
      "0.407\n",
      "0.611\n",
      "0.481\n",
      "0.250\n",
      "0.113\n",
      "0.311\n",
      "0.225\n",
      "0.426\n",
      "0.590\n",
      "0.527\n",
      "0.321\n",
      "0.208\n",
      "0.399\n",
      "0.195\n",
      "0.166\n",
      "0.187\n",
      "0.508\n",
      "0.084\n",
      "0.939\n",
      "0.554\n",
      "0.418\n",
      "0.951\n",
      "0.820\n",
      "0.324\n",
      "0.105\n",
      "0.645\n",
      "0.528\n",
      "0.262\n",
      "0.301\n",
      "0.814\n",
      "0.955\n",
      "0.554\n",
      "0.446\n",
      "0.396\n",
      "0.848\n",
      "0.559\n",
      "0.958\n",
      "0.559\n",
      "0.777\n",
      "0.677\n",
      "0.336\n",
      "0.211\n",
      "0.327\n",
      "0.327\n",
      "0.341\n",
      "0.177\n",
      "0.166\n",
      "0.163\n",
      "0.288\n",
      "0.262\n",
      "0.433\n",
      "0.178\n",
      "0.222\n",
      "0.117\n",
      "0.314\n",
      "0.356\n",
      "0.285\n",
      "0.172\n",
      "0.584\n",
      "0.400\n",
      "0.334\n",
      "0.110\n",
      "0.116\n",
      "0.419\n",
      "0.177\n",
      "0.150\n",
      "0.318\n",
      "0.399\n",
      "0.447\n",
      "0.607\n",
      "0.289\n",
      "0.132\n",
      "0.909\n",
      "0.821\n",
      "0.090\n",
      "0.235\n",
      "0.610\n",
      "0.503\n",
      "0.290\n",
      "0.280\n",
      "0.958\n",
      "0.414\n",
      "0.233\n",
      "0.518\n",
      "0.646\n",
      "0.127\n",
      "0.704\n",
      "0.624\n",
      "0.223\n",
      "0.590\n",
      "0.644\n",
      "0.142\n",
      "0.270\n",
      "0.074\n",
      "0.295\n",
      "0.587\n",
      "0.241\n",
      "0.320\n",
      "0.757\n",
      "0.345\n",
      "0.091\n",
      "0.603\n",
      "0.222\n",
      "0.393\n",
      "0.075\n",
      "0.075\n",
      "0.471\n",
      "0.076\n",
      "0.379\n",
      "0.222\n",
      "0.127\n",
      "0.481\n",
      "0.084\n",
      "0.450\n",
      "0.091\n",
      "0.075\n",
      "0.523\n",
      "0.656\n",
      "0.241\n",
      "0.349\n",
      "0.131\n",
      "0.125\n",
      "0.728\n",
      "0.853\n",
      "0.249\n",
      "0.157\n",
      "0.212\n",
      "0.288\n",
      "0.566\n",
      "0.177\n",
      "0.316\n",
      "0.074\n",
      "0.143\n",
      "0.069\n",
      "0.072\n",
      "0.083\n",
      "0.103\n",
      "0.213\n",
      "0.213\n",
      "0.228\n",
      "0.097\n",
      "0.121\n",
      "0.497\n",
      "0.101\n",
      "0.237\n",
      "0.087\n",
      "0.244\n",
      "0.099\n",
      "0.359\n",
      "0.079\n",
      "0.333\n",
      "0.117\n",
      "0.112\n",
      "0.512\n",
      "0.636\n",
      "0.534\n",
      "0.243\n",
      "0.344\n",
      "0.081\n",
      "0.164\n",
      "0.289\n",
      "0.532\n",
      "0.299\n",
      "0.725\n",
      "0.528\n",
      "0.335\n",
      "0.483\n",
      "0.295\n",
      "0.351\n",
      "0.414\n",
      "0.617\n",
      "0.487\n",
      "0.256\n",
      "0.120\n",
      "0.317\n",
      "0.231\n",
      "0.432\n",
      "0.597\n",
      "0.534\n",
      "0.327\n",
      "0.215\n",
      "0.406\n",
      "0.202\n",
      "0.172\n",
      "0.194\n",
      "0.515\n",
      "0.091\n",
      "0.945\n",
      "0.560\n",
      "0.425\n",
      "0.958\n",
      "0.827\n",
      "0.330\n",
      "0.112\n",
      "0.651\n",
      "0.535\n",
      "0.269\n",
      "0.308\n",
      "0.820\n",
      "0.961\n",
      "0.561\n",
      "0.453\n",
      "0.402\n",
      "0.855\n",
      "0.565\n",
      "0.965\n",
      "0.566\n",
      "0.784\n",
      "0.683\n",
      "0.343\n",
      "0.217\n",
      "0.334\n",
      "0.333\n",
      "0.348\n",
      "0.183\n",
      "0.172\n",
      "0.170\n",
      "0.294\n",
      "0.268\n",
      "0.440\n",
      "0.184\n",
      "0.229\n",
      "0.124\n",
      "0.320\n",
      "0.363\n",
      "0.291\n",
      "0.178\n",
      "0.590\n",
      "0.407\n",
      "0.340\n",
      "0.116\n",
      "0.123\n",
      "0.426\n",
      "0.183\n",
      "0.157\n",
      "0.325\n",
      "0.406\n",
      "0.454\n",
      "0.613\n",
      "0.296\n",
      "0.139\n",
      "0.916\n",
      "0.828\n",
      "0.096\n",
      "0.242\n",
      "0.616\n",
      "0.510\n",
      "0.297\n",
      "0.287\n",
      "0.964\n",
      "0.421\n",
      "0.240\n",
      "0.525\n",
      "0.652\n",
      "0.133\n",
      "0.710\n",
      "0.631\n",
      "0.230\n",
      "0.596\n",
      "0.650\n",
      "0.149\n",
      "0.277\n",
      "0.080\n",
      "0.301\n",
      "0.593\n",
      "0.248\n",
      "0.326\n",
      "0.764\n",
      "0.352\n",
      "0.098\n",
      "0.610\n",
      "0.228\n",
      "0.399\n",
      "0.081\n",
      "0.081\n",
      "0.478\n",
      "0.083\n",
      "0.386\n",
      "0.229\n",
      "0.134\n",
      "0.488\n",
      "0.091\n",
      "0.457\n",
      "0.098\n",
      "0.081\n",
      "0.530\n",
      "0.663\n",
      "0.248\n",
      "0.355\n",
      "0.138\n",
      "0.126\n",
      "0.728\n",
      "0.854\n",
      "0.249\n",
      "0.158\n",
      "0.213\n",
      "0.288\n",
      "0.567\n",
      "0.178\n",
      "0.317\n",
      "0.075\n",
      "0.143\n",
      "0.070\n",
      "0.073\n",
      "0.084\n",
      "0.104\n",
      "0.213\n",
      "0.213\n",
      "0.228\n",
      "0.098\n",
      "0.121\n",
      "0.498\n",
      "0.102\n",
      "0.238\n",
      "0.088\n",
      "0.245\n",
      "0.100\n",
      "0.359\n",
      "0.080\n",
      "0.333\n",
      "0.118\n",
      "0.113\n",
      "0.513\n",
      "0.637\n",
      "0.534\n",
      "0.244\n",
      "0.345\n",
      "0.081\n",
      "0.164\n",
      "0.289\n",
      "0.533\n",
      "0.300\n",
      "0.726\n",
      "0.529\n",
      "0.335\n",
      "0.484\n",
      "0.296\n",
      "0.352\n",
      "0.415\n",
      "0.618\n",
      "0.488\n",
      "0.257\n",
      "0.121\n",
      "0.318\n",
      "0.232\n",
      "0.433\n",
      "0.598\n",
      "0.535\n",
      "0.328\n",
      "0.216\n",
      "0.407\n",
      "0.203\n",
      "0.173\n",
      "0.194\n",
      "0.516\n",
      "0.092\n",
      "0.946\n",
      "0.561\n",
      "0.426\n",
      "0.958\n",
      "0.828\n",
      "0.331\n",
      "0.113\n",
      "0.652\n",
      "0.536\n",
      "0.269\n",
      "0.309\n",
      "0.821\n",
      "0.962\n",
      "0.562\n",
      "0.454\n",
      "0.403\n",
      "0.855\n",
      "0.566\n",
      "0.965\n",
      "0.566\n",
      "0.784\n",
      "0.684\n",
      "0.344\n",
      "0.218\n",
      "0.335\n",
      "0.334\n",
      "0.349\n",
      "0.184\n",
      "0.173\n",
      "0.170\n",
      "0.295\n",
      "0.269\n",
      "0.440\n",
      "0.185\n",
      "0.230\n",
      "0.125\n",
      "0.321\n",
      "0.364\n",
      "0.292\n",
      "0.179\n",
      "0.591\n",
      "0.408\n",
      "0.341\n",
      "0.117\n",
      "0.123\n",
      "0.426\n",
      "0.184\n",
      "0.158\n",
      "0.326\n",
      "0.407\n",
      "0.454\n",
      "0.614\n",
      "0.297\n",
      "0.140\n",
      "0.916\n",
      "0.828\n",
      "0.097\n",
      "0.243\n",
      "0.617\n",
      "0.511\n",
      "0.297\n",
      "0.288\n",
      "0.965\n",
      "0.422\n",
      "0.241\n",
      "0.526\n",
      "0.653\n",
      "0.134\n",
      "0.711\n",
      "0.632\n",
      "0.231\n",
      "0.597\n",
      "0.651\n",
      "0.150\n",
      "0.278\n",
      "0.081\n",
      "0.302\n",
      "0.594\n",
      "0.248\n",
      "0.327\n",
      "0.764\n",
      "0.353\n",
      "0.098\n",
      "0.611\n",
      "0.229\n",
      "0.400\n",
      "0.082\n",
      "0.082\n",
      "0.479\n",
      "0.084\n",
      "0.386\n",
      "0.229\n",
      "0.135\n",
      "0.489\n",
      "0.091\n",
      "0.457\n",
      "0.098\n",
      "0.082\n",
      "0.531\n",
      "0.664\n",
      "0.249\n",
      "0.356\n",
      "0.139\n",
      "0.102\n",
      "0.705\n",
      "0.830\n",
      "0.226\n",
      "0.134\n",
      "0.189\n",
      "0.265\n",
      "0.544\n",
      "0.154\n",
      "0.293\n",
      "0.051\n",
      "0.120\n",
      "0.046\n",
      "0.049\n",
      "0.060\n",
      "0.080\n",
      "0.190\n",
      "0.190\n",
      "0.205\n",
      "0.074\n",
      "0.098\n",
      "0.475\n",
      "0.078\n",
      "0.214\n",
      "0.064\n",
      "0.221\n",
      "0.077\n",
      "0.336\n",
      "0.057\n",
      "0.310\n",
      "0.095\n",
      "0.089\n",
      "0.489\n",
      "0.614\n",
      "0.511\n",
      "0.220\n",
      "0.321\n",
      "0.058\n",
      "0.141\n",
      "0.266\n",
      "0.510\n",
      "0.276\n",
      "0.702\n",
      "0.505\n",
      "0.312\n",
      "0.460\n",
      "0.273\n",
      "0.328\n",
      "0.391\n",
      "0.594\n",
      "0.465\n",
      "0.234\n",
      "0.097\n",
      "0.294\n",
      "0.209\n",
      "0.409\n",
      "0.574\n",
      "0.511\n",
      "0.305\n",
      "0.192\n",
      "0.383\n",
      "0.179\n",
      "0.150\n",
      "0.171\n",
      "0.492\n",
      "0.068\n",
      "0.922\n",
      "0.537\n",
      "0.402\n",
      "0.935\n",
      "0.804\n",
      "0.308\n",
      "0.089\n",
      "0.629\n",
      "0.512\n",
      "0.246\n",
      "0.285\n",
      "0.798\n",
      "0.938\n",
      "0.538\n",
      "0.430\n",
      "0.379\n",
      "0.832\n",
      "0.542\n",
      "0.942\n",
      "0.543\n",
      "0.761\n",
      "0.660\n",
      "0.320\n",
      "0.194\n",
      "0.311\n",
      "0.310\n",
      "0.325\n",
      "0.161\n",
      "0.150\n",
      "0.147\n",
      "0.271\n",
      "0.245\n",
      "0.417\n",
      "0.161\n",
      "0.206\n",
      "0.101\n",
      "0.297\n",
      "0.340\n",
      "0.269\n",
      "0.155\n",
      "0.568\n",
      "0.384\n",
      "0.317\n",
      "0.094\n",
      "0.100\n",
      "0.403\n",
      "0.161\n",
      "0.134\n",
      "0.302\n",
      "0.383\n",
      "0.431\n",
      "0.590\n",
      "0.273\n",
      "0.116\n",
      "0.893\n",
      "0.805\n",
      "0.074\n",
      "0.219\n",
      "0.594\n",
      "0.487\n",
      "0.274\n",
      "0.264\n",
      "0.942\n",
      "0.398\n",
      "0.217\n",
      "0.502\n",
      "0.629\n",
      "0.110\n",
      "0.688\n",
      "0.608\n",
      "0.207\n",
      "0.574\n",
      "0.627\n",
      "0.126\n",
      "0.254\n",
      "0.057\n",
      "0.279\n",
      "0.571\n",
      "0.225\n",
      "0.303\n",
      "0.741\n",
      "0.329\n",
      "0.075\n",
      "0.587\n",
      "0.206\n",
      "0.377\n",
      "0.059\n",
      "0.059\n",
      "0.455\n",
      "0.060\n",
      "0.363\n",
      "0.206\n",
      "0.111\n",
      "0.465\n",
      "0.068\n",
      "0.434\n",
      "0.075\n",
      "0.059\n",
      "0.507\n",
      "0.640\n",
      "0.225\n",
      "0.332\n",
      "0.115\n",
      "0.119\n",
      "0.722\n",
      "0.847\n",
      "0.243\n",
      "0.151\n",
      "0.206\n",
      "0.282\n",
      "0.561\n",
      "0.171\n",
      "0.310\n",
      "0.068\n",
      "0.137\n",
      "0.063\n",
      "0.066\n",
      "0.077\n",
      "0.097\n",
      "0.207\n",
      "0.207\n",
      "0.222\n",
      "0.092\n",
      "0.115\n",
      "0.492\n",
      "0.095\n",
      "0.231\n",
      "0.081\n",
      "0.238\n",
      "0.094\n",
      "0.353\n",
      "0.074\n",
      "0.327\n",
      "0.112\n",
      "0.106\n",
      "0.506\n",
      "0.631\n",
      "0.528\n",
      "0.237\n",
      "0.338\n",
      "0.075\n",
      "0.158\n",
      "0.283\n",
      "0.527\n",
      "0.293\n",
      "0.720\n",
      "0.522\n",
      "0.329\n",
      "0.477\n",
      "0.290\n",
      "0.345\n",
      "0.408\n",
      "0.612\n",
      "0.482\n",
      "0.251\n",
      "0.114\n",
      "0.311\n",
      "0.226\n",
      "0.426\n",
      "0.591\n",
      "0.528\n",
      "0.322\n",
      "0.209\n",
      "0.400\n",
      "0.196\n",
      "0.167\n",
      "0.188\n",
      "0.509\n",
      "0.085\n",
      "0.939\n",
      "0.554\n",
      "0.419\n",
      "0.952\n",
      "0.821\n",
      "0.325\n",
      "0.106\n",
      "0.646\n",
      "0.529\n",
      "0.263\n",
      "0.302\n",
      "0.815\n",
      "0.955\n",
      "0.555\n",
      "0.447\n",
      "0.396\n",
      "0.849\n",
      "0.559\n",
      "0.959\n",
      "0.560\n",
      "0.778\n",
      "0.677\n",
      "0.337\n",
      "0.212\n",
      "0.328\n",
      "0.327\n",
      "0.342\n",
      "0.178\n",
      "0.167\n",
      "0.164\n",
      "0.288\n",
      "0.262\n",
      "0.434\n",
      "0.178\n",
      "0.223\n",
      "0.118\n",
      "0.314\n",
      "0.357\n",
      "0.286\n",
      "0.172\n",
      "0.585\n",
      "0.401\n",
      "0.334\n",
      "0.111\n",
      "0.117\n",
      "0.420\n",
      "0.178\n",
      "0.151\n",
      "0.319\n",
      "0.400\n",
      "0.448\n",
      "0.607\n",
      "0.290\n",
      "0.133\n",
      "0.910\n",
      "0.822\n",
      "0.091\n",
      "0.236\n",
      "0.611\n",
      "0.504\n",
      "0.291\n",
      "0.281\n",
      "0.959\n",
      "0.415\n",
      "0.234\n",
      "0.519\n",
      "0.647\n",
      "0.127\n",
      "0.705\n",
      "0.625\n",
      "0.224\n",
      "0.591\n",
      "0.644\n",
      "0.143\n",
      "0.271\n",
      "0.074\n",
      "0.296\n",
      "0.588\n",
      "0.242\n",
      "0.320\n",
      "0.758\n",
      "0.346\n",
      "0.092\n",
      "0.604\n",
      "0.223\n",
      "0.394\n",
      "0.076\n",
      "0.076\n",
      "0.472\n",
      "0.077\n",
      "0.380\n",
      "0.223\n",
      "0.128\n",
      "0.482\n",
      "0.085\n",
      "0.451\n",
      "0.092\n",
      "0.076\n",
      "0.524\n",
      "0.657\n",
      "0.242\n",
      "0.349\n",
      "0.132\n",
      "0.124\n",
      "0.727\n",
      "0.852\n",
      "0.248\n",
      "0.156\n",
      "0.211\n",
      "0.287\n",
      "0.566\n",
      "0.176\n",
      "0.315\n",
      "0.073\n",
      "0.142\n",
      "0.068\n",
      "0.071\n",
      "0.082\n",
      "0.102\n",
      "0.212\n",
      "0.212\n",
      "0.227\n",
      "0.096\n",
      "0.120\n",
      "0.496\n",
      "0.100\n",
      "0.236\n",
      "0.086\n",
      "0.243\n",
      "0.099\n",
      "0.358\n",
      "0.078\n",
      "0.332\n",
      "0.116\n",
      "0.111\n",
      "0.511\n",
      "0.636\n",
      "0.533\n",
      "0.242\n",
      "0.343\n",
      "0.080\n",
      "0.163\n",
      "0.288\n",
      "0.531\n",
      "0.298\n",
      "0.724\n",
      "0.527\n",
      "0.334\n",
      "0.482\n",
      "0.294\n",
      "0.350\n",
      "0.413\n",
      "0.616\n",
      "0.487\n",
      "0.256\n",
      "0.119\n",
      "0.316\n",
      "0.230\n",
      "0.431\n",
      "0.596\n",
      "0.533\n",
      "0.327\n",
      "0.214\n",
      "0.405\n",
      "0.201\n",
      "0.172\n",
      "0.193\n",
      "0.514\n",
      "0.090\n",
      "0.944\n",
      "0.559\n",
      "0.424\n",
      "0.957\n",
      "0.826\n",
      "0.330\n",
      "0.111\n",
      "0.651\n",
      "0.534\n",
      "0.268\n",
      "0.307\n",
      "0.820\n",
      "0.960\n",
      "0.560\n",
      "0.452\n",
      "0.401\n",
      "0.854\n",
      "0.564\n",
      "0.964\n",
      "0.565\n",
      "0.783\n",
      "0.682\n",
      "0.342\n",
      "0.216\n",
      "0.333\n",
      "0.332\n",
      "0.347\n",
      "0.183\n",
      "0.172\n",
      "0.169\n",
      "0.293\n",
      "0.267\n",
      "0.439\n",
      "0.183\n",
      "0.228\n",
      "0.123\n",
      "0.319\n",
      "0.362\n",
      "0.291\n",
      "0.177\n",
      "0.590\n",
      "0.406\n",
      "0.339\n",
      "0.116\n",
      "0.122\n",
      "0.425\n",
      "0.183\n",
      "0.156\n",
      "0.324\n",
      "0.405\n",
      "0.453\n",
      "0.612\n",
      "0.295\n",
      "0.138\n",
      "0.915\n",
      "0.827\n",
      "0.096\n",
      "0.241\n",
      "0.616\n",
      "0.509\n",
      "0.296\n",
      "0.286\n",
      "0.963\n",
      "0.420\n",
      "0.239\n",
      "0.524\n",
      "0.651\n",
      "0.132\n",
      "0.709\n",
      "0.630\n",
      "0.229\n",
      "0.595\n",
      "0.649\n",
      "0.148\n",
      "0.276\n",
      "0.079\n",
      "0.300\n",
      "0.592\n",
      "0.247\n",
      "0.325\n",
      "0.763\n",
      "0.351\n",
      "0.097\n",
      "0.609\n",
      "0.227\n",
      "0.399\n",
      "0.081\n",
      "0.081\n",
      "0.477\n",
      "0.082\n",
      "0.385\n",
      "0.228\n",
      "0.133\n",
      "0.487\n",
      "0.090\n",
      "0.456\n",
      "0.097\n",
      "0.081\n",
      "0.529\n",
      "0.662\n",
      "0.247\n",
      "0.354\n",
      "0.137\n",
      "0.110\n",
      "0.713\n",
      "0.838\n",
      "0.234\n",
      "0.142\n",
      "0.197\n",
      "0.273\n",
      "0.552\n",
      "0.162\n",
      "0.301\n",
      "0.059\n",
      "0.128\n",
      "0.054\n",
      "0.057\n",
      "0.068\n",
      "0.088\n",
      "0.198\n",
      "0.198\n",
      "0.213\n",
      "0.082\n",
      "0.106\n",
      "0.482\n",
      "0.086\n",
      "0.222\n",
      "0.072\n",
      "0.229\n",
      "0.085\n",
      "0.344\n",
      "0.065\n",
      "0.318\n",
      "0.103\n",
      "0.097\n",
      "0.497\n",
      "0.622\n",
      "0.519\n",
      "0.228\n",
      "0.329\n",
      "0.066\n",
      "0.149\n",
      "0.274\n",
      "0.517\n",
      "0.284\n",
      "0.710\n",
      "0.513\n",
      "0.320\n",
      "0.468\n",
      "0.281\n",
      "0.336\n",
      "0.399\n",
      "0.602\n",
      "0.473\n",
      "0.242\n",
      "0.105\n",
      "0.302\n",
      "0.216\n",
      "0.417\n",
      "0.582\n",
      "0.519\n",
      "0.313\n",
      "0.200\n",
      "0.391\n",
      "0.187\n",
      "0.158\n",
      "0.179\n",
      "0.500\n",
      "0.076\n",
      "0.930\n",
      "0.545\n",
      "0.410\n",
      "0.943\n",
      "0.812\n",
      "0.316\n",
      "0.097\n",
      "0.637\n",
      "0.520\n",
      "0.254\n",
      "0.293\n",
      "0.806\n",
      "0.946\n",
      "0.546\n",
      "0.438\n",
      "0.387\n",
      "0.840\n",
      "0.550\n",
      "0.950\n",
      "0.551\n",
      "0.769\n",
      "0.668\n",
      "0.328\n",
      "0.202\n",
      "0.319\n",
      "0.318\n",
      "0.333\n",
      "0.169\n",
      "0.158\n",
      "0.155\n",
      "0.279\n",
      "0.253\n",
      "0.425\n",
      "0.169\n",
      "0.214\n",
      "0.109\n",
      "0.305\n",
      "0.348\n",
      "0.277\n",
      "0.163\n",
      "0.576\n",
      "0.392\n",
      "0.325\n",
      "0.102\n",
      "0.108\n",
      "0.411\n",
      "0.169\n",
      "0.142\n",
      "0.310\n",
      "0.391\n",
      "0.439\n",
      "0.598\n",
      "0.281\n",
      "0.124\n",
      "0.901\n",
      "0.813\n",
      "0.082\n",
      "0.227\n",
      "0.602\n",
      "0.495\n",
      "0.282\n",
      "0.272\n",
      "0.950\n",
      "0.406\n",
      "0.225\n",
      "0.510\n",
      "0.637\n",
      "0.118\n",
      "0.696\n",
      "0.616\n",
      "0.215\n",
      "0.582\n",
      "0.635\n",
      "0.134\n",
      "0.262\n",
      "0.065\n",
      "0.287\n",
      "0.579\n",
      "0.233\n",
      "0.311\n",
      "0.749\n",
      "0.337\n",
      "0.083\n",
      "0.595\n",
      "0.214\n",
      "0.385\n",
      "0.067\n",
      "0.067\n",
      "0.463\n",
      "0.068\n",
      "0.371\n",
      "0.214\n",
      "0.119\n",
      "0.473\n",
      "0.076\n",
      "0.442\n",
      "0.083\n",
      "0.067\n",
      "0.515\n",
      "0.648\n",
      "0.233\n",
      "0.340\n",
      "0.123\n",
      "0.131\n",
      "0.734\n",
      "0.859\n",
      "0.255\n",
      "0.163\n",
      "0.218\n",
      "0.293\n",
      "0.572\n",
      "0.183\n",
      "0.322\n",
      "0.080\n",
      "0.149\n",
      "0.075\n",
      "0.078\n",
      "0.089\n",
      "0.109\n",
      "0.218\n",
      "0.218\n",
      "0.234\n",
      "0.103\n",
      "0.126\n",
      "0.503\n",
      "0.107\n",
      "0.243\n",
      "0.093\n",
      "0.250\n",
      "0.105\n",
      "0.364\n",
      "0.085\n",
      "0.339\n",
      "0.123\n",
      "0.118\n",
      "0.518\n",
      "0.642\n",
      "0.539\n",
      "0.249\n",
      "0.350\n",
      "0.086\n",
      "0.170\n",
      "0.295\n",
      "0.538\n",
      "0.305\n",
      "0.731\n",
      "0.534\n",
      "0.340\n",
      "0.489\n",
      "0.301\n",
      "0.357\n",
      "0.420\n",
      "0.623\n",
      "0.493\n",
      "0.262\n",
      "0.126\n",
      "0.323\n",
      "0.237\n",
      "0.438\n",
      "0.603\n",
      "0.540\n",
      "0.333\n",
      "0.221\n",
      "0.412\n",
      "0.208\n",
      "0.178\n",
      "0.199\n",
      "0.521\n",
      "0.097\n",
      "0.951\n",
      "0.566\n",
      "0.431\n",
      "0.964\n",
      "0.833\n",
      "0.336\n",
      "0.118\n",
      "0.657\n",
      "0.541\n",
      "0.275\n",
      "0.314\n",
      "0.826\n",
      "0.967\n",
      "0.567\n",
      "0.459\n",
      "0.408\n",
      "0.860\n",
      "0.571\n",
      "0.971\n",
      "0.571\n",
      "0.789\n",
      "0.689\n",
      "0.349\n",
      "0.223\n",
      "0.340\n",
      "0.339\n",
      "0.354\n",
      "0.189\n",
      "0.178\n",
      "0.176\n",
      "0.300\n",
      "0.274\n",
      "0.445\n",
      "0.190\n",
      "0.235\n",
      "0.130\n",
      "0.326\n",
      "0.369\n",
      "0.297\n",
      "0.184\n",
      "0.596\n",
      "0.413\n",
      "0.346\n",
      "0.122\n",
      "0.129\n",
      "0.431\n",
      "0.189\n",
      "0.163\n",
      "0.331\n",
      "0.412\n",
      "0.459\n",
      "0.619\n",
      "0.302\n",
      "0.145\n",
      "0.921\n",
      "0.833\n",
      "0.102\n",
      "0.248\n",
      "0.622\n",
      "0.516\n",
      "0.302\n",
      "0.293\n",
      "0.970\n",
      "0.427\n",
      "0.246\n",
      "0.531\n",
      "0.658\n",
      "0.139\n",
      "0.716\n",
      "0.637\n",
      "0.236\n",
      "0.602\n",
      "0.656\n",
      "0.155\n",
      "0.283\n",
      "0.086\n",
      "0.307\n",
      "0.599\n",
      "0.253\n",
      "0.332\n",
      "0.769\n",
      "0.358\n",
      "0.103\n",
      "0.616\n",
      "0.234\n",
      "0.405\n",
      "0.087\n",
      "0.087\n",
      "0.484\n",
      "0.089\n",
      "0.392\n",
      "0.234\n",
      "0.140\n",
      "0.494\n",
      "0.097\n",
      "0.462\n",
      "0.103\n",
      "0.087\n",
      "0.536\n",
      "0.669\n",
      "0.254\n",
      "0.361\n",
      "0.144\n",
      "0.131\n",
      "0.734\n",
      "0.859\n",
      "0.255\n",
      "0.163\n",
      "0.219\n",
      "0.294\n",
      "0.573\n",
      "0.184\n",
      "0.323\n",
      "0.080\n",
      "0.149\n",
      "0.076\n",
      "0.079\n",
      "0.089\n",
      "0.109\n",
      "0.219\n",
      "0.219\n",
      "0.234\n",
      "0.104\n",
      "0.127\n",
      "0.504\n",
      "0.108\n",
      "0.243\n",
      "0.093\n",
      "0.251\n",
      "0.106\n",
      "0.365\n",
      "0.086\n",
      "0.339\n",
      "0.124\n",
      "0.118\n",
      "0.518\n",
      "0.643\n",
      "0.540\n",
      "0.250\n",
      "0.350\n",
      "0.087\n",
      "0.170\n",
      "0.295\n",
      "0.539\n",
      "0.306\n",
      "0.732\n",
      "0.534\n",
      "0.341\n",
      "0.490\n",
      "0.302\n",
      "0.358\n",
      "0.420\n",
      "0.624\n",
      "0.494\n",
      "0.263\n",
      "0.126\n",
      "0.324\n",
      "0.238\n",
      "0.439\n",
      "0.604\n",
      "0.540\n",
      "0.334\n",
      "0.222\n",
      "0.412\n",
      "0.209\n",
      "0.179\n",
      "0.200\n",
      "0.521\n",
      "0.097\n",
      "0.952\n",
      "0.567\n",
      "0.432\n",
      "0.964\n",
      "0.833\n",
      "0.337\n",
      "0.119\n",
      "0.658\n",
      "0.541\n",
      "0.275\n",
      "0.315\n",
      "0.827\n",
      "0.968\n",
      "0.567\n",
      "0.460\n",
      "0.409\n",
      "0.861\n",
      "0.572\n",
      "0.971\n",
      "0.572\n",
      "0.790\n",
      "0.690\n",
      "0.350\n",
      "0.224\n",
      "0.340\n",
      "0.340\n",
      "0.355\n",
      "0.190\n",
      "0.179\n",
      "0.176\n",
      "0.301\n",
      "0.275\n",
      "0.446\n",
      "0.191\n",
      "0.236\n",
      "0.130\n",
      "0.327\n",
      "0.369\n",
      "0.298\n",
      "0.185\n",
      "0.597\n",
      "0.413\n",
      "0.347\n",
      "0.123\n",
      "0.129\n",
      "0.432\n",
      "0.190\n",
      "0.164\n",
      "0.332\n",
      "0.412\n",
      "0.460\n",
      "0.620\n",
      "0.303\n",
      "0.146\n",
      "0.922\n",
      "0.834\n",
      "0.103\n",
      "0.248\n",
      "0.623\n",
      "0.517\n",
      "0.303\n",
      "0.294\n",
      "0.971\n",
      "0.428\n",
      "0.246\n",
      "0.531\n",
      "0.659\n",
      "0.140\n",
      "0.717\n",
      "0.637\n",
      "0.237\n",
      "0.603\n",
      "0.657\n",
      "0.155\n",
      "0.283\n",
      "0.087\n",
      "0.308\n",
      "0.600\n",
      "0.254\n",
      "0.333\n",
      "0.770\n",
      "0.359\n",
      "0.104\n",
      "0.617\n",
      "0.235\n",
      "0.406\n",
      "0.088\n",
      "0.088\n",
      "0.485\n",
      "0.089\n",
      "0.392\n",
      "0.235\n",
      "0.141\n",
      "0.495\n",
      "0.097\n",
      "0.463\n",
      "0.104\n",
      "0.088\n",
      "0.536\n",
      "0.669\n",
      "0.255\n",
      "0.362\n",
      "0.144\n",
      "0.142\n",
      "0.745\n",
      "0.870\n",
      "0.266\n",
      "0.174\n",
      "0.229\n",
      "0.305\n",
      "0.584\n",
      "0.194\n",
      "0.333\n",
      "0.091\n",
      "0.160\n",
      "0.086\n",
      "0.089\n",
      "0.100\n",
      "0.120\n",
      "0.230\n",
      "0.230\n",
      "0.245\n",
      "0.114\n",
      "0.138\n",
      "0.514\n",
      "0.118\n",
      "0.254\n",
      "0.104\n",
      "0.261\n",
      "0.117\n",
      "0.376\n",
      "0.096\n",
      "0.350\n",
      "0.134\n",
      "0.129\n",
      "0.529\n",
      "0.654\n",
      "0.551\n",
      "0.260\n",
      "0.361\n",
      "0.098\n",
      "0.181\n",
      "0.306\n",
      "0.549\n",
      "0.316\n",
      "0.742\n",
      "0.545\n",
      "0.352\n",
      "0.500\n",
      "0.312\n",
      "0.368\n",
      "0.431\n",
      "0.634\n",
      "0.505\n",
      "0.274\n",
      "0.137\n",
      "0.334\n",
      "0.248\n",
      "0.449\n",
      "0.614\n",
      "0.551\n",
      "0.345\n",
      "0.232\n",
      "0.423\n",
      "0.219\n",
      "0.190\n",
      "0.211\n",
      "0.532\n",
      "0.108\n",
      "0.962\n",
      "0.577\n",
      "0.442\n",
      "0.975\n",
      "0.844\n",
      "0.347\n",
      "0.129\n",
      "0.669\n",
      "0.552\n",
      "0.286\n",
      "0.325\n",
      "0.838\n",
      "0.978\n",
      "0.578\n",
      "0.470\n",
      "0.419\n",
      "0.872\n",
      "0.582\n",
      "0.982\n",
      "0.583\n",
      "0.801\n",
      "0.700\n",
      "0.360\n",
      "0.234\n",
      "0.351\n",
      "0.350\n",
      "0.365\n",
      "0.201\n",
      "0.190\n",
      "0.187\n",
      "0.311\n",
      "0.285\n",
      "0.457\n",
      "0.201\n",
      "0.246\n",
      "0.141\n",
      "0.337\n",
      "0.380\n",
      "0.309\n",
      "0.195\n",
      "0.607\n",
      "0.424\n",
      "0.357\n",
      "0.134\n",
      "0.140\n",
      "0.443\n",
      "0.201\n",
      "0.174\n",
      "0.342\n",
      "0.423\n",
      "0.471\n",
      "0.630\n",
      "0.313\n",
      "0.156\n",
      "0.933\n",
      "0.845\n",
      "0.114\n",
      "0.259\n",
      "0.634\n",
      "0.527\n",
      "0.314\n",
      "0.304\n",
      "0.981\n",
      "0.438\n",
      "0.257\n",
      "0.542\n",
      "0.669\n",
      "0.150\n",
      "0.727\n",
      "0.648\n",
      "0.247\n",
      "0.613\n",
      "0.667\n",
      "0.166\n",
      "0.294\n",
      "0.097\n",
      "0.318\n",
      "0.610\n",
      "0.265\n",
      "0.343\n",
      "0.781\n",
      "0.369\n",
      "0.115\n",
      "0.627\n",
      "0.245\n",
      "0.417\n",
      "0.099\n",
      "0.099\n",
      "0.495\n",
      "0.100\n",
      "0.403\n",
      "0.246\n",
      "0.151\n",
      "0.505\n",
      "0.108\n",
      "0.474\n",
      "0.115\n",
      "0.099\n",
      "0.547\n",
      "0.680\n",
      "0.265\n",
      "0.372\n",
      "0.155\n",
      "0.124\n",
      "0.726\n",
      "0.852\n",
      "0.247\n",
      "0.156\n",
      "0.211\n",
      "0.286\n",
      "0.565\n",
      "0.176\n",
      "0.315\n",
      "0.073\n",
      "0.142\n",
      "0.068\n",
      "0.071\n",
      "0.082\n",
      "0.102\n",
      "0.211\n",
      "0.211\n",
      "0.227\n",
      "0.096\n",
      "0.119\n",
      "0.496\n",
      "0.100\n",
      "0.236\n",
      "0.086\n",
      "0.243\n",
      "0.098\n",
      "0.357\n",
      "0.078\n",
      "0.332\n",
      "0.116\n",
      "0.111\n",
      "0.511\n",
      "0.635\n",
      "0.532\n",
      "0.242\n",
      "0.343\n",
      "0.079\n",
      "0.162\n",
      "0.288\n",
      "0.531\n",
      "0.298\n",
      "0.724\n",
      "0.527\n",
      "0.333\n",
      "0.482\n",
      "0.294\n",
      "0.350\n",
      "0.413\n",
      "0.616\n",
      "0.486\n",
      "0.255\n",
      "0.119\n",
      "0.316\n",
      "0.230\n",
      "0.431\n",
      "0.596\n",
      "0.533\n",
      "0.326\n",
      "0.214\n",
      "0.405\n",
      "0.201\n",
      "0.171\n",
      "0.192\n",
      "0.514\n",
      "0.090\n",
      "0.944\n",
      "0.559\n",
      "0.424\n",
      "0.957\n",
      "0.826\n",
      "0.329\n",
      "0.111\n",
      "0.650\n",
      "0.534\n",
      "0.268\n",
      "0.307\n",
      "0.819\n",
      "0.960\n",
      "0.560\n",
      "0.452\n",
      "0.401\n",
      "0.853\n",
      "0.564\n",
      "0.963\n",
      "0.564\n",
      "0.782\n",
      "0.682\n",
      "0.342\n",
      "0.216\n",
      "0.333\n",
      "0.332\n",
      "0.347\n",
      "0.182\n",
      "0.171\n",
      "0.168\n",
      "0.293\n",
      "0.267\n",
      "0.438\n",
      "0.183\n",
      "0.228\n",
      "0.123\n",
      "0.319\n",
      "0.362\n",
      "0.290\n",
      "0.177\n",
      "0.589\n",
      "0.406\n",
      "0.339\n",
      "0.115\n",
      "0.121\n",
      "0.424\n",
      "0.182\n",
      "0.156\n",
      "0.324\n",
      "0.405\n",
      "0.452\n",
      "0.612\n",
      "0.295\n",
      "0.138\n",
      "0.914\n",
      "0.826\n",
      "0.095\n",
      "0.241\n",
      "0.615\n",
      "0.509\n",
      "0.295\n",
      "0.286\n",
      "0.963\n",
      "0.420\n",
      "0.239\n",
      "0.524\n",
      "0.651\n",
      "0.132\n",
      "0.709\n",
      "0.630\n",
      "0.229\n",
      "0.595\n",
      "0.649\n",
      "0.148\n",
      "0.276\n",
      "0.079\n",
      "0.300\n",
      "0.592\n",
      "0.246\n",
      "0.325\n",
      "0.762\n",
      "0.351\n",
      "0.096\n",
      "0.609\n",
      "0.227\n",
      "0.398\n",
      "0.080\n",
      "0.080\n",
      "0.477\n",
      "0.082\n",
      "0.384\n",
      "0.227\n",
      "0.133\n",
      "0.487\n",
      "0.089\n",
      "0.455\n",
      "0.096\n",
      "0.080\n",
      "0.529\n",
      "0.662\n",
      "0.247\n",
      "0.354\n",
      "0.137\n",
      "0.140\n",
      "0.743\n",
      "0.868\n",
      "0.264\n",
      "0.172\n",
      "0.227\n",
      "0.303\n",
      "0.582\n",
      "0.192\n",
      "0.331\n",
      "0.089\n",
      "0.158\n",
      "0.084\n",
      "0.087\n",
      "0.098\n",
      "0.118\n",
      "0.228\n",
      "0.228\n",
      "0.243\n",
      "0.113\n",
      "0.136\n",
      "0.513\n",
      "0.116\n",
      "0.252\n",
      "0.102\n",
      "0.259\n",
      "0.115\n",
      "0.374\n",
      "0.095\n",
      "0.348\n",
      "0.133\n",
      "0.127\n",
      "0.527\n",
      "0.652\n",
      "0.549\n",
      "0.258\n",
      "0.359\n",
      "0.096\n",
      "0.179\n",
      "0.304\n",
      "0.548\n",
      "0.315\n",
      "0.741\n",
      "0.543\n",
      "0.350\n",
      "0.498\n",
      "0.311\n",
      "0.366\n",
      "0.429\n",
      "0.633\n",
      "0.503\n",
      "0.272\n",
      "0.135\n",
      "0.332\n",
      "0.247\n",
      "0.447\n",
      "0.612\n",
      "0.549\n",
      "0.343\n",
      "0.230\n",
      "0.421\n",
      "0.217\n",
      "0.188\n",
      "0.209\n",
      "0.530\n",
      "0.106\n",
      "0.960\n",
      "0.575\n",
      "0.440\n",
      "0.973\n",
      "0.842\n",
      "0.346\n",
      "0.127\n",
      "0.667\n",
      "0.550\n",
      "0.284\n",
      "0.323\n",
      "0.836\n",
      "0.976\n",
      "0.576\n",
      "0.468\n",
      "0.417\n",
      "0.870\n",
      "0.581\n",
      "0.980\n",
      "0.581\n",
      "0.799\n",
      "0.698\n",
      "0.358\n",
      "0.233\n",
      "0.349\n",
      "0.348\n",
      "0.363\n",
      "0.199\n",
      "0.188\n",
      "0.185\n",
      "0.309\n",
      "0.283\n",
      "0.455\n",
      "0.199\n",
      "0.244\n",
      "0.139\n",
      "0.335\n",
      "0.378\n",
      "0.307\n",
      "0.193\n",
      "0.606\n",
      "0.422\n",
      "0.356\n",
      "0.132\n",
      "0.138\n",
      "0.441\n",
      "0.199\n",
      "0.172\n",
      "0.340\n",
      "0.421\n",
      "0.469\n",
      "0.628\n",
      "0.311\n",
      "0.154\n",
      "0.931\n",
      "0.843\n",
      "0.112\n",
      "0.257\n",
      "0.632\n",
      "0.525\n",
      "0.312\n",
      "0.302\n",
      "0.980\n",
      "0.436\n",
      "0.255\n",
      "0.540\n",
      "0.668\n",
      "0.148\n",
      "0.726\n",
      "0.646\n",
      "0.245\n",
      "0.612\n",
      "0.665\n",
      "0.164\n",
      "0.292\n",
      "0.096\n",
      "0.317\n",
      "0.609\n",
      "0.263\n",
      "0.341\n",
      "0.779\n",
      "0.367\n",
      "0.113\n",
      "0.625\n",
      "0.244\n",
      "0.415\n",
      "0.097\n",
      "0.097\n",
      "0.493\n",
      "0.098\n",
      "0.401\n",
      "0.244\n",
      "0.149\n",
      "0.503\n",
      "0.106\n",
      "0.472\n",
      "0.113\n",
      "0.097\n",
      "0.545\n",
      "0.678\n",
      "0.263\n",
      "0.370\n",
      "0.153\n",
      "0.133\n",
      "0.736\n",
      "0.862\n",
      "0.257\n",
      "0.165\n",
      "0.221\n",
      "0.296\n",
      "0.575\n",
      "0.186\n",
      "0.325\n",
      "0.083\n",
      "0.151\n",
      "0.078\n",
      "0.081\n",
      "0.092\n",
      "0.112\n",
      "0.221\n",
      "0.221\n",
      "0.236\n",
      "0.106\n",
      "0.129\n",
      "0.506\n",
      "0.110\n",
      "0.246\n",
      "0.095\n",
      "0.253\n",
      "0.108\n",
      "0.367\n",
      "0.088\n",
      "0.341\n",
      "0.126\n",
      "0.121\n",
      "0.521\n",
      "0.645\n",
      "0.542\n",
      "0.252\n",
      "0.352\n",
      "0.089\n",
      "0.172\n",
      "0.297\n",
      "0.541\n",
      "0.308\n",
      "0.734\n",
      "0.536\n",
      "0.343\n",
      "0.492\n",
      "0.304\n",
      "0.360\n",
      "0.422\n",
      "0.626\n",
      "0.496\n",
      "0.265\n",
      "0.129\n",
      "0.326\n",
      "0.240\n",
      "0.441\n",
      "0.606\n",
      "0.542\n",
      "0.336\n",
      "0.224\n",
      "0.415\n",
      "0.211\n",
      "0.181\n",
      "0.202\n",
      "0.524\n",
      "0.100\n",
      "0.954\n",
      "0.569\n",
      "0.434\n",
      "0.966\n",
      "0.836\n",
      "0.339\n",
      "0.121\n",
      "0.660\n",
      "0.544\n",
      "0.277\n",
      "0.317\n",
      "0.829\n",
      "0.970\n",
      "0.570\n",
      "0.462\n",
      "0.411\n",
      "0.863\n",
      "0.574\n",
      "0.973\n",
      "0.574\n",
      "0.792\n",
      "0.692\n",
      "0.352\n",
      "0.226\n",
      "0.343\n",
      "0.342\n",
      "0.357\n",
      "0.192\n",
      "0.181\n",
      "0.178\n",
      "0.303\n",
      "0.277\n",
      "0.448\n",
      "0.193\n",
      "0.238\n",
      "0.133\n",
      "0.329\n",
      "0.372\n",
      "0.300\n",
      "0.187\n",
      "0.599\n",
      "0.416\n",
      "0.349\n",
      "0.125\n",
      "0.131\n",
      "0.434\n",
      "0.192\n",
      "0.166\n",
      "0.334\n",
      "0.415\n",
      "0.462\n",
      "0.622\n",
      "0.305\n",
      "0.148\n",
      "0.924\n",
      "0.836\n",
      "0.105\n",
      "0.250\n",
      "0.625\n",
      "0.519\n",
      "0.305\n",
      "0.296\n",
      "0.973\n",
      "0.430\n",
      "0.249\n",
      "0.533\n",
      "0.661\n",
      "0.142\n",
      "0.719\n",
      "0.640\n",
      "0.239\n",
      "0.605\n",
      "0.659\n",
      "0.158\n",
      "0.285\n",
      "0.089\n",
      "0.310\n",
      "0.602\n",
      "0.256\n",
      "0.335\n",
      "0.772\n",
      "0.361\n",
      "0.106\n",
      "0.619\n",
      "0.237\n",
      "0.408\n",
      "0.090\n",
      "0.090\n",
      "0.487\n",
      "0.092\n",
      "0.394\n",
      "0.237\n",
      "0.143\n",
      "0.497\n",
      "0.099\n",
      "0.465\n",
      "0.106\n",
      "0.090\n",
      "0.539\n",
      "0.672\n",
      "0.257\n",
      "0.364\n",
      "0.147\n",
      "0.133\n",
      "0.736\n",
      "0.861\n",
      "0.257\n",
      "0.165\n",
      "0.220\n",
      "0.296\n",
      "0.575\n",
      "0.185\n",
      "0.324\n",
      "0.082\n",
      "0.151\n",
      "0.077\n",
      "0.080\n",
      "0.091\n",
      "0.111\n",
      "0.221\n",
      "0.221\n",
      "0.236\n",
      "0.106\n",
      "0.129\n",
      "0.506\n",
      "0.109\n",
      "0.245\n",
      "0.095\n",
      "0.252\n",
      "0.108\n",
      "0.367\n",
      "0.088\n",
      "0.341\n",
      "0.126\n",
      "0.120\n",
      "0.520\n",
      "0.645\n",
      "0.542\n",
      "0.251\n",
      "0.352\n",
      "0.089\n",
      "0.172\n",
      "0.297\n",
      "0.541\n",
      "0.308\n",
      "0.734\n",
      "0.536\n",
      "0.343\n",
      "0.491\n",
      "0.304\n",
      "0.359\n",
      "0.422\n",
      "0.626\n",
      "0.496\n",
      "0.265\n",
      "0.128\n",
      "0.325\n",
      "0.240\n",
      "0.440\n",
      "0.605\n",
      "0.542\n",
      "0.336\n",
      "0.223\n",
      "0.414\n",
      "0.210\n",
      "0.181\n",
      "0.202\n",
      "0.523\n",
      "0.099\n",
      "0.953\n",
      "0.568\n",
      "0.433\n",
      "0.966\n",
      "0.835\n",
      "0.339\n",
      "0.120\n",
      "0.660\n",
      "0.543\n",
      "0.277\n",
      "0.316\n",
      "0.829\n",
      "0.969\n",
      "0.569\n",
      "0.461\n",
      "0.410\n",
      "0.863\n",
      "0.573\n",
      "0.973\n",
      "0.574\n",
      "0.792\n",
      "0.691\n",
      "0.351\n",
      "0.226\n",
      "0.342\n",
      "0.341\n",
      "0.356\n",
      "0.192\n",
      "0.181\n",
      "0.178\n",
      "0.302\n",
      "0.276\n",
      "0.448\n",
      "0.192\n",
      "0.237\n",
      "0.132\n",
      "0.328\n",
      "0.371\n",
      "0.300\n",
      "0.186\n",
      "0.599\n",
      "0.415\n",
      "0.348\n",
      "0.125\n",
      "0.131\n",
      "0.434\n",
      "0.192\n",
      "0.165\n",
      "0.333\n",
      "0.414\n",
      "0.462\n",
      "0.621\n",
      "0.304\n",
      "0.147\n",
      "0.924\n",
      "0.836\n",
      "0.105\n",
      "0.250\n",
      "0.625\n",
      "0.518\n",
      "0.305\n",
      "0.295\n",
      "0.973\n",
      "0.429\n",
      "0.248\n",
      "0.533\n",
      "0.661\n",
      "0.141\n",
      "0.719\n",
      "0.639\n",
      "0.238\n",
      "0.605\n",
      "0.658\n",
      "0.157\n",
      "0.285\n",
      "0.088\n",
      "0.310\n",
      "0.602\n",
      "0.256\n",
      "0.334\n",
      "0.772\n",
      "0.360\n",
      "0.106\n",
      "0.618\n",
      "0.237\n",
      "0.408\n",
      "0.090\n",
      "0.090\n",
      "0.486\n",
      "0.091\n",
      "0.394\n",
      "0.237\n",
      "0.142\n",
      "0.496\n",
      "0.099\n",
      "0.465\n",
      "0.106\n",
      "0.090\n",
      "0.538\n",
      "0.671\n",
      "0.256\n",
      "0.363\n",
      "0.146\n",
      "0.131\n",
      "0.733\n",
      "0.859\n",
      "0.254\n",
      "0.163\n",
      "0.218\n",
      "0.293\n",
      "0.572\n",
      "0.183\n",
      "0.322\n",
      "0.080\n",
      "0.149\n",
      "0.075\n",
      "0.078\n",
      "0.089\n",
      "0.109\n",
      "0.218\n",
      "0.218\n",
      "0.233\n",
      "0.103\n",
      "0.126\n",
      "0.503\n",
      "0.107\n",
      "0.243\n",
      "0.093\n",
      "0.250\n",
      "0.105\n",
      "0.364\n",
      "0.085\n",
      "0.338\n",
      "0.123\n",
      "0.118\n",
      "0.518\n",
      "0.642\n",
      "0.539\n",
      "0.249\n",
      "0.350\n",
      "0.086\n",
      "0.169\n",
      "0.295\n",
      "0.538\n",
      "0.305\n",
      "0.731\n",
      "0.534\n",
      "0.340\n",
      "0.489\n",
      "0.301\n",
      "0.357\n",
      "0.420\n",
      "0.623\n",
      "0.493\n",
      "0.262\n",
      "0.126\n",
      "0.323\n",
      "0.237\n",
      "0.438\n",
      "0.603\n",
      "0.540\n",
      "0.333\n",
      "0.221\n",
      "0.412\n",
      "0.208\n",
      "0.178\n",
      "0.199\n",
      "0.521\n",
      "0.097\n",
      "0.951\n",
      "0.566\n",
      "0.431\n",
      "0.964\n",
      "0.833\n",
      "0.336\n",
      "0.118\n",
      "0.657\n",
      "0.541\n",
      "0.274\n",
      "0.314\n",
      "0.826\n",
      "0.967\n",
      "0.567\n",
      "0.459\n",
      "0.408\n",
      "0.860\n",
      "0.571\n",
      "0.970\n",
      "0.571\n",
      "0.789\n",
      "0.689\n",
      "0.349\n",
      "0.223\n",
      "0.340\n",
      "0.339\n",
      "0.354\n",
      "0.189\n",
      "0.178\n",
      "0.175\n",
      "0.300\n",
      "0.274\n",
      "0.445\n",
      "0.190\n",
      "0.235\n",
      "0.130\n",
      "0.326\n",
      "0.369\n",
      "0.297\n",
      "0.184\n",
      "0.596\n",
      "0.413\n",
      "0.346\n",
      "0.122\n",
      "0.128\n",
      "0.431\n",
      "0.189\n",
      "0.163\n",
      "0.331\n",
      "0.412\n",
      "0.459\n",
      "0.619\n",
      "0.302\n",
      "0.145\n",
      "0.921\n",
      "0.833\n",
      "0.102\n",
      "0.248\n",
      "0.622\n",
      "0.516\n",
      "0.302\n",
      "0.293\n",
      "0.970\n",
      "0.427\n",
      "0.246\n",
      "0.531\n",
      "0.658\n",
      "0.139\n",
      "0.716\n",
      "0.637\n",
      "0.236\n",
      "0.602\n",
      "0.656\n",
      "0.155\n",
      "0.283\n",
      "0.086\n",
      "0.307\n",
      "0.599\n",
      "0.253\n",
      "0.332\n",
      "0.769\n",
      "0.358\n",
      "0.103\n",
      "0.616\n",
      "0.234\n",
      "0.405\n",
      "0.087\n",
      "0.087\n",
      "0.484\n",
      "0.089\n",
      "0.391\n",
      "0.234\n",
      "0.140\n",
      "0.494\n",
      "0.096\n",
      "0.462\n",
      "0.103\n",
      "0.087\n",
      "0.536\n",
      "0.669\n",
      "0.254\n",
      "0.361\n",
      "0.144\n",
      "0.124\n",
      "0.727\n",
      "0.853\n",
      "0.248\n",
      "0.156\n",
      "0.212\n",
      "0.287\n",
      "0.566\n",
      "0.177\n",
      "0.316\n",
      "0.074\n",
      "0.142\n",
      "0.069\n",
      "0.072\n",
      "0.083\n",
      "0.103\n",
      "0.212\n",
      "0.212\n",
      "0.227\n",
      "0.097\n",
      "0.120\n",
      "0.497\n",
      "0.101\n",
      "0.237\n",
      "0.086\n",
      "0.244\n",
      "0.099\n",
      "0.358\n",
      "0.079\n",
      "0.332\n",
      "0.117\n",
      "0.112\n",
      "0.512\n",
      "0.636\n",
      "0.533\n",
      "0.243\n",
      "0.343\n",
      "0.080\n",
      "0.163\n",
      "0.288\n",
      "0.532\n",
      "0.299\n",
      "0.725\n",
      "0.527\n",
      "0.334\n",
      "0.483\n",
      "0.295\n",
      "0.351\n",
      "0.413\n",
      "0.617\n",
      "0.487\n",
      "0.256\n",
      "0.120\n",
      "0.317\n",
      "0.231\n",
      "0.432\n",
      "0.597\n",
      "0.533\n",
      "0.327\n",
      "0.215\n",
      "0.406\n",
      "0.202\n",
      "0.172\n",
      "0.193\n",
      "0.515\n",
      "0.091\n",
      "0.945\n",
      "0.560\n",
      "0.425\n",
      "0.957\n",
      "0.827\n",
      "0.330\n",
      "0.112\n",
      "0.651\n",
      "0.535\n",
      "0.268\n",
      "0.308\n",
      "0.820\n",
      "0.961\n",
      "0.561\n",
      "0.453\n",
      "0.402\n",
      "0.854\n",
      "0.565\n",
      "0.964\n",
      "0.565\n",
      "0.783\n",
      "0.683\n",
      "0.343\n",
      "0.217\n",
      "0.334\n",
      "0.333\n",
      "0.348\n",
      "0.183\n",
      "0.172\n",
      "0.169\n",
      "0.294\n",
      "0.268\n",
      "0.439\n",
      "0.184\n",
      "0.229\n",
      "0.124\n",
      "0.320\n",
      "0.363\n",
      "0.291\n",
      "0.178\n",
      "0.590\n",
      "0.407\n",
      "0.340\n",
      "0.116\n",
      "0.122\n",
      "0.425\n",
      "0.183\n",
      "0.157\n",
      "0.325\n",
      "0.406\n",
      "0.453\n",
      "0.613\n",
      "0.296\n",
      "0.139\n",
      "0.915\n",
      "0.827\n",
      "0.096\n",
      "0.241\n",
      "0.616\n",
      "0.510\n",
      "0.296\n",
      "0.287\n",
      "0.964\n",
      "0.421\n",
      "0.240\n",
      "0.524\n",
      "0.652\n",
      "0.133\n",
      "0.710\n",
      "0.631\n",
      "0.230\n",
      "0.596\n",
      "0.650\n",
      "0.149\n",
      "0.276\n",
      "0.080\n",
      "0.301\n",
      "0.593\n",
      "0.247\n",
      "0.326\n",
      "0.763\n",
      "0.352\n",
      "0.097\n",
      "0.610\n",
      "0.228\n",
      "0.399\n",
      "0.081\n",
      "0.081\n",
      "0.478\n",
      "0.083\n",
      "0.385\n",
      "0.228\n",
      "0.134\n",
      "0.488\n",
      "0.090\n",
      "0.456\n",
      "0.097\n",
      "0.081\n",
      "0.530\n",
      "0.663\n",
      "0.248\n",
      "0.355\n",
      "0.138\n",
      "0.137\n",
      "0.740\n",
      "0.865\n",
      "0.261\n",
      "0.169\n",
      "0.224\n",
      "0.300\n",
      "0.579\n",
      "0.189\n",
      "0.328\n",
      "0.086\n",
      "0.155\n",
      "0.081\n",
      "0.084\n",
      "0.095\n",
      "0.115\n",
      "0.225\n",
      "0.225\n",
      "0.240\n",
      "0.110\n",
      "0.133\n",
      "0.510\n",
      "0.113\n",
      "0.249\n",
      "0.099\n",
      "0.256\n",
      "0.112\n",
      "0.371\n",
      "0.092\n",
      "0.345\n",
      "0.130\n",
      "0.124\n",
      "0.524\n",
      "0.649\n",
      "0.546\n",
      "0.255\n",
      "0.356\n",
      "0.093\n",
      "0.176\n",
      "0.301\n",
      "0.545\n",
      "0.311\n",
      "0.738\n",
      "0.540\n",
      "0.347\n",
      "0.495\n",
      "0.308\n",
      "0.363\n",
      "0.426\n",
      "0.630\n",
      "0.500\n",
      "0.269\n",
      "0.132\n",
      "0.329\n",
      "0.244\n",
      "0.444\n",
      "0.609\n",
      "0.546\n",
      "0.340\n",
      "0.227\n",
      "0.418\n",
      "0.214\n",
      "0.185\n",
      "0.206\n",
      "0.527\n",
      "0.103\n",
      "0.957\n",
      "0.572\n",
      "0.437\n",
      "0.970\n",
      "0.839\n",
      "0.343\n",
      "0.124\n",
      "0.664\n",
      "0.547\n",
      "0.281\n",
      "0.320\n",
      "0.833\n",
      "0.973\n",
      "0.573\n",
      "0.465\n",
      "0.414\n",
      "0.867\n",
      "0.577\n",
      "0.977\n",
      "0.578\n",
      "0.796\n",
      "0.695\n",
      "0.355\n",
      "0.229\n",
      "0.346\n",
      "0.345\n",
      "0.360\n",
      "0.196\n",
      "0.185\n",
      "0.182\n",
      "0.306\n",
      "0.280\n",
      "0.452\n",
      "0.196\n",
      "0.241\n",
      "0.136\n",
      "0.332\n",
      "0.375\n",
      "0.304\n",
      "0.190\n",
      "0.603\n",
      "0.419\n",
      "0.352\n",
      "0.129\n",
      "0.135\n",
      "0.438\n",
      "0.196\n",
      "0.169\n",
      "0.337\n",
      "0.418\n",
      "0.466\n",
      "0.625\n",
      "0.308\n",
      "0.151\n",
      "0.928\n",
      "0.840\n",
      "0.109\n",
      "0.254\n",
      "0.629\n",
      "0.522\n",
      "0.309\n",
      "0.299\n",
      "0.977\n",
      "0.433\n",
      "0.252\n",
      "0.537\n",
      "0.665\n",
      "0.145\n",
      "0.723\n",
      "0.643\n",
      "0.242\n",
      "0.609\n",
      "0.662\n",
      "0.161\n",
      "0.289\n",
      "0.092\n",
      "0.314\n",
      "0.606\n",
      "0.260\n",
      "0.338\n",
      "0.776\n",
      "0.364\n",
      "0.110\n",
      "0.622\n",
      "0.241\n",
      "0.412\n",
      "0.094\n",
      "0.094\n",
      "0.490\n",
      "0.095\n",
      "0.398\n",
      "0.241\n",
      "0.146\n",
      "0.500\n",
      "0.103\n",
      "0.469\n",
      "0.110\n",
      "0.094\n",
      "0.542\n",
      "0.675\n",
      "0.260\n",
      "0.367\n",
      "0.150\n",
      "0.113\n",
      "0.716\n",
      "0.841\n",
      "0.237\n",
      "0.145\n",
      "0.200\n",
      "0.276\n",
      "0.555\n",
      "0.165\n",
      "0.304\n",
      "0.062\n",
      "0.131\n",
      "0.057\n",
      "0.060\n",
      "0.071\n",
      "0.091\n",
      "0.201\n",
      "0.201\n",
      "0.216\n",
      "0.086\n",
      "0.109\n",
      "0.486\n",
      "0.089\n",
      "0.225\n",
      "0.075\n",
      "0.232\n",
      "0.088\n",
      "0.347\n",
      "0.068\n",
      "0.321\n",
      "0.106\n",
      "0.100\n",
      "0.500\n",
      "0.625\n",
      "0.522\n",
      "0.231\n",
      "0.332\n",
      "0.069\n",
      "0.152\n",
      "0.277\n",
      "0.521\n",
      "0.288\n",
      "0.714\n",
      "0.516\n",
      "0.323\n",
      "0.471\n",
      "0.284\n",
      "0.339\n",
      "0.402\n",
      "0.606\n",
      "0.476\n",
      "0.245\n",
      "0.108\n",
      "0.305\n",
      "0.220\n",
      "0.420\n",
      "0.585\n",
      "0.522\n",
      "0.316\n",
      "0.203\n",
      "0.394\n",
      "0.190\n",
      "0.161\n",
      "0.182\n",
      "0.503\n",
      "0.079\n",
      "0.934\n",
      "0.548\n",
      "0.413\n",
      "0.946\n",
      "0.815\n",
      "0.319\n",
      "0.100\n",
      "0.640\n",
      "0.523\n",
      "0.257\n",
      "0.296\n",
      "0.809\n",
      "0.949\n",
      "0.549\n",
      "0.441\n",
      "0.390\n",
      "0.843\n",
      "0.554\n",
      "0.953\n",
      "0.554\n",
      "0.772\n",
      "0.671\n",
      "0.331\n",
      "0.206\n",
      "0.322\n",
      "0.321\n",
      "0.336\n",
      "0.172\n",
      "0.161\n",
      "0.158\n",
      "0.282\n",
      "0.256\n",
      "0.428\n",
      "0.172\n",
      "0.217\n",
      "0.112\n",
      "0.308\n",
      "0.351\n",
      "0.280\n",
      "0.166\n",
      "0.579\n",
      "0.395\n",
      "0.329\n",
      "0.105\n",
      "0.111\n",
      "0.414\n",
      "0.172\n",
      "0.145\n",
      "0.313\n",
      "0.394\n",
      "0.442\n",
      "0.601\n",
      "0.284\n",
      "0.127\n",
      "0.904\n",
      "0.816\n",
      "0.085\n",
      "0.230\n",
      "0.605\n",
      "0.498\n",
      "0.285\n",
      "0.275\n",
      "0.953\n",
      "0.409\n",
      "0.228\n",
      "0.513\n",
      "0.641\n",
      "0.121\n",
      "0.699\n",
      "0.619\n",
      "0.218\n",
      "0.585\n",
      "0.638\n",
      "0.137\n",
      "0.265\n",
      "0.069\n",
      "0.290\n",
      "0.582\n",
      "0.236\n",
      "0.314\n",
      "0.752\n",
      "0.340\n",
      "0.086\n",
      "0.598\n",
      "0.217\n",
      "0.388\n",
      "0.070\n",
      "0.070\n",
      "0.466\n",
      "0.071\n",
      "0.374\n",
      "0.217\n",
      "0.122\n",
      "0.476\n",
      "0.079\n",
      "0.445\n",
      "0.086\n",
      "0.070\n",
      "0.518\n",
      "0.651\n",
      "0.236\n",
      "0.343\n",
      "0.126\n",
      "0.125\n",
      "0.728\n",
      "0.853\n",
      "0.249\n",
      "0.157\n",
      "0.212\n",
      "0.287\n",
      "0.566\n",
      "0.177\n",
      "0.316\n",
      "0.074\n",
      "0.143\n",
      "0.069\n",
      "0.072\n",
      "0.083\n",
      "0.103\n",
      "0.212\n",
      "0.212\n",
      "0.228\n",
      "0.097\n",
      "0.120\n",
      "0.497\n",
      "0.101\n",
      "0.237\n",
      "0.087\n",
      "0.244\n",
      "0.099\n",
      "0.358\n",
      "0.079\n",
      "0.333\n",
      "0.117\n",
      "0.112\n",
      "0.512\n",
      "0.636\n",
      "0.533\n",
      "0.243\n",
      "0.344\n",
      "0.080\n",
      "0.164\n",
      "0.289\n",
      "0.532\n",
      "0.299\n",
      "0.725\n",
      "0.528\n",
      "0.334\n",
      "0.483\n",
      "0.295\n",
      "0.351\n",
      "0.414\n",
      "0.617\n",
      "0.487\n",
      "0.256\n",
      "0.120\n",
      "0.317\n",
      "0.231\n",
      "0.432\n",
      "0.597\n",
      "0.534\n",
      "0.327\n",
      "0.215\n",
      "0.406\n",
      "0.202\n",
      "0.172\n",
      "0.193\n",
      "0.515\n",
      "0.091\n",
      "0.945\n",
      "0.560\n",
      "0.425\n",
      "0.958\n",
      "0.827\n",
      "0.330\n",
      "0.112\n",
      "0.651\n",
      "0.535\n",
      "0.269\n",
      "0.308\n",
      "0.820\n",
      "0.961\n",
      "0.561\n",
      "0.453\n",
      "0.402\n",
      "0.854\n",
      "0.565\n",
      "0.964\n",
      "0.565\n",
      "0.783\n",
      "0.683\n",
      "0.343\n",
      "0.217\n",
      "0.334\n",
      "0.333\n",
      "0.348\n",
      "0.183\n",
      "0.172\n",
      "0.170\n",
      "0.294\n",
      "0.268\n",
      "0.439\n",
      "0.184\n",
      "0.229\n",
      "0.124\n",
      "0.320\n",
      "0.363\n",
      "0.291\n",
      "0.178\n",
      "0.590\n",
      "0.407\n",
      "0.340\n",
      "0.116\n",
      "0.123\n",
      "0.425\n",
      "0.183\n",
      "0.157\n",
      "0.325\n",
      "0.406\n",
      "0.453\n",
      "0.613\n",
      "0.296\n",
      "0.139\n",
      "0.915\n",
      "0.827\n",
      "0.096\n",
      "0.242\n",
      "0.616\n",
      "0.510\n",
      "0.296\n",
      "0.287\n",
      "0.964\n",
      "0.421\n",
      "0.240\n",
      "0.525\n",
      "0.652\n",
      "0.133\n",
      "0.710\n",
      "0.631\n",
      "0.230\n",
      "0.596\n",
      "0.650\n",
      "0.149\n",
      "0.277\n",
      "0.080\n",
      "0.301\n",
      "0.593\n",
      "0.247\n",
      "0.326\n",
      "0.763\n",
      "0.352\n",
      "0.097\n",
      "0.610\n",
      "0.228\n",
      "0.399\n",
      "0.081\n",
      "0.081\n",
      "0.478\n",
      "0.083\n",
      "0.386\n",
      "0.228\n",
      "0.134\n",
      "0.488\n",
      "0.091\n",
      "0.456\n",
      "0.097\n",
      "0.081\n",
      "0.530\n",
      "0.663\n",
      "0.248\n",
      "0.355\n",
      "0.138\n",
      "0.084\n",
      "0.687\n",
      "0.812\n",
      "0.208\n",
      "0.116\n",
      "0.171\n",
      "0.246\n",
      "0.525\n",
      "0.136\n",
      "0.275\n",
      "0.033\n",
      "0.102\n",
      "0.028\n",
      "0.031\n",
      "0.042\n",
      "0.062\n",
      "0.171\n",
      "0.171\n",
      "0.187\n",
      "0.056\n",
      "0.079\n",
      "0.456\n",
      "0.060\n",
      "0.196\n",
      "0.046\n",
      "0.203\n",
      "0.058\n",
      "0.317\n",
      "0.038\n",
      "0.292\n",
      "0.076\n",
      "0.071\n",
      "0.471\n",
      "0.595\n",
      "0.492\n",
      "0.202\n",
      "0.303\n",
      "0.039\n",
      "0.123\n",
      "0.248\n",
      "0.491\n",
      "0.258\n",
      "0.684\n",
      "0.487\n",
      "0.293\n",
      "0.442\n",
      "0.254\n",
      "0.310\n",
      "0.373\n",
      "0.576\n",
      "0.446\n",
      "0.215\n",
      "0.079\n",
      "0.276\n",
      "0.190\n",
      "0.391\n",
      "0.556\n",
      "0.493\n",
      "0.286\n",
      "0.174\n",
      "0.365\n",
      "0.161\n",
      "0.131\n",
      "0.152\n",
      "0.474\n",
      "0.050\n",
      "0.904\n",
      "0.519\n",
      "0.384\n",
      "0.917\n",
      "0.786\n",
      "0.289\n",
      "0.071\n",
      "0.610\n",
      "0.494\n",
      "0.228\n",
      "0.267\n",
      "0.779\n",
      "0.920\n",
      "0.520\n",
      "0.412\n",
      "0.361\n",
      "0.813\n",
      "0.524\n",
      "0.924\n",
      "0.524\n",
      "0.743\n",
      "0.642\n",
      "0.302\n",
      "0.176\n",
      "0.293\n",
      "0.292\n",
      "0.307\n",
      "0.142\n",
      "0.131\n",
      "0.129\n",
      "0.253\n",
      "0.227\n",
      "0.398\n",
      "0.143\n",
      "0.188\n",
      "0.083\n",
      "0.279\n",
      "0.322\n",
      "0.250\n",
      "0.137\n",
      "0.549\n",
      "0.366\n",
      "0.299\n",
      "0.075\n",
      "0.082\n",
      "0.384\n",
      "0.142\n",
      "0.116\n",
      "0.284\n",
      "0.365\n",
      "0.412\n",
      "0.572\n",
      "0.255\n",
      "0.098\n",
      "0.874\n",
      "0.786\n",
      "0.055\n",
      "0.201\n",
      "0.575\n",
      "0.469\n",
      "0.255\n",
      "0.246\n",
      "0.923\n",
      "0.380\n",
      "0.199\n",
      "0.484\n",
      "0.611\n",
      "0.092\n",
      "0.669\n",
      "0.590\n",
      "0.189\n",
      "0.555\n",
      "0.609\n",
      "0.108\n",
      "0.236\n",
      "0.039\n",
      "0.260\n",
      "0.552\n",
      "0.206\n",
      "0.285\n",
      "0.722\n",
      "0.311\n",
      "0.056\n",
      "0.569\n",
      "0.187\n",
      "0.358\n",
      "0.040\n",
      "0.040\n",
      "0.437\n",
      "0.042\n",
      "0.345\n",
      "0.187\n",
      "0.093\n",
      "0.447\n",
      "0.050\n",
      "0.415\n",
      "0.056\n",
      "0.040\n",
      "0.489\n",
      "0.622\n",
      "0.207\n",
      "0.314\n",
      "0.097\n",
      "0.127\n",
      "0.729\n",
      "0.855\n",
      "0.250\n",
      "0.159\n",
      "0.214\n",
      "0.289\n",
      "0.568\n",
      "0.179\n",
      "0.318\n",
      "0.076\n",
      "0.145\n",
      "0.071\n",
      "0.074\n",
      "0.085\n",
      "0.105\n",
      "0.214\n",
      "0.214\n",
      "0.229\n",
      "0.099\n",
      "0.122\n",
      "0.499\n",
      "0.103\n",
      "0.239\n",
      "0.089\n",
      "0.246\n",
      "0.101\n",
      "0.360\n",
      "0.081\n",
      "0.335\n",
      "0.119\n",
      "0.114\n",
      "0.514\n",
      "0.638\n",
      "0.535\n",
      "0.245\n",
      "0.346\n",
      "0.082\n",
      "0.165\n",
      "0.291\n",
      "0.534\n",
      "0.301\n",
      "0.727\n",
      "0.530\n",
      "0.336\n",
      "0.485\n",
      "0.297\n",
      "0.353\n",
      "0.416\n",
      "0.619\n",
      "0.489\n",
      "0.258\n",
      "0.122\n",
      "0.319\n",
      "0.233\n",
      "0.434\n",
      "0.599\n",
      "0.536\n",
      "0.329\n",
      "0.217\n",
      "0.408\n",
      "0.204\n",
      "0.174\n",
      "0.195\n",
      "0.517\n",
      "0.093\n",
      "0.947\n",
      "0.562\n",
      "0.427\n",
      "0.960\n",
      "0.829\n",
      "0.332\n",
      "0.114\n",
      "0.653\n",
      "0.537\n",
      "0.270\n",
      "0.310\n",
      "0.822\n",
      "0.963\n",
      "0.563\n",
      "0.455\n",
      "0.404\n",
      "0.856\n",
      "0.567\n",
      "0.966\n",
      "0.567\n",
      "0.785\n",
      "0.685\n",
      "0.345\n",
      "0.219\n",
      "0.336\n",
      "0.335\n",
      "0.350\n",
      "0.185\n",
      "0.174\n",
      "0.171\n",
      "0.296\n",
      "0.270\n",
      "0.441\n",
      "0.186\n",
      "0.231\n",
      "0.126\n",
      "0.322\n",
      "0.365\n",
      "0.293\n",
      "0.180\n",
      "0.592\n",
      "0.409\n",
      "0.342\n",
      "0.118\n",
      "0.124\n",
      "0.427\n",
      "0.185\n",
      "0.159\n",
      "0.327\n",
      "0.408\n",
      "0.455\n",
      "0.615\n",
      "0.298\n",
      "0.141\n",
      "0.917\n",
      "0.829\n",
      "0.098\n",
      "0.244\n",
      "0.618\n",
      "0.512\n",
      "0.298\n",
      "0.289\n",
      "0.966\n",
      "0.423\n",
      "0.242\n",
      "0.527\n",
      "0.654\n",
      "0.135\n",
      "0.712\n",
      "0.633\n",
      "0.232\n",
      "0.598\n",
      "0.652\n",
      "0.151\n",
      "0.279\n",
      "0.082\n",
      "0.303\n",
      "0.595\n",
      "0.249\n",
      "0.328\n",
      "0.765\n",
      "0.354\n",
      "0.099\n",
      "0.612\n",
      "0.230\n",
      "0.401\n",
      "0.083\n",
      "0.083\n",
      "0.480\n",
      "0.085\n",
      "0.387\n",
      "0.230\n",
      "0.136\n",
      "0.490\n",
      "0.092\n",
      "0.458\n",
      "0.099\n",
      "0.083\n",
      "0.532\n",
      "0.665\n",
      "0.250\n",
      "0.357\n",
      "0.140\n",
      "0.120\n",
      "0.723\n",
      "0.849\n",
      "0.244\n",
      "0.152\n",
      "0.208\n",
      "0.283\n",
      "0.562\n",
      "0.173\n",
      "0.312\n",
      "0.070\n",
      "0.138\n",
      "0.065\n",
      "0.068\n",
      "0.079\n",
      "0.099\n",
      "0.208\n",
      "0.208\n",
      "0.223\n",
      "0.093\n",
      "0.116\n",
      "0.493\n",
      "0.097\n",
      "0.233\n",
      "0.082\n",
      "0.240\n",
      "0.095\n",
      "0.354\n",
      "0.075\n",
      "0.328\n",
      "0.113\n",
      "0.108\n",
      "0.508\n",
      "0.632\n",
      "0.529\n",
      "0.239\n",
      "0.339\n",
      "0.076\n",
      "0.159\n",
      "0.284\n",
      "0.528\n",
      "0.295\n",
      "0.721\n",
      "0.524\n",
      "0.330\n",
      "0.479\n",
      "0.291\n",
      "0.347\n",
      "0.410\n",
      "0.613\n",
      "0.483\n",
      "0.252\n",
      "0.116\n",
      "0.313\n",
      "0.227\n",
      "0.428\n",
      "0.593\n",
      "0.529\n",
      "0.323\n",
      "0.211\n",
      "0.402\n",
      "0.198\n",
      "0.168\n",
      "0.189\n",
      "0.511\n",
      "0.087\n",
      "0.941\n",
      "0.556\n",
      "0.421\n",
      "0.953\n",
      "0.823\n",
      "0.326\n",
      "0.108\n",
      "0.647\n",
      "0.531\n",
      "0.264\n",
      "0.304\n",
      "0.816\n",
      "0.957\n",
      "0.557\n",
      "0.449\n",
      "0.398\n",
      "0.850\n",
      "0.561\n",
      "0.960\n",
      "0.561\n",
      "0.779\n",
      "0.679\n",
      "0.339\n",
      "0.213\n",
      "0.330\n",
      "0.329\n",
      "0.344\n",
      "0.179\n",
      "0.168\n",
      "0.165\n",
      "0.290\n",
      "0.264\n",
      "0.435\n",
      "0.180\n",
      "0.225\n",
      "0.120\n",
      "0.316\n",
      "0.359\n",
      "0.287\n",
      "0.174\n",
      "0.586\n",
      "0.403\n",
      "0.336\n",
      "0.112\n",
      "0.118\n",
      "0.421\n",
      "0.179\n",
      "0.153\n",
      "0.321\n",
      "0.402\n",
      "0.449\n",
      "0.609\n",
      "0.292\n",
      "0.135\n",
      "0.911\n",
      "0.823\n",
      "0.092\n",
      "0.237\n",
      "0.612\n",
      "0.506\n",
      "0.292\n",
      "0.283\n",
      "0.960\n",
      "0.417\n",
      "0.236\n",
      "0.521\n",
      "0.648\n",
      "0.129\n",
      "0.706\n",
      "0.627\n",
      "0.226\n",
      "0.592\n",
      "0.646\n",
      "0.145\n",
      "0.272\n",
      "0.076\n",
      "0.297\n",
      "0.589\n",
      "0.243\n",
      "0.322\n",
      "0.759\n",
      "0.348\n",
      "0.093\n",
      "0.606\n",
      "0.224\n",
      "0.395\n",
      "0.077\n",
      "0.077\n",
      "0.474\n",
      "0.079\n",
      "0.381\n",
      "0.224\n",
      "0.130\n",
      "0.484\n",
      "0.086\n",
      "0.452\n",
      "0.093\n",
      "0.077\n",
      "0.526\n",
      "0.659\n",
      "0.244\n",
      "0.351\n",
      "0.134\n",
      "0.141\n",
      "0.744\n",
      "0.869\n",
      "0.265\n",
      "0.173\n",
      "0.229\n",
      "0.304\n",
      "0.583\n",
      "0.194\n",
      "0.332\n",
      "0.090\n",
      "0.159\n",
      "0.086\n",
      "0.089\n",
      "0.099\n",
      "0.119\n",
      "0.229\n",
      "0.229\n",
      "0.244\n",
      "0.114\n",
      "0.137\n",
      "0.514\n",
      "0.117\n",
      "0.253\n",
      "0.103\n",
      "0.261\n",
      "0.116\n",
      "0.375\n",
      "0.096\n",
      "0.349\n",
      "0.134\n",
      "0.128\n",
      "0.528\n",
      "0.653\n",
      "0.550\n",
      "0.259\n",
      "0.360\n",
      "0.097\n",
      "0.180\n",
      "0.305\n",
      "0.549\n",
      "0.316\n",
      "0.742\n",
      "0.544\n",
      "0.351\n",
      "0.499\n",
      "0.312\n",
      "0.367\n",
      "0.430\n",
      "0.634\n",
      "0.504\n",
      "0.273\n",
      "0.136\n",
      "0.334\n",
      "0.248\n",
      "0.448\n",
      "0.613\n",
      "0.550\n",
      "0.344\n",
      "0.231\n",
      "0.422\n",
      "0.218\n",
      "0.189\n",
      "0.210\n",
      "0.531\n",
      "0.107\n",
      "0.962\n",
      "0.577\n",
      "0.441\n",
      "0.974\n",
      "0.843\n",
      "0.347\n",
      "0.128\n",
      "0.668\n",
      "0.551\n",
      "0.285\n",
      "0.324\n",
      "0.837\n",
      "0.977\n",
      "0.577\n",
      "0.469\n",
      "0.419\n",
      "0.871\n",
      "0.582\n",
      "0.981\n",
      "0.582\n",
      "0.800\n",
      "0.700\n",
      "0.359\n",
      "0.234\n",
      "0.350\n",
      "0.349\n",
      "0.364\n",
      "0.200\n",
      "0.189\n",
      "0.186\n",
      "0.311\n",
      "0.285\n",
      "0.456\n",
      "0.200\n",
      "0.245\n",
      "0.140\n",
      "0.337\n",
      "0.379\n",
      "0.308\n",
      "0.194\n",
      "0.607\n",
      "0.423\n",
      "0.357\n",
      "0.133\n",
      "0.139\n",
      "0.442\n",
      "0.200\n",
      "0.173\n",
      "0.341\n",
      "0.422\n",
      "0.470\n",
      "0.629\n",
      "0.312\n",
      "0.155\n",
      "0.932\n",
      "0.844\n",
      "0.113\n",
      "0.258\n",
      "0.633\n",
      "0.526\n",
      "0.313\n",
      "0.303\n",
      "0.981\n",
      "0.437\n",
      "0.256\n",
      "0.541\n",
      "0.669\n",
      "0.150\n",
      "0.727\n",
      "0.647\n",
      "0.246\n",
      "0.613\n",
      "0.667\n",
      "0.165\n",
      "0.293\n",
      "0.097\n",
      "0.318\n",
      "0.610\n",
      "0.264\n",
      "0.343\n",
      "0.780\n",
      "0.368\n",
      "0.114\n",
      "0.626\n",
      "0.245\n",
      "0.416\n",
      "0.098\n",
      "0.098\n",
      "0.494\n",
      "0.099\n",
      "0.402\n",
      "0.245\n",
      "0.150\n",
      "0.504\n",
      "0.107\n",
      "0.473\n",
      "0.114\n",
      "0.098\n",
      "0.546\n",
      "0.679\n",
      "0.264\n",
      "0.372\n",
      "0.154\n",
      "0.146\n",
      "0.749\n",
      "0.875\n",
      "0.270\n",
      "0.178\n",
      "0.234\n",
      "0.309\n",
      "0.588\n",
      "0.199\n",
      "0.338\n",
      "0.096\n",
      "0.164\n",
      "0.091\n",
      "0.094\n",
      "0.105\n",
      "0.125\n",
      "0.234\n",
      "0.234\n",
      "0.249\n",
      "0.119\n",
      "0.142\n",
      "0.519\n",
      "0.123\n",
      "0.259\n",
      "0.108\n",
      "0.266\n",
      "0.121\n",
      "0.380\n",
      "0.101\n",
      "0.354\n",
      "0.139\n",
      "0.134\n",
      "0.534\n",
      "0.658\n",
      "0.555\n",
      "0.265\n",
      "0.365\n",
      "0.102\n",
      "0.185\n",
      "0.310\n",
      "0.554\n",
      "0.321\n",
      "0.747\n",
      "0.549\n",
      "0.356\n",
      "0.505\n",
      "0.317\n",
      "0.373\n",
      "0.435\n",
      "0.639\n",
      "0.509\n",
      "0.278\n",
      "0.142\n",
      "0.339\n",
      "0.253\n",
      "0.454\n",
      "0.619\n",
      "0.555\n",
      "0.349\n",
      "0.237\n",
      "0.428\n",
      "0.224\n",
      "0.194\n",
      "0.215\n",
      "0.537\n",
      "0.113\n",
      "0.967\n",
      "0.582\n",
      "0.447\n",
      "0.979\n",
      "0.849\n",
      "0.352\n",
      "0.134\n",
      "0.673\n",
      "0.557\n",
      "0.290\n",
      "0.330\n",
      "0.842\n",
      "0.983\n",
      "0.583\n",
      "0.475\n",
      "0.424\n",
      "0.876\n",
      "0.587\n",
      "0.986\n",
      "0.587\n",
      "0.805\n",
      "0.705\n",
      "0.365\n",
      "0.239\n",
      "0.356\n",
      "0.355\n",
      "0.370\n",
      "0.205\n",
      "0.194\n",
      "0.191\n",
      "0.316\n",
      "0.290\n",
      "0.461\n",
      "0.206\n",
      "0.251\n",
      "0.145\n",
      "0.342\n",
      "0.385\n",
      "0.313\n",
      "0.200\n",
      "0.612\n",
      "0.429\n",
      "0.362\n",
      "0.138\n",
      "0.144\n",
      "0.447\n",
      "0.205\n",
      "0.179\n",
      "0.347\n",
      "0.428\n",
      "0.475\n",
      "0.635\n",
      "0.318\n",
      "0.161\n",
      "0.937\n",
      "0.849\n",
      "0.118\n",
      "0.263\n",
      "0.638\n",
      "0.532\n",
      "0.318\n",
      "0.309\n",
      "0.986\n",
      "0.443\n",
      "0.262\n",
      "0.546\n",
      "0.674\n",
      "0.155\n",
      "0.732\n",
      "0.653\n",
      "0.252\n",
      "0.618\n",
      "0.672\n",
      "0.171\n",
      "0.298\n",
      "0.102\n",
      "0.323\n",
      "0.615\n",
      "0.269\n",
      "0.348\n",
      "0.785\n",
      "0.374\n",
      "0.119\n",
      "0.632\n",
      "0.250\n",
      "0.421\n",
      "0.103\n",
      "0.103\n",
      "0.500\n",
      "0.105\n",
      "0.407\n",
      "0.250\n",
      "0.156\n",
      "0.510\n",
      "0.112\n",
      "0.478\n",
      "0.119\n",
      "0.103\n",
      "0.552\n",
      "0.685\n",
      "0.270\n",
      "0.377\n",
      "0.160\n",
      "0.154\n",
      "0.757\n",
      "0.882\n",
      "0.278\n",
      "0.186\n",
      "0.241\n",
      "0.317\n",
      "0.595\n",
      "0.206\n",
      "0.345\n",
      "0.103\n",
      "0.172\n",
      "0.098\n",
      "0.101\n",
      "0.112\n",
      "0.132\n",
      "0.241\n",
      "0.241\n",
      "0.257\n",
      "0.126\n",
      "0.150\n",
      "0.526\n",
      "0.130\n",
      "0.266\n",
      "0.116\n",
      "0.273\n",
      "0.128\n",
      "0.387\n",
      "0.108\n",
      "0.362\n",
      "0.146\n",
      "0.141\n",
      "0.541\n",
      "0.665\n",
      "0.563\n",
      "0.272\n",
      "0.373\n",
      "0.110\n",
      "0.193\n",
      "0.318\n",
      "0.561\n",
      "0.328\n",
      "0.754\n",
      "0.557\n",
      "0.364\n",
      "0.512\n",
      "0.324\n",
      "0.380\n",
      "0.443\n",
      "0.646\n",
      "0.516\n",
      "0.285\n",
      "0.149\n",
      "0.346\n",
      "0.260\n",
      "0.461\n",
      "0.626\n",
      "0.563\n",
      "0.356\n",
      "0.244\n",
      "0.435\n",
      "0.231\n",
      "0.201\n",
      "0.223\n",
      "0.544\n",
      "0.120\n",
      "0.974\n",
      "0.589\n",
      "0.454\n",
      "0.987\n",
      "0.856\n",
      "0.359\n",
      "0.141\n",
      "0.680\n",
      "0.564\n",
      "0.298\n",
      "0.337\n",
      "0.849\n",
      "0.990\n",
      "0.590\n",
      "0.482\n",
      "0.431\n",
      "0.884\n",
      "0.594\n",
      "0.994\n",
      "0.595\n",
      "0.813\n",
      "0.712\n",
      "0.372\n",
      "0.246\n",
      "0.363\n",
      "0.362\n",
      "0.377\n",
      "0.212\n",
      "0.201\n",
      "0.199\n",
      "0.323\n",
      "0.297\n",
      "0.469\n",
      "0.213\n",
      "0.258\n",
      "0.153\n",
      "0.349\n",
      "0.392\n",
      "0.320\n",
      "0.207\n",
      "0.619\n",
      "0.436\n",
      "0.369\n",
      "0.145\n",
      "0.152\n",
      "0.455\n",
      "0.212\n",
      "0.186\n",
      "0.354\n",
      "0.435\n",
      "0.483\n",
      "0.642\n",
      "0.325\n",
      "0.168\n",
      "0.945\n",
      "0.857\n",
      "0.125\n",
      "0.271\n",
      "0.645\n",
      "0.539\n",
      "0.326\n",
      "0.316\n",
      "0.993\n",
      "0.450\n",
      "0.269\n",
      "0.554\n",
      "0.681\n",
      "0.162\n",
      "0.739\n",
      "0.660\n",
      "0.259\n",
      "0.625\n",
      "0.679\n",
      "0.178\n",
      "0.306\n",
      "0.109\n",
      "0.330\n",
      "0.622\n",
      "0.276\n",
      "0.355\n",
      "0.793\n",
      "0.381\n",
      "0.127\n",
      "0.639\n",
      "0.257\n",
      "0.428\n",
      "0.110\n",
      "0.110\n",
      "0.507\n",
      "0.112\n",
      "0.415\n",
      "0.258\n",
      "0.163\n",
      "0.517\n",
      "0.120\n",
      "0.486\n",
      "0.127\n",
      "0.110\n",
      "0.559\n",
      "0.692\n",
      "0.277\n",
      "0.384\n",
      "0.167\n",
      "0.135\n",
      "0.738\n",
      "0.863\n",
      "0.259\n",
      "0.167\n",
      "0.222\n",
      "0.297\n",
      "0.576\n",
      "0.187\n",
      "0.326\n",
      "0.084\n",
      "0.153\n",
      "0.079\n",
      "0.082\n",
      "0.093\n",
      "0.113\n",
      "0.222\n",
      "0.222\n",
      "0.238\n",
      "0.107\n",
      "0.130\n",
      "0.507\n",
      "0.111\n",
      "0.247\n",
      "0.097\n",
      "0.254\n",
      "0.109\n",
      "0.368\n",
      "0.089\n",
      "0.343\n",
      "0.127\n",
      "0.122\n",
      "0.522\n",
      "0.646\n",
      "0.543\n",
      "0.253\n",
      "0.354\n",
      "0.090\n",
      "0.174\n",
      "0.299\n",
      "0.542\n",
      "0.309\n",
      "0.735\n",
      "0.538\n",
      "0.344\n",
      "0.493\n",
      "0.305\n",
      "0.361\n",
      "0.424\n",
      "0.627\n",
      "0.497\n",
      "0.266\n",
      "0.130\n",
      "0.327\n",
      "0.241\n",
      "0.442\n",
      "0.607\n",
      "0.544\n",
      "0.337\n",
      "0.225\n",
      "0.416\n",
      "0.212\n",
      "0.182\n",
      "0.203\n",
      "0.525\n",
      "0.101\n",
      "0.955\n",
      "0.570\n",
      "0.435\n",
      "0.968\n",
      "0.837\n",
      "0.340\n",
      "0.122\n",
      "0.661\n",
      "0.545\n",
      "0.279\n",
      "0.318\n",
      "0.830\n",
      "0.971\n",
      "0.571\n",
      "0.463\n",
      "0.412\n",
      "0.864\n",
      "0.575\n",
      "0.975\n",
      "0.575\n",
      "0.794\n",
      "0.693\n",
      "0.353\n",
      "0.227\n",
      "0.344\n",
      "0.343\n",
      "0.358\n",
      "0.193\n",
      "0.182\n",
      "0.180\n",
      "0.304\n",
      "0.278\n",
      "0.449\n",
      "0.194\n",
      "0.239\n",
      "0.134\n",
      "0.330\n",
      "0.373\n",
      "0.301\n",
      "0.188\n",
      "0.600\n",
      "0.417\n",
      "0.350\n",
      "0.126\n",
      "0.133\n",
      "0.435\n",
      "0.193\n",
      "0.167\n",
      "0.335\n",
      "0.416\n",
      "0.463\n",
      "0.623\n",
      "0.306\n",
      "0.149\n",
      "0.925\n",
      "0.837\n",
      "0.106\n",
      "0.252\n",
      "0.626\n",
      "0.520\n",
      "0.306\n",
      "0.297\n",
      "0.974\n",
      "0.431\n",
      "0.250\n",
      "0.535\n",
      "0.662\n",
      "0.143\n",
      "0.720\n",
      "0.641\n",
      "0.240\n",
      "0.606\n",
      "0.660\n",
      "0.159\n",
      "0.287\n",
      "0.090\n",
      "0.311\n",
      "0.603\n",
      "0.257\n",
      "0.336\n",
      "0.773\n",
      "0.362\n",
      "0.107\n",
      "0.620\n",
      "0.238\n",
      "0.409\n",
      "0.091\n",
      "0.091\n",
      "0.488\n",
      "0.093\n",
      "0.396\n",
      "0.238\n",
      "0.144\n",
      "0.498\n",
      "0.101\n",
      "0.466\n",
      "0.107\n",
      "0.091\n",
      "0.540\n",
      "0.673\n",
      "0.258\n",
      "0.365\n",
      "0.148\n",
      "0.152\n",
      "0.755\n",
      "0.880\n",
      "0.276\n",
      "0.184\n",
      "0.239\n",
      "0.315\n",
      "0.593\n",
      "0.204\n",
      "0.343\n",
      "0.101\n",
      "0.170\n",
      "0.096\n",
      "0.099\n",
      "0.110\n",
      "0.130\n",
      "0.240\n",
      "0.240\n",
      "0.255\n",
      "0.124\n",
      "0.148\n",
      "0.524\n",
      "0.128\n",
      "0.264\n",
      "0.114\n",
      "0.271\n",
      "0.126\n",
      "0.386\n",
      "0.106\n",
      "0.360\n",
      "0.144\n",
      "0.139\n",
      "0.539\n",
      "0.664\n",
      "0.561\n",
      "0.270\n",
      "0.371\n",
      "0.108\n",
      "0.191\n",
      "0.316\n",
      "0.559\n",
      "0.326\n",
      "0.752\n",
      "0.555\n",
      "0.362\n",
      "0.510\n",
      "0.322\n",
      "0.378\n",
      "0.441\n",
      "0.644\n",
      "0.515\n",
      "0.284\n",
      "0.147\n",
      "0.344\n",
      "0.258\n",
      "0.459\n",
      "0.624\n",
      "0.561\n",
      "0.354\n",
      "0.242\n",
      "0.433\n",
      "0.229\n",
      "0.199\n",
      "0.221\n",
      "0.542\n",
      "0.118\n",
      "0.972\n",
      "0.587\n",
      "0.452\n",
      "0.985\n",
      "0.854\n",
      "0.357\n",
      "0.139\n",
      "0.678\n",
      "0.562\n",
      "0.296\n",
      "0.335\n",
      "0.848\n",
      "0.988\n",
      "0.588\n",
      "0.480\n",
      "0.429\n",
      "0.882\n",
      "0.592\n",
      "0.992\n",
      "0.593\n",
      "0.811\n",
      "0.710\n",
      "0.370\n",
      "0.244\n",
      "0.361\n",
      "0.360\n",
      "0.375\n",
      "0.211\n",
      "0.199\n",
      "0.197\n",
      "0.321\n",
      "0.295\n",
      "0.467\n",
      "0.211\n",
      "0.256\n",
      "0.151\n",
      "0.347\n",
      "0.390\n",
      "0.319\n",
      "0.205\n",
      "0.617\n",
      "0.434\n",
      "0.367\n",
      "0.144\n",
      "0.150\n",
      "0.453\n",
      "0.211\n",
      "0.184\n",
      "0.352\n",
      "0.433\n",
      "0.481\n",
      "0.640\n",
      "0.323\n",
      "0.166\n",
      "0.943\n",
      "0.855\n",
      "0.123\n",
      "0.269\n",
      "0.643\n",
      "0.537\n",
      "0.324\n",
      "0.314\n",
      "0.991\n",
      "0.448\n",
      "0.267\n",
      "0.552\n",
      "0.679\n",
      "0.160\n",
      "0.737\n",
      "0.658\n",
      "0.257\n",
      "0.623\n",
      "0.677\n",
      "0.176\n",
      "0.304\n",
      "0.107\n",
      "0.328\n",
      "0.620\n",
      "0.275\n",
      "0.353\n",
      "0.791\n",
      "0.379\n",
      "0.125\n",
      "0.637\n",
      "0.255\n",
      "0.427\n",
      "0.109\n",
      "0.109\n",
      "0.505\n",
      "0.110\n",
      "0.413\n",
      "0.256\n",
      "0.161\n",
      "0.515\n",
      "0.118\n",
      "0.484\n",
      "0.125\n",
      "0.109\n",
      "0.557\n",
      "0.690\n",
      "0.275\n",
      "0.382\n",
      "0.165\n",
      "0.160\n",
      "0.763\n",
      "0.888\n",
      "0.284\n",
      "0.192\n",
      "0.248\n",
      "0.323\n",
      "0.602\n",
      "0.213\n",
      "0.351\n",
      "0.109\n",
      "0.178\n",
      "0.105\n",
      "0.108\n",
      "0.118\n",
      "0.138\n",
      "0.248\n",
      "0.248\n",
      "0.263\n",
      "0.133\n",
      "0.156\n",
      "0.533\n",
      "0.136\n",
      "0.272\n",
      "0.122\n",
      "0.280\n",
      "0.135\n",
      "0.394\n",
      "0.115\n",
      "0.368\n",
      "0.153\n",
      "0.147\n",
      "0.547\n",
      "0.672\n",
      "0.569\n",
      "0.278\n",
      "0.379\n",
      "0.116\n",
      "0.199\n",
      "0.324\n",
      "0.568\n",
      "0.335\n",
      "0.761\n",
      "0.563\n",
      "0.370\n",
      "0.518\n",
      "0.331\n",
      "0.386\n",
      "0.449\n",
      "0.653\n",
      "0.523\n",
      "0.292\n",
      "0.155\n",
      "0.353\n",
      "0.267\n",
      "0.468\n",
      "0.632\n",
      "0.569\n",
      "0.363\n",
      "0.250\n",
      "0.441\n",
      "0.237\n",
      "0.208\n",
      "0.229\n",
      "0.550\n",
      "0.126\n",
      "0.981\n",
      "0.596\n",
      "0.460\n",
      "0.993\n",
      "0.862\n",
      "0.366\n",
      "0.147\n",
      "0.687\n",
      "0.570\n",
      "0.304\n",
      "0.343\n",
      "0.856\n",
      "0.997\n",
      "0.596\n",
      "0.489\n",
      "0.438\n",
      "0.890\n",
      "0.601\n",
      "1.000\n",
      "0.601\n",
      "0.819\n",
      "0.719\n",
      "0.378\n",
      "0.253\n",
      "0.369\n",
      "0.369\n",
      "0.384\n",
      "0.219\n",
      "0.208\n",
      "0.205\n",
      "0.330\n",
      "0.304\n",
      "0.475\n",
      "0.220\n",
      "0.264\n",
      "0.159\n",
      "0.356\n",
      "0.398\n",
      "0.327\n",
      "0.214\n",
      "0.626\n",
      "0.442\n",
      "0.376\n",
      "0.152\n",
      "0.158\n",
      "0.461\n",
      "0.219\n",
      "0.192\n",
      "0.360\n",
      "0.441\n",
      "0.489\n",
      "0.649\n",
      "0.331\n",
      "0.174\n",
      "0.951\n",
      "0.863\n",
      "0.132\n",
      "0.277\n",
      "0.652\n",
      "0.545\n",
      "0.332\n",
      "0.322\n",
      "1.000\n",
      "0.457\n",
      "0.275\n",
      "0.560\n",
      "0.688\n",
      "0.169\n",
      "0.746\n",
      "0.666\n",
      "0.265\n",
      "0.632\n",
      "0.686\n",
      "0.184\n",
      "0.312\n",
      "0.116\n",
      "0.337\n",
      "0.629\n",
      "0.283\n",
      "0.362\n",
      "0.799\n",
      "0.387\n",
      "0.133\n",
      "0.645\n",
      "0.264\n",
      "0.435\n",
      "0.117\n",
      "0.117\n",
      "0.513\n",
      "0.118\n",
      "0.421\n",
      "0.264\n",
      "0.169\n",
      "0.524\n",
      "0.126\n",
      "0.492\n",
      "0.133\n",
      "0.117\n",
      "0.565\n",
      "0.698\n",
      "0.283\n",
      "0.391\n",
      "0.173\n",
      "0.154\n",
      "0.757\n",
      "0.882\n",
      "0.278\n",
      "0.186\n",
      "0.241\n",
      "0.317\n",
      "0.596\n",
      "0.206\n",
      "0.345\n",
      "0.103\n",
      "0.172\n",
      "0.098\n",
      "0.101\n",
      "0.112\n",
      "0.132\n",
      "0.242\n",
      "0.242\n",
      "0.257\n",
      "0.126\n",
      "0.150\n",
      "0.526\n",
      "0.130\n",
      "0.266\n",
      "0.116\n",
      "0.273\n",
      "0.129\n",
      "0.388\n",
      "0.109\n",
      "0.362\n",
      "0.147\n",
      "0.141\n",
      "0.541\n",
      "0.666\n",
      "0.563\n",
      "0.272\n",
      "0.373\n",
      "0.110\n",
      "0.193\n",
      "0.318\n",
      "0.561\n",
      "0.328\n",
      "0.754\n",
      "0.557\n",
      "0.364\n",
      "0.512\n",
      "0.325\n",
      "0.380\n",
      "0.443\n",
      "0.646\n",
      "0.517\n",
      "0.286\n",
      "0.149\n",
      "0.346\n",
      "0.260\n",
      "0.461\n",
      "0.626\n",
      "0.563\n",
      "0.357\n",
      "0.244\n",
      "0.435\n",
      "0.231\n",
      "0.202\n",
      "0.223\n",
      "0.544\n",
      "0.120\n",
      "0.974\n",
      "0.589\n",
      "0.454\n",
      "0.987\n",
      "0.856\n",
      "0.360\n",
      "0.141\n",
      "0.681\n",
      "0.564\n",
      "0.298\n",
      "0.337\n",
      "0.850\n",
      "0.990\n",
      "0.590\n",
      "0.482\n",
      "0.431\n",
      "0.884\n",
      "0.594\n",
      "0.994\n",
      "0.595\n",
      "0.813\n",
      "0.712\n",
      "0.372\n",
      "0.246\n",
      "0.363\n",
      "0.362\n",
      "0.377\n",
      "0.213\n",
      "0.202\n",
      "0.199\n",
      "0.323\n",
      "0.297\n",
      "0.469\n",
      "0.213\n",
      "0.258\n",
      "0.153\n",
      "0.349\n",
      "0.392\n",
      "0.321\n",
      "0.207\n",
      "0.620\n",
      "0.436\n",
      "0.369\n",
      "0.146\n",
      "0.152\n",
      "0.455\n",
      "0.213\n",
      "0.186\n",
      "0.354\n",
      "0.435\n",
      "0.483\n",
      "0.642\n",
      "0.325\n",
      "0.168\n",
      "0.945\n",
      "0.857\n",
      "0.126\n",
      "0.271\n",
      "0.646\n",
      "0.539\n",
      "0.326\n",
      "0.316\n",
      "0.994\n",
      "0.450\n",
      "0.269\n",
      "0.554\n",
      "0.681\n",
      "0.162\n",
      "0.740\n",
      "0.660\n",
      "0.259\n",
      "0.626\n",
      "0.679\n",
      "0.178\n",
      "0.306\n",
      "0.109\n",
      "0.331\n",
      "0.623\n",
      "0.277\n",
      "0.355\n",
      "0.793\n",
      "0.381\n",
      "0.127\n",
      "0.639\n",
      "0.258\n",
      "0.429\n",
      "0.111\n",
      "0.111\n",
      "0.507\n",
      "0.112\n",
      "0.415\n",
      "0.258\n",
      "0.163\n",
      "0.517\n",
      "0.120\n",
      "0.486\n",
      "0.127\n",
      "0.111\n",
      "0.559\n",
      "0.692\n",
      "0.277\n",
      "0.384\n",
      "0.167\n",
      "0.137\n",
      "0.740\n",
      "0.866\n",
      "0.261\n",
      "0.169\n",
      "0.225\n",
      "0.300\n",
      "0.579\n",
      "0.190\n",
      "0.329\n",
      "0.087\n",
      "0.155\n",
      "0.082\n",
      "0.085\n",
      "0.096\n",
      "0.116\n",
      "0.225\n",
      "0.225\n",
      "0.240\n",
      "0.110\n",
      "0.133\n",
      "0.510\n",
      "0.114\n",
      "0.250\n",
      "0.099\n",
      "0.257\n",
      "0.112\n",
      "0.371\n",
      "0.092\n",
      "0.345\n",
      "0.130\n",
      "0.125\n",
      "0.525\n",
      "0.649\n",
      "0.546\n",
      "0.256\n",
      "0.356\n",
      "0.093\n",
      "0.176\n",
      "0.301\n",
      "0.545\n",
      "0.312\n",
      "0.738\n",
      "0.540\n",
      "0.347\n",
      "0.496\n",
      "0.308\n",
      "0.364\n",
      "0.426\n",
      "0.630\n",
      "0.500\n",
      "0.269\n",
      "0.133\n",
      "0.330\n",
      "0.244\n",
      "0.445\n",
      "0.610\n",
      "0.546\n",
      "0.340\n",
      "0.228\n",
      "0.419\n",
      "0.215\n",
      "0.185\n",
      "0.206\n",
      "0.528\n",
      "0.104\n",
      "0.958\n",
      "0.573\n",
      "0.438\n",
      "0.970\n",
      "0.840\n",
      "0.343\n",
      "0.125\n",
      "0.664\n",
      "0.548\n",
      "0.281\n",
      "0.321\n",
      "0.833\n",
      "0.974\n",
      "0.574\n",
      "0.466\n",
      "0.415\n",
      "0.867\n",
      "0.578\n",
      "0.977\n",
      "0.578\n",
      "0.796\n",
      "0.696\n",
      "0.356\n",
      "0.230\n",
      "0.347\n",
      "0.346\n",
      "0.361\n",
      "0.196\n",
      "0.185\n",
      "0.182\n",
      "0.307\n",
      "0.281\n",
      "0.452\n",
      "0.197\n",
      "0.242\n",
      "0.137\n",
      "0.333\n",
      "0.376\n",
      "0.304\n",
      "0.191\n",
      "0.603\n",
      "0.420\n",
      "0.353\n",
      "0.129\n",
      "0.135\n",
      "0.438\n",
      "0.196\n",
      "0.170\n",
      "0.338\n",
      "0.419\n",
      "0.466\n",
      "0.626\n",
      "0.309\n",
      "0.152\n",
      "0.928\n",
      "0.840\n",
      "0.109\n",
      "0.254\n",
      "0.629\n",
      "0.523\n",
      "0.309\n",
      "0.300\n",
      "0.977\n",
      "0.434\n",
      "0.253\n",
      "0.537\n",
      "0.665\n",
      "0.146\n",
      "0.723\n",
      "0.644\n",
      "0.243\n",
      "0.609\n",
      "0.663\n",
      "0.162\n",
      "0.289\n",
      "0.093\n",
      "0.314\n",
      "0.606\n",
      "0.260\n",
      "0.339\n",
      "0.776\n",
      "0.365\n",
      "0.110\n",
      "0.623\n",
      "0.241\n",
      "0.412\n",
      "0.094\n",
      "0.094\n",
      "0.491\n",
      "0.096\n",
      "0.398\n",
      "0.241\n",
      "0.147\n",
      "0.501\n",
      "0.103\n",
      "0.469\n",
      "0.110\n",
      "0.094\n",
      "0.543\n",
      "0.676\n",
      "0.261\n",
      "0.368\n",
      "0.151\n",
      "0.142\n",
      "0.745\n",
      "0.870\n",
      "0.266\n",
      "0.174\n",
      "0.230\n",
      "0.305\n",
      "0.584\n",
      "0.195\n",
      "0.334\n",
      "0.091\n",
      "0.160\n",
      "0.087\n",
      "0.090\n",
      "0.100\n",
      "0.120\n",
      "0.230\n",
      "0.230\n",
      "0.245\n",
      "0.115\n",
      "0.138\n",
      "0.515\n",
      "0.119\n",
      "0.254\n",
      "0.104\n",
      "0.262\n",
      "0.117\n",
      "0.376\n",
      "0.097\n",
      "0.350\n",
      "0.135\n",
      "0.129\n",
      "0.529\n",
      "0.654\n",
      "0.551\n",
      "0.261\n",
      "0.361\n",
      "0.098\n",
      "0.181\n",
      "0.306\n",
      "0.550\n",
      "0.317\n",
      "0.743\n",
      "0.545\n",
      "0.352\n",
      "0.501\n",
      "0.313\n",
      "0.369\n",
      "0.431\n",
      "0.635\n",
      "0.505\n",
      "0.274\n",
      "0.137\n",
      "0.335\n",
      "0.249\n",
      "0.450\n",
      "0.615\n",
      "0.551\n",
      "0.345\n",
      "0.233\n",
      "0.423\n",
      "0.220\n",
      "0.190\n",
      "0.211\n",
      "0.532\n",
      "0.108\n",
      "0.963\n",
      "0.578\n",
      "0.443\n",
      "0.975\n",
      "0.844\n",
      "0.348\n",
      "0.130\n",
      "0.669\n",
      "0.552\n",
      "0.286\n",
      "0.326\n",
      "0.838\n",
      "0.979\n",
      "0.578\n",
      "0.471\n",
      "0.420\n",
      "0.872\n",
      "0.583\n",
      "0.982\n",
      "0.583\n",
      "0.801\n",
      "0.701\n",
      "0.361\n",
      "0.235\n",
      "0.351\n",
      "0.351\n",
      "0.366\n",
      "0.201\n",
      "0.190\n",
      "0.187\n",
      "0.312\n",
      "0.286\n",
      "0.457\n",
      "0.202\n",
      "0.247\n",
      "0.141\n",
      "0.338\n",
      "0.380\n",
      "0.309\n",
      "0.196\n",
      "0.608\n",
      "0.424\n",
      "0.358\n",
      "0.134\n",
      "0.140\n",
      "0.443\n",
      "0.201\n",
      "0.175\n",
      "0.343\n",
      "0.423\n",
      "0.471\n",
      "0.631\n",
      "0.314\n",
      "0.157\n",
      "0.933\n",
      "0.845\n",
      "0.114\n",
      "0.259\n",
      "0.634\n",
      "0.528\n",
      "0.314\n",
      "0.305\n",
      "0.982\n",
      "0.439\n",
      "0.257\n",
      "0.542\n",
      "0.670\n",
      "0.151\n",
      "0.728\n",
      "0.648\n",
      "0.248\n",
      "0.614\n",
      "0.668\n",
      "0.166\n",
      "0.294\n",
      "0.098\n",
      "0.319\n",
      "0.611\n",
      "0.265\n",
      "0.344\n",
      "0.781\n",
      "0.370\n",
      "0.115\n",
      "0.628\n",
      "0.246\n",
      "0.417\n",
      "0.099\n",
      "0.099\n",
      "0.496\n",
      "0.100\n",
      "0.403\n",
      "0.246\n",
      "0.152\n",
      "0.506\n",
      "0.108\n",
      "0.474\n",
      "0.115\n",
      "0.099\n",
      "0.547\n",
      "0.681\n",
      "0.266\n",
      "0.373\n",
      "0.155\n",
      "0.147\n",
      "0.750\n",
      "0.875\n",
      "0.271\n",
      "0.179\n",
      "0.234\n",
      "0.310\n",
      "0.588\n",
      "0.199\n",
      "0.338\n",
      "0.096\n",
      "0.165\n",
      "0.091\n",
      "0.094\n",
      "0.105\n",
      "0.125\n",
      "0.234\n",
      "0.234\n",
      "0.250\n",
      "0.119\n",
      "0.143\n",
      "0.519\n",
      "0.123\n",
      "0.259\n",
      "0.109\n",
      "0.266\n",
      "0.121\n",
      "0.380\n",
      "0.101\n",
      "0.355\n",
      "0.139\n",
      "0.134\n",
      "0.534\n",
      "0.658\n",
      "0.556\n",
      "0.265\n",
      "0.366\n",
      "0.103\n",
      "0.186\n",
      "0.311\n",
      "0.554\n",
      "0.321\n",
      "0.747\n",
      "0.550\n",
      "0.357\n",
      "0.505\n",
      "0.317\n",
      "0.373\n",
      "0.436\n",
      "0.639\n",
      "0.509\n",
      "0.278\n",
      "0.142\n",
      "0.339\n",
      "0.253\n",
      "0.454\n",
      "0.619\n",
      "0.556\n",
      "0.349\n",
      "0.237\n",
      "0.428\n",
      "0.224\n",
      "0.194\n",
      "0.216\n",
      "0.537\n",
      "0.113\n",
      "0.967\n",
      "0.582\n",
      "0.447\n",
      "0.980\n",
      "0.849\n",
      "0.352\n",
      "0.134\n",
      "0.673\n",
      "0.557\n",
      "0.291\n",
      "0.330\n",
      "0.842\n",
      "0.983\n",
      "0.583\n",
      "0.475\n",
      "0.424\n",
      "0.877\n",
      "0.587\n",
      "0.987\n",
      "0.588\n",
      "0.806\n",
      "0.705\n",
      "0.365\n",
      "0.239\n",
      "0.356\n",
      "0.355\n",
      "0.370\n",
      "0.205\n",
      "0.194\n",
      "0.192\n",
      "0.316\n",
      "0.290\n",
      "0.462\n",
      "0.206\n",
      "0.251\n",
      "0.146\n",
      "0.342\n",
      "0.385\n",
      "0.313\n",
      "0.200\n",
      "0.612\n",
      "0.429\n",
      "0.362\n",
      "0.138\n",
      "0.145\n",
      "0.448\n",
      "0.205\n",
      "0.179\n",
      "0.347\n",
      "0.428\n",
      "0.476\n",
      "0.635\n",
      "0.318\n",
      "0.161\n",
      "0.938\n",
      "0.850\n",
      "0.118\n",
      "0.264\n",
      "0.638\n",
      "0.532\n",
      "0.319\n",
      "0.309\n",
      "0.986\n",
      "0.443\n",
      "0.262\n",
      "0.547\n",
      "0.674\n",
      "0.155\n",
      "0.732\n",
      "0.653\n",
      "0.252\n",
      "0.618\n",
      "0.672\n",
      "0.171\n",
      "0.299\n",
      "0.102\n",
      "0.323\n",
      "0.615\n",
      "0.269\n",
      "0.348\n",
      "0.786\n",
      "0.374\n",
      "0.120\n",
      "0.632\n",
      "0.250\n",
      "0.421\n",
      "0.103\n",
      "0.103\n",
      "0.500\n",
      "0.105\n",
      "0.408\n",
      "0.251\n",
      "0.156\n",
      "0.510\n",
      "0.113\n",
      "0.479\n",
      "0.120\n",
      "0.103\n",
      "0.552\n",
      "0.685\n",
      "0.270\n",
      "0.377\n",
      "0.160\n",
      "0.144\n",
      "0.747\n",
      "0.872\n",
      "0.268\n",
      "0.176\n",
      "0.232\n",
      "0.307\n",
      "0.586\n",
      "0.197\n",
      "0.336\n",
      "0.093\n",
      "0.162\n",
      "0.089\n",
      "0.092\n",
      "0.102\n",
      "0.122\n",
      "0.232\n",
      "0.232\n",
      "0.247\n",
      "0.117\n",
      "0.140\n",
      "0.517\n",
      "0.120\n",
      "0.256\n",
      "0.106\n",
      "0.264\n",
      "0.119\n",
      "0.378\n",
      "0.099\n",
      "0.352\n",
      "0.137\n",
      "0.131\n",
      "0.531\n",
      "0.656\n",
      "0.553\n",
      "0.263\n",
      "0.363\n",
      "0.100\n",
      "0.183\n",
      "0.308\n",
      "0.552\n",
      "0.319\n",
      "0.745\n",
      "0.547\n",
      "0.354\n",
      "0.502\n",
      "0.315\n",
      "0.371\n",
      "0.433\n",
      "0.637\n",
      "0.507\n",
      "0.276\n",
      "0.139\n",
      "0.337\n",
      "0.251\n",
      "0.452\n",
      "0.616\n",
      "0.553\n",
      "0.347\n",
      "0.234\n",
      "0.425\n",
      "0.222\n",
      "0.192\n",
      "0.213\n",
      "0.534\n",
      "0.110\n",
      "0.965\n",
      "0.580\n",
      "0.444\n",
      "0.977\n",
      "0.846\n",
      "0.350\n",
      "0.131\n",
      "0.671\n",
      "0.554\n",
      "0.288\n",
      "0.327\n",
      "0.840\n",
      "0.981\n",
      "0.580\n",
      "0.473\n",
      "0.422\n",
      "0.874\n",
      "0.585\n",
      "0.984\n",
      "0.585\n",
      "0.803\n",
      "0.703\n",
      "0.362\n",
      "0.237\n",
      "0.353\n",
      "0.353\n",
      "0.368\n",
      "0.203\n",
      "0.192\n",
      "0.189\n",
      "0.314\n",
      "0.288\n",
      "0.459\n",
      "0.204\n",
      "0.248\n",
      "0.143\n",
      "0.340\n",
      "0.382\n",
      "0.311\n",
      "0.198\n",
      "0.610\n",
      "0.426\n",
      "0.360\n",
      "0.136\n",
      "0.142\n",
      "0.445\n",
      "0.203\n",
      "0.176\n",
      "0.345\n",
      "0.425\n",
      "0.473\n",
      "0.633\n",
      "0.315\n",
      "0.158\n",
      "0.935\n",
      "0.847\n",
      "0.116\n",
      "0.261\n",
      "0.636\n",
      "0.529\n",
      "0.316\n",
      "0.307\n",
      "0.984\n",
      "0.441\n",
      "0.259\n",
      "0.544\n",
      "0.672\n",
      "0.153\n",
      "0.730\n",
      "0.650\n",
      "0.249\n",
      "0.616\n",
      "0.670\n",
      "0.168\n",
      "0.296\n",
      "0.100\n",
      "0.321\n",
      "0.613\n",
      "0.267\n",
      "0.346\n",
      "0.783\n",
      "0.371\n",
      "0.117\n",
      "0.629\n",
      "0.248\n",
      "0.419\n",
      "0.101\n",
      "0.101\n",
      "0.497\n",
      "0.102\n",
      "0.405\n",
      "0.248\n",
      "0.153\n",
      "0.508\n",
      "0.110\n",
      "0.476\n",
      "0.117\n",
      "0.101\n",
      "0.549\n",
      "0.682\n",
      "0.267\n",
      "0.375\n",
      "0.157\n",
      "0.149\n",
      "0.752\n",
      "0.877\n",
      "0.273\n",
      "0.181\n",
      "0.237\n",
      "0.312\n",
      "0.591\n",
      "0.202\n",
      "0.340\n",
      "0.098\n",
      "0.167\n",
      "0.094\n",
      "0.097\n",
      "0.107\n",
      "0.127\n",
      "0.237\n",
      "0.237\n",
      "0.252\n",
      "0.122\n",
      "0.145\n",
      "0.522\n",
      "0.125\n",
      "0.261\n",
      "0.111\n",
      "0.269\n",
      "0.124\n",
      "0.383\n",
      "0.104\n",
      "0.357\n",
      "0.142\n",
      "0.136\n",
      "0.536\n",
      "0.661\n",
      "0.558\n",
      "0.267\n",
      "0.368\n",
      "0.105\n",
      "0.188\n",
      "0.313\n",
      "0.557\n",
      "0.324\n",
      "0.750\n",
      "0.552\n",
      "0.359\n",
      "0.507\n",
      "0.320\n",
      "0.375\n",
      "0.438\n",
      "0.642\n",
      "0.512\n",
      "0.281\n",
      "0.144\n",
      "0.342\n",
      "0.256\n",
      "0.456\n",
      "0.621\n",
      "0.558\n",
      "0.352\n",
      "0.239\n",
      "0.430\n",
      "0.226\n",
      "0.197\n",
      "0.218\n",
      "0.539\n",
      "0.115\n",
      "0.970\n",
      "0.585\n",
      "0.449\n",
      "0.982\n",
      "0.851\n",
      "0.355\n",
      "0.136\n",
      "0.676\n",
      "0.559\n",
      "0.293\n",
      "0.332\n",
      "0.845\n",
      "0.985\n",
      "0.585\n",
      "0.477\n",
      "0.427\n",
      "0.879\n",
      "0.590\n",
      "0.989\n",
      "0.590\n",
      "0.808\n",
      "0.708\n",
      "0.367\n",
      "0.242\n",
      "0.358\n",
      "0.357\n",
      "0.372\n",
      "0.208\n",
      "0.197\n",
      "0.194\n",
      "0.319\n",
      "0.293\n",
      "0.464\n",
      "0.208\n",
      "0.253\n",
      "0.148\n",
      "0.345\n",
      "0.387\n",
      "0.316\n",
      "0.202\n",
      "0.615\n",
      "0.431\n",
      "0.365\n",
      "0.141\n",
      "0.147\n",
      "0.450\n",
      "0.208\n",
      "0.181\n",
      "0.349\n",
      "0.430\n",
      "0.478\n",
      "0.638\n",
      "0.320\n",
      "0.163\n",
      "0.940\n",
      "0.852\n",
      "0.121\n",
      "0.266\n",
      "0.641\n",
      "0.534\n",
      "0.321\n",
      "0.311\n",
      "0.989\n",
      "0.445\n",
      "0.264\n",
      "0.549\n",
      "0.677\n",
      "0.158\n",
      "0.735\n",
      "0.655\n",
      "0.254\n",
      "0.621\n",
      "0.675\n",
      "0.173\n",
      "0.301\n",
      "0.105\n",
      "0.326\n",
      "0.618\n",
      "0.272\n",
      "0.351\n",
      "0.788\n",
      "0.376\n",
      "0.122\n",
      "0.634\n",
      "0.253\n",
      "0.424\n",
      "0.106\n",
      "0.106\n",
      "0.502\n",
      "0.107\n",
      "0.410\n",
      "0.253\n",
      "0.158\n",
      "0.512\n",
      "0.115\n",
      "0.481\n",
      "0.122\n",
      "0.106\n",
      "0.554\n",
      "0.687\n",
      "0.272\n",
      "0.380\n",
      "0.162\n",
      "0.146\n",
      "0.749\n",
      "0.875\n",
      "0.270\n",
      "0.178\n",
      "0.234\n",
      "0.309\n",
      "0.588\n",
      "0.199\n",
      "0.338\n",
      "0.095\n",
      "0.164\n",
      "0.091\n",
      "0.094\n",
      "0.104\n",
      "0.124\n",
      "0.234\n",
      "0.234\n",
      "0.249\n",
      "0.119\n",
      "0.142\n",
      "0.519\n",
      "0.123\n",
      "0.259\n",
      "0.108\n",
      "0.266\n",
      "0.121\n",
      "0.380\n",
      "0.101\n",
      "0.354\n",
      "0.139\n",
      "0.133\n",
      "0.533\n",
      "0.658\n",
      "0.555\n",
      "0.265\n",
      "0.365\n",
      "0.102\n",
      "0.185\n",
      "0.310\n",
      "0.554\n",
      "0.321\n",
      "0.747\n",
      "0.549\n",
      "0.356\n",
      "0.505\n",
      "0.317\n",
      "0.373\n",
      "0.435\n",
      "0.639\n",
      "0.509\n",
      "0.278\n",
      "0.142\n",
      "0.339\n",
      "0.253\n",
      "0.454\n",
      "0.619\n",
      "0.555\n",
      "0.349\n",
      "0.237\n",
      "0.428\n",
      "0.224\n",
      "0.194\n",
      "0.215\n",
      "0.536\n",
      "0.112\n",
      "0.967\n",
      "0.582\n",
      "0.447\n",
      "0.979\n",
      "0.849\n",
      "0.352\n",
      "0.134\n",
      "0.673\n",
      "0.557\n",
      "0.290\n",
      "0.330\n",
      "0.842\n",
      "0.983\n",
      "0.583\n",
      "0.475\n",
      "0.424\n",
      "0.876\n",
      "0.587\n",
      "0.986\n",
      "0.587\n",
      "0.805\n",
      "0.705\n",
      "0.365\n",
      "0.239\n",
      "0.355\n",
      "0.355\n",
      "0.370\n",
      "0.205\n",
      "0.194\n",
      "0.191\n",
      "0.316\n",
      "0.290\n",
      "0.461\n",
      "0.206\n",
      "0.251\n",
      "0.145\n",
      "0.342\n",
      "0.384\n",
      "0.313\n",
      "0.200\n",
      "0.612\n",
      "0.428\n",
      "0.362\n",
      "0.138\n",
      "0.144\n",
      "0.447\n",
      "0.205\n",
      "0.179\n",
      "0.347\n",
      "0.428\n",
      "0.475\n",
      "0.635\n",
      "0.318\n",
      "0.161\n",
      "0.937\n",
      "0.849\n",
      "0.118\n",
      "0.263\n",
      "0.638\n",
      "0.532\n",
      "0.318\n",
      "0.309\n",
      "0.986\n",
      "0.443\n",
      "0.261\n",
      "0.546\n",
      "0.674\n",
      "0.155\n",
      "0.732\n",
      "0.653\n",
      "0.252\n",
      "0.618\n",
      "0.672\n",
      "0.171\n",
      "0.298\n",
      "0.102\n",
      "0.323\n",
      "0.615\n",
      "0.269\n",
      "0.348\n",
      "0.785\n",
      "0.374\n",
      "0.119\n",
      "0.632\n",
      "0.250\n",
      "0.421\n",
      "0.103\n",
      "0.103\n",
      "0.500\n",
      "0.104\n",
      "0.407\n",
      "0.250\n",
      "0.156\n",
      "0.510\n",
      "0.112\n",
      "0.478\n",
      "0.119\n",
      "0.103\n",
      "0.551\n",
      "0.685\n",
      "0.270\n",
      "0.377\n",
      "0.159\n",
      "0.149\n",
      "0.752\n",
      "0.877\n",
      "0.273\n",
      "0.181\n",
      "0.237\n",
      "0.312\n",
      "0.591\n",
      "0.202\n",
      "0.340\n",
      "0.098\n",
      "0.167\n",
      "0.094\n",
      "0.097\n",
      "0.107\n",
      "0.127\n",
      "0.237\n",
      "0.237\n",
      "0.252\n",
      "0.122\n",
      "0.145\n",
      "0.522\n",
      "0.125\n",
      "0.261\n",
      "0.111\n",
      "0.269\n",
      "0.124\n",
      "0.383\n",
      "0.104\n",
      "0.357\n",
      "0.142\n",
      "0.136\n",
      "0.536\n",
      "0.661\n",
      "0.558\n",
      "0.267\n",
      "0.368\n",
      "0.105\n",
      "0.188\n",
      "0.313\n",
      "0.557\n",
      "0.324\n",
      "0.750\n",
      "0.552\n",
      "0.359\n",
      "0.507\n",
      "0.320\n",
      "0.375\n",
      "0.438\n",
      "0.642\n",
      "0.512\n",
      "0.281\n",
      "0.144\n",
      "0.342\n",
      "0.256\n",
      "0.456\n",
      "0.621\n",
      "0.558\n",
      "0.352\n",
      "0.239\n",
      "0.430\n",
      "0.226\n",
      "0.197\n",
      "0.218\n",
      "0.539\n",
      "0.115\n",
      "0.970\n",
      "0.584\n",
      "0.449\n",
      "0.982\n",
      "0.851\n",
      "0.355\n",
      "0.136\n",
      "0.676\n",
      "0.559\n",
      "0.293\n",
      "0.332\n",
      "0.845\n",
      "0.985\n",
      "0.585\n",
      "0.477\n",
      "0.427\n",
      "0.879\n",
      "0.590\n",
      "0.989\n",
      "0.590\n",
      "0.808\n",
      "0.707\n",
      "0.367\n",
      "0.242\n",
      "0.358\n",
      "0.357\n",
      "0.372\n",
      "0.208\n",
      "0.197\n",
      "0.194\n",
      "0.319\n",
      "0.292\n",
      "0.464\n",
      "0.208\n",
      "0.253\n",
      "0.148\n",
      "0.345\n",
      "0.387\n",
      "0.316\n",
      "0.202\n",
      "0.615\n",
      "0.431\n",
      "0.365\n",
      "0.141\n",
      "0.147\n",
      "0.450\n",
      "0.208\n",
      "0.181\n",
      "0.349\n",
      "0.430\n",
      "0.478\n",
      "0.637\n",
      "0.320\n",
      "0.163\n",
      "0.940\n",
      "0.852\n",
      "0.121\n",
      "0.266\n",
      "0.641\n",
      "0.534\n",
      "0.321\n",
      "0.311\n",
      "0.989\n",
      "0.445\n",
      "0.264\n",
      "0.549\n",
      "0.677\n",
      "0.158\n",
      "0.735\n",
      "0.655\n",
      "0.254\n",
      "0.621\n",
      "0.675\n",
      "0.173\n",
      "0.301\n",
      "0.105\n",
      "0.326\n",
      "0.618\n",
      "0.272\n",
      "0.351\n",
      "0.788\n",
      "0.376\n",
      "0.122\n",
      "0.634\n",
      "0.253\n",
      "0.424\n",
      "0.106\n",
      "0.106\n",
      "0.502\n",
      "0.107\n",
      "0.410\n",
      "0.253\n",
      "0.158\n",
      "0.512\n",
      "0.115\n",
      "0.481\n",
      "0.122\n",
      "0.106\n",
      "0.554\n",
      "0.687\n",
      "0.272\n",
      "0.380\n",
      "0.162\n",
      "0.122\n",
      "0.725\n",
      "0.850\n",
      "0.246\n",
      "0.154\n",
      "0.210\n",
      "0.285\n",
      "0.564\n",
      "0.175\n",
      "0.314\n",
      "0.071\n",
      "0.140\n",
      "0.067\n",
      "0.070\n",
      "0.080\n",
      "0.100\n",
      "0.210\n",
      "0.210\n",
      "0.225\n",
      "0.095\n",
      "0.118\n",
      "0.495\n",
      "0.099\n",
      "0.234\n",
      "0.084\n",
      "0.242\n",
      "0.097\n",
      "0.356\n",
      "0.077\n",
      "0.330\n",
      "0.115\n",
      "0.109\n",
      "0.509\n",
      "0.634\n",
      "0.531\n",
      "0.241\n",
      "0.341\n",
      "0.078\n",
      "0.161\n",
      "0.286\n",
      "0.530\n",
      "0.297\n",
      "0.723\n",
      "0.525\n",
      "0.332\n",
      "0.481\n",
      "0.293\n",
      "0.349\n",
      "0.411\n",
      "0.615\n",
      "0.485\n",
      "0.254\n",
      "0.117\n",
      "0.315\n",
      "0.229\n",
      "0.430\n",
      "0.595\n",
      "0.531\n",
      "0.325\n",
      "0.213\n",
      "0.403\n",
      "0.200\n",
      "0.170\n",
      "0.191\n",
      "0.512\n",
      "0.088\n",
      "0.943\n",
      "0.558\n",
      "0.423\n",
      "0.955\n",
      "0.824\n",
      "0.328\n",
      "0.110\n",
      "0.649\n",
      "0.532\n",
      "0.266\n",
      "0.306\n",
      "0.818\n",
      "0.959\n",
      "0.558\n",
      "0.451\n",
      "0.400\n",
      "0.852\n",
      "0.563\n",
      "0.962\n",
      "0.563\n",
      "0.781\n",
      "0.681\n",
      "0.341\n",
      "0.215\n",
      "0.331\n",
      "0.331\n",
      "0.346\n",
      "0.181\n",
      "0.170\n",
      "0.167\n",
      "0.292\n",
      "0.266\n",
      "0.437\n",
      "0.182\n",
      "0.227\n",
      "0.121\n",
      "0.318\n",
      "0.360\n",
      "0.289\n",
      "0.176\n",
      "0.588\n",
      "0.404\n",
      "0.338\n",
      "0.114\n",
      "0.120\n",
      "0.423\n",
      "0.181\n",
      "0.155\n",
      "0.323\n",
      "0.403\n",
      "0.451\n",
      "0.611\n",
      "0.294\n",
      "0.137\n",
      "0.913\n",
      "0.825\n",
      "0.094\n",
      "0.239\n",
      "0.614\n",
      "0.508\n",
      "0.294\n",
      "0.285\n",
      "0.962\n",
      "0.419\n",
      "0.237\n",
      "0.522\n",
      "0.650\n",
      "0.131\n",
      "0.708\n",
      "0.628\n",
      "0.228\n",
      "0.594\n",
      "0.648\n",
      "0.146\n",
      "0.274\n",
      "0.078\n",
      "0.299\n",
      "0.591\n",
      "0.245\n",
      "0.324\n",
      "0.761\n",
      "0.350\n",
      "0.095\n",
      "0.607\n",
      "0.226\n",
      "0.397\n",
      "0.079\n",
      "0.079\n",
      "0.476\n",
      "0.080\n",
      "0.383\n",
      "0.226\n",
      "0.131\n",
      "0.486\n",
      "0.088\n",
      "0.454\n",
      "0.095\n",
      "0.079\n",
      "0.527\n",
      "0.660\n",
      "0.245\n",
      "0.353\n",
      "0.135\n",
      "0.148\n",
      "0.751\n",
      "0.876\n",
      "0.272\n",
      "0.180\n",
      "0.235\n",
      "0.310\n",
      "0.589\n",
      "0.200\n",
      "0.339\n",
      "0.097\n",
      "0.166\n",
      "0.092\n",
      "0.095\n",
      "0.106\n",
      "0.126\n",
      "0.235\n",
      "0.235\n",
      "0.251\n",
      "0.120\n",
      "0.144\n",
      "0.520\n",
      "0.124\n",
      "0.260\n",
      "0.110\n",
      "0.267\n",
      "0.122\n",
      "0.381\n",
      "0.102\n",
      "0.356\n",
      "0.140\n",
      "0.135\n",
      "0.535\n",
      "0.659\n",
      "0.556\n",
      "0.266\n",
      "0.367\n",
      "0.103\n",
      "0.187\n",
      "0.312\n",
      "0.555\n",
      "0.322\n",
      "0.748\n",
      "0.551\n",
      "0.357\n",
      "0.506\n",
      "0.318\n",
      "0.374\n",
      "0.437\n",
      "0.640\n",
      "0.510\n",
      "0.279\n",
      "0.143\n",
      "0.340\n",
      "0.254\n",
      "0.455\n",
      "0.620\n",
      "0.557\n",
      "0.350\n",
      "0.238\n",
      "0.429\n",
      "0.225\n",
      "0.195\n",
      "0.217\n",
      "0.538\n",
      "0.114\n",
      "0.968\n",
      "0.583\n",
      "0.448\n",
      "0.981\n",
      "0.850\n",
      "0.353\n",
      "0.135\n",
      "0.674\n",
      "0.558\n",
      "0.292\n",
      "0.331\n",
      "0.843\n",
      "0.984\n",
      "0.584\n",
      "0.476\n",
      "0.425\n",
      "0.877\n",
      "0.588\n",
      "0.988\n",
      "0.588\n",
      "0.807\n",
      "0.706\n",
      "0.366\n",
      "0.240\n",
      "0.357\n",
      "0.356\n",
      "0.371\n",
      "0.206\n",
      "0.195\n",
      "0.193\n",
      "0.317\n",
      "0.291\n",
      "0.462\n",
      "0.207\n",
      "0.252\n",
      "0.147\n",
      "0.343\n",
      "0.386\n",
      "0.314\n",
      "0.201\n",
      "0.613\n",
      "0.430\n",
      "0.363\n",
      "0.139\n",
      "0.146\n",
      "0.448\n",
      "0.206\n",
      "0.180\n",
      "0.348\n",
      "0.429\n",
      "0.477\n",
      "0.636\n",
      "0.319\n",
      "0.162\n",
      "0.938\n",
      "0.851\n",
      "0.119\n",
      "0.265\n",
      "0.639\n",
      "0.533\n",
      "0.319\n",
      "0.310\n",
      "0.987\n",
      "0.444\n",
      "0.263\n",
      "0.548\n",
      "0.675\n",
      "0.156\n",
      "0.733\n",
      "0.654\n",
      "0.253\n",
      "0.619\n",
      "0.673\n",
      "0.172\n",
      "0.300\n",
      "0.103\n",
      "0.324\n",
      "0.616\n",
      "0.270\n",
      "0.349\n",
      "0.786\n",
      "0.375\n",
      "0.120\n",
      "0.633\n",
      "0.251\n",
      "0.422\n",
      "0.104\n",
      "0.104\n",
      "0.501\n",
      "0.106\n",
      "0.409\n",
      "0.252\n",
      "0.157\n",
      "0.511\n",
      "0.114\n",
      "0.480\n",
      "0.120\n",
      "0.104\n",
      "0.553\n",
      "0.686\n",
      "0.271\n",
      "0.378\n",
      "0.161\n",
      "0.147\n",
      "0.750\n",
      "0.875\n",
      "0.271\n",
      "0.179\n",
      "0.234\n",
      "0.310\n",
      "0.588\n",
      "0.199\n",
      "0.338\n",
      "0.096\n",
      "0.165\n",
      "0.091\n",
      "0.094\n",
      "0.105\n",
      "0.125\n",
      "0.235\n",
      "0.235\n",
      "0.250\n",
      "0.119\n",
      "0.143\n",
      "0.519\n",
      "0.123\n",
      "0.259\n",
      "0.109\n",
      "0.266\n",
      "0.121\n",
      "0.381\n",
      "0.101\n",
      "0.355\n",
      "0.139\n",
      "0.134\n",
      "0.534\n",
      "0.658\n",
      "0.556\n",
      "0.265\n",
      "0.366\n",
      "0.103\n",
      "0.186\n",
      "0.311\n",
      "0.554\n",
      "0.321\n",
      "0.747\n",
      "0.550\n",
      "0.357\n",
      "0.505\n",
      "0.317\n",
      "0.373\n",
      "0.436\n",
      "0.639\n",
      "0.509\n",
      "0.279\n",
      "0.142\n",
      "0.339\n",
      "0.253\n",
      "0.454\n",
      "0.619\n",
      "0.556\n",
      "0.349\n",
      "0.237\n",
      "0.428\n",
      "0.224\n",
      "0.194\n",
      "0.216\n",
      "0.537\n",
      "0.113\n",
      "0.967\n",
      "0.582\n",
      "0.447\n",
      "0.980\n",
      "0.849\n",
      "0.352\n",
      "0.134\n",
      "0.673\n",
      "0.557\n",
      "0.291\n",
      "0.330\n",
      "0.843\n",
      "0.983\n",
      "0.583\n",
      "0.475\n",
      "0.424\n",
      "0.877\n",
      "0.587\n",
      "0.987\n",
      "0.588\n",
      "0.806\n",
      "0.705\n",
      "0.365\n",
      "0.239\n",
      "0.356\n",
      "0.355\n",
      "0.370\n",
      "0.206\n",
      "0.194\n",
      "0.192\n",
      "0.316\n",
      "0.290\n",
      "0.462\n",
      "0.206\n",
      "0.251\n",
      "0.146\n",
      "0.342\n",
      "0.385\n",
      "0.314\n",
      "0.200\n",
      "0.612\n",
      "0.429\n",
      "0.362\n",
      "0.138\n",
      "0.145\n",
      "0.448\n",
      "0.206\n",
      "0.179\n",
      "0.347\n",
      "0.428\n",
      "0.476\n",
      "0.635\n",
      "0.318\n",
      "0.161\n",
      "0.938\n",
      "0.850\n",
      "0.118\n",
      "0.264\n",
      "0.638\n",
      "0.532\n",
      "0.319\n",
      "0.309\n",
      "0.986\n",
      "0.443\n",
      "0.262\n",
      "0.547\n",
      "0.674\n",
      "0.155\n",
      "0.732\n",
      "0.653\n",
      "0.252\n",
      "0.618\n",
      "0.672\n",
      "0.171\n",
      "0.299\n",
      "0.102\n",
      "0.323\n",
      "0.615\n",
      "0.270\n",
      "0.348\n",
      "0.786\n",
      "0.374\n",
      "0.120\n",
      "0.632\n",
      "0.250\n",
      "0.422\n",
      "0.103\n",
      "0.103\n",
      "0.500\n",
      "0.105\n",
      "0.408\n",
      "0.251\n",
      "0.156\n",
      "0.510\n",
      "0.113\n",
      "0.479\n",
      "0.120\n",
      "0.103\n",
      "0.552\n",
      "0.685\n",
      "0.270\n",
      "0.377\n",
      "0.160\n",
      "0.138\n",
      "0.741\n",
      "0.866\n",
      "0.262\n",
      "0.170\n",
      "0.226\n",
      "0.301\n",
      "0.580\n",
      "0.191\n",
      "0.329\n",
      "0.087\n",
      "0.156\n",
      "0.083\n",
      "0.086\n",
      "0.096\n",
      "0.116\n",
      "0.226\n",
      "0.226\n",
      "0.241\n",
      "0.111\n",
      "0.134\n",
      "0.511\n",
      "0.114\n",
      "0.250\n",
      "0.100\n",
      "0.258\n",
      "0.113\n",
      "0.372\n",
      "0.093\n",
      "0.346\n",
      "0.131\n",
      "0.125\n",
      "0.525\n",
      "0.650\n",
      "0.547\n",
      "0.256\n",
      "0.357\n",
      "0.094\n",
      "0.177\n",
      "0.302\n",
      "0.546\n",
      "0.313\n",
      "0.739\n",
      "0.541\n",
      "0.348\n",
      "0.496\n",
      "0.309\n",
      "0.364\n",
      "0.427\n",
      "0.631\n",
      "0.501\n",
      "0.270\n",
      "0.133\n",
      "0.331\n",
      "0.245\n",
      "0.445\n",
      "0.610\n",
      "0.547\n",
      "0.341\n",
      "0.228\n",
      "0.419\n",
      "0.215\n",
      "0.186\n",
      "0.207\n",
      "0.528\n",
      "0.104\n",
      "0.959\n",
      "0.574\n",
      "0.438\n",
      "0.971\n",
      "0.840\n",
      "0.344\n",
      "0.125\n",
      "0.665\n",
      "0.548\n",
      "0.282\n",
      "0.321\n",
      "0.834\n",
      "0.974\n",
      "0.574\n",
      "0.466\n",
      "0.416\n",
      "0.868\n",
      "0.579\n",
      "0.978\n",
      "0.579\n",
      "0.797\n",
      "0.696\n",
      "0.356\n",
      "0.231\n",
      "0.347\n",
      "0.346\n",
      "0.361\n",
      "0.197\n",
      "0.186\n",
      "0.183\n",
      "0.308\n",
      "0.282\n",
      "0.453\n",
      "0.197\n",
      "0.242\n",
      "0.137\n",
      "0.334\n",
      "0.376\n",
      "0.305\n",
      "0.191\n",
      "0.604\n",
      "0.420\n",
      "0.354\n",
      "0.130\n",
      "0.136\n",
      "0.439\n",
      "0.197\n",
      "0.170\n",
      "0.338\n",
      "0.419\n",
      "0.467\n",
      "0.626\n",
      "0.309\n",
      "0.152\n",
      "0.929\n",
      "0.841\n",
      "0.110\n",
      "0.255\n",
      "0.630\n",
      "0.523\n",
      "0.310\n",
      "0.300\n",
      "0.978\n",
      "0.434\n",
      "0.253\n",
      "0.538\n",
      "0.666\n",
      "0.147\n",
      "0.724\n",
      "0.644\n",
      "0.243\n",
      "0.610\n",
      "0.664\n",
      "0.162\n",
      "0.290\n",
      "0.094\n",
      "0.315\n",
      "0.607\n",
      "0.261\n",
      "0.340\n",
      "0.777\n",
      "0.365\n",
      "0.111\n",
      "0.623\n",
      "0.242\n",
      "0.413\n",
      "0.095\n",
      "0.095\n",
      "0.491\n",
      "0.096\n",
      "0.399\n",
      "0.242\n",
      "0.147\n",
      "0.501\n",
      "0.104\n",
      "0.470\n",
      "0.111\n",
      "0.095\n",
      "0.543\n",
      "0.676\n",
      "0.261\n",
      "0.369\n",
      "0.151\n",
      "0.151\n",
      "0.754\n",
      "0.880\n",
      "0.275\n",
      "0.183\n",
      "0.239\n",
      "0.314\n",
      "0.593\n",
      "0.204\n",
      "0.343\n",
      "0.100\n",
      "0.169\n",
      "0.096\n",
      "0.099\n",
      "0.109\n",
      "0.129\n",
      "0.239\n",
      "0.239\n",
      "0.254\n",
      "0.124\n",
      "0.147\n",
      "0.524\n",
      "0.128\n",
      "0.263\n",
      "0.113\n",
      "0.271\n",
      "0.126\n",
      "0.385\n",
      "0.106\n",
      "0.359\n",
      "0.144\n",
      "0.138\n",
      "0.538\n",
      "0.663\n",
      "0.560\n",
      "0.270\n",
      "0.370\n",
      "0.107\n",
      "0.190\n",
      "0.315\n",
      "0.559\n",
      "0.326\n",
      "0.752\n",
      "0.554\n",
      "0.361\n",
      "0.510\n",
      "0.322\n",
      "0.378\n",
      "0.440\n",
      "0.644\n",
      "0.514\n",
      "0.283\n",
      "0.146\n",
      "0.344\n",
      "0.258\n",
      "0.459\n",
      "0.624\n",
      "0.560\n",
      "0.354\n",
      "0.242\n",
      "0.433\n",
      "0.229\n",
      "0.199\n",
      "0.220\n",
      "0.541\n",
      "0.117\n",
      "0.972\n",
      "0.587\n",
      "0.452\n",
      "0.984\n",
      "0.853\n",
      "0.357\n",
      "0.139\n",
      "0.678\n",
      "0.561\n",
      "0.295\n",
      "0.335\n",
      "0.847\n",
      "0.988\n",
      "0.587\n",
      "0.480\n",
      "0.429\n",
      "0.881\n",
      "0.592\n",
      "0.991\n",
      "0.592\n",
      "0.810\n",
      "0.710\n",
      "0.370\n",
      "0.244\n",
      "0.360\n",
      "0.360\n",
      "0.375\n",
      "0.210\n",
      "0.199\n",
      "0.196\n",
      "0.321\n",
      "0.295\n",
      "0.466\n",
      "0.211\n",
      "0.256\n",
      "0.150\n",
      "0.347\n",
      "0.389\n",
      "0.318\n",
      "0.205\n",
      "0.617\n",
      "0.433\n",
      "0.367\n",
      "0.143\n",
      "0.149\n",
      "0.452\n",
      "0.210\n",
      "0.184\n",
      "0.352\n",
      "0.433\n",
      "0.480\n",
      "0.640\n",
      "0.323\n",
      "0.166\n",
      "0.942\n",
      "0.854\n",
      "0.123\n",
      "0.268\n",
      "0.643\n",
      "0.537\n",
      "0.323\n",
      "0.314\n",
      "0.991\n",
      "0.448\n",
      "0.266\n",
      "0.551\n",
      "0.679\n",
      "0.160\n",
      "0.737\n",
      "0.658\n",
      "0.257\n",
      "0.623\n",
      "0.677\n",
      "0.176\n",
      "0.303\n",
      "0.107\n",
      "0.328\n",
      "0.620\n",
      "0.274\n",
      "0.353\n",
      "0.790\n",
      "0.379\n",
      "0.124\n",
      "0.637\n",
      "0.255\n",
      "0.426\n",
      "0.108\n",
      "0.108\n",
      "0.505\n",
      "0.109\n",
      "0.412\n",
      "0.255\n",
      "0.161\n",
      "0.515\n",
      "0.117\n",
      "0.483\n",
      "0.124\n",
      "0.108\n",
      "0.556\n",
      "0.690\n",
      "0.275\n",
      "0.382\n",
      "0.164\n",
      "0.159\n",
      "0.761\n",
      "0.887\n",
      "0.282\n",
      "0.191\n",
      "0.246\n",
      "0.321\n",
      "0.600\n",
      "0.211\n",
      "0.350\n",
      "0.108\n",
      "0.176\n",
      "0.103\n",
      "0.106\n",
      "0.117\n",
      "0.137\n",
      "0.246\n",
      "0.246\n",
      "0.261\n",
      "0.131\n",
      "0.154\n",
      "0.531\n",
      "0.135\n",
      "0.271\n",
      "0.121\n",
      "0.278\n",
      "0.133\n",
      "0.392\n",
      "0.113\n",
      "0.366\n",
      "0.151\n",
      "0.146\n",
      "0.546\n",
      "0.670\n",
      "0.567\n",
      "0.277\n",
      "0.378\n",
      "0.114\n",
      "0.197\n",
      "0.323\n",
      "0.566\n",
      "0.333\n",
      "0.759\n",
      "0.562\n",
      "0.368\n",
      "0.517\n",
      "0.329\n",
      "0.385\n",
      "0.448\n",
      "0.651\n",
      "0.521\n",
      "0.290\n",
      "0.154\n",
      "0.351\n",
      "0.265\n",
      "0.466\n",
      "0.631\n",
      "0.568\n",
      "0.361\n",
      "0.249\n",
      "0.440\n",
      "0.236\n",
      "0.206\n",
      "0.227\n",
      "0.549\n",
      "0.125\n",
      "0.979\n",
      "0.594\n",
      "0.459\n",
      "0.992\n",
      "0.861\n",
      "0.364\n",
      "0.146\n",
      "0.685\n",
      "0.569\n",
      "0.302\n",
      "0.342\n",
      "0.854\n",
      "0.995\n",
      "0.595\n",
      "0.487\n",
      "0.436\n",
      "0.888\n",
      "0.599\n",
      "0.998\n",
      "0.599\n",
      "0.817\n",
      "0.717\n",
      "0.377\n",
      "0.251\n",
      "0.368\n",
      "0.367\n",
      "0.382\n",
      "0.217\n",
      "0.206\n",
      "0.203\n",
      "0.328\n",
      "0.302\n",
      "0.473\n",
      "0.218\n",
      "0.263\n",
      "0.158\n",
      "0.354\n",
      "0.397\n",
      "0.325\n",
      "0.212\n",
      "0.624\n",
      "0.441\n",
      "0.374\n",
      "0.150\n",
      "0.156\n",
      "0.459\n",
      "0.217\n",
      "0.191\n",
      "0.359\n",
      "0.440\n",
      "0.487\n",
      "0.647\n",
      "0.330\n",
      "0.173\n",
      "0.949\n",
      "0.861\n",
      "0.130\n",
      "0.276\n",
      "0.650\n",
      "0.544\n",
      "0.330\n",
      "0.321\n",
      "0.998\n",
      "0.455\n",
      "0.274\n",
      "0.559\n",
      "0.686\n",
      "0.167\n",
      "0.744\n",
      "0.665\n",
      "0.264\n",
      "0.630\n",
      "0.684\n",
      "0.183\n",
      "0.311\n",
      "0.114\n",
      "0.335\n",
      "0.627\n",
      "0.281\n",
      "0.360\n",
      "0.797\n",
      "0.386\n",
      "0.131\n",
      "0.644\n",
      "0.262\n",
      "0.433\n",
      "0.115\n",
      "0.115\n",
      "0.512\n",
      "0.117\n",
      "0.419\n",
      "0.262\n",
      "0.168\n",
      "0.522\n",
      "0.124\n",
      "0.490\n",
      "0.131\n",
      "0.115\n",
      "0.564\n",
      "0.697\n",
      "0.282\n",
      "0.389\n",
      "0.172\n",
      "0.157\n",
      "0.760\n",
      "0.885\n",
      "0.281\n",
      "0.189\n",
      "0.245\n",
      "0.320\n",
      "0.599\n",
      "0.210\n",
      "0.349\n",
      "0.106\n",
      "0.175\n",
      "0.102\n",
      "0.105\n",
      "0.115\n",
      "0.135\n",
      "0.245\n",
      "0.245\n",
      "0.260\n",
      "0.130\n",
      "0.153\n",
      "0.530\n",
      "0.133\n",
      "0.269\n",
      "0.119\n",
      "0.277\n",
      "0.132\n",
      "0.391\n",
      "0.112\n",
      "0.365\n",
      "0.150\n",
      "0.144\n",
      "0.544\n",
      "0.669\n",
      "0.566\n",
      "0.276\n",
      "0.376\n",
      "0.113\n",
      "0.196\n",
      "0.321\n",
      "0.565\n",
      "0.332\n",
      "0.758\n",
      "0.560\n",
      "0.367\n",
      "0.516\n",
      "0.328\n",
      "0.384\n",
      "0.446\n",
      "0.650\n",
      "0.520\n",
      "0.289\n",
      "0.152\n",
      "0.350\n",
      "0.264\n",
      "0.465\n",
      "0.630\n",
      "0.566\n",
      "0.360\n",
      "0.247\n",
      "0.438\n",
      "0.235\n",
      "0.205\n",
      "0.226\n",
      "0.547\n",
      "0.123\n",
      "0.978\n",
      "0.593\n",
      "0.458\n",
      "0.990\n",
      "0.859\n",
      "0.363\n",
      "0.145\n",
      "0.684\n",
      "0.567\n",
      "0.301\n",
      "0.341\n",
      "0.853\n",
      "0.994\n",
      "0.593\n",
      "0.486\n",
      "0.435\n",
      "0.887\n",
      "0.598\n",
      "0.997\n",
      "0.598\n",
      "0.816\n",
      "0.716\n",
      "0.376\n",
      "0.250\n",
      "0.366\n",
      "0.366\n",
      "0.381\n",
      "0.216\n",
      "0.205\n",
      "0.202\n",
      "0.327\n",
      "0.301\n",
      "0.472\n",
      "0.217\n",
      "0.262\n",
      "0.156\n",
      "0.353\n",
      "0.395\n",
      "0.324\n",
      "0.211\n",
      "0.623\n",
      "0.439\n",
      "0.373\n",
      "0.149\n",
      "0.155\n",
      "0.458\n",
      "0.216\n",
      "0.189\n",
      "0.358\n",
      "0.438\n",
      "0.486\n",
      "0.646\n",
      "0.329\n",
      "0.171\n",
      "0.948\n",
      "0.860\n",
      "0.129\n",
      "0.274\n",
      "0.649\n",
      "0.542\n",
      "0.329\n",
      "0.320\n",
      "0.997\n",
      "0.454\n",
      "0.272\n",
      "0.557\n",
      "0.685\n",
      "0.166\n",
      "0.743\n",
      "0.663\n",
      "0.262\n",
      "0.629\n",
      "0.683\n",
      "0.181\n",
      "0.309\n",
      "0.113\n",
      "0.334\n",
      "0.626\n",
      "0.280\n",
      "0.359\n",
      "0.796\n",
      "0.385\n",
      "0.130\n",
      "0.642\n",
      "0.261\n",
      "0.432\n",
      "0.114\n",
      "0.114\n",
      "0.510\n",
      "0.115\n",
      "0.418\n",
      "0.261\n",
      "0.166\n",
      "0.521\n",
      "0.123\n",
      "0.489\n",
      "0.130\n",
      "0.114\n",
      "0.562\n",
      "0.695\n",
      "0.280\n",
      "0.388\n",
      "0.170\n",
      "0.153\n",
      "0.756\n",
      "0.881\n",
      "0.276\n",
      "0.185\n",
      "0.240\n",
      "0.315\n",
      "0.594\n",
      "0.205\n",
      "0.344\n",
      "0.102\n",
      "0.171\n",
      "0.097\n",
      "0.100\n",
      "0.111\n",
      "0.131\n",
      "0.240\n",
      "0.240\n",
      "0.256\n",
      "0.125\n",
      "0.148\n",
      "0.525\n",
      "0.129\n",
      "0.265\n",
      "0.115\n",
      "0.272\n",
      "0.127\n",
      "0.386\n",
      "0.107\n",
      "0.361\n",
      "0.145\n",
      "0.140\n",
      "0.540\n",
      "0.664\n",
      "0.561\n",
      "0.271\n",
      "0.372\n",
      "0.108\n",
      "0.192\n",
      "0.317\n",
      "0.560\n",
      "0.327\n",
      "0.753\n",
      "0.556\n",
      "0.362\n",
      "0.511\n",
      "0.323\n",
      "0.379\n",
      "0.442\n",
      "0.645\n",
      "0.515\n",
      "0.284\n",
      "0.148\n",
      "0.345\n",
      "0.259\n",
      "0.460\n",
      "0.625\n",
      "0.562\n",
      "0.355\n",
      "0.243\n",
      "0.434\n",
      "0.230\n",
      "0.200\n",
      "0.221\n",
      "0.543\n",
      "0.119\n",
      "0.973\n",
      "0.588\n",
      "0.453\n",
      "0.986\n",
      "0.855\n",
      "0.358\n",
      "0.140\n",
      "0.679\n",
      "0.563\n",
      "0.297\n",
      "0.336\n",
      "0.848\n",
      "0.989\n",
      "0.589\n",
      "0.481\n",
      "0.430\n",
      "0.882\n",
      "0.593\n",
      "0.992\n",
      "0.593\n",
      "0.811\n",
      "0.711\n",
      "0.371\n",
      "0.245\n",
      "0.362\n",
      "0.361\n",
      "0.376\n",
      "0.211\n",
      "0.200\n",
      "0.198\n",
      "0.322\n",
      "0.296\n",
      "0.467\n",
      "0.212\n",
      "0.257\n",
      "0.152\n",
      "0.348\n",
      "0.391\n",
      "0.319\n",
      "0.206\n",
      "0.618\n",
      "0.435\n",
      "0.368\n",
      "0.144\n",
      "0.151\n",
      "0.453\n",
      "0.211\n",
      "0.185\n",
      "0.353\n",
      "0.434\n",
      "0.481\n",
      "0.641\n",
      "0.324\n",
      "0.167\n",
      "0.943\n",
      "0.855\n",
      "0.124\n",
      "0.270\n",
      "0.644\n",
      "0.538\n",
      "0.324\n",
      "0.315\n",
      "0.992\n",
      "0.449\n",
      "0.268\n",
      "0.553\n",
      "0.680\n",
      "0.161\n",
      "0.738\n",
      "0.659\n",
      "0.258\n",
      "0.624\n",
      "0.678\n",
      "0.177\n",
      "0.305\n",
      "0.108\n",
      "0.329\n",
      "0.621\n",
      "0.275\n",
      "0.354\n",
      "0.791\n",
      "0.380\n",
      "0.125\n",
      "0.638\n",
      "0.256\n",
      "0.427\n",
      "0.109\n",
      "0.109\n",
      "0.506\n",
      "0.111\n",
      "0.414\n",
      "0.256\n",
      "0.162\n",
      "0.516\n",
      "0.119\n",
      "0.484\n",
      "0.125\n",
      "0.109\n",
      "0.558\n",
      "0.691\n",
      "0.276\n",
      "0.383\n",
      "0.166\n",
      "0.145\n",
      "0.748\n",
      "0.873\n",
      "0.269\n",
      "0.177\n",
      "0.232\n",
      "0.308\n",
      "0.586\n",
      "0.197\n",
      "0.336\n",
      "0.094\n",
      "0.163\n",
      "0.089\n",
      "0.092\n",
      "0.103\n",
      "0.123\n",
      "0.233\n",
      "0.233\n",
      "0.248\n",
      "0.117\n",
      "0.141\n",
      "0.517\n",
      "0.121\n",
      "0.257\n",
      "0.107\n",
      "0.264\n",
      "0.119\n",
      "0.379\n",
      "0.099\n",
      "0.353\n",
      "0.137\n",
      "0.132\n",
      "0.532\n",
      "0.656\n",
      "0.554\n",
      "0.263\n",
      "0.364\n",
      "0.101\n",
      "0.184\n",
      "0.309\n",
      "0.552\n",
      "0.319\n",
      "0.745\n",
      "0.548\n",
      "0.355\n",
      "0.503\n",
      "0.315\n",
      "0.371\n",
      "0.434\n",
      "0.637\n",
      "0.507\n",
      "0.276\n",
      "0.140\n",
      "0.337\n",
      "0.251\n",
      "0.452\n",
      "0.617\n",
      "0.554\n",
      "0.347\n",
      "0.235\n",
      "0.426\n",
      "0.222\n",
      "0.192\n",
      "0.214\n",
      "0.535\n",
      "0.111\n",
      "0.965\n",
      "0.580\n",
      "0.445\n",
      "0.978\n",
      "0.847\n",
      "0.350\n",
      "0.132\n",
      "0.671\n",
      "0.555\n",
      "0.289\n",
      "0.328\n",
      "0.840\n",
      "0.981\n",
      "0.581\n",
      "0.473\n",
      "0.422\n",
      "0.875\n",
      "0.585\n",
      "0.985\n",
      "0.586\n",
      "0.804\n",
      "0.703\n",
      "0.363\n",
      "0.237\n",
      "0.354\n",
      "0.353\n",
      "0.368\n",
      "0.203\n",
      "0.192\n",
      "0.190\n",
      "0.314\n",
      "0.288\n",
      "0.460\n",
      "0.204\n",
      "0.249\n",
      "0.144\n",
      "0.340\n",
      "0.383\n",
      "0.311\n",
      "0.198\n",
      "0.610\n",
      "0.427\n",
      "0.360\n",
      "0.136\n",
      "0.143\n",
      "0.446\n",
      "0.203\n",
      "0.177\n",
      "0.345\n",
      "0.426\n",
      "0.474\n",
      "0.633\n",
      "0.316\n",
      "0.159\n",
      "0.936\n",
      "0.848\n",
      "0.116\n",
      "0.262\n",
      "0.636\n",
      "0.530\n",
      "0.317\n",
      "0.307\n",
      "0.984\n",
      "0.441\n",
      "0.260\n",
      "0.545\n",
      "0.672\n",
      "0.153\n",
      "0.730\n",
      "0.651\n",
      "0.250\n",
      "0.616\n",
      "0.670\n",
      "0.169\n",
      "0.297\n",
      "0.100\n",
      "0.321\n",
      "0.613\n",
      "0.268\n",
      "0.346\n",
      "0.784\n",
      "0.372\n",
      "0.118\n",
      "0.630\n",
      "0.248\n",
      "0.420\n",
      "0.101\n",
      "0.101\n",
      "0.498\n",
      "0.103\n",
      "0.406\n",
      "0.249\n",
      "0.154\n",
      "0.508\n",
      "0.111\n",
      "0.477\n",
      "0.118\n",
      "0.101\n",
      "0.550\n",
      "0.683\n",
      "0.268\n",
      "0.375\n",
      "0.158\n",
      "0.150\n",
      "0.753\n",
      "0.878\n",
      "0.274\n",
      "0.182\n",
      "0.238\n",
      "0.313\n",
      "0.592\n",
      "0.203\n",
      "0.342\n",
      "0.099\n",
      "0.168\n",
      "0.095\n",
      "0.098\n",
      "0.108\n",
      "0.128\n",
      "0.238\n",
      "0.238\n",
      "0.253\n",
      "0.123\n",
      "0.146\n",
      "0.523\n",
      "0.126\n",
      "0.262\n",
      "0.112\n",
      "0.270\n",
      "0.125\n",
      "0.384\n",
      "0.105\n",
      "0.358\n",
      "0.143\n",
      "0.137\n",
      "0.537\n",
      "0.662\n",
      "0.559\n",
      "0.269\n",
      "0.369\n",
      "0.106\n",
      "0.189\n",
      "0.314\n",
      "0.558\n",
      "0.325\n",
      "0.751\n",
      "0.553\n",
      "0.360\n",
      "0.508\n",
      "0.321\n",
      "0.377\n",
      "0.439\n",
      "0.643\n",
      "0.513\n",
      "0.282\n",
      "0.145\n",
      "0.343\n",
      "0.257\n",
      "0.458\n",
      "0.622\n",
      "0.559\n",
      "0.353\n",
      "0.240\n",
      "0.431\n",
      "0.228\n",
      "0.198\n",
      "0.219\n",
      "0.540\n",
      "0.116\n",
      "0.971\n",
      "0.586\n",
      "0.450\n",
      "0.983\n",
      "0.852\n",
      "0.356\n",
      "0.137\n",
      "0.677\n",
      "0.560\n",
      "0.294\n",
      "0.333\n",
      "0.846\n",
      "0.987\n",
      "0.586\n",
      "0.479\n",
      "0.428\n",
      "0.880\n",
      "0.591\n",
      "0.990\n",
      "0.591\n",
      "0.809\n",
      "0.709\n",
      "0.368\n",
      "0.243\n",
      "0.359\n",
      "0.359\n",
      "0.374\n",
      "0.209\n",
      "0.198\n",
      "0.195\n",
      "0.320\n",
      "0.294\n",
      "0.465\n",
      "0.210\n",
      "0.254\n",
      "0.149\n",
      "0.346\n",
      "0.388\n",
      "0.317\n",
      "0.204\n",
      "0.616\n",
      "0.432\n",
      "0.366\n",
      "0.142\n",
      "0.148\n",
      "0.451\n",
      "0.209\n",
      "0.182\n",
      "0.350\n",
      "0.431\n",
      "0.479\n",
      "0.639\n",
      "0.321\n",
      "0.164\n",
      "0.941\n",
      "0.853\n",
      "0.122\n",
      "0.267\n",
      "0.642\n",
      "0.535\n",
      "0.322\n",
      "0.313\n",
      "0.990\n",
      "0.447\n",
      "0.265\n",
      "0.550\n",
      "0.678\n",
      "0.159\n",
      "0.736\n",
      "0.656\n",
      "0.255\n",
      "0.622\n",
      "0.676\n",
      "0.174\n",
      "0.302\n",
      "0.106\n",
      "0.327\n",
      "0.619\n",
      "0.273\n",
      "0.352\n",
      "0.789\n",
      "0.377\n",
      "0.123\n",
      "0.635\n",
      "0.254\n",
      "0.425\n",
      "0.107\n",
      "0.107\n",
      "0.503\n",
      "0.108\n",
      "0.411\n",
      "0.254\n",
      "0.159\n",
      "0.514\n",
      "0.116\n",
      "0.482\n",
      "0.123\n",
      "0.107\n",
      "0.555\n",
      "0.688\n",
      "0.273\n",
      "0.381\n",
      "0.163\n",
      "0.141\n",
      "0.743\n",
      "0.869\n",
      "0.264\n",
      "0.173\n",
      "0.228\n",
      "0.303\n",
      "0.582\n",
      "0.193\n",
      "0.332\n",
      "0.090\n",
      "0.159\n",
      "0.085\n",
      "0.088\n",
      "0.099\n",
      "0.119\n",
      "0.228\n",
      "0.228\n",
      "0.243\n",
      "0.113\n",
      "0.136\n",
      "0.513\n",
      "0.117\n",
      "0.253\n",
      "0.103\n",
      "0.260\n",
      "0.115\n",
      "0.374\n",
      "0.095\n",
      "0.348\n",
      "0.133\n",
      "0.128\n",
      "0.528\n",
      "0.652\n",
      "0.549\n",
      "0.259\n",
      "0.360\n",
      "0.096\n",
      "0.179\n",
      "0.305\n",
      "0.548\n",
      "0.315\n",
      "0.741\n",
      "0.544\n",
      "0.350\n",
      "0.499\n",
      "0.311\n",
      "0.367\n",
      "0.430\n",
      "0.633\n",
      "0.503\n",
      "0.272\n",
      "0.136\n",
      "0.333\n",
      "0.247\n",
      "0.448\n",
      "0.613\n",
      "0.550\n",
      "0.343\n",
      "0.231\n",
      "0.422\n",
      "0.218\n",
      "0.188\n",
      "0.209\n",
      "0.531\n",
      "0.107\n",
      "0.961\n",
      "0.576\n",
      "0.441\n",
      "0.974\n",
      "0.843\n",
      "0.346\n",
      "0.128\n",
      "0.667\n",
      "0.551\n",
      "0.284\n",
      "0.324\n",
      "0.836\n",
      "0.977\n",
      "0.577\n",
      "0.469\n",
      "0.418\n",
      "0.870\n",
      "0.581\n",
      "0.980\n",
      "0.581\n",
      "0.799\n",
      "0.699\n",
      "0.359\n",
      "0.233\n",
      "0.350\n",
      "0.349\n",
      "0.364\n",
      "0.199\n",
      "0.188\n",
      "0.185\n",
      "0.310\n",
      "0.284\n",
      "0.455\n",
      "0.200\n",
      "0.245\n",
      "0.140\n",
      "0.336\n",
      "0.379\n",
      "0.307\n",
      "0.194\n",
      "0.606\n",
      "0.423\n",
      "0.356\n",
      "0.132\n",
      "0.138\n",
      "0.441\n",
      "0.199\n",
      "0.173\n",
      "0.341\n",
      "0.422\n",
      "0.469\n",
      "0.629\n",
      "0.312\n",
      "0.155\n",
      "0.931\n",
      "0.843\n",
      "0.112\n",
      "0.258\n",
      "0.632\n",
      "0.526\n",
      "0.312\n",
      "0.303\n",
      "0.980\n",
      "0.437\n",
      "0.256\n",
      "0.541\n",
      "0.668\n",
      "0.149\n",
      "0.726\n",
      "0.647\n",
      "0.246\n",
      "0.612\n",
      "0.666\n",
      "0.165\n",
      "0.293\n",
      "0.096\n",
      "0.317\n",
      "0.609\n",
      "0.263\n",
      "0.342\n",
      "0.779\n",
      "0.368\n",
      "0.113\n",
      "0.626\n",
      "0.244\n",
      "0.415\n",
      "0.097\n",
      "0.097\n",
      "0.494\n",
      "0.099\n",
      "0.401\n",
      "0.244\n",
      "0.150\n",
      "0.504\n",
      "0.106\n",
      "0.472\n",
      "0.113\n",
      "0.097\n",
      "0.546\n",
      "0.679\n",
      "0.264\n",
      "0.371\n",
      "0.154\n",
      "0.144\n",
      "0.747\n",
      "0.872\n",
      "0.268\n",
      "0.176\n",
      "0.231\n",
      "0.307\n",
      "0.586\n",
      "0.196\n",
      "0.335\n",
      "0.093\n",
      "0.162\n",
      "0.088\n",
      "0.091\n",
      "0.102\n",
      "0.122\n",
      "0.232\n",
      "0.232\n",
      "0.247\n",
      "0.117\n",
      "0.140\n",
      "0.517\n",
      "0.120\n",
      "0.256\n",
      "0.106\n",
      "0.263\n",
      "0.119\n",
      "0.378\n",
      "0.099\n",
      "0.352\n",
      "0.137\n",
      "0.131\n",
      "0.531\n",
      "0.656\n",
      "0.553\n",
      "0.262\n",
      "0.363\n",
      "0.100\n",
      "0.183\n",
      "0.308\n",
      "0.552\n",
      "0.319\n",
      "0.745\n",
      "0.547\n",
      "0.354\n",
      "0.502\n",
      "0.315\n",
      "0.370\n",
      "0.433\n",
      "0.637\n",
      "0.507\n",
      "0.276\n",
      "0.139\n",
      "0.336\n",
      "0.251\n",
      "0.451\n",
      "0.616\n",
      "0.553\n",
      "0.347\n",
      "0.234\n",
      "0.425\n",
      "0.221\n",
      "0.192\n",
      "0.213\n",
      "0.534\n",
      "0.110\n",
      "0.965\n",
      "0.579\n",
      "0.444\n",
      "0.977\n",
      "0.846\n",
      "0.350\n",
      "0.131\n",
      "0.671\n",
      "0.554\n",
      "0.288\n",
      "0.327\n",
      "0.840\n",
      "0.980\n",
      "0.580\n",
      "0.472\n",
      "0.421\n",
      "0.874\n",
      "0.585\n",
      "0.984\n",
      "0.585\n",
      "0.803\n",
      "0.702\n",
      "0.362\n",
      "0.237\n",
      "0.353\n",
      "0.352\n",
      "0.367\n",
      "0.203\n",
      "0.192\n",
      "0.189\n",
      "0.313\n",
      "0.287\n",
      "0.459\n",
      "0.203\n",
      "0.248\n",
      "0.143\n",
      "0.339\n",
      "0.382\n",
      "0.311\n",
      "0.197\n",
      "0.610\n",
      "0.426\n",
      "0.360\n",
      "0.136\n",
      "0.142\n",
      "0.445\n",
      "0.203\n",
      "0.176\n",
      "0.344\n",
      "0.425\n",
      "0.473\n",
      "0.632\n",
      "0.315\n",
      "0.158\n",
      "0.935\n",
      "0.847\n",
      "0.116\n",
      "0.261\n",
      "0.636\n",
      "0.529\n",
      "0.316\n",
      "0.306\n",
      "0.984\n",
      "0.440\n",
      "0.259\n",
      "0.544\n",
      "0.672\n",
      "0.152\n",
      "0.730\n",
      "0.650\n",
      "0.249\n",
      "0.616\n",
      "0.669\n",
      "0.168\n",
      "0.296\n",
      "0.100\n",
      "0.321\n",
      "0.613\n",
      "0.267\n",
      "0.345\n",
      "0.783\n",
      "0.371\n",
      "0.117\n",
      "0.629\n",
      "0.248\n",
      "0.419\n",
      "0.101\n",
      "0.101\n",
      "0.497\n",
      "0.102\n",
      "0.405\n",
      "0.248\n",
      "0.153\n",
      "0.507\n",
      "0.110\n",
      "0.476\n",
      "0.117\n",
      "0.101\n",
      "0.549\n",
      "0.682\n",
      "0.267\n",
      "0.374\n",
      "0.157\n",
      "0.139\n",
      "0.742\n",
      "0.867\n",
      "0.263\n",
      "0.171\n",
      "0.226\n",
      "0.302\n",
      "0.581\n",
      "0.191\n",
      "0.330\n",
      "0.088\n",
      "0.157\n",
      "0.083\n",
      "0.086\n",
      "0.097\n",
      "0.117\n",
      "0.227\n",
      "0.227\n",
      "0.242\n",
      "0.111\n",
      "0.135\n",
      "0.511\n",
      "0.115\n",
      "0.251\n",
      "0.101\n",
      "0.258\n",
      "0.114\n",
      "0.373\n",
      "0.094\n",
      "0.347\n",
      "0.132\n",
      "0.126\n",
      "0.526\n",
      "0.651\n",
      "0.548\n",
      "0.257\n",
      "0.358\n",
      "0.095\n",
      "0.178\n",
      "0.303\n",
      "0.546\n",
      "0.313\n",
      "0.739\n",
      "0.542\n",
      "0.349\n",
      "0.497\n",
      "0.310\n",
      "0.365\n",
      "0.428\n",
      "0.631\n",
      "0.502\n",
      "0.271\n",
      "0.134\n",
      "0.331\n",
      "0.245\n",
      "0.446\n",
      "0.611\n",
      "0.548\n",
      "0.342\n",
      "0.229\n",
      "0.420\n",
      "0.216\n",
      "0.187\n",
      "0.208\n",
      "0.529\n",
      "0.105\n",
      "0.959\n",
      "0.574\n",
      "0.439\n",
      "0.972\n",
      "0.841\n",
      "0.345\n",
      "0.126\n",
      "0.666\n",
      "0.549\n",
      "0.283\n",
      "0.322\n",
      "0.835\n",
      "0.975\n",
      "0.575\n",
      "0.467\n",
      "0.416\n",
      "0.869\n",
      "0.579\n",
      "0.979\n",
      "0.580\n",
      "0.798\n",
      "0.697\n",
      "0.357\n",
      "0.231\n",
      "0.348\n",
      "0.347\n",
      "0.362\n",
      "0.198\n",
      "0.187\n",
      "0.184\n",
      "0.308\n",
      "0.282\n",
      "0.454\n",
      "0.198\n",
      "0.243\n",
      "0.138\n",
      "0.334\n",
      "0.377\n",
      "0.306\n",
      "0.192\n",
      "0.605\n",
      "0.421\n",
      "0.354\n",
      "0.131\n",
      "0.137\n",
      "0.440\n",
      "0.198\n",
      "0.171\n",
      "0.339\n",
      "0.420\n",
      "0.468\n",
      "0.627\n",
      "0.310\n",
      "0.153\n",
      "0.930\n",
      "0.842\n",
      "0.111\n",
      "0.256\n",
      "0.631\n",
      "0.524\n",
      "0.311\n",
      "0.301\n",
      "0.979\n",
      "0.435\n",
      "0.254\n",
      "0.539\n",
      "0.666\n",
      "0.147\n",
      "0.725\n",
      "0.645\n",
      "0.244\n",
      "0.611\n",
      "0.664\n",
      "0.163\n",
      "0.291\n",
      "0.094\n",
      "0.316\n",
      "0.608\n",
      "0.262\n",
      "0.340\n",
      "0.778\n",
      "0.366\n",
      "0.112\n",
      "0.624\n",
      "0.243\n",
      "0.414\n",
      "0.096\n",
      "0.096\n",
      "0.492\n",
      "0.097\n",
      "0.400\n",
      "0.243\n",
      "0.148\n",
      "0.502\n",
      "0.105\n",
      "0.471\n",
      "0.112\n",
      "0.096\n",
      "0.544\n",
      "0.677\n",
      "0.262\n",
      "0.369\n",
      "0.152\n",
      "0.131\n",
      "0.734\n",
      "0.859\n",
      "0.255\n",
      "0.163\n",
      "0.219\n",
      "0.294\n",
      "0.573\n",
      "0.184\n",
      "0.322\n",
      "0.080\n",
      "0.149\n",
      "0.076\n",
      "0.079\n",
      "0.089\n",
      "0.109\n",
      "0.219\n",
      "0.219\n",
      "0.234\n",
      "0.104\n",
      "0.127\n",
      "0.504\n",
      "0.107\n",
      "0.243\n",
      "0.093\n",
      "0.251\n",
      "0.106\n",
      "0.365\n",
      "0.086\n",
      "0.339\n",
      "0.124\n",
      "0.118\n",
      "0.518\n",
      "0.643\n",
      "0.540\n",
      "0.249\n",
      "0.350\n",
      "0.087\n",
      "0.170\n",
      "0.295\n",
      "0.539\n",
      "0.306\n",
      "0.732\n",
      "0.534\n",
      "0.341\n",
      "0.489\n",
      "0.302\n",
      "0.357\n",
      "0.420\n",
      "0.624\n",
      "0.494\n",
      "0.263\n",
      "0.126\n",
      "0.324\n",
      "0.238\n",
      "0.438\n",
      "0.603\n",
      "0.540\n",
      "0.334\n",
      "0.221\n",
      "0.412\n",
      "0.208\n",
      "0.179\n",
      "0.200\n",
      "0.521\n",
      "0.097\n",
      "0.952\n",
      "0.567\n",
      "0.431\n",
      "0.964\n",
      "0.833\n",
      "0.337\n",
      "0.118\n",
      "0.658\n",
      "0.541\n",
      "0.275\n",
      "0.314\n",
      "0.827\n",
      "0.967\n",
      "0.567\n",
      "0.459\n",
      "0.409\n",
      "0.861\n",
      "0.572\n",
      "0.971\n",
      "0.572\n",
      "0.790\n",
      "0.689\n",
      "0.349\n",
      "0.224\n",
      "0.340\n",
      "0.339\n",
      "0.354\n",
      "0.190\n",
      "0.179\n",
      "0.176\n",
      "0.301\n",
      "0.275\n",
      "0.446\n",
      "0.190\n",
      "0.235\n",
      "0.130\n",
      "0.327\n",
      "0.369\n",
      "0.298\n",
      "0.184\n",
      "0.597\n",
      "0.413\n",
      "0.347\n",
      "0.123\n",
      "0.129\n",
      "0.432\n",
      "0.190\n",
      "0.163\n",
      "0.331\n",
      "0.412\n",
      "0.460\n",
      "0.619\n",
      "0.302\n",
      "0.145\n",
      "0.922\n",
      "0.834\n",
      "0.103\n",
      "0.248\n",
      "0.623\n",
      "0.516\n",
      "0.303\n",
      "0.293\n",
      "0.971\n",
      "0.427\n",
      "0.246\n",
      "0.531\n",
      "0.659\n",
      "0.140\n",
      "0.717\n",
      "0.637\n",
      "0.236\n",
      "0.603\n",
      "0.657\n",
      "0.155\n",
      "0.283\n",
      "0.087\n",
      "0.308\n",
      "0.600\n",
      "0.254\n",
      "0.333\n",
      "0.770\n",
      "0.358\n",
      "0.104\n",
      "0.616\n",
      "0.235\n",
      "0.406\n",
      "0.088\n",
      "0.088\n",
      "0.484\n",
      "0.089\n",
      "0.392\n",
      "0.235\n",
      "0.140\n",
      "0.494\n",
      "0.097\n",
      "0.463\n",
      "0.104\n",
      "0.088\n",
      "0.536\n",
      "0.669\n",
      "0.254\n",
      "0.362\n",
      "0.144\n",
      "0.133\n",
      "0.736\n",
      "0.861\n",
      "0.257\n",
      "0.165\n",
      "0.221\n",
      "0.296\n",
      "0.575\n",
      "0.186\n",
      "0.325\n",
      "0.082\n",
      "0.151\n",
      "0.078\n",
      "0.081\n",
      "0.091\n",
      "0.111\n",
      "0.221\n",
      "0.221\n",
      "0.236\n",
      "0.106\n",
      "0.129\n",
      "0.506\n",
      "0.110\n",
      "0.245\n",
      "0.095\n",
      "0.253\n",
      "0.108\n",
      "0.367\n",
      "0.088\n",
      "0.341\n",
      "0.126\n",
      "0.120\n",
      "0.520\n",
      "0.645\n",
      "0.542\n",
      "0.252\n",
      "0.352\n",
      "0.089\n",
      "0.172\n",
      "0.297\n",
      "0.541\n",
      "0.308\n",
      "0.734\n",
      "0.536\n",
      "0.343\n",
      "0.492\n",
      "0.304\n",
      "0.360\n",
      "0.422\n",
      "0.626\n",
      "0.496\n",
      "0.265\n",
      "0.128\n",
      "0.326\n",
      "0.240\n",
      "0.441\n",
      "0.606\n",
      "0.542\n",
      "0.336\n",
      "0.224\n",
      "0.414\n",
      "0.211\n",
      "0.181\n",
      "0.202\n",
      "0.523\n",
      "0.099\n",
      "0.954\n",
      "0.569\n",
      "0.434\n",
      "0.966\n",
      "0.835\n",
      "0.339\n",
      "0.121\n",
      "0.660\n",
      "0.543\n",
      "0.277\n",
      "0.317\n",
      "0.829\n",
      "0.970\n",
      "0.569\n",
      "0.462\n",
      "0.411\n",
      "0.863\n",
      "0.574\n",
      "0.973\n",
      "0.574\n",
      "0.792\n",
      "0.692\n",
      "0.352\n",
      "0.226\n",
      "0.342\n",
      "0.342\n",
      "0.357\n",
      "0.192\n",
      "0.181\n",
      "0.178\n",
      "0.303\n",
      "0.277\n",
      "0.448\n",
      "0.193\n",
      "0.238\n",
      "0.132\n",
      "0.329\n",
      "0.371\n",
      "0.300\n",
      "0.187\n",
      "0.599\n",
      "0.415\n",
      "0.349\n",
      "0.125\n",
      "0.131\n",
      "0.434\n",
      "0.192\n",
      "0.166\n",
      "0.334\n",
      "0.414\n",
      "0.462\n",
      "0.622\n",
      "0.305\n",
      "0.148\n",
      "0.924\n",
      "0.836\n",
      "0.105\n",
      "0.250\n",
      "0.625\n",
      "0.519\n",
      "0.305\n",
      "0.296\n",
      "0.973\n",
      "0.430\n",
      "0.248\n",
      "0.533\n",
      "0.661\n",
      "0.142\n",
      "0.719\n",
      "0.639\n",
      "0.239\n",
      "0.605\n",
      "0.659\n",
      "0.157\n",
      "0.285\n",
      "0.089\n",
      "0.310\n",
      "0.602\n",
      "0.256\n",
      "0.335\n",
      "0.772\n",
      "0.361\n",
      "0.106\n",
      "0.619\n",
      "0.237\n",
      "0.408\n",
      "0.090\n",
      "0.090\n",
      "0.487\n",
      "0.091\n",
      "0.394\n",
      "0.237\n",
      "0.142\n",
      "0.497\n",
      "0.099\n",
      "0.465\n",
      "0.106\n",
      "0.090\n",
      "0.538\n",
      "0.671\n",
      "0.256\n",
      "0.364\n",
      "0.146\n",
      "0.127\n",
      "0.730\n",
      "0.855\n",
      "0.251\n",
      "0.159\n",
      "0.215\n",
      "0.290\n",
      "0.569\n",
      "0.180\n",
      "0.319\n",
      "0.076\n",
      "0.145\n",
      "0.072\n",
      "0.075\n",
      "0.085\n",
      "0.105\n",
      "0.215\n",
      "0.215\n",
      "0.230\n",
      "0.100\n",
      "0.123\n",
      "0.500\n",
      "0.104\n",
      "0.239\n",
      "0.089\n",
      "0.247\n",
      "0.102\n",
      "0.361\n",
      "0.082\n",
      "0.335\n",
      "0.120\n",
      "0.114\n",
      "0.514\n",
      "0.639\n",
      "0.536\n",
      "0.246\n",
      "0.346\n",
      "0.083\n",
      "0.166\n",
      "0.291\n",
      "0.535\n",
      "0.302\n",
      "0.728\n",
      "0.530\n",
      "0.337\n",
      "0.486\n",
      "0.298\n",
      "0.354\n",
      "0.416\n",
      "0.620\n",
      "0.490\n",
      "0.259\n",
      "0.122\n",
      "0.320\n",
      "0.234\n",
      "0.435\n",
      "0.600\n",
      "0.536\n",
      "0.330\n",
      "0.217\n",
      "0.408\n",
      "0.205\n",
      "0.175\n",
      "0.196\n",
      "0.517\n",
      "0.093\n",
      "0.948\n",
      "0.563\n",
      "0.428\n",
      "0.960\n",
      "0.829\n",
      "0.333\n",
      "0.115\n",
      "0.654\n",
      "0.537\n",
      "0.271\n",
      "0.311\n",
      "0.823\n",
      "0.964\n",
      "0.563\n",
      "0.456\n",
      "0.405\n",
      "0.857\n",
      "0.568\n",
      "0.967\n",
      "0.568\n",
      "0.786\n",
      "0.686\n",
      "0.346\n",
      "0.220\n",
      "0.336\n",
      "0.336\n",
      "0.351\n",
      "0.186\n",
      "0.175\n",
      "0.172\n",
      "0.297\n",
      "0.271\n",
      "0.442\n",
      "0.187\n",
      "0.232\n",
      "0.126\n",
      "0.323\n",
      "0.365\n",
      "0.294\n",
      "0.181\n",
      "0.593\n",
      "0.409\n",
      "0.343\n",
      "0.119\n",
      "0.125\n",
      "0.428\n",
      "0.186\n",
      "0.159\n",
      "0.328\n",
      "0.408\n",
      "0.456\n",
      "0.616\n",
      "0.299\n",
      "0.142\n",
      "0.918\n",
      "0.830\n",
      "0.099\n",
      "0.244\n",
      "0.619\n",
      "0.513\n",
      "0.299\n",
      "0.290\n",
      "0.967\n",
      "0.424\n",
      "0.242\n",
      "0.527\n",
      "0.655\n",
      "0.136\n",
      "0.713\n",
      "0.633\n",
      "0.232\n",
      "0.599\n",
      "0.653\n",
      "0.151\n",
      "0.279\n",
      "0.083\n",
      "0.304\n",
      "0.596\n",
      "0.250\n",
      "0.329\n",
      "0.766\n",
      "0.355\n",
      "0.100\n",
      "0.612\n",
      "0.231\n",
      "0.402\n",
      "0.084\n",
      "0.084\n",
      "0.480\n",
      "0.085\n",
      "0.388\n",
      "0.231\n",
      "0.136\n",
      "0.491\n",
      "0.093\n",
      "0.459\n",
      "0.100\n",
      "0.084\n",
      "0.532\n",
      "0.665\n",
      "0.250\n",
      "0.358\n",
      "0.140\n",
      "0.120\n",
      "0.723\n",
      "0.848\n",
      "0.244\n",
      "0.152\n",
      "0.208\n",
      "0.283\n",
      "0.562\n",
      "0.173\n",
      "0.312\n",
      "0.069\n",
      "0.138\n",
      "0.065\n",
      "0.068\n",
      "0.078\n",
      "0.098\n",
      "0.208\n",
      "0.208\n",
      "0.223\n",
      "0.093\n",
      "0.116\n",
      "0.493\n",
      "0.096\n",
      "0.232\n",
      "0.082\n",
      "0.240\n",
      "0.095\n",
      "0.354\n",
      "0.075\n",
      "0.328\n",
      "0.113\n",
      "0.107\n",
      "0.507\n",
      "0.632\n",
      "0.529\n",
      "0.239\n",
      "0.339\n",
      "0.076\n",
      "0.159\n",
      "0.284\n",
      "0.528\n",
      "0.295\n",
      "0.721\n",
      "0.523\n",
      "0.330\n",
      "0.478\n",
      "0.291\n",
      "0.347\n",
      "0.409\n",
      "0.613\n",
      "0.483\n",
      "0.252\n",
      "0.115\n",
      "0.313\n",
      "0.227\n",
      "0.428\n",
      "0.592\n",
      "0.529\n",
      "0.323\n",
      "0.210\n",
      "0.401\n",
      "0.198\n",
      "0.168\n",
      "0.189\n",
      "0.510\n",
      "0.086\n",
      "0.941\n",
      "0.556\n",
      "0.420\n",
      "0.953\n",
      "0.822\n",
      "0.326\n",
      "0.107\n",
      "0.647\n",
      "0.530\n",
      "0.264\n",
      "0.303\n",
      "0.816\n",
      "0.957\n",
      "0.556\n",
      "0.449\n",
      "0.398\n",
      "0.850\n",
      "0.561\n",
      "0.960\n",
      "0.561\n",
      "0.779\n",
      "0.679\n",
      "0.338\n",
      "0.213\n",
      "0.329\n",
      "0.329\n",
      "0.344\n",
      "0.179\n",
      "0.168\n",
      "0.165\n",
      "0.290\n",
      "0.264\n",
      "0.435\n",
      "0.180\n",
      "0.224\n",
      "0.119\n",
      "0.316\n",
      "0.358\n",
      "0.287\n",
      "0.174\n",
      "0.586\n",
      "0.402\n",
      "0.336\n",
      "0.112\n",
      "0.118\n",
      "0.421\n",
      "0.179\n",
      "0.152\n",
      "0.320\n",
      "0.401\n",
      "0.449\n",
      "0.609\n",
      "0.291\n",
      "0.134\n",
      "0.911\n",
      "0.823\n",
      "0.092\n",
      "0.237\n",
      "0.612\n",
      "0.505\n",
      "0.292\n",
      "0.282\n",
      "0.960\n",
      "0.417\n",
      "0.235\n",
      "0.520\n",
      "0.648\n",
      "0.129\n",
      "0.706\n",
      "0.626\n",
      "0.225\n",
      "0.592\n",
      "0.646\n",
      "0.144\n",
      "0.272\n",
      "0.076\n",
      "0.297\n",
      "0.589\n",
      "0.243\n",
      "0.322\n",
      "0.759\n",
      "0.347\n",
      "0.093\n",
      "0.605\n",
      "0.224\n",
      "0.395\n",
      "0.077\n",
      "0.077\n",
      "0.473\n",
      "0.078\n",
      "0.381\n",
      "0.224\n",
      "0.129\n",
      "0.484\n",
      "0.086\n",
      "0.452\n",
      "0.093\n",
      "0.077\n",
      "0.525\n",
      "0.658\n",
      "0.243\n",
      "0.351\n",
      "0.133\n",
      "0.131\n",
      "0.734\n",
      "0.859\n",
      "0.255\n",
      "0.163\n",
      "0.219\n",
      "0.294\n",
      "0.573\n",
      "0.184\n",
      "0.323\n",
      "0.080\n",
      "0.149\n",
      "0.076\n",
      "0.079\n",
      "0.089\n",
      "0.109\n",
      "0.219\n",
      "0.219\n",
      "0.234\n",
      "0.104\n",
      "0.127\n",
      "0.504\n",
      "0.108\n",
      "0.243\n",
      "0.093\n",
      "0.251\n",
      "0.106\n",
      "0.365\n",
      "0.086\n",
      "0.339\n",
      "0.124\n",
      "0.118\n",
      "0.518\n",
      "0.643\n",
      "0.540\n",
      "0.250\n",
      "0.350\n",
      "0.087\n",
      "0.170\n",
      "0.295\n",
      "0.539\n",
      "0.306\n",
      "0.732\n",
      "0.534\n",
      "0.341\n",
      "0.490\n",
      "0.302\n",
      "0.358\n",
      "0.420\n",
      "0.624\n",
      "0.494\n",
      "0.263\n",
      "0.126\n",
      "0.324\n",
      "0.238\n",
      "0.439\n",
      "0.604\n",
      "0.540\n",
      "0.334\n",
      "0.222\n",
      "0.412\n",
      "0.209\n",
      "0.179\n",
      "0.200\n",
      "0.521\n",
      "0.097\n",
      "0.952\n",
      "0.567\n",
      "0.432\n",
      "0.964\n",
      "0.833\n",
      "0.337\n",
      "0.119\n",
      "0.658\n",
      "0.541\n",
      "0.275\n",
      "0.315\n",
      "0.827\n",
      "0.968\n",
      "0.567\n",
      "0.460\n",
      "0.409\n",
      "0.861\n",
      "0.572\n",
      "0.971\n",
      "0.572\n",
      "0.790\n",
      "0.690\n",
      "0.350\n",
      "0.224\n",
      "0.340\n",
      "0.340\n",
      "0.355\n",
      "0.190\n",
      "0.179\n",
      "0.176\n",
      "0.301\n",
      "0.275\n",
      "0.446\n",
      "0.191\n",
      "0.236\n",
      "0.130\n",
      "0.327\n",
      "0.369\n",
      "0.298\n",
      "0.185\n",
      "0.597\n",
      "0.413\n",
      "0.347\n",
      "0.123\n",
      "0.129\n",
      "0.432\n",
      "0.190\n",
      "0.164\n",
      "0.332\n",
      "0.412\n",
      "0.460\n",
      "0.620\n",
      "0.303\n",
      "0.146\n",
      "0.922\n",
      "0.834\n",
      "0.103\n",
      "0.248\n",
      "0.623\n",
      "0.517\n",
      "0.303\n",
      "0.294\n",
      "0.971\n",
      "0.428\n",
      "0.246\n",
      "0.531\n",
      "0.659\n",
      "0.140\n",
      "0.717\n",
      "0.637\n",
      "0.237\n",
      "0.603\n",
      "0.657\n",
      "0.155\n",
      "0.283\n",
      "0.087\n",
      "0.308\n",
      "0.600\n",
      "0.254\n",
      "0.333\n",
      "0.770\n",
      "0.359\n",
      "0.104\n",
      "0.617\n",
      "0.235\n",
      "0.406\n",
      "0.088\n",
      "0.088\n",
      "0.485\n",
      "0.089\n",
      "0.392\n",
      "0.235\n",
      "0.141\n",
      "0.495\n",
      "0.097\n",
      "0.463\n",
      "0.104\n",
      "0.088\n",
      "0.536\n",
      "0.670\n",
      "0.255\n",
      "0.362\n",
      "0.144\n",
      "0.118\n",
      "0.721\n",
      "0.846\n",
      "0.242\n",
      "0.150\n",
      "0.205\n",
      "0.281\n",
      "0.559\n",
      "0.170\n",
      "0.309\n",
      "0.067\n",
      "0.136\n",
      "0.062\n",
      "0.065\n",
      "0.076\n",
      "0.096\n",
      "0.205\n",
      "0.205\n",
      "0.221\n",
      "0.090\n",
      "0.114\n",
      "0.490\n",
      "0.094\n",
      "0.230\n",
      "0.080\n",
      "0.237\n",
      "0.092\n",
      "0.351\n",
      "0.072\n",
      "0.326\n",
      "0.110\n",
      "0.105\n",
      "0.505\n",
      "0.629\n",
      "0.527\n",
      "0.236\n",
      "0.337\n",
      "0.074\n",
      "0.157\n",
      "0.282\n",
      "0.525\n",
      "0.292\n",
      "0.718\n",
      "0.521\n",
      "0.328\n",
      "0.476\n",
      "0.288\n",
      "0.344\n",
      "0.407\n",
      "0.610\n",
      "0.480\n",
      "0.249\n",
      "0.113\n",
      "0.310\n",
      "0.224\n",
      "0.425\n",
      "0.590\n",
      "0.527\n",
      "0.320\n",
      "0.208\n",
      "0.399\n",
      "0.195\n",
      "0.165\n",
      "0.187\n",
      "0.508\n",
      "0.084\n",
      "0.938\n",
      "0.553\n",
      "0.418\n",
      "0.951\n",
      "0.820\n",
      "0.323\n",
      "0.105\n",
      "0.644\n",
      "0.528\n",
      "0.262\n",
      "0.301\n",
      "0.813\n",
      "0.954\n",
      "0.554\n",
      "0.446\n",
      "0.395\n",
      "0.848\n",
      "0.558\n",
      "0.958\n",
      "0.559\n",
      "0.777\n",
      "0.676\n",
      "0.336\n",
      "0.210\n",
      "0.327\n",
      "0.326\n",
      "0.341\n",
      "0.176\n",
      "0.165\n",
      "0.163\n",
      "0.287\n",
      "0.261\n",
      "0.433\n",
      "0.177\n",
      "0.222\n",
      "0.117\n",
      "0.313\n",
      "0.356\n",
      "0.284\n",
      "0.171\n",
      "0.583\n",
      "0.400\n",
      "0.333\n",
      "0.109\n",
      "0.116\n",
      "0.419\n",
      "0.176\n",
      "0.150\n",
      "0.318\n",
      "0.399\n",
      "0.447\n",
      "0.606\n",
      "0.289\n",
      "0.132\n",
      "0.909\n",
      "0.821\n",
      "0.089\n",
      "0.235\n",
      "0.609\n",
      "0.503\n",
      "0.290\n",
      "0.280\n",
      "0.957\n",
      "0.414\n",
      "0.233\n",
      "0.518\n",
      "0.645\n",
      "0.126\n",
      "0.703\n",
      "0.624\n",
      "0.223\n",
      "0.589\n",
      "0.643\n",
      "0.142\n",
      "0.270\n",
      "0.073\n",
      "0.294\n",
      "0.586\n",
      "0.240\n",
      "0.319\n",
      "0.757\n",
      "0.345\n",
      "0.091\n",
      "0.603\n",
      "0.221\n",
      "0.392\n",
      "0.074\n",
      "0.074\n",
      "0.471\n",
      "0.076\n",
      "0.379\n",
      "0.222\n",
      "0.127\n",
      "0.481\n",
      "0.084\n",
      "0.450\n",
      "0.091\n",
      "0.074\n",
      "0.523\n",
      "0.656\n",
      "0.241\n",
      "0.348\n",
      "0.131\n",
      "0.122\n",
      "0.724\n",
      "0.850\n",
      "0.245\n",
      "0.154\n",
      "0.209\n",
      "0.284\n",
      "0.563\n",
      "0.174\n",
      "0.313\n",
      "0.071\n",
      "0.139\n",
      "0.066\n",
      "0.069\n",
      "0.080\n",
      "0.100\n",
      "0.209\n",
      "0.209\n",
      "0.224\n",
      "0.094\n",
      "0.117\n",
      "0.494\n",
      "0.098\n",
      "0.234\n",
      "0.084\n",
      "0.241\n",
      "0.096\n",
      "0.355\n",
      "0.076\n",
      "0.329\n",
      "0.114\n",
      "0.109\n",
      "0.509\n",
      "0.633\n",
      "0.530\n",
      "0.240\n",
      "0.341\n",
      "0.077\n",
      "0.160\n",
      "0.285\n",
      "0.529\n",
      "0.296\n",
      "0.722\n",
      "0.525\n",
      "0.331\n",
      "0.480\n",
      "0.292\n",
      "0.348\n",
      "0.411\n",
      "0.614\n",
      "0.484\n",
      "0.253\n",
      "0.117\n",
      "0.314\n",
      "0.228\n",
      "0.429\n",
      "0.594\n",
      "0.531\n",
      "0.324\n",
      "0.212\n",
      "0.403\n",
      "0.199\n",
      "0.169\n",
      "0.190\n",
      "0.512\n",
      "0.088\n",
      "0.942\n",
      "0.557\n",
      "0.422\n",
      "0.955\n",
      "0.824\n",
      "0.327\n",
      "0.109\n",
      "0.648\n",
      "0.532\n",
      "0.265\n",
      "0.305\n",
      "0.817\n",
      "0.958\n",
      "0.558\n",
      "0.450\n",
      "0.399\n",
      "0.851\n",
      "0.562\n",
      "0.961\n",
      "0.562\n",
      "0.780\n",
      "0.680\n",
      "0.340\n",
      "0.214\n",
      "0.331\n",
      "0.330\n",
      "0.345\n",
      "0.180\n",
      "0.169\n",
      "0.166\n",
      "0.291\n",
      "0.265\n",
      "0.436\n",
      "0.181\n",
      "0.226\n",
      "0.121\n",
      "0.317\n",
      "0.360\n",
      "0.288\n",
      "0.175\n",
      "0.587\n",
      "0.404\n",
      "0.337\n",
      "0.113\n",
      "0.119\n",
      "0.422\n",
      "0.180\n",
      "0.154\n",
      "0.322\n",
      "0.403\n",
      "0.450\n",
      "0.610\n",
      "0.293\n",
      "0.136\n",
      "0.912\n",
      "0.824\n",
      "0.093\n",
      "0.239\n",
      "0.613\n",
      "0.507\n",
      "0.293\n",
      "0.284\n",
      "0.961\n",
      "0.418\n",
      "0.237\n",
      "0.522\n",
      "0.649\n",
      "0.130\n",
      "0.707\n",
      "0.628\n",
      "0.227\n",
      "0.593\n",
      "0.647\n",
      "0.146\n",
      "0.274\n",
      "0.077\n",
      "0.298\n",
      "0.590\n",
      "0.244\n",
      "0.323\n",
      "0.760\n",
      "0.349\n",
      "0.094\n",
      "0.607\n",
      "0.225\n",
      "0.396\n",
      "0.078\n",
      "0.078\n",
      "0.475\n",
      "0.080\n",
      "0.382\n",
      "0.225\n",
      "0.131\n",
      "0.485\n",
      "0.087\n",
      "0.453\n",
      "0.094\n",
      "0.078\n",
      "0.527\n",
      "0.660\n",
      "0.245\n",
      "0.352\n",
      "0.135\n",
      "0.108\n",
      "0.711\n",
      "0.836\n",
      "0.232\n",
      "0.140\n",
      "0.195\n",
      "0.270\n",
      "0.549\n",
      "0.160\n",
      "0.299\n",
      "0.057\n",
      "0.126\n",
      "0.052\n",
      "0.055\n",
      "0.066\n",
      "0.086\n",
      "0.195\n",
      "0.195\n",
      "0.211\n",
      "0.080\n",
      "0.104\n",
      "0.480\n",
      "0.084\n",
      "0.220\n",
      "0.070\n",
      "0.227\n",
      "0.082\n",
      "0.341\n",
      "0.062\n",
      "0.316\n",
      "0.100\n",
      "0.095\n",
      "0.495\n",
      "0.619\n",
      "0.516\n",
      "0.226\n",
      "0.327\n",
      "0.063\n",
      "0.147\n",
      "0.272\n",
      "0.515\n",
      "0.282\n",
      "0.708\n",
      "0.511\n",
      "0.317\n",
      "0.466\n",
      "0.278\n",
      "0.334\n",
      "0.397\n",
      "0.600\n",
      "0.470\n",
      "0.239\n",
      "0.103\n",
      "0.300\n",
      "0.214\n",
      "0.415\n",
      "0.580\n",
      "0.517\n",
      "0.310\n",
      "0.198\n",
      "0.389\n",
      "0.185\n",
      "0.155\n",
      "0.177\n",
      "0.498\n",
      "0.074\n",
      "0.928\n",
      "0.543\n",
      "0.408\n",
      "0.941\n",
      "0.810\n",
      "0.313\n",
      "0.095\n",
      "0.634\n",
      "0.518\n",
      "0.252\n",
      "0.291\n",
      "0.803\n",
      "0.944\n",
      "0.544\n",
      "0.436\n",
      "0.385\n",
      "0.837\n",
      "0.548\n",
      "0.948\n",
      "0.548\n",
      "0.767\n",
      "0.666\n",
      "0.326\n",
      "0.200\n",
      "0.317\n",
      "0.316\n",
      "0.331\n",
      "0.166\n",
      "0.155\n",
      "0.153\n",
      "0.277\n",
      "0.251\n",
      "0.422\n",
      "0.167\n",
      "0.212\n",
      "0.107\n",
      "0.303\n",
      "0.346\n",
      "0.274\n",
      "0.161\n",
      "0.573\n",
      "0.390\n",
      "0.323\n",
      "0.099\n",
      "0.106\n",
      "0.408\n",
      "0.166\n",
      "0.140\n",
      "0.308\n",
      "0.389\n",
      "0.437\n",
      "0.596\n",
      "0.279\n",
      "0.122\n",
      "0.898\n",
      "0.811\n",
      "0.079\n",
      "0.225\n",
      "0.599\n",
      "0.493\n",
      "0.279\n",
      "0.270\n",
      "0.947\n",
      "0.404\n",
      "0.223\n",
      "0.508\n",
      "0.635\n",
      "0.116\n",
      "0.693\n",
      "0.614\n",
      "0.213\n",
      "0.579\n",
      "0.633\n",
      "0.132\n",
      "0.260\n",
      "0.063\n",
      "0.284\n",
      "0.576\n",
      "0.230\n",
      "0.309\n",
      "0.747\n",
      "0.335\n",
      "0.080\n",
      "0.593\n",
      "0.211\n",
      "0.382\n",
      "0.064\n",
      "0.064\n",
      "0.461\n",
      "0.066\n",
      "0.369\n",
      "0.212\n",
      "0.117\n",
      "0.471\n",
      "0.074\n",
      "0.440\n",
      "0.080\n",
      "0.064\n",
      "0.513\n",
      "0.646\n",
      "0.231\n",
      "0.338\n",
      "0.121\n",
      "0.113\n",
      "0.716\n",
      "0.842\n",
      "0.237\n",
      "0.145\n",
      "0.201\n",
      "0.276\n",
      "0.555\n",
      "0.166\n",
      "0.305\n",
      "0.063\n",
      "0.131\n",
      "0.058\n",
      "0.061\n",
      "0.071\n",
      "0.092\n",
      "0.201\n",
      "0.201\n",
      "0.216\n",
      "0.086\n",
      "0.109\n",
      "0.486\n",
      "0.090\n",
      "0.226\n",
      "0.075\n",
      "0.233\n",
      "0.088\n",
      "0.347\n",
      "0.068\n",
      "0.321\n",
      "0.106\n",
      "0.101\n",
      "0.501\n",
      "0.625\n",
      "0.522\n",
      "0.232\n",
      "0.332\n",
      "0.069\n",
      "0.152\n",
      "0.277\n",
      "0.521\n",
      "0.288\n",
      "0.714\n",
      "0.516\n",
      "0.323\n",
      "0.472\n",
      "0.284\n",
      "0.340\n",
      "0.402\n",
      "0.606\n",
      "0.476\n",
      "0.245\n",
      "0.109\n",
      "0.306\n",
      "0.220\n",
      "0.421\n",
      "0.586\n",
      "0.522\n",
      "0.316\n",
      "0.204\n",
      "0.395\n",
      "0.191\n",
      "0.161\n",
      "0.182\n",
      "0.504\n",
      "0.080\n",
      "0.934\n",
      "0.549\n",
      "0.414\n",
      "0.946\n",
      "0.816\n",
      "0.319\n",
      "0.101\n",
      "0.640\n",
      "0.524\n",
      "0.257\n",
      "0.297\n",
      "0.809\n",
      "0.950\n",
      "0.550\n",
      "0.442\n",
      "0.391\n",
      "0.843\n",
      "0.554\n",
      "0.953\n",
      "0.554\n",
      "0.772\n",
      "0.672\n",
      "0.332\n",
      "0.206\n",
      "0.323\n",
      "0.322\n",
      "0.337\n",
      "0.172\n",
      "0.161\n",
      "0.158\n",
      "0.283\n",
      "0.257\n",
      "0.428\n",
      "0.173\n",
      "0.218\n",
      "0.112\n",
      "0.309\n",
      "0.352\n",
      "0.280\n",
      "0.167\n",
      "0.579\n",
      "0.396\n",
      "0.329\n",
      "0.105\n",
      "0.111\n",
      "0.414\n",
      "0.172\n",
      "0.146\n",
      "0.314\n",
      "0.395\n",
      "0.442\n",
      "0.602\n",
      "0.285\n",
      "0.128\n",
      "0.904\n",
      "0.816\n",
      "0.085\n",
      "0.230\n",
      "0.605\n",
      "0.499\n",
      "0.285\n",
      "0.276\n",
      "0.953\n",
      "0.410\n",
      "0.229\n",
      "0.513\n",
      "0.641\n",
      "0.122\n",
      "0.699\n",
      "0.620\n",
      "0.219\n",
      "0.585\n",
      "0.639\n",
      "0.138\n",
      "0.265\n",
      "0.069\n",
      "0.290\n",
      "0.582\n",
      "0.236\n",
      "0.315\n",
      "0.752\n",
      "0.341\n",
      "0.086\n",
      "0.599\n",
      "0.217\n",
      "0.388\n",
      "0.070\n",
      "0.070\n",
      "0.467\n",
      "0.071\n",
      "0.374\n",
      "0.217\n",
      "0.123\n",
      "0.477\n",
      "0.079\n",
      "0.445\n",
      "0.086\n",
      "0.070\n",
      "0.518\n",
      "0.652\n",
      "0.237\n",
      "0.344\n",
      "0.127\n",
      "0.093\n",
      "0.696\n",
      "0.822\n",
      "0.217\n",
      "0.125\n",
      "0.181\n",
      "0.256\n",
      "0.535\n",
      "0.146\n",
      "0.285\n",
      "0.042\n",
      "0.111\n",
      "0.038\n",
      "0.041\n",
      "0.051\n",
      "0.071\n",
      "0.181\n",
      "0.181\n",
      "0.196\n",
      "0.066\n",
      "0.089\n",
      "0.466\n",
      "0.070\n",
      "0.205\n",
      "0.055\n",
      "0.213\n",
      "0.068\n",
      "0.327\n",
      "0.048\n",
      "0.301\n",
      "0.086\n",
      "0.080\n",
      "0.480\n",
      "0.605\n",
      "0.502\n",
      "0.212\n",
      "0.312\n",
      "0.049\n",
      "0.132\n",
      "0.257\n",
      "0.501\n",
      "0.268\n",
      "0.694\n",
      "0.496\n",
      "0.303\n",
      "0.452\n",
      "0.264\n",
      "0.320\n",
      "0.382\n",
      "0.586\n",
      "0.456\n",
      "0.225\n",
      "0.088\n",
      "0.286\n",
      "0.200\n",
      "0.401\n",
      "0.566\n",
      "0.502\n",
      "0.296\n",
      "0.184\n",
      "0.375\n",
      "0.171\n",
      "0.141\n",
      "0.162\n",
      "0.483\n",
      "0.059\n",
      "0.914\n",
      "0.529\n",
      "0.394\n",
      "0.926\n",
      "0.795\n",
      "0.299\n",
      "0.081\n",
      "0.620\n",
      "0.503\n",
      "0.237\n",
      "0.277\n",
      "0.789\n",
      "0.930\n",
      "0.530\n",
      "0.422\n",
      "0.371\n",
      "0.823\n",
      "0.534\n",
      "0.933\n",
      "0.534\n",
      "0.752\n",
      "0.652\n",
      "0.312\n",
      "0.186\n",
      "0.302\n",
      "0.302\n",
      "0.317\n",
      "0.152\n",
      "0.141\n",
      "0.138\n",
      "0.263\n",
      "0.237\n",
      "0.408\n",
      "0.153\n",
      "0.198\n",
      "0.092\n",
      "0.289\n",
      "0.331\n",
      "0.260\n",
      "0.147\n",
      "0.559\n",
      "0.375\n",
      "0.309\n",
      "0.085\n",
      "0.091\n",
      "0.394\n",
      "0.152\n",
      "0.126\n",
      "0.294\n",
      "0.375\n",
      "0.422\n",
      "0.582\n",
      "0.265\n",
      "0.108\n",
      "0.884\n",
      "0.796\n",
      "0.065\n",
      "0.210\n",
      "0.585\n",
      "0.479\n",
      "0.265\n",
      "0.256\n",
      "0.933\n",
      "0.390\n",
      "0.208\n",
      "0.493\n",
      "0.621\n",
      "0.102\n",
      "0.679\n",
      "0.600\n",
      "0.199\n",
      "0.565\n",
      "0.619\n",
      "0.118\n",
      "0.245\n",
      "0.049\n",
      "0.270\n",
      "0.562\n",
      "0.216\n",
      "0.295\n",
      "0.732\n",
      "0.321\n",
      "0.066\n",
      "0.579\n",
      "0.197\n",
      "0.368\n",
      "0.050\n",
      "0.050\n",
      "0.447\n",
      "0.051\n",
      "0.354\n",
      "0.197\n",
      "0.103\n",
      "0.457\n",
      "0.059\n",
      "0.425\n",
      "0.066\n",
      "0.050\n",
      "0.498\n",
      "0.632\n",
      "0.217\n",
      "0.324\n",
      "0.106\n",
      "0.112\n",
      "0.715\n",
      "0.840\n",
      "0.236\n",
      "0.144\n",
      "0.199\n",
      "0.275\n",
      "0.554\n",
      "0.164\n",
      "0.303\n",
      "0.061\n",
      "0.130\n",
      "0.056\n",
      "0.059\n",
      "0.070\n",
      "0.090\n",
      "0.200\n",
      "0.200\n",
      "0.215\n",
      "0.084\n",
      "0.108\n",
      "0.484\n",
      "0.088\n",
      "0.224\n",
      "0.074\n",
      "0.231\n",
      "0.086\n",
      "0.346\n",
      "0.066\n",
      "0.320\n",
      "0.104\n",
      "0.099\n",
      "0.499\n",
      "0.624\n",
      "0.521\n",
      "0.230\n",
      "0.331\n",
      "0.068\n",
      "0.151\n",
      "0.276\n",
      "0.519\n",
      "0.286\n",
      "0.712\n",
      "0.515\n",
      "0.322\n",
      "0.470\n",
      "0.282\n",
      "0.338\n",
      "0.401\n",
      "0.604\n",
      "0.475\n",
      "0.244\n",
      "0.107\n",
      "0.304\n",
      "0.218\n",
      "0.419\n",
      "0.584\n",
      "0.521\n",
      "0.314\n",
      "0.202\n",
      "0.393\n",
      "0.189\n",
      "0.159\n",
      "0.181\n",
      "0.502\n",
      "0.078\n",
      "0.932\n",
      "0.547\n",
      "0.412\n",
      "0.945\n",
      "0.814\n",
      "0.317\n",
      "0.099\n",
      "0.638\n",
      "0.522\n",
      "0.256\n",
      "0.295\n",
      "0.808\n",
      "0.948\n",
      "0.548\n",
      "0.440\n",
      "0.389\n",
      "0.842\n",
      "0.552\n",
      "0.952\n",
      "0.553\n",
      "0.771\n",
      "0.670\n",
      "0.330\n",
      "0.204\n",
      "0.321\n",
      "0.320\n",
      "0.335\n",
      "0.171\n",
      "0.159\n",
      "0.157\n",
      "0.281\n",
      "0.255\n",
      "0.427\n",
      "0.171\n",
      "0.216\n",
      "0.111\n",
      "0.307\n",
      "0.350\n",
      "0.279\n",
      "0.165\n",
      "0.577\n",
      "0.394\n",
      "0.327\n",
      "0.104\n",
      "0.110\n",
      "0.413\n",
      "0.171\n",
      "0.144\n",
      "0.312\n",
      "0.393\n",
      "0.441\n",
      "0.600\n",
      "0.283\n",
      "0.126\n",
      "0.903\n",
      "0.815\n",
      "0.083\n",
      "0.229\n",
      "0.603\n",
      "0.497\n",
      "0.284\n",
      "0.274\n",
      "0.951\n",
      "0.408\n",
      "0.227\n",
      "0.512\n",
      "0.639\n",
      "0.120\n",
      "0.697\n",
      "0.618\n",
      "0.217\n",
      "0.583\n",
      "0.637\n",
      "0.136\n",
      "0.264\n",
      "0.067\n",
      "0.288\n",
      "0.580\n",
      "0.235\n",
      "0.313\n",
      "0.751\n",
      "0.339\n",
      "0.085\n",
      "0.597\n",
      "0.215\n",
      "0.387\n",
      "0.069\n",
      "0.069\n",
      "0.465\n",
      "0.070\n",
      "0.373\n",
      "0.216\n",
      "0.121\n",
      "0.475\n",
      "0.078\n",
      "0.444\n",
      "0.085\n",
      "0.069\n",
      "0.517\n",
      "0.650\n",
      "0.235\n",
      "0.342\n",
      "0.125\n",
      "0.099\n",
      "0.702\n",
      "0.827\n",
      "0.223\n",
      "0.131\n",
      "0.186\n",
      "0.261\n",
      "0.540\n",
      "0.151\n",
      "0.290\n",
      "0.048\n",
      "0.117\n",
      "0.043\n",
      "0.046\n",
      "0.057\n",
      "0.077\n",
      "0.186\n",
      "0.186\n",
      "0.202\n",
      "0.071\n",
      "0.094\n",
      "0.471\n",
      "0.075\n",
      "0.211\n",
      "0.061\n",
      "0.218\n",
      "0.073\n",
      "0.332\n",
      "0.053\n",
      "0.307\n",
      "0.091\n",
      "0.086\n",
      "0.486\n",
      "0.610\n",
      "0.507\n",
      "0.217\n",
      "0.318\n",
      "0.054\n",
      "0.138\n",
      "0.263\n",
      "0.506\n",
      "0.273\n",
      "0.699\n",
      "0.502\n",
      "0.308\n",
      "0.457\n",
      "0.269\n",
      "0.325\n",
      "0.388\n",
      "0.591\n",
      "0.461\n",
      "0.230\n",
      "0.094\n",
      "0.291\n",
      "0.205\n",
      "0.406\n",
      "0.571\n",
      "0.508\n",
      "0.301\n",
      "0.189\n",
      "0.380\n",
      "0.176\n",
      "0.146\n",
      "0.167\n",
      "0.489\n",
      "0.065\n",
      "0.919\n",
      "0.534\n",
      "0.399\n",
      "0.932\n",
      "0.801\n",
      "0.304\n",
      "0.086\n",
      "0.625\n",
      "0.509\n",
      "0.243\n",
      "0.282\n",
      "0.794\n",
      "0.935\n",
      "0.535\n",
      "0.427\n",
      "0.376\n",
      "0.828\n",
      "0.539\n",
      "0.938\n",
      "0.539\n",
      "0.757\n",
      "0.657\n",
      "0.317\n",
      "0.191\n",
      "0.308\n",
      "0.307\n",
      "0.322\n",
      "0.157\n",
      "0.146\n",
      "0.144\n",
      "0.268\n",
      "0.242\n",
      "0.413\n",
      "0.158\n",
      "0.203\n",
      "0.098\n",
      "0.294\n",
      "0.337\n",
      "0.265\n",
      "0.152\n",
      "0.564\n",
      "0.381\n",
      "0.314\n",
      "0.090\n",
      "0.097\n",
      "0.399\n",
      "0.157\n",
      "0.131\n",
      "0.299\n",
      "0.380\n",
      "0.427\n",
      "0.587\n",
      "0.270\n",
      "0.113\n",
      "0.889\n",
      "0.801\n",
      "0.070\n",
      "0.216\n",
      "0.590\n",
      "0.484\n",
      "0.270\n",
      "0.261\n",
      "0.938\n",
      "0.395\n",
      "0.214\n",
      "0.499\n",
      "0.626\n",
      "0.107\n",
      "0.684\n",
      "0.605\n",
      "0.204\n",
      "0.570\n",
      "0.624\n",
      "0.123\n",
      "0.251\n",
      "0.054\n",
      "0.275\n",
      "0.567\n",
      "0.221\n",
      "0.300\n",
      "0.737\n",
      "0.326\n",
      "0.071\n",
      "0.584\n",
      "0.202\n",
      "0.373\n",
      "0.055\n",
      "0.055\n",
      "0.452\n",
      "0.057\n",
      "0.360\n",
      "0.202\n",
      "0.108\n",
      "0.462\n",
      "0.065\n",
      "0.430\n",
      "0.071\n",
      "0.055\n",
      "0.504\n",
      "0.637\n",
      "0.222\n",
      "0.329\n",
      "0.112\n",
      "0.125\n",
      "0.728\n",
      "0.853\n",
      "0.249\n",
      "0.157\n",
      "0.212\n",
      "0.287\n",
      "0.566\n",
      "0.177\n",
      "0.316\n",
      "0.074\n",
      "0.143\n",
      "0.069\n",
      "0.072\n",
      "0.083\n",
      "0.103\n",
      "0.212\n",
      "0.212\n",
      "0.228\n",
      "0.097\n",
      "0.120\n",
      "0.497\n",
      "0.101\n",
      "0.237\n",
      "0.087\n",
      "0.244\n",
      "0.099\n",
      "0.358\n",
      "0.079\n",
      "0.333\n",
      "0.117\n",
      "0.112\n",
      "0.512\n",
      "0.636\n",
      "0.533\n",
      "0.243\n",
      "0.344\n",
      "0.080\n",
      "0.164\n",
      "0.289\n",
      "0.532\n",
      "0.299\n",
      "0.725\n",
      "0.528\n",
      "0.334\n",
      "0.483\n",
      "0.295\n",
      "0.351\n",
      "0.414\n",
      "0.617\n",
      "0.487\n",
      "0.256\n",
      "0.120\n",
      "0.317\n",
      "0.231\n",
      "0.432\n",
      "0.597\n",
      "0.534\n",
      "0.327\n",
      "0.215\n",
      "0.406\n",
      "0.202\n",
      "0.172\n",
      "0.193\n",
      "0.515\n",
      "0.091\n",
      "0.945\n",
      "0.560\n",
      "0.425\n",
      "0.958\n",
      "0.827\n",
      "0.330\n",
      "0.112\n",
      "0.651\n",
      "0.535\n",
      "0.269\n",
      "0.308\n",
      "0.820\n",
      "0.961\n",
      "0.561\n",
      "0.453\n",
      "0.402\n",
      "0.854\n",
      "0.565\n",
      "0.965\n",
      "0.565\n",
      "0.784\n",
      "0.683\n",
      "0.343\n",
      "0.217\n",
      "0.334\n",
      "0.333\n",
      "0.348\n",
      "0.183\n",
      "0.172\n",
      "0.170\n",
      "0.294\n",
      "0.268\n",
      "0.439\n",
      "0.184\n",
      "0.229\n",
      "0.124\n",
      "0.320\n",
      "0.363\n",
      "0.291\n",
      "0.178\n",
      "0.590\n",
      "0.407\n",
      "0.340\n",
      "0.116\n",
      "0.123\n",
      "0.425\n",
      "0.183\n",
      "0.157\n",
      "0.325\n",
      "0.406\n",
      "0.453\n",
      "0.613\n",
      "0.296\n",
      "0.139\n",
      "0.915\n",
      "0.827\n",
      "0.096\n",
      "0.242\n",
      "0.616\n",
      "0.510\n",
      "0.296\n",
      "0.287\n",
      "0.964\n",
      "0.421\n",
      "0.240\n",
      "0.525\n",
      "0.652\n",
      "0.133\n",
      "0.710\n",
      "0.631\n",
      "0.230\n",
      "0.596\n",
      "0.650\n",
      "0.149\n",
      "0.277\n",
      "0.080\n",
      "0.301\n",
      "0.593\n",
      "0.247\n",
      "0.326\n",
      "0.763\n",
      "0.352\n",
      "0.097\n",
      "0.610\n",
      "0.228\n",
      "0.399\n",
      "0.081\n",
      "0.081\n",
      "0.478\n",
      "0.083\n",
      "0.386\n",
      "0.228\n",
      "0.134\n",
      "0.488\n",
      "0.091\n",
      "0.456\n",
      "0.097\n",
      "0.081\n",
      "0.530\n",
      "0.663\n",
      "0.248\n",
      "0.355\n",
      "0.138\n",
      "0.101\n",
      "0.704\n",
      "0.829\n",
      "0.225\n",
      "0.133\n",
      "0.188\n",
      "0.263\n",
      "0.542\n",
      "0.153\n",
      "0.292\n",
      "0.050\n",
      "0.119\n",
      "0.045\n",
      "0.048\n",
      "0.059\n",
      "0.079\n",
      "0.188\n",
      "0.188\n",
      "0.204\n",
      "0.073\n",
      "0.097\n",
      "0.473\n",
      "0.077\n",
      "0.213\n",
      "0.063\n",
      "0.220\n",
      "0.075\n",
      "0.334\n",
      "0.055\n",
      "0.309\n",
      "0.093\n",
      "0.088\n",
      "0.488\n",
      "0.612\n",
      "0.509\n",
      "0.219\n",
      "0.320\n",
      "0.056\n",
      "0.140\n",
      "0.265\n",
      "0.508\n",
      "0.275\n",
      "0.701\n",
      "0.504\n",
      "0.310\n",
      "0.459\n",
      "0.271\n",
      "0.327\n",
      "0.390\n",
      "0.593\n",
      "0.463\n",
      "0.232\n",
      "0.096\n",
      "0.293\n",
      "0.207\n",
      "0.408\n",
      "0.573\n",
      "0.510\n",
      "0.303\n",
      "0.191\n",
      "0.382\n",
      "0.178\n",
      "0.148\n",
      "0.170\n",
      "0.491\n",
      "0.067\n",
      "0.921\n",
      "0.536\n",
      "0.401\n",
      "0.934\n",
      "0.803\n",
      "0.306\n",
      "0.088\n",
      "0.627\n",
      "0.511\n",
      "0.245\n",
      "0.284\n",
      "0.796\n",
      "0.937\n",
      "0.537\n",
      "0.429\n",
      "0.378\n",
      "0.830\n",
      "0.541\n",
      "0.941\n",
      "0.541\n",
      "0.760\n",
      "0.659\n",
      "0.319\n",
      "0.193\n",
      "0.310\n",
      "0.309\n",
      "0.324\n",
      "0.159\n",
      "0.148\n",
      "0.146\n",
      "0.270\n",
      "0.244\n",
      "0.415\n",
      "0.160\n",
      "0.205\n",
      "0.100\n",
      "0.296\n",
      "0.339\n",
      "0.267\n",
      "0.154\n",
      "0.566\n",
      "0.383\n",
      "0.316\n",
      "0.092\n",
      "0.099\n",
      "0.401\n",
      "0.159\n",
      "0.133\n",
      "0.301\n",
      "0.382\n",
      "0.430\n",
      "0.589\n",
      "0.272\n",
      "0.115\n",
      "0.892\n",
      "0.804\n",
      "0.072\n",
      "0.218\n",
      "0.592\n",
      "0.486\n",
      "0.272\n",
      "0.263\n",
      "0.940\n",
      "0.397\n",
      "0.216\n",
      "0.501\n",
      "0.628\n",
      "0.109\n",
      "0.686\n",
      "0.607\n",
      "0.206\n",
      "0.572\n",
      "0.626\n",
      "0.125\n",
      "0.253\n",
      "0.056\n",
      "0.277\n",
      "0.569\n",
      "0.223\n",
      "0.302\n",
      "0.740\n",
      "0.328\n",
      "0.073\n",
      "0.586\n",
      "0.204\n",
      "0.375\n",
      "0.057\n",
      "0.057\n",
      "0.454\n",
      "0.059\n",
      "0.362\n",
      "0.205\n",
      "0.110\n",
      "0.464\n",
      "0.067\n",
      "0.433\n",
      "0.073\n",
      "0.057\n",
      "0.506\n",
      "0.639\n",
      "0.224\n",
      "0.331\n",
      "0.114\n",
      "0.122\n",
      "0.725\n",
      "0.851\n",
      "0.246\n",
      "0.154\n",
      "0.210\n",
      "0.285\n",
      "0.564\n",
      "0.175\n",
      "0.314\n",
      "0.071\n",
      "0.140\n",
      "0.067\n",
      "0.070\n",
      "0.080\n",
      "0.101\n",
      "0.210\n",
      "0.210\n",
      "0.225\n",
      "0.095\n",
      "0.118\n",
      "0.495\n",
      "0.099\n",
      "0.235\n",
      "0.084\n",
      "0.242\n",
      "0.097\n",
      "0.356\n",
      "0.077\n",
      "0.330\n",
      "0.115\n",
      "0.109\n",
      "0.510\n",
      "0.634\n",
      "0.531\n",
      "0.241\n",
      "0.341\n",
      "0.078\n",
      "0.161\n",
      "0.286\n",
      "0.530\n",
      "0.297\n",
      "0.723\n",
      "0.525\n",
      "0.332\n",
      "0.481\n",
      "0.293\n",
      "0.349\n",
      "0.411\n",
      "0.615\n",
      "0.485\n",
      "0.254\n",
      "0.118\n",
      "0.315\n",
      "0.229\n",
      "0.430\n",
      "0.595\n",
      "0.531\n",
      "0.325\n",
      "0.213\n",
      "0.404\n",
      "0.200\n",
      "0.170\n",
      "0.191\n",
      "0.513\n",
      "0.089\n",
      "0.943\n",
      "0.558\n",
      "0.423\n",
      "0.955\n",
      "0.825\n",
      "0.328\n",
      "0.110\n",
      "0.649\n",
      "0.533\n",
      "0.266\n",
      "0.306\n",
      "0.818\n",
      "0.959\n",
      "0.559\n",
      "0.451\n",
      "0.400\n",
      "0.852\n",
      "0.563\n",
      "0.962\n",
      "0.563\n",
      "0.781\n",
      "0.681\n",
      "0.341\n",
      "0.215\n",
      "0.331\n",
      "0.331\n",
      "0.346\n",
      "0.181\n",
      "0.170\n",
      "0.167\n",
      "0.292\n",
      "0.266\n",
      "0.437\n",
      "0.182\n",
      "0.227\n",
      "0.121\n",
      "0.318\n",
      "0.361\n",
      "0.289\n",
      "0.176\n",
      "0.588\n",
      "0.404\n",
      "0.338\n",
      "0.114\n",
      "0.120\n",
      "0.423\n",
      "0.181\n",
      "0.155\n",
      "0.323\n",
      "0.404\n",
      "0.451\n",
      "0.611\n",
      "0.294\n",
      "0.137\n",
      "0.913\n",
      "0.825\n",
      "0.094\n",
      "0.239\n",
      "0.614\n",
      "0.508\n",
      "0.294\n",
      "0.285\n",
      "0.962\n",
      "0.419\n",
      "0.238\n",
      "0.522\n",
      "0.650\n",
      "0.131\n",
      "0.708\n",
      "0.629\n",
      "0.228\n",
      "0.594\n",
      "0.648\n",
      "0.147\n",
      "0.274\n",
      "0.078\n",
      "0.299\n",
      "0.591\n",
      "0.245\n",
      "0.324\n",
      "0.761\n",
      "0.350\n",
      "0.095\n",
      "0.608\n",
      "0.226\n",
      "0.397\n",
      "0.079\n",
      "0.079\n",
      "0.476\n",
      "0.080\n",
      "0.383\n",
      "0.226\n",
      "0.132\n",
      "0.486\n",
      "0.088\n",
      "0.454\n",
      "0.095\n",
      "0.079\n",
      "0.527\n",
      "0.661\n",
      "0.246\n",
      "0.353\n",
      "0.136\n",
      "0.138\n",
      "0.741\n",
      "0.866\n",
      "0.262\n",
      "0.170\n",
      "0.225\n",
      "0.300\n",
      "0.579\n",
      "0.190\n",
      "0.329\n",
      "0.087\n",
      "0.156\n",
      "0.082\n",
      "0.085\n",
      "0.096\n",
      "0.116\n",
      "0.225\n",
      "0.225\n",
      "0.241\n",
      "0.110\n",
      "0.133\n",
      "0.510\n",
      "0.114\n",
      "0.250\n",
      "0.100\n",
      "0.257\n",
      "0.112\n",
      "0.371\n",
      "0.092\n",
      "0.346\n",
      "0.130\n",
      "0.125\n",
      "0.525\n",
      "0.649\n",
      "0.546\n",
      "0.256\n",
      "0.357\n",
      "0.093\n",
      "0.177\n",
      "0.302\n",
      "0.545\n",
      "0.312\n",
      "0.738\n",
      "0.541\n",
      "0.347\n",
      "0.496\n",
      "0.308\n",
      "0.364\n",
      "0.427\n",
      "0.630\n",
      "0.500\n",
      "0.269\n",
      "0.133\n",
      "0.330\n",
      "0.244\n",
      "0.445\n",
      "0.610\n",
      "0.547\n",
      "0.340\n",
      "0.228\n",
      "0.419\n",
      "0.215\n",
      "0.185\n",
      "0.206\n",
      "0.528\n",
      "0.104\n",
      "0.958\n",
      "0.573\n",
      "0.438\n",
      "0.971\n",
      "0.840\n",
      "0.343\n",
      "0.125\n",
      "0.664\n",
      "0.548\n",
      "0.282\n",
      "0.321\n",
      "0.833\n",
      "0.974\n",
      "0.574\n",
      "0.466\n",
      "0.415\n",
      "0.867\n",
      "0.578\n",
      "0.978\n",
      "0.578\n",
      "0.797\n",
      "0.696\n",
      "0.356\n",
      "0.230\n",
      "0.347\n",
      "0.346\n",
      "0.361\n",
      "0.196\n",
      "0.185\n",
      "0.183\n",
      "0.307\n",
      "0.281\n",
      "0.452\n",
      "0.197\n",
      "0.242\n",
      "0.137\n",
      "0.333\n",
      "0.376\n",
      "0.304\n",
      "0.191\n",
      "0.603\n",
      "0.420\n",
      "0.353\n",
      "0.129\n",
      "0.136\n",
      "0.438\n",
      "0.196\n",
      "0.170\n",
      "0.338\n",
      "0.419\n",
      "0.466\n",
      "0.626\n",
      "0.309\n",
      "0.152\n",
      "0.928\n",
      "0.840\n",
      "0.109\n",
      "0.255\n",
      "0.629\n",
      "0.523\n",
      "0.309\n",
      "0.300\n",
      "0.977\n",
      "0.434\n",
      "0.253\n",
      "0.538\n",
      "0.665\n",
      "0.146\n",
      "0.723\n",
      "0.644\n",
      "0.243\n",
      "0.609\n",
      "0.663\n",
      "0.162\n",
      "0.290\n",
      "0.093\n",
      "0.314\n",
      "0.606\n",
      "0.260\n",
      "0.339\n",
      "0.776\n",
      "0.365\n",
      "0.110\n",
      "0.623\n",
      "0.241\n",
      "0.412\n",
      "0.094\n",
      "0.094\n",
      "0.491\n",
      "0.096\n",
      "0.399\n",
      "0.242\n",
      "0.147\n",
      "0.501\n",
      "0.104\n",
      "0.469\n",
      "0.110\n",
      "0.094\n",
      "0.543\n",
      "0.676\n",
      "0.261\n",
      "0.368\n",
      "0.151\n",
      "0.123\n",
      "0.726\n",
      "0.851\n",
      "0.247\n",
      "0.155\n",
      "0.210\n",
      "0.286\n",
      "0.565\n",
      "0.175\n",
      "0.314\n",
      "0.072\n",
      "0.141\n",
      "0.067\n",
      "0.070\n",
      "0.081\n",
      "0.101\n",
      "0.211\n",
      "0.211\n",
      "0.226\n",
      "0.095\n",
      "0.119\n",
      "0.495\n",
      "0.099\n",
      "0.235\n",
      "0.085\n",
      "0.242\n",
      "0.098\n",
      "0.357\n",
      "0.077\n",
      "0.331\n",
      "0.115\n",
      "0.110\n",
      "0.510\n",
      "0.635\n",
      "0.532\n",
      "0.241\n",
      "0.342\n",
      "0.079\n",
      "0.162\n",
      "0.287\n",
      "0.530\n",
      "0.297\n",
      "0.723\n",
      "0.526\n",
      "0.333\n",
      "0.481\n",
      "0.294\n",
      "0.349\n",
      "0.412\n",
      "0.615\n",
      "0.486\n",
      "0.255\n",
      "0.118\n",
      "0.315\n",
      "0.229\n",
      "0.430\n",
      "0.595\n",
      "0.532\n",
      "0.326\n",
      "0.213\n",
      "0.404\n",
      "0.200\n",
      "0.171\n",
      "0.192\n",
      "0.513\n",
      "0.089\n",
      "0.943\n",
      "0.558\n",
      "0.423\n",
      "0.956\n",
      "0.825\n",
      "0.329\n",
      "0.110\n",
      "0.650\n",
      "0.533\n",
      "0.267\n",
      "0.306\n",
      "0.819\n",
      "0.959\n",
      "0.559\n",
      "0.451\n",
      "0.400\n",
      "0.853\n",
      "0.563\n",
      "0.963\n",
      "0.564\n",
      "0.782\n",
      "0.681\n",
      "0.341\n",
      "0.215\n",
      "0.332\n",
      "0.331\n",
      "0.346\n",
      "0.182\n",
      "0.171\n",
      "0.168\n",
      "0.292\n",
      "0.266\n",
      "0.438\n",
      "0.182\n",
      "0.227\n",
      "0.122\n",
      "0.318\n",
      "0.361\n",
      "0.290\n",
      "0.176\n",
      "0.589\n",
      "0.405\n",
      "0.338\n",
      "0.115\n",
      "0.121\n",
      "0.424\n",
      "0.182\n",
      "0.155\n",
      "0.323\n",
      "0.404\n",
      "0.452\n",
      "0.611\n",
      "0.294\n",
      "0.137\n",
      "0.914\n",
      "0.826\n",
      "0.095\n",
      "0.240\n",
      "0.615\n",
      "0.508\n",
      "0.295\n",
      "0.285\n",
      "0.963\n",
      "0.419\n",
      "0.238\n",
      "0.523\n",
      "0.650\n",
      "0.131\n",
      "0.708\n",
      "0.629\n",
      "0.228\n",
      "0.594\n",
      "0.648\n",
      "0.147\n",
      "0.275\n",
      "0.078\n",
      "0.299\n",
      "0.592\n",
      "0.246\n",
      "0.324\n",
      "0.762\n",
      "0.350\n",
      "0.096\n",
      "0.608\n",
      "0.226\n",
      "0.398\n",
      "0.080\n",
      "0.080\n",
      "0.476\n",
      "0.081\n",
      "0.384\n",
      "0.227\n",
      "0.132\n",
      "0.486\n",
      "0.089\n",
      "0.455\n",
      "0.096\n",
      "0.080\n",
      "0.528\n",
      "0.661\n",
      "0.246\n",
      "0.353\n",
      "0.136\n",
      "0.120\n",
      "0.723\n",
      "0.848\n",
      "0.244\n",
      "0.152\n",
      "0.208\n",
      "0.283\n",
      "0.562\n",
      "0.173\n",
      "0.312\n",
      "0.069\n",
      "0.138\n",
      "0.065\n",
      "0.068\n",
      "0.078\n",
      "0.098\n",
      "0.208\n",
      "0.208\n",
      "0.223\n",
      "0.093\n",
      "0.116\n",
      "0.493\n",
      "0.096\n",
      "0.232\n",
      "0.082\n",
      "0.240\n",
      "0.095\n",
      "0.354\n",
      "0.075\n",
      "0.328\n",
      "0.113\n",
      "0.107\n",
      "0.507\n",
      "0.632\n",
      "0.529\n",
      "0.239\n",
      "0.339\n",
      "0.076\n",
      "0.159\n",
      "0.284\n",
      "0.528\n",
      "0.295\n",
      "0.721\n",
      "0.523\n",
      "0.330\n",
      "0.479\n",
      "0.291\n",
      "0.347\n",
      "0.409\n",
      "0.613\n",
      "0.483\n",
      "0.252\n",
      "0.115\n",
      "0.313\n",
      "0.227\n",
      "0.428\n",
      "0.593\n",
      "0.529\n",
      "0.323\n",
      "0.210\n",
      "0.401\n",
      "0.198\n",
      "0.168\n",
      "0.189\n",
      "0.510\n",
      "0.086\n",
      "0.941\n",
      "0.556\n",
      "0.420\n",
      "0.953\n",
      "0.822\n",
      "0.326\n",
      "0.108\n",
      "0.647\n",
      "0.530\n",
      "0.264\n",
      "0.304\n",
      "0.816\n",
      "0.957\n",
      "0.556\n",
      "0.449\n",
      "0.398\n",
      "0.850\n",
      "0.561\n",
      "0.960\n",
      "0.561\n",
      "0.779\n",
      "0.679\n",
      "0.339\n",
      "0.213\n",
      "0.329\n",
      "0.329\n",
      "0.344\n",
      "0.179\n",
      "0.168\n",
      "0.165\n",
      "0.290\n",
      "0.264\n",
      "0.435\n",
      "0.180\n",
      "0.225\n",
      "0.119\n",
      "0.316\n",
      "0.358\n",
      "0.287\n",
      "0.174\n",
      "0.586\n",
      "0.402\n",
      "0.336\n",
      "0.112\n",
      "0.118\n",
      "0.421\n",
      "0.179\n",
      "0.152\n",
      "0.321\n",
      "0.401\n",
      "0.449\n",
      "0.609\n",
      "0.292\n",
      "0.134\n",
      "0.911\n",
      "0.823\n",
      "0.092\n",
      "0.237\n",
      "0.612\n",
      "0.505\n",
      "0.292\n",
      "0.283\n",
      "0.960\n",
      "0.417\n",
      "0.235\n",
      "0.520\n",
      "0.648\n",
      "0.129\n",
      "0.706\n",
      "0.626\n",
      "0.225\n",
      "0.592\n",
      "0.646\n",
      "0.144\n",
      "0.272\n",
      "0.076\n",
      "0.297\n",
      "0.589\n",
      "0.243\n",
      "0.322\n",
      "0.759\n",
      "0.347\n",
      "0.093\n",
      "0.605\n",
      "0.224\n",
      "0.395\n",
      "0.077\n",
      "0.077\n",
      "0.473\n",
      "0.078\n",
      "0.381\n",
      "0.224\n",
      "0.129\n",
      "0.484\n",
      "0.086\n",
      "0.452\n",
      "0.093\n",
      "0.077\n",
      "0.525\n",
      "0.658\n",
      "0.243\n",
      "0.351\n",
      "0.133\n",
      "0.113\n",
      "0.716\n",
      "0.841\n",
      "0.237\n",
      "0.145\n",
      "0.200\n",
      "0.276\n",
      "0.555\n",
      "0.165\n",
      "0.304\n",
      "0.062\n",
      "0.131\n",
      "0.057\n",
      "0.060\n",
      "0.071\n",
      "0.091\n",
      "0.201\n",
      "0.201\n",
      "0.216\n",
      "0.085\n",
      "0.109\n",
      "0.485\n",
      "0.089\n",
      "0.225\n",
      "0.075\n",
      "0.232\n",
      "0.088\n",
      "0.347\n",
      "0.067\n",
      "0.321\n",
      "0.105\n",
      "0.100\n",
      "0.500\n",
      "0.625\n",
      "0.522\n",
      "0.231\n",
      "0.332\n",
      "0.069\n",
      "0.152\n",
      "0.277\n",
      "0.520\n",
      "0.287\n",
      "0.713\n",
      "0.516\n",
      "0.323\n",
      "0.471\n",
      "0.284\n",
      "0.339\n",
      "0.402\n",
      "0.605\n",
      "0.476\n",
      "0.245\n",
      "0.108\n",
      "0.305\n",
      "0.219\n",
      "0.420\n",
      "0.585\n",
      "0.522\n",
      "0.316\n",
      "0.203\n",
      "0.394\n",
      "0.190\n",
      "0.161\n",
      "0.182\n",
      "0.503\n",
      "0.079\n",
      "0.933\n",
      "0.548\n",
      "0.413\n",
      "0.946\n",
      "0.815\n",
      "0.319\n",
      "0.100\n",
      "0.640\n",
      "0.523\n",
      "0.257\n",
      "0.296\n",
      "0.809\n",
      "0.949\n",
      "0.549\n",
      "0.441\n",
      "0.390\n",
      "0.843\n",
      "0.553\n",
      "0.953\n",
      "0.554\n",
      "0.772\n",
      "0.671\n",
      "0.331\n",
      "0.205\n",
      "0.322\n",
      "0.321\n",
      "0.336\n",
      "0.172\n",
      "0.161\n",
      "0.158\n",
      "0.282\n",
      "0.256\n",
      "0.428\n",
      "0.172\n",
      "0.217\n",
      "0.112\n",
      "0.308\n",
      "0.351\n",
      "0.280\n",
      "0.166\n",
      "0.579\n",
      "0.395\n",
      "0.328\n",
      "0.105\n",
      "0.111\n",
      "0.414\n",
      "0.172\n",
      "0.145\n",
      "0.313\n",
      "0.394\n",
      "0.442\n",
      "0.601\n",
      "0.284\n",
      "0.127\n",
      "0.904\n",
      "0.816\n",
      "0.085\n",
      "0.230\n",
      "0.605\n",
      "0.498\n",
      "0.285\n",
      "0.275\n",
      "0.953\n",
      "0.409\n",
      "0.228\n",
      "0.513\n",
      "0.640\n",
      "0.121\n",
      "0.698\n",
      "0.619\n",
      "0.218\n",
      "0.585\n",
      "0.638\n",
      "0.137\n",
      "0.265\n",
      "0.068\n",
      "0.289\n",
      "0.582\n",
      "0.236\n",
      "0.314\n",
      "0.752\n",
      "0.340\n",
      "0.086\n",
      "0.598\n",
      "0.216\n",
      "0.388\n",
      "0.070\n",
      "0.070\n",
      "0.466\n",
      "0.071\n",
      "0.374\n",
      "0.217\n",
      "0.122\n",
      "0.476\n",
      "0.079\n",
      "0.445\n",
      "0.086\n",
      "0.070\n",
      "0.518\n",
      "0.651\n",
      "0.236\n",
      "0.343\n",
      "0.126\n",
      "0.089\n",
      "0.692\n",
      "0.817\n",
      "0.213\n",
      "0.121\n",
      "0.176\n",
      "0.252\n",
      "0.531\n",
      "0.141\n",
      "0.280\n",
      "0.038\n",
      "0.107\n",
      "0.033\n",
      "0.036\n",
      "0.047\n",
      "0.067\n",
      "0.177\n",
      "0.177\n",
      "0.192\n",
      "0.061\n",
      "0.085\n",
      "0.461\n",
      "0.065\n",
      "0.201\n",
      "0.051\n",
      "0.208\n",
      "0.064\n",
      "0.323\n",
      "0.044\n",
      "0.297\n",
      "0.082\n",
      "0.076\n",
      "0.476\n",
      "0.601\n",
      "0.498\n",
      "0.207\n",
      "0.308\n",
      "0.045\n",
      "0.128\n",
      "0.253\n",
      "0.496\n",
      "0.263\n",
      "0.689\n",
      "0.492\n",
      "0.299\n",
      "0.447\n",
      "0.260\n",
      "0.315\n",
      "0.378\n",
      "0.581\n",
      "0.452\n",
      "0.221\n",
      "0.084\n",
      "0.281\n",
      "0.195\n",
      "0.396\n",
      "0.561\n",
      "0.498\n",
      "0.292\n",
      "0.179\n",
      "0.370\n",
      "0.166\n",
      "0.137\n",
      "0.158\n",
      "0.479\n",
      "0.055\n",
      "0.909\n",
      "0.524\n",
      "0.389\n",
      "0.922\n",
      "0.791\n",
      "0.295\n",
      "0.076\n",
      "0.616\n",
      "0.499\n",
      "0.233\n",
      "0.272\n",
      "0.785\n",
      "0.925\n",
      "0.525\n",
      "0.417\n",
      "0.366\n",
      "0.819\n",
      "0.529\n",
      "0.929\n",
      "0.530\n",
      "0.748\n",
      "0.647\n",
      "0.307\n",
      "0.181\n",
      "0.298\n",
      "0.297\n",
      "0.312\n",
      "0.148\n",
      "0.137\n",
      "0.134\n",
      "0.258\n",
      "0.232\n",
      "0.404\n",
      "0.148\n",
      "0.193\n",
      "0.088\n",
      "0.284\n",
      "0.327\n",
      "0.256\n",
      "0.142\n",
      "0.555\n",
      "0.371\n",
      "0.304\n",
      "0.081\n",
      "0.087\n",
      "0.390\n",
      "0.148\n",
      "0.121\n",
      "0.289\n",
      "0.370\n",
      "0.418\n",
      "0.577\n",
      "0.260\n",
      "0.103\n",
      "0.880\n",
      "0.792\n",
      "0.061\n",
      "0.206\n",
      "0.581\n",
      "0.474\n",
      "0.261\n",
      "0.251\n",
      "0.929\n",
      "0.385\n",
      "0.204\n",
      "0.489\n",
      "0.616\n",
      "0.097\n",
      "0.675\n",
      "0.595\n",
      "0.194\n",
      "0.561\n",
      "0.614\n",
      "0.113\n",
      "0.241\n",
      "0.044\n",
      "0.266\n",
      "0.558\n",
      "0.212\n",
      "0.290\n",
      "0.728\n",
      "0.316\n",
      "0.062\n",
      "0.574\n",
      "0.193\n",
      "0.364\n",
      "0.046\n",
      "0.046\n",
      "0.442\n",
      "0.047\n",
      "0.350\n",
      "0.193\n",
      "0.098\n",
      "0.452\n",
      "0.055\n",
      "0.421\n",
      "0.062\n",
      "0.046\n",
      "0.494\n",
      "0.627\n",
      "0.212\n",
      "0.319\n",
      "0.102\n",
      "0.103\n",
      "0.706\n",
      "0.831\n",
      "0.227\n",
      "0.135\n",
      "0.190\n",
      "0.265\n",
      "0.544\n",
      "0.155\n",
      "0.294\n",
      "0.052\n",
      "0.121\n",
      "0.047\n",
      "0.050\n",
      "0.061\n",
      "0.081\n",
      "0.190\n",
      "0.190\n",
      "0.206\n",
      "0.075\n",
      "0.098\n",
      "0.475\n",
      "0.079\n",
      "0.215\n",
      "0.065\n",
      "0.222\n",
      "0.077\n",
      "0.336\n",
      "0.057\n",
      "0.311\n",
      "0.095\n",
      "0.090\n",
      "0.490\n",
      "0.614\n",
      "0.511\n",
      "0.221\n",
      "0.322\n",
      "0.058\n",
      "0.142\n",
      "0.267\n",
      "0.510\n",
      "0.277\n",
      "0.703\n",
      "0.506\n",
      "0.312\n",
      "0.461\n",
      "0.273\n",
      "0.329\n",
      "0.392\n",
      "0.595\n",
      "0.465\n",
      "0.234\n",
      "0.098\n",
      "0.295\n",
      "0.209\n",
      "0.410\n",
      "0.575\n",
      "0.512\n",
      "0.305\n",
      "0.193\n",
      "0.384\n",
      "0.180\n",
      "0.150\n",
      "0.171\n",
      "0.493\n",
      "0.069\n",
      "0.923\n",
      "0.538\n",
      "0.403\n",
      "0.936\n",
      "0.805\n",
      "0.308\n",
      "0.090\n",
      "0.629\n",
      "0.513\n",
      "0.247\n",
      "0.286\n",
      "0.798\n",
      "0.939\n",
      "0.539\n",
      "0.431\n",
      "0.380\n",
      "0.832\n",
      "0.543\n",
      "0.943\n",
      "0.543\n",
      "0.762\n",
      "0.661\n",
      "0.321\n",
      "0.195\n",
      "0.312\n",
      "0.311\n",
      "0.326\n",
      "0.161\n",
      "0.150\n",
      "0.148\n",
      "0.272\n",
      "0.246\n",
      "0.417\n",
      "0.162\n",
      "0.207\n",
      "0.102\n",
      "0.298\n",
      "0.341\n",
      "0.269\n",
      "0.156\n",
      "0.568\n",
      "0.385\n",
      "0.318\n",
      "0.094\n",
      "0.101\n",
      "0.403\n",
      "0.161\n",
      "0.135\n",
      "0.303\n",
      "0.384\n",
      "0.431\n",
      "0.591\n",
      "0.274\n",
      "0.117\n",
      "0.893\n",
      "0.805\n",
      "0.074\n",
      "0.220\n",
      "0.594\n",
      "0.488\n",
      "0.274\n",
      "0.265\n",
      "0.942\n",
      "0.399\n",
      "0.218\n",
      "0.503\n",
      "0.630\n",
      "0.111\n",
      "0.688\n",
      "0.609\n",
      "0.208\n",
      "0.574\n",
      "0.628\n",
      "0.127\n",
      "0.255\n",
      "0.058\n",
      "0.279\n",
      "0.571\n",
      "0.225\n",
      "0.304\n",
      "0.741\n",
      "0.330\n",
      "0.075\n",
      "0.588\n",
      "0.206\n",
      "0.377\n",
      "0.059\n",
      "0.059\n",
      "0.456\n",
      "0.061\n",
      "0.364\n",
      "0.206\n",
      "0.112\n",
      "0.466\n",
      "0.069\n",
      "0.434\n",
      "0.075\n",
      "0.059\n",
      "0.508\n",
      "0.641\n",
      "0.226\n",
      "0.333\n",
      "0.116\n",
      "0.095\n",
      "0.698\n",
      "0.823\n",
      "0.219\n",
      "0.127\n",
      "0.183\n",
      "0.258\n",
      "0.537\n",
      "0.148\n",
      "0.286\n",
      "0.044\n",
      "0.113\n",
      "0.040\n",
      "0.043\n",
      "0.053\n",
      "0.073\n",
      "0.183\n",
      "0.183\n",
      "0.198\n",
      "0.068\n",
      "0.091\n",
      "0.468\n",
      "0.071\n",
      "0.207\n",
      "0.057\n",
      "0.215\n",
      "0.070\n",
      "0.329\n",
      "0.050\n",
      "0.303\n",
      "0.088\n",
      "0.082\n",
      "0.482\n",
      "0.607\n",
      "0.504\n",
      "0.213\n",
      "0.314\n",
      "0.051\n",
      "0.134\n",
      "0.259\n",
      "0.503\n",
      "0.270\n",
      "0.696\n",
      "0.498\n",
      "0.305\n",
      "0.453\n",
      "0.266\n",
      "0.321\n",
      "0.384\n",
      "0.588\n",
      "0.458\n",
      "0.227\n",
      "0.090\n",
      "0.288\n",
      "0.202\n",
      "0.402\n",
      "0.567\n",
      "0.504\n",
      "0.298\n",
      "0.185\n",
      "0.376\n",
      "0.172\n",
      "0.143\n",
      "0.164\n",
      "0.485\n",
      "0.061\n",
      "0.916\n",
      "0.530\n",
      "0.395\n",
      "0.928\n",
      "0.797\n",
      "0.301\n",
      "0.082\n",
      "0.622\n",
      "0.505\n",
      "0.239\n",
      "0.278\n",
      "0.791\n",
      "0.931\n",
      "0.531\n",
      "0.423\n",
      "0.373\n",
      "0.825\n",
      "0.536\n",
      "0.935\n",
      "0.536\n",
      "0.754\n",
      "0.653\n",
      "0.313\n",
      "0.188\n",
      "0.304\n",
      "0.303\n",
      "0.318\n",
      "0.154\n",
      "0.143\n",
      "0.140\n",
      "0.265\n",
      "0.238\n",
      "0.410\n",
      "0.154\n",
      "0.199\n",
      "0.094\n",
      "0.291\n",
      "0.333\n",
      "0.262\n",
      "0.148\n",
      "0.561\n",
      "0.377\n",
      "0.311\n",
      "0.087\n",
      "0.093\n",
      "0.396\n",
      "0.154\n",
      "0.127\n",
      "0.295\n",
      "0.376\n",
      "0.424\n",
      "0.583\n",
      "0.266\n",
      "0.109\n",
      "0.886\n",
      "0.798\n",
      "0.067\n",
      "0.212\n",
      "0.587\n",
      "0.480\n",
      "0.267\n",
      "0.257\n",
      "0.935\n",
      "0.391\n",
      "0.210\n",
      "0.495\n",
      "0.623\n",
      "0.104\n",
      "0.681\n",
      "0.601\n",
      "0.200\n",
      "0.567\n",
      "0.621\n",
      "0.119\n",
      "0.247\n",
      "0.051\n",
      "0.272\n",
      "0.564\n",
      "0.218\n",
      "0.297\n",
      "0.734\n",
      "0.322\n",
      "0.068\n",
      "0.580\n",
      "0.199\n",
      "0.370\n",
      "0.052\n",
      "0.052\n",
      "0.448\n",
      "0.053\n",
      "0.356\n",
      "0.199\n",
      "0.104\n",
      "0.458\n",
      "0.061\n",
      "0.427\n",
      "0.068\n",
      "0.052\n",
      "0.500\n",
      "0.633\n",
      "0.218\n",
      "0.326\n",
      "0.108\n",
      "0.066\n",
      "0.669\n",
      "0.795\n",
      "0.190\n",
      "0.098\n",
      "0.154\n",
      "0.229\n",
      "0.508\n",
      "0.119\n",
      "0.258\n",
      "0.016\n",
      "0.084\n",
      "0.011\n",
      "0.014\n",
      "0.025\n",
      "0.045\n",
      "0.154\n",
      "0.154\n",
      "0.169\n",
      "0.039\n",
      "0.062\n",
      "0.439\n",
      "0.043\n",
      "0.179\n",
      "0.028\n",
      "0.186\n",
      "0.041\n",
      "0.300\n",
      "0.021\n",
      "0.274\n",
      "0.059\n",
      "0.054\n",
      "0.454\n",
      "0.578\n",
      "0.475\n",
      "0.185\n",
      "0.285\n",
      "0.022\n",
      "0.105\n",
      "0.230\n",
      "0.474\n",
      "0.241\n",
      "0.667\n",
      "0.469\n",
      "0.276\n",
      "0.425\n",
      "0.237\n",
      "0.293\n",
      "0.355\n",
      "0.559\n",
      "0.429\n",
      "0.198\n",
      "0.062\n",
      "0.259\n",
      "0.173\n",
      "0.374\n",
      "0.539\n",
      "0.475\n",
      "0.269\n",
      "0.157\n",
      "0.348\n",
      "0.144\n",
      "0.114\n",
      "0.135\n",
      "0.457\n",
      "0.033\n",
      "0.887\n",
      "0.502\n",
      "0.367\n",
      "0.899\n",
      "0.769\n",
      "0.272\n",
      "0.054\n",
      "0.593\n",
      "0.477\n",
      "0.210\n",
      "0.250\n",
      "0.762\n",
      "0.903\n",
      "0.503\n",
      "0.395\n",
      "0.344\n",
      "0.796\n",
      "0.507\n",
      "0.906\n",
      "0.507\n",
      "0.725\n",
      "0.625\n",
      "0.285\n",
      "0.159\n",
      "0.276\n",
      "0.275\n",
      "0.290\n",
      "0.125\n",
      "0.114\n",
      "0.111\n",
      "0.236\n",
      "0.210\n",
      "0.381\n",
      "0.126\n",
      "0.171\n",
      "0.066\n",
      "0.262\n",
      "0.305\n",
      "0.233\n",
      "0.120\n",
      "0.532\n",
      "0.349\n",
      "0.282\n",
      "0.058\n",
      "0.064\n",
      "0.367\n",
      "0.125\n",
      "0.099\n",
      "0.267\n",
      "0.348\n",
      "0.395\n",
      "0.555\n",
      "0.238\n",
      "0.081\n",
      "0.857\n",
      "0.769\n",
      "0.038\n",
      "0.183\n",
      "0.558\n",
      "0.452\n",
      "0.238\n",
      "0.229\n",
      "0.906\n",
      "0.363\n",
      "0.182\n",
      "0.466\n",
      "0.594\n",
      "0.075\n",
      "0.652\n",
      "0.573\n",
      "0.172\n",
      "0.538\n",
      "0.592\n",
      "0.091\n",
      "0.218\n",
      "0.022\n",
      "0.243\n",
      "0.535\n",
      "0.189\n",
      "0.268\n",
      "0.705\n",
      "0.294\n",
      "0.039\n",
      "0.552\n",
      "0.170\n",
      "0.341\n",
      "0.023\n",
      "0.023\n",
      "0.420\n",
      "0.025\n",
      "0.327\n",
      "0.170\n",
      "0.076\n",
      "0.430\n",
      "0.032\n",
      "0.398\n",
      "0.039\n",
      "0.023\n",
      "0.472\n",
      "0.605\n",
      "0.190\n",
      "0.297\n",
      "0.080\n",
      "0.114\n",
      "0.717\n",
      "0.842\n",
      "0.238\n",
      "0.146\n",
      "0.201\n",
      "0.276\n",
      "0.555\n",
      "0.166\n",
      "0.305\n",
      "0.063\n",
      "0.132\n",
      "0.058\n",
      "0.061\n",
      "0.072\n",
      "0.092\n",
      "0.201\n",
      "0.201\n",
      "0.217\n",
      "0.086\n",
      "0.110\n",
      "0.486\n",
      "0.090\n",
      "0.226\n",
      "0.076\n",
      "0.233\n",
      "0.088\n",
      "0.347\n",
      "0.068\n",
      "0.322\n",
      "0.106\n",
      "0.101\n",
      "0.501\n",
      "0.625\n",
      "0.522\n",
      "0.232\n",
      "0.333\n",
      "0.069\n",
      "0.153\n",
      "0.278\n",
      "0.521\n",
      "0.288\n",
      "0.714\n",
      "0.517\n",
      "0.323\n",
      "0.472\n",
      "0.284\n",
      "0.340\n",
      "0.403\n",
      "0.606\n",
      "0.476\n",
      "0.245\n",
      "0.109\n",
      "0.306\n",
      "0.220\n",
      "0.421\n",
      "0.586\n",
      "0.523\n",
      "0.316\n",
      "0.204\n",
      "0.395\n",
      "0.191\n",
      "0.161\n",
      "0.183\n",
      "0.504\n",
      "0.080\n",
      "0.934\n",
      "0.549\n",
      "0.414\n",
      "0.947\n",
      "0.816\n",
      "0.319\n",
      "0.101\n",
      "0.640\n",
      "0.524\n",
      "0.258\n",
      "0.297\n",
      "0.809\n",
      "0.950\n",
      "0.550\n",
      "0.442\n",
      "0.391\n",
      "0.843\n",
      "0.554\n",
      "0.954\n",
      "0.554\n",
      "0.773\n",
      "0.672\n",
      "0.332\n",
      "0.206\n",
      "0.323\n",
      "0.322\n",
      "0.337\n",
      "0.172\n",
      "0.161\n",
      "0.159\n",
      "0.283\n",
      "0.257\n",
      "0.428\n",
      "0.173\n",
      "0.218\n",
      "0.113\n",
      "0.309\n",
      "0.352\n",
      "0.280\n",
      "0.167\n",
      "0.579\n",
      "0.396\n",
      "0.329\n",
      "0.105\n",
      "0.112\n",
      "0.414\n",
      "0.172\n",
      "0.146\n",
      "0.314\n",
      "0.395\n",
      "0.443\n",
      "0.602\n",
      "0.285\n",
      "0.128\n",
      "0.905\n",
      "0.817\n",
      "0.085\n",
      "0.231\n",
      "0.605\n",
      "0.499\n",
      "0.285\n",
      "0.276\n",
      "0.953\n",
      "0.410\n",
      "0.229\n",
      "0.514\n",
      "0.641\n",
      "0.122\n",
      "0.699\n",
      "0.620\n",
      "0.219\n",
      "0.585\n",
      "0.639\n",
      "0.138\n",
      "0.266\n",
      "0.069\n",
      "0.290\n",
      "0.582\n",
      "0.236\n",
      "0.315\n",
      "0.753\n",
      "0.341\n",
      "0.087\n",
      "0.599\n",
      "0.217\n",
      "0.388\n",
      "0.070\n",
      "0.070\n",
      "0.467\n",
      "0.072\n",
      "0.375\n",
      "0.218\n",
      "0.123\n",
      "0.477\n",
      "0.080\n",
      "0.446\n",
      "0.087\n",
      "0.070\n",
      "0.519\n",
      "0.652\n",
      "0.237\n",
      "0.344\n",
      "0.127\n",
      "0.122\n",
      "0.725\n",
      "0.850\n",
      "0.245\n",
      "0.154\n",
      "0.209\n",
      "0.284\n",
      "0.563\n",
      "0.174\n",
      "0.313\n",
      "0.071\n",
      "0.140\n",
      "0.066\n",
      "0.069\n",
      "0.080\n",
      "0.100\n",
      "0.209\n",
      "0.209\n",
      "0.225\n",
      "0.094\n",
      "0.117\n",
      "0.494\n",
      "0.098\n",
      "0.234\n",
      "0.084\n",
      "0.241\n",
      "0.096\n",
      "0.355\n",
      "0.076\n",
      "0.330\n",
      "0.114\n",
      "0.109\n",
      "0.509\n",
      "0.633\n",
      "0.530\n",
      "0.240\n",
      "0.341\n",
      "0.077\n",
      "0.161\n",
      "0.286\n",
      "0.529\n",
      "0.296\n",
      "0.722\n",
      "0.525\n",
      "0.331\n",
      "0.480\n",
      "0.292\n",
      "0.348\n",
      "0.411\n",
      "0.614\n",
      "0.484\n",
      "0.253\n",
      "0.117\n",
      "0.314\n",
      "0.228\n",
      "0.429\n",
      "0.594\n",
      "0.531\n",
      "0.324\n",
      "0.212\n",
      "0.403\n",
      "0.199\n",
      "0.169\n",
      "0.190\n",
      "0.512\n",
      "0.088\n",
      "0.942\n",
      "0.557\n",
      "0.422\n",
      "0.955\n",
      "0.824\n",
      "0.327\n",
      "0.109\n",
      "0.648\n",
      "0.532\n",
      "0.266\n",
      "0.305\n",
      "0.817\n",
      "0.958\n",
      "0.558\n",
      "0.450\n",
      "0.399\n",
      "0.851\n",
      "0.562\n",
      "0.961\n",
      "0.562\n",
      "0.780\n",
      "0.680\n",
      "0.340\n",
      "0.214\n",
      "0.331\n",
      "0.330\n",
      "0.345\n",
      "0.180\n",
      "0.169\n",
      "0.167\n",
      "0.291\n",
      "0.265\n",
      "0.436\n",
      "0.181\n",
      "0.226\n",
      "0.121\n",
      "0.317\n",
      "0.360\n",
      "0.288\n",
      "0.175\n",
      "0.587\n",
      "0.404\n",
      "0.337\n",
      "0.113\n",
      "0.120\n",
      "0.422\n",
      "0.180\n",
      "0.154\n",
      "0.322\n",
      "0.403\n",
      "0.450\n",
      "0.610\n",
      "0.293\n",
      "0.136\n",
      "0.912\n",
      "0.824\n",
      "0.093\n",
      "0.239\n",
      "0.613\n",
      "0.507\n",
      "0.293\n",
      "0.284\n",
      "0.961\n",
      "0.418\n",
      "0.237\n",
      "0.522\n",
      "0.649\n",
      "0.130\n",
      "0.707\n",
      "0.628\n",
      "0.227\n",
      "0.593\n",
      "0.647\n",
      "0.146\n",
      "0.274\n",
      "0.077\n",
      "0.298\n",
      "0.590\n",
      "0.244\n",
      "0.323\n",
      "0.760\n",
      "0.349\n",
      "0.094\n",
      "0.607\n",
      "0.225\n",
      "0.396\n",
      "0.078\n",
      "0.078\n",
      "0.475\n",
      "0.080\n",
      "0.383\n",
      "0.225\n",
      "0.131\n",
      "0.485\n",
      "0.088\n",
      "0.453\n",
      "0.094\n",
      "0.078\n",
      "0.527\n",
      "0.660\n",
      "0.245\n",
      "0.352\n",
      "0.135\n",
      "0.156\n",
      "0.759\n",
      "0.884\n",
      "0.280\n",
      "0.188\n",
      "0.244\n",
      "0.319\n",
      "0.598\n",
      "0.209\n",
      "0.347\n",
      "0.105\n",
      "0.174\n",
      "0.101\n",
      "0.104\n",
      "0.114\n",
      "0.134\n",
      "0.244\n",
      "0.244\n",
      "0.259\n",
      "0.129\n",
      "0.152\n",
      "0.529\n",
      "0.132\n",
      "0.268\n",
      "0.118\n",
      "0.276\n",
      "0.131\n",
      "0.390\n",
      "0.111\n",
      "0.364\n",
      "0.149\n",
      "0.143\n",
      "0.543\n",
      "0.668\n",
      "0.565\n",
      "0.274\n",
      "0.375\n",
      "0.112\n",
      "0.195\n",
      "0.320\n",
      "0.564\n",
      "0.331\n",
      "0.757\n",
      "0.559\n",
      "0.366\n",
      "0.514\n",
      "0.327\n",
      "0.383\n",
      "0.445\n",
      "0.649\n",
      "0.519\n",
      "0.288\n",
      "0.151\n",
      "0.349\n",
      "0.263\n",
      "0.464\n",
      "0.628\n",
      "0.565\n",
      "0.359\n",
      "0.246\n",
      "0.437\n",
      "0.234\n",
      "0.204\n",
      "0.225\n",
      "0.546\n",
      "0.122\n",
      "0.977\n",
      "0.592\n",
      "0.456\n",
      "0.989\n",
      "0.858\n",
      "0.362\n",
      "0.143\n",
      "0.683\n",
      "0.566\n",
      "0.300\n",
      "0.339\n",
      "0.852\n",
      "0.993\n",
      "0.592\n",
      "0.485\n",
      "0.434\n",
      "0.886\n",
      "0.597\n",
      "0.996\n",
      "0.597\n",
      "0.815\n",
      "0.715\n",
      "0.374\n",
      "0.249\n",
      "0.365\n",
      "0.365\n",
      "0.380\n",
      "0.215\n",
      "0.204\n",
      "0.201\n",
      "0.326\n",
      "0.300\n",
      "0.471\n",
      "0.216\n",
      "0.260\n",
      "0.155\n",
      "0.352\n",
      "0.394\n",
      "0.323\n",
      "0.210\n",
      "0.622\n",
      "0.438\n",
      "0.372\n",
      "0.148\n",
      "0.154\n",
      "0.457\n",
      "0.215\n",
      "0.188\n",
      "0.356\n",
      "0.437\n",
      "0.485\n",
      "0.645\n",
      "0.327\n",
      "0.170\n",
      "0.947\n",
      "0.859\n",
      "0.128\n",
      "0.273\n",
      "0.648\n",
      "0.541\n",
      "0.328\n",
      "0.318\n",
      "0.996\n",
      "0.453\n",
      "0.271\n",
      "0.556\n",
      "0.684\n",
      "0.165\n",
      "0.742\n",
      "0.662\n",
      "0.261\n",
      "0.628\n",
      "0.682\n",
      "0.180\n",
      "0.308\n",
      "0.112\n",
      "0.333\n",
      "0.625\n",
      "0.279\n",
      "0.358\n",
      "0.795\n",
      "0.383\n",
      "0.129\n",
      "0.641\n",
      "0.260\n",
      "0.431\n",
      "0.113\n",
      "0.113\n",
      "0.509\n",
      "0.114\n",
      "0.417\n",
      "0.260\n",
      "0.165\n",
      "0.520\n",
      "0.122\n",
      "0.488\n",
      "0.129\n",
      "0.113\n",
      "0.561\n",
      "0.694\n",
      "0.279\n",
      "0.387\n",
      "0.169\n",
      "0.136\n",
      "0.739\n",
      "0.865\n",
      "0.260\n",
      "0.168\n",
      "0.224\n",
      "0.299\n",
      "0.578\n",
      "0.189\n",
      "0.328\n",
      "0.086\n",
      "0.154\n",
      "0.081\n",
      "0.084\n",
      "0.095\n",
      "0.115\n",
      "0.224\n",
      "0.224\n",
      "0.239\n",
      "0.109\n",
      "0.132\n",
      "0.509\n",
      "0.113\n",
      "0.249\n",
      "0.098\n",
      "0.256\n",
      "0.111\n",
      "0.370\n",
      "0.091\n",
      "0.344\n",
      "0.129\n",
      "0.124\n",
      "0.524\n",
      "0.648\n",
      "0.545\n",
      "0.255\n",
      "0.355\n",
      "0.092\n",
      "0.175\n",
      "0.300\n",
      "0.544\n",
      "0.311\n",
      "0.737\n",
      "0.539\n",
      "0.346\n",
      "0.495\n",
      "0.307\n",
      "0.363\n",
      "0.425\n",
      "0.629\n",
      "0.499\n",
      "0.268\n",
      "0.132\n",
      "0.329\n",
      "0.243\n",
      "0.444\n",
      "0.609\n",
      "0.545\n",
      "0.339\n",
      "0.227\n",
      "0.418\n",
      "0.214\n",
      "0.184\n",
      "0.205\n",
      "0.527\n",
      "0.103\n",
      "0.957\n",
      "0.572\n",
      "0.437\n",
      "0.969\n",
      "0.839\n",
      "0.342\n",
      "0.124\n",
      "0.663\n",
      "0.547\n",
      "0.280\n",
      "0.320\n",
      "0.832\n",
      "0.973\n",
      "0.573\n",
      "0.465\n",
      "0.414\n",
      "0.866\n",
      "0.577\n",
      "0.976\n",
      "0.577\n",
      "0.795\n",
      "0.695\n",
      "0.355\n",
      "0.229\n",
      "0.346\n",
      "0.345\n",
      "0.360\n",
      "0.195\n",
      "0.184\n",
      "0.181\n",
      "0.306\n",
      "0.280\n",
      "0.451\n",
      "0.196\n",
      "0.241\n",
      "0.136\n",
      "0.332\n",
      "0.375\n",
      "0.303\n",
      "0.190\n",
      "0.602\n",
      "0.419\n",
      "0.352\n",
      "0.128\n",
      "0.134\n",
      "0.437\n",
      "0.195\n",
      "0.169\n",
      "0.337\n",
      "0.418\n",
      "0.465\n",
      "0.625\n",
      "0.308\n",
      "0.151\n",
      "0.927\n",
      "0.839\n",
      "0.108\n",
      "0.253\n",
      "0.628\n",
      "0.522\n",
      "0.308\n",
      "0.299\n",
      "0.976\n",
      "0.433\n",
      "0.252\n",
      "0.536\n",
      "0.664\n",
      "0.145\n",
      "0.722\n",
      "0.643\n",
      "0.242\n",
      "0.608\n",
      "0.662\n",
      "0.161\n",
      "0.288\n",
      "0.092\n",
      "0.313\n",
      "0.605\n",
      "0.259\n",
      "0.338\n",
      "0.775\n",
      "0.364\n",
      "0.109\n",
      "0.622\n",
      "0.240\n",
      "0.411\n",
      "0.093\n",
      "0.093\n",
      "0.490\n",
      "0.095\n",
      "0.397\n",
      "0.240\n",
      "0.146\n",
      "0.500\n",
      "0.102\n",
      "0.468\n",
      "0.109\n",
      "0.093\n",
      "0.542\n",
      "0.675\n",
      "0.260\n",
      "0.367\n",
      "0.150\n",
      "0.087\n",
      "0.690\n",
      "0.815\n",
      "0.211\n",
      "0.119\n",
      "0.175\n",
      "0.250\n",
      "0.529\n",
      "0.140\n",
      "0.278\n",
      "0.036\n",
      "0.105\n",
      "0.032\n",
      "0.035\n",
      "0.045\n",
      "0.065\n",
      "0.175\n",
      "0.175\n",
      "0.190\n",
      "0.060\n",
      "0.083\n",
      "0.460\n",
      "0.063\n",
      "0.199\n",
      "0.049\n",
      "0.207\n",
      "0.062\n",
      "0.321\n",
      "0.042\n",
      "0.295\n",
      "0.080\n",
      "0.074\n",
      "0.474\n",
      "0.599\n",
      "0.496\n",
      "0.205\n",
      "0.306\n",
      "0.043\n",
      "0.126\n",
      "0.251\n",
      "0.495\n",
      "0.262\n",
      "0.688\n",
      "0.490\n",
      "0.297\n",
      "0.445\n",
      "0.258\n",
      "0.313\n",
      "0.376\n",
      "0.580\n",
      "0.450\n",
      "0.219\n",
      "0.082\n",
      "0.280\n",
      "0.194\n",
      "0.395\n",
      "0.559\n",
      "0.496\n",
      "0.290\n",
      "0.177\n",
      "0.368\n",
      "0.164\n",
      "0.135\n",
      "0.156\n",
      "0.477\n",
      "0.053\n",
      "0.908\n",
      "0.523\n",
      "0.387\n",
      "0.920\n",
      "0.789\n",
      "0.293\n",
      "0.074\n",
      "0.614\n",
      "0.497\n",
      "0.231\n",
      "0.270\n",
      "0.783\n",
      "0.924\n",
      "0.523\n",
      "0.415\n",
      "0.365\n",
      "0.817\n",
      "0.528\n",
      "0.927\n",
      "0.528\n",
      "0.746\n",
      "0.646\n",
      "0.305\n",
      "0.180\n",
      "0.296\n",
      "0.295\n",
      "0.310\n",
      "0.146\n",
      "0.135\n",
      "0.132\n",
      "0.257\n",
      "0.231\n",
      "0.402\n",
      "0.146\n",
      "0.191\n",
      "0.086\n",
      "0.283\n",
      "0.325\n",
      "0.254\n",
      "0.141\n",
      "0.553\n",
      "0.369\n",
      "0.303\n",
      "0.079\n",
      "0.085\n",
      "0.388\n",
      "0.146\n",
      "0.119\n",
      "0.287\n",
      "0.368\n",
      "0.416\n",
      "0.576\n",
      "0.258\n",
      "0.101\n",
      "0.878\n",
      "0.790\n",
      "0.059\n",
      "0.204\n",
      "0.579\n",
      "0.472\n",
      "0.259\n",
      "0.249\n",
      "0.927\n",
      "0.383\n",
      "0.202\n",
      "0.487\n",
      "0.615\n",
      "0.096\n",
      "0.673\n",
      "0.593\n",
      "0.192\n",
      "0.559\n",
      "0.613\n",
      "0.111\n",
      "0.239\n",
      "0.043\n",
      "0.264\n",
      "0.556\n",
      "0.210\n",
      "0.289\n",
      "0.726\n",
      "0.314\n",
      "0.060\n",
      "0.572\n",
      "0.191\n",
      "0.362\n",
      "0.044\n",
      "0.044\n",
      "0.440\n",
      "0.045\n",
      "0.348\n",
      "0.191\n",
      "0.096\n",
      "0.450\n",
      "0.053\n",
      "0.419\n",
      "0.060\n",
      "0.044\n",
      "0.492\n",
      "0.625\n",
      "0.210\n",
      "0.318\n",
      "0.100\n",
      "0.076\n",
      "0.679\n",
      "0.804\n",
      "0.200\n",
      "0.108\n",
      "0.163\n",
      "0.239\n",
      "0.518\n",
      "0.128\n",
      "0.267\n",
      "0.025\n",
      "0.094\n",
      "0.020\n",
      "0.023\n",
      "0.034\n",
      "0.054\n",
      "0.164\n",
      "0.164\n",
      "0.179\n",
      "0.048\n",
      "0.072\n",
      "0.448\n",
      "0.052\n",
      "0.188\n",
      "0.038\n",
      "0.195\n",
      "0.051\n",
      "0.310\n",
      "0.031\n",
      "0.284\n",
      "0.068\n",
      "0.063\n",
      "0.463\n",
      "0.588\n",
      "0.485\n",
      "0.194\n",
      "0.295\n",
      "0.032\n",
      "0.115\n",
      "0.240\n",
      "0.483\n",
      "0.250\n",
      "0.676\n",
      "0.479\n",
      "0.286\n",
      "0.434\n",
      "0.247\n",
      "0.302\n",
      "0.365\n",
      "0.568\n",
      "0.439\n",
      "0.208\n",
      "0.071\n",
      "0.268\n",
      "0.182\n",
      "0.383\n",
      "0.548\n",
      "0.485\n",
      "0.279\n",
      "0.166\n",
      "0.357\n",
      "0.153\n",
      "0.124\n",
      "0.145\n",
      "0.466\n",
      "0.042\n",
      "0.896\n",
      "0.511\n",
      "0.376\n",
      "0.909\n",
      "0.778\n",
      "0.282\n",
      "0.063\n",
      "0.603\n",
      "0.486\n",
      "0.220\n",
      "0.259\n",
      "0.772\n",
      "0.912\n",
      "0.512\n",
      "0.404\n",
      "0.353\n",
      "0.806\n",
      "0.516\n",
      "0.916\n",
      "0.517\n",
      "0.735\n",
      "0.634\n",
      "0.294\n",
      "0.168\n",
      "0.285\n",
      "0.284\n",
      "0.299\n",
      "0.135\n",
      "0.124\n",
      "0.121\n",
      "0.245\n",
      "0.219\n",
      "0.391\n",
      "0.135\n",
      "0.180\n",
      "0.075\n",
      "0.271\n",
      "0.314\n",
      "0.243\n",
      "0.129\n",
      "0.542\n",
      "0.358\n",
      "0.291\n",
      "0.068\n",
      "0.074\n",
      "0.377\n",
      "0.135\n",
      "0.108\n",
      "0.276\n",
      "0.357\n",
      "0.405\n",
      "0.564\n",
      "0.247\n",
      "0.090\n",
      "0.867\n",
      "0.779\n",
      "0.048\n",
      "0.193\n",
      "0.568\n",
      "0.461\n",
      "0.248\n",
      "0.238\n",
      "0.916\n",
      "0.372\n",
      "0.191\n",
      "0.476\n",
      "0.603\n",
      "0.084\n",
      "0.662\n",
      "0.582\n",
      "0.181\n",
      "0.548\n",
      "0.601\n",
      "0.100\n",
      "0.228\n",
      "0.031\n",
      "0.253\n",
      "0.545\n",
      "0.199\n",
      "0.277\n",
      "0.715\n",
      "0.303\n",
      "0.049\n",
      "0.561\n",
      "0.180\n",
      "0.351\n",
      "0.033\n",
      "0.033\n",
      "0.429\n",
      "0.034\n",
      "0.337\n",
      "0.180\n",
      "0.085\n",
      "0.439\n",
      "0.042\n",
      "0.408\n",
      "0.049\n",
      "0.033\n",
      "0.481\n",
      "0.614\n",
      "0.199\n",
      "0.306\n",
      "0.089\n",
      "0.148\n",
      "0.751\n",
      "0.877\n",
      "0.272\n",
      "0.180\n",
      "0.236\n",
      "0.311\n",
      "0.590\n",
      "0.201\n",
      "0.340\n",
      "0.098\n",
      "0.166\n",
      "0.093\n",
      "0.096\n",
      "0.107\n",
      "0.127\n",
      "0.236\n",
      "0.236\n",
      "0.251\n",
      "0.121\n",
      "0.144\n",
      "0.521\n",
      "0.125\n",
      "0.261\n",
      "0.110\n",
      "0.268\n",
      "0.123\n",
      "0.382\n",
      "0.103\n",
      "0.356\n",
      "0.141\n",
      "0.136\n",
      "0.536\n",
      "0.660\n",
      "0.557\n",
      "0.267\n",
      "0.367\n",
      "0.104\n",
      "0.187\n",
      "0.312\n",
      "0.556\n",
      "0.323\n",
      "0.749\n",
      "0.551\n",
      "0.358\n",
      "0.507\n",
      "0.319\n",
      "0.375\n",
      "0.437\n",
      "0.641\n",
      "0.511\n",
      "0.280\n",
      "0.144\n",
      "0.341\n",
      "0.255\n",
      "0.456\n",
      "0.621\n",
      "0.557\n",
      "0.351\n",
      "0.239\n",
      "0.430\n",
      "0.226\n",
      "0.196\n",
      "0.217\n",
      "0.539\n",
      "0.115\n",
      "0.969\n",
      "0.584\n",
      "0.449\n",
      "0.981\n",
      "0.851\n",
      "0.354\n",
      "0.136\n",
      "0.675\n",
      "0.559\n",
      "0.292\n",
      "0.332\n",
      "0.844\n",
      "0.985\n",
      "0.585\n",
      "0.477\n",
      "0.426\n",
      "0.878\n",
      "0.589\n",
      "0.988\n",
      "0.589\n",
      "0.807\n",
      "0.707\n",
      "0.367\n",
      "0.241\n",
      "0.358\n",
      "0.357\n",
      "0.372\n",
      "0.207\n",
      "0.196\n",
      "0.193\n",
      "0.318\n",
      "0.292\n",
      "0.463\n",
      "0.208\n",
      "0.253\n",
      "0.147\n",
      "0.344\n",
      "0.387\n",
      "0.315\n",
      "0.202\n",
      "0.614\n",
      "0.431\n",
      "0.364\n",
      "0.140\n",
      "0.146\n",
      "0.449\n",
      "0.207\n",
      "0.181\n",
      "0.349\n",
      "0.430\n",
      "0.477\n",
      "0.637\n",
      "0.320\n",
      "0.163\n",
      "0.939\n",
      "0.851\n",
      "0.120\n",
      "0.265\n",
      "0.640\n",
      "0.534\n",
      "0.320\n",
      "0.311\n",
      "0.988\n",
      "0.445\n",
      "0.264\n",
      "0.548\n",
      "0.676\n",
      "0.157\n",
      "0.734\n",
      "0.655\n",
      "0.254\n",
      "0.620\n",
      "0.674\n",
      "0.173\n",
      "0.300\n",
      "0.104\n",
      "0.325\n",
      "0.617\n",
      "0.271\n",
      "0.350\n",
      "0.787\n",
      "0.376\n",
      "0.121\n",
      "0.634\n",
      "0.252\n",
      "0.423\n",
      "0.105\n",
      "0.105\n",
      "0.502\n",
      "0.107\n",
      "0.409\n",
      "0.252\n",
      "0.158\n",
      "0.512\n",
      "0.114\n",
      "0.480\n",
      "0.121\n",
      "0.105\n",
      "0.554\n",
      "0.687\n",
      "0.272\n",
      "0.379\n",
      "0.162\n",
      "0.144\n",
      "0.747\n",
      "0.872\n",
      "0.268\n",
      "0.176\n",
      "0.232\n",
      "0.307\n",
      "0.586\n",
      "0.197\n",
      "0.335\n",
      "0.093\n",
      "0.162\n",
      "0.089\n",
      "0.092\n",
      "0.102\n",
      "0.122\n",
      "0.232\n",
      "0.232\n",
      "0.247\n",
      "0.117\n",
      "0.140\n",
      "0.517\n",
      "0.120\n",
      "0.256\n",
      "0.106\n",
      "0.264\n",
      "0.119\n",
      "0.378\n",
      "0.099\n",
      "0.352\n",
      "0.137\n",
      "0.131\n",
      "0.531\n",
      "0.656\n",
      "0.553\n",
      "0.262\n",
      "0.363\n",
      "0.100\n",
      "0.183\n",
      "0.308\n",
      "0.552\n",
      "0.319\n",
      "0.745\n",
      "0.547\n",
      "0.354\n",
      "0.502\n",
      "0.315\n",
      "0.370\n",
      "0.433\n",
      "0.637\n",
      "0.507\n",
      "0.276\n",
      "0.139\n",
      "0.337\n",
      "0.251\n",
      "0.452\n",
      "0.616\n",
      "0.553\n",
      "0.347\n",
      "0.234\n",
      "0.425\n",
      "0.221\n",
      "0.192\n",
      "0.213\n",
      "0.534\n",
      "0.110\n",
      "0.965\n",
      "0.580\n",
      "0.444\n",
      "0.977\n",
      "0.846\n",
      "0.350\n",
      "0.131\n",
      "0.671\n",
      "0.554\n",
      "0.288\n",
      "0.327\n",
      "0.840\n",
      "0.980\n",
      "0.580\n",
      "0.472\n",
      "0.422\n",
      "0.874\n",
      "0.585\n",
      "0.984\n",
      "0.585\n",
      "0.803\n",
      "0.703\n",
      "0.362\n",
      "0.237\n",
      "0.353\n",
      "0.352\n",
      "0.367\n",
      "0.203\n",
      "0.192\n",
      "0.189\n",
      "0.314\n",
      "0.288\n",
      "0.459\n",
      "0.203\n",
      "0.248\n",
      "0.143\n",
      "0.340\n",
      "0.382\n",
      "0.311\n",
      "0.197\n",
      "0.610\n",
      "0.426\n",
      "0.360\n",
      "0.136\n",
      "0.142\n",
      "0.445\n",
      "0.203\n",
      "0.176\n",
      "0.344\n",
      "0.425\n",
      "0.473\n",
      "0.633\n",
      "0.315\n",
      "0.158\n",
      "0.935\n",
      "0.847\n",
      "0.116\n",
      "0.261\n",
      "0.636\n",
      "0.529\n",
      "0.316\n",
      "0.306\n",
      "0.984\n",
      "0.440\n",
      "0.259\n",
      "0.544\n",
      "0.672\n",
      "0.153\n",
      "0.730\n",
      "0.650\n",
      "0.249\n",
      "0.616\n",
      "0.670\n",
      "0.168\n",
      "0.296\n",
      "0.100\n",
      "0.321\n",
      "0.613\n",
      "0.267\n",
      "0.346\n",
      "0.783\n",
      "0.371\n",
      "0.117\n",
      "0.629\n",
      "0.248\n",
      "0.419\n",
      "0.101\n",
      "0.101\n",
      "0.497\n",
      "0.102\n",
      "0.405\n",
      "0.248\n",
      "0.153\n",
      "0.507\n",
      "0.110\n",
      "0.476\n",
      "0.117\n",
      "0.101\n",
      "0.549\n",
      "0.682\n",
      "0.267\n",
      "0.375\n",
      "0.157\n",
      "0.056\n",
      "0.658\n",
      "0.784\n",
      "0.179\n",
      "0.088\n",
      "0.143\n",
      "0.218\n",
      "0.497\n",
      "0.108\n",
      "0.247\n",
      "0.005\n",
      "0.073\n",
      "0.000\n",
      "0.003\n",
      "0.014\n",
      "0.034\n",
      "0.143\n",
      "0.143\n",
      "0.158\n",
      "0.028\n",
      "0.051\n",
      "0.428\n",
      "0.032\n",
      "0.168\n",
      "0.018\n",
      "0.175\n",
      "0.030\n",
      "0.289\n",
      "0.010\n",
      "0.263\n",
      "0.048\n",
      "0.043\n",
      "0.443\n",
      "0.567\n",
      "0.464\n",
      "0.174\n",
      "0.275\n",
      "0.011\n",
      "0.094\n",
      "0.219\n",
      "0.463\n",
      "0.230\n",
      "0.656\n",
      "0.459\n",
      "0.265\n",
      "0.414\n",
      "0.226\n",
      "0.282\n",
      "0.345\n",
      "0.548\n",
      "0.418\n",
      "0.187\n",
      "0.051\n",
      "0.248\n",
      "0.162\n",
      "0.363\n",
      "0.528\n",
      "0.465\n",
      "0.258\n",
      "0.146\n",
      "0.337\n",
      "0.133\n",
      "0.103\n",
      "0.124\n",
      "0.446\n",
      "0.022\n",
      "0.876\n",
      "0.491\n",
      "0.356\n",
      "0.888\n",
      "0.758\n",
      "0.261\n",
      "0.043\n",
      "0.582\n",
      "0.466\n",
      "0.199\n",
      "0.239\n",
      "0.751\n",
      "0.892\n",
      "0.492\n",
      "0.384\n",
      "0.333\n",
      "0.785\n",
      "0.496\n",
      "0.895\n",
      "0.496\n",
      "0.714\n",
      "0.614\n",
      "0.274\n",
      "0.148\n",
      "0.265\n",
      "0.264\n",
      "0.279\n",
      "0.114\n",
      "0.103\n",
      "0.100\n",
      "0.225\n",
      "0.199\n",
      "0.370\n",
      "0.115\n",
      "0.160\n",
      "0.055\n",
      "0.251\n",
      "0.294\n",
      "0.222\n",
      "0.109\n",
      "0.521\n",
      "0.338\n",
      "0.271\n",
      "0.047\n",
      "0.053\n",
      "0.356\n",
      "0.114\n",
      "0.088\n",
      "0.256\n",
      "0.337\n",
      "0.384\n",
      "0.544\n",
      "0.227\n",
      "0.070\n",
      "0.846\n",
      "0.758\n",
      "0.027\n",
      "0.172\n",
      "0.547\n",
      "0.441\n",
      "0.227\n",
      "0.218\n",
      "0.895\n",
      "0.352\n",
      "0.171\n",
      "0.456\n",
      "0.583\n",
      "0.064\n",
      "0.641\n",
      "0.562\n",
      "0.161\n",
      "0.527\n",
      "0.581\n",
      "0.080\n",
      "0.207\n",
      "0.011\n",
      "0.232\n",
      "0.524\n",
      "0.178\n",
      "0.257\n",
      "0.694\n",
      "0.283\n",
      "0.028\n",
      "0.541\n",
      "0.159\n",
      "0.330\n",
      "0.012\n",
      "0.012\n",
      "0.409\n",
      "0.014\n",
      "0.316\n",
      "0.159\n",
      "0.065\n",
      "0.419\n",
      "0.021\n",
      "0.387\n",
      "0.028\n",
      "0.012\n",
      "0.461\n",
      "0.594\n",
      "0.179\n",
      "0.286\n",
      "0.069\n",
      "0.108\n",
      "0.711\n",
      "0.836\n",
      "0.232\n",
      "0.140\n",
      "0.196\n",
      "0.271\n",
      "0.550\n",
      "0.161\n",
      "0.300\n",
      "0.057\n",
      "0.126\n",
      "0.053\n",
      "0.056\n",
      "0.066\n",
      "0.086\n",
      "0.196\n",
      "0.196\n",
      "0.211\n",
      "0.081\n",
      "0.104\n",
      "0.481\n",
      "0.084\n",
      "0.220\n",
      "0.070\n",
      "0.228\n",
      "0.083\n",
      "0.342\n",
      "0.063\n",
      "0.316\n",
      "0.101\n",
      "0.095\n",
      "0.495\n",
      "0.620\n",
      "0.517\n",
      "0.227\n",
      "0.327\n",
      "0.064\n",
      "0.147\n",
      "0.272\n",
      "0.516\n",
      "0.283\n",
      "0.709\n",
      "0.511\n",
      "0.318\n",
      "0.467\n",
      "0.279\n",
      "0.335\n",
      "0.397\n",
      "0.601\n",
      "0.471\n",
      "0.240\n",
      "0.103\n",
      "0.301\n",
      "0.215\n",
      "0.416\n",
      "0.581\n",
      "0.517\n",
      "0.311\n",
      "0.198\n",
      "0.389\n",
      "0.186\n",
      "0.156\n",
      "0.177\n",
      "0.498\n",
      "0.074\n",
      "0.929\n",
      "0.544\n",
      "0.409\n",
      "0.941\n",
      "0.810\n",
      "0.314\n",
      "0.096\n",
      "0.635\n",
      "0.518\n",
      "0.252\n",
      "0.292\n",
      "0.804\n",
      "0.945\n",
      "0.544\n",
      "0.437\n",
      "0.386\n",
      "0.838\n",
      "0.549\n",
      "0.948\n",
      "0.549\n",
      "0.767\n",
      "0.667\n",
      "0.327\n",
      "0.201\n",
      "0.317\n",
      "0.317\n",
      "0.332\n",
      "0.167\n",
      "0.156\n",
      "0.153\n",
      "0.278\n",
      "0.252\n",
      "0.423\n",
      "0.168\n",
      "0.213\n",
      "0.107\n",
      "0.304\n",
      "0.346\n",
      "0.275\n",
      "0.162\n",
      "0.574\n",
      "0.390\n",
      "0.324\n",
      "0.100\n",
      "0.106\n",
      "0.409\n",
      "0.167\n",
      "0.140\n",
      "0.309\n",
      "0.389\n",
      "0.437\n",
      "0.597\n",
      "0.280\n",
      "0.122\n",
      "0.899\n",
      "0.811\n",
      "0.080\n",
      "0.225\n",
      "0.600\n",
      "0.493\n",
      "0.280\n",
      "0.271\n",
      "0.948\n",
      "0.405\n",
      "0.223\n",
      "0.508\n",
      "0.636\n",
      "0.117\n",
      "0.694\n",
      "0.614\n",
      "0.213\n",
      "0.580\n",
      "0.634\n",
      "0.132\n",
      "0.260\n",
      "0.064\n",
      "0.285\n",
      "0.577\n",
      "0.231\n",
      "0.310\n",
      "0.747\n",
      "0.336\n",
      "0.081\n",
      "0.593\n",
      "0.212\n",
      "0.383\n",
      "0.065\n",
      "0.065\n",
      "0.461\n",
      "0.066\n",
      "0.369\n",
      "0.212\n",
      "0.117\n",
      "0.472\n",
      "0.074\n",
      "0.440\n",
      "0.081\n",
      "0.065\n",
      "0.513\n",
      "0.646\n",
      "0.231\n",
      "0.339\n",
      "0.121\n",
      "0.124\n",
      "0.727\n",
      "0.853\n",
      "0.248\n",
      "0.156\n",
      "0.212\n",
      "0.287\n",
      "0.566\n",
      "0.177\n",
      "0.316\n",
      "0.074\n",
      "0.142\n",
      "0.069\n",
      "0.072\n",
      "0.083\n",
      "0.103\n",
      "0.212\n",
      "0.212\n",
      "0.227\n",
      "0.097\n",
      "0.120\n",
      "0.497\n",
      "0.101\n",
      "0.237\n",
      "0.086\n",
      "0.244\n",
      "0.099\n",
      "0.358\n",
      "0.079\n",
      "0.332\n",
      "0.117\n",
      "0.112\n",
      "0.512\n",
      "0.636\n",
      "0.533\n",
      "0.243\n",
      "0.343\n",
      "0.080\n",
      "0.163\n",
      "0.288\n",
      "0.532\n",
      "0.299\n",
      "0.725\n",
      "0.527\n",
      "0.334\n",
      "0.483\n",
      "0.295\n",
      "0.351\n",
      "0.414\n",
      "0.617\n",
      "0.487\n",
      "0.256\n",
      "0.120\n",
      "0.317\n",
      "0.231\n",
      "0.432\n",
      "0.597\n",
      "0.533\n",
      "0.327\n",
      "0.215\n",
      "0.406\n",
      "0.202\n",
      "0.172\n",
      "0.193\n",
      "0.515\n",
      "0.091\n",
      "0.945\n",
      "0.560\n",
      "0.425\n",
      "0.957\n",
      "0.827\n",
      "0.330\n",
      "0.112\n",
      "0.651\n",
      "0.535\n",
      "0.268\n",
      "0.308\n",
      "0.820\n",
      "0.961\n",
      "0.561\n",
      "0.453\n",
      "0.402\n",
      "0.854\n",
      "0.565\n",
      "0.964\n",
      "0.565\n",
      "0.783\n",
      "0.683\n",
      "0.343\n",
      "0.217\n",
      "0.334\n",
      "0.333\n",
      "0.348\n",
      "0.183\n",
      "0.172\n",
      "0.169\n",
      "0.294\n",
      "0.268\n",
      "0.439\n",
      "0.184\n",
      "0.229\n",
      "0.124\n",
      "0.320\n",
      "0.363\n",
      "0.291\n",
      "0.178\n",
      "0.590\n",
      "0.407\n",
      "0.340\n",
      "0.116\n",
      "0.122\n",
      "0.425\n",
      "0.183\n",
      "0.157\n",
      "0.325\n",
      "0.406\n",
      "0.453\n",
      "0.613\n",
      "0.296\n",
      "0.139\n",
      "0.915\n",
      "0.827\n",
      "0.096\n",
      "0.241\n",
      "0.616\n",
      "0.510\n",
      "0.296\n",
      "0.287\n",
      "0.964\n",
      "0.421\n",
      "0.240\n",
      "0.525\n",
      "0.652\n",
      "0.133\n",
      "0.710\n",
      "0.631\n",
      "0.230\n",
      "0.596\n",
      "0.650\n",
      "0.149\n",
      "0.276\n",
      "0.080\n",
      "0.301\n",
      "0.593\n",
      "0.247\n",
      "0.326\n",
      "0.763\n",
      "0.352\n",
      "0.097\n",
      "0.610\n",
      "0.228\n",
      "0.399\n",
      "0.081\n",
      "0.081\n",
      "0.478\n",
      "0.083\n",
      "0.385\n",
      "0.228\n",
      "0.134\n",
      "0.488\n",
      "0.090\n",
      "0.456\n",
      "0.097\n",
      "0.081\n",
      "0.530\n",
      "0.663\n",
      "0.248\n",
      "0.355\n",
      "0.138\n",
      "0.116\n",
      "0.719\n",
      "0.844\n",
      "0.240\n",
      "0.148\n",
      "0.203\n",
      "0.278\n",
      "0.557\n",
      "0.168\n",
      "0.307\n",
      "0.065\n",
      "0.134\n",
      "0.060\n",
      "0.063\n",
      "0.074\n",
      "0.094\n",
      "0.203\n",
      "0.203\n",
      "0.219\n",
      "0.088\n",
      "0.111\n",
      "0.488\n",
      "0.092\n",
      "0.228\n",
      "0.078\n",
      "0.235\n",
      "0.090\n",
      "0.349\n",
      "0.070\n",
      "0.324\n",
      "0.108\n",
      "0.103\n",
      "0.503\n",
      "0.627\n",
      "0.524\n",
      "0.234\n",
      "0.335\n",
      "0.071\n",
      "0.155\n",
      "0.280\n",
      "0.523\n",
      "0.290\n",
      "0.716\n",
      "0.519\n",
      "0.325\n",
      "0.474\n",
      "0.286\n",
      "0.342\n",
      "0.405\n",
      "0.608\n",
      "0.478\n",
      "0.247\n",
      "0.111\n",
      "0.308\n",
      "0.222\n",
      "0.423\n",
      "0.588\n",
      "0.525\n",
      "0.318\n",
      "0.206\n",
      "0.397\n",
      "0.193\n",
      "0.163\n",
      "0.184\n",
      "0.506\n",
      "0.082\n",
      "0.936\n",
      "0.551\n",
      "0.416\n",
      "0.949\n",
      "0.818\n",
      "0.321\n",
      "0.103\n",
      "0.642\n",
      "0.526\n",
      "0.260\n",
      "0.299\n",
      "0.811\n",
      "0.952\n",
      "0.552\n",
      "0.444\n",
      "0.393\n",
      "0.845\n",
      "0.556\n",
      "0.956\n",
      "0.556\n",
      "0.775\n",
      "0.674\n",
      "0.334\n",
      "0.208\n",
      "0.325\n",
      "0.324\n",
      "0.339\n",
      "0.174\n",
      "0.163\n",
      "0.161\n",
      "0.285\n",
      "0.259\n",
      "0.430\n",
      "0.175\n",
      "0.220\n",
      "0.115\n",
      "0.311\n",
      "0.354\n",
      "0.282\n",
      "0.169\n",
      "0.581\n",
      "0.398\n",
      "0.331\n",
      "0.107\n",
      "0.114\n",
      "0.416\n",
      "0.174\n",
      "0.148\n",
      "0.316\n",
      "0.397\n",
      "0.444\n",
      "0.604\n",
      "0.287\n",
      "0.130\n",
      "0.906\n",
      "0.818\n",
      "0.087\n",
      "0.233\n",
      "0.607\n",
      "0.501\n",
      "0.287\n",
      "0.278\n",
      "0.955\n",
      "0.412\n",
      "0.231\n",
      "0.516\n",
      "0.643\n",
      "0.124\n",
      "0.701\n",
      "0.622\n",
      "0.221\n",
      "0.587\n",
      "0.641\n",
      "0.140\n",
      "0.268\n",
      "0.071\n",
      "0.292\n",
      "0.584\n",
      "0.238\n",
      "0.317\n",
      "0.754\n",
      "0.343\n",
      "0.088\n",
      "0.601\n",
      "0.219\n",
      "0.390\n",
      "0.072\n",
      "0.072\n",
      "0.469\n",
      "0.074\n",
      "0.377\n",
      "0.220\n",
      "0.125\n",
      "0.479\n",
      "0.082\n",
      "0.447\n",
      "0.088\n",
      "0.072\n",
      "0.521\n",
      "0.654\n",
      "0.239\n",
      "0.346\n",
      "0.129\n",
      "0.078\n",
      "0.680\n",
      "0.806\n",
      "0.201\n",
      "0.110\n",
      "0.165\n",
      "0.240\n",
      "0.519\n",
      "0.130\n",
      "0.269\n",
      "0.027\n",
      "0.096\n",
      "0.022\n",
      "0.025\n",
      "0.036\n",
      "0.056\n",
      "0.165\n",
      "0.165\n",
      "0.180\n",
      "0.050\n",
      "0.073\n",
      "0.450\n",
      "0.054\n",
      "0.190\n",
      "0.040\n",
      "0.197\n",
      "0.052\n",
      "0.311\n",
      "0.032\n",
      "0.285\n",
      "0.070\n",
      "0.065\n",
      "0.465\n",
      "0.589\n",
      "0.486\n",
      "0.196\n",
      "0.297\n",
      "0.033\n",
      "0.116\n",
      "0.242\n",
      "0.485\n",
      "0.252\n",
      "0.678\n",
      "0.481\n",
      "0.287\n",
      "0.436\n",
      "0.248\n",
      "0.304\n",
      "0.367\n",
      "0.570\n",
      "0.440\n",
      "0.209\n",
      "0.073\n",
      "0.270\n",
      "0.184\n",
      "0.385\n",
      "0.550\n",
      "0.487\n",
      "0.280\n",
      "0.168\n",
      "0.359\n",
      "0.155\n",
      "0.125\n",
      "0.146\n",
      "0.468\n",
      "0.044\n",
      "0.898\n",
      "0.513\n",
      "0.378\n",
      "0.911\n",
      "0.780\n",
      "0.283\n",
      "0.065\n",
      "0.604\n",
      "0.488\n",
      "0.221\n",
      "0.261\n",
      "0.773\n",
      "0.914\n",
      "0.514\n",
      "0.406\n",
      "0.355\n",
      "0.807\n",
      "0.518\n",
      "0.917\n",
      "0.518\n",
      "0.736\n",
      "0.636\n",
      "0.296\n",
      "0.170\n",
      "0.287\n",
      "0.286\n",
      "0.301\n",
      "0.136\n",
      "0.125\n",
      "0.122\n",
      "0.247\n",
      "0.221\n",
      "0.392\n",
      "0.137\n",
      "0.182\n",
      "0.077\n",
      "0.273\n",
      "0.316\n",
      "0.244\n",
      "0.131\n",
      "0.543\n",
      "0.360\n",
      "0.293\n",
      "0.069\n",
      "0.075\n",
      "0.378\n",
      "0.136\n",
      "0.110\n",
      "0.278\n",
      "0.359\n",
      "0.406\n",
      "0.566\n",
      "0.249\n",
      "0.092\n",
      "0.868\n",
      "0.780\n",
      "0.049\n",
      "0.195\n",
      "0.569\n",
      "0.463\n",
      "0.249\n",
      "0.240\n",
      "0.917\n",
      "0.374\n",
      "0.193\n",
      "0.478\n",
      "0.605\n",
      "0.086\n",
      "0.663\n",
      "0.584\n",
      "0.183\n",
      "0.549\n",
      "0.603\n",
      "0.102\n",
      "0.230\n",
      "0.033\n",
      "0.254\n",
      "0.546\n",
      "0.200\n",
      "0.279\n",
      "0.716\n",
      "0.305\n",
      "0.050\n",
      "0.563\n",
      "0.181\n",
      "0.352\n",
      "0.034\n",
      "0.034\n",
      "0.431\n",
      "0.036\n",
      "0.338\n",
      "0.181\n",
      "0.087\n",
      "0.441\n",
      "0.043\n",
      "0.409\n",
      "0.050\n",
      "0.034\n",
      "0.483\n",
      "0.616\n",
      "0.201\n",
      "0.308\n",
      "0.091\n",
      "0.126\n",
      "0.729\n",
      "0.854\n",
      "0.250\n",
      "0.158\n",
      "0.213\n",
      "0.289\n",
      "0.567\n",
      "0.178\n",
      "0.317\n",
      "0.075\n",
      "0.144\n",
      "0.070\n",
      "0.073\n",
      "0.084\n",
      "0.104\n",
      "0.213\n",
      "0.213\n",
      "0.229\n",
      "0.098\n",
      "0.122\n",
      "0.498\n",
      "0.102\n",
      "0.238\n",
      "0.088\n",
      "0.245\n",
      "0.100\n",
      "0.359\n",
      "0.080\n",
      "0.334\n",
      "0.118\n",
      "0.113\n",
      "0.513\n",
      "0.637\n",
      "0.534\n",
      "0.244\n",
      "0.345\n",
      "0.081\n",
      "0.165\n",
      "0.290\n",
      "0.533\n",
      "0.300\n",
      "0.726\n",
      "0.529\n",
      "0.336\n",
      "0.484\n",
      "0.296\n",
      "0.352\n",
      "0.415\n",
      "0.618\n",
      "0.488\n",
      "0.257\n",
      "0.121\n",
      "0.318\n",
      "0.232\n",
      "0.433\n",
      "0.598\n",
      "0.535\n",
      "0.328\n",
      "0.216\n",
      "0.407\n",
      "0.203\n",
      "0.173\n",
      "0.195\n",
      "0.516\n",
      "0.092\n",
      "0.946\n",
      "0.561\n",
      "0.426\n",
      "0.959\n",
      "0.828\n",
      "0.331\n",
      "0.113\n",
      "0.652\n",
      "0.536\n",
      "0.270\n",
      "0.309\n",
      "0.821\n",
      "0.962\n",
      "0.562\n",
      "0.454\n",
      "0.403\n",
      "0.856\n",
      "0.566\n",
      "0.966\n",
      "0.566\n",
      "0.785\n",
      "0.684\n",
      "0.344\n",
      "0.218\n",
      "0.335\n",
      "0.334\n",
      "0.349\n",
      "0.184\n",
      "0.173\n",
      "0.171\n",
      "0.295\n",
      "0.269\n",
      "0.441\n",
      "0.185\n",
      "0.230\n",
      "0.125\n",
      "0.321\n",
      "0.364\n",
      "0.292\n",
      "0.179\n",
      "0.591\n",
      "0.408\n",
      "0.341\n",
      "0.117\n",
      "0.124\n",
      "0.426\n",
      "0.184\n",
      "0.158\n",
      "0.326\n",
      "0.407\n",
      "0.455\n",
      "0.614\n",
      "0.297\n",
      "0.140\n",
      "0.917\n",
      "0.829\n",
      "0.097\n",
      "0.243\n",
      "0.617\n",
      "0.511\n",
      "0.298\n",
      "0.288\n",
      "0.965\n",
      "0.422\n",
      "0.241\n",
      "0.526\n",
      "0.653\n",
      "0.134\n",
      "0.711\n",
      "0.632\n",
      "0.231\n",
      "0.597\n",
      "0.651\n",
      "0.150\n",
      "0.278\n",
      "0.081\n",
      "0.302\n",
      "0.594\n",
      "0.248\n",
      "0.327\n",
      "0.765\n",
      "0.353\n",
      "0.099\n",
      "0.611\n",
      "0.229\n",
      "0.400\n",
      "0.082\n",
      "0.082\n",
      "0.479\n",
      "0.084\n",
      "0.387\n",
      "0.230\n",
      "0.135\n",
      "0.489\n",
      "0.092\n",
      "0.458\n",
      "0.099\n",
      "0.082\n",
      "0.531\n",
      "0.664\n",
      "0.249\n",
      "0.356\n",
      "0.139\n",
      "0.133\n",
      "0.736\n",
      "0.861\n",
      "0.257\n",
      "0.165\n",
      "0.221\n",
      "0.296\n",
      "0.575\n",
      "0.186\n",
      "0.325\n",
      "0.082\n",
      "0.151\n",
      "0.078\n",
      "0.081\n",
      "0.091\n",
      "0.111\n",
      "0.221\n",
      "0.221\n",
      "0.236\n",
      "0.106\n",
      "0.129\n",
      "0.506\n",
      "0.109\n",
      "0.245\n",
      "0.095\n",
      "0.253\n",
      "0.108\n",
      "0.367\n",
      "0.088\n",
      "0.341\n",
      "0.126\n",
      "0.120\n",
      "0.520\n",
      "0.645\n",
      "0.542\n",
      "0.252\n",
      "0.352\n",
      "0.089\n",
      "0.172\n",
      "0.297\n",
      "0.541\n",
      "0.308\n",
      "0.734\n",
      "0.536\n",
      "0.343\n",
      "0.492\n",
      "0.304\n",
      "0.360\n",
      "0.422\n",
      "0.626\n",
      "0.496\n",
      "0.265\n",
      "0.128\n",
      "0.326\n",
      "0.240\n",
      "0.441\n",
      "0.606\n",
      "0.542\n",
      "0.336\n",
      "0.223\n",
      "0.414\n",
      "0.211\n",
      "0.181\n",
      "0.202\n",
      "0.523\n",
      "0.099\n",
      "0.954\n",
      "0.569\n",
      "0.434\n",
      "0.966\n",
      "0.835\n",
      "0.339\n",
      "0.121\n",
      "0.660\n",
      "0.543\n",
      "0.277\n",
      "0.317\n",
      "0.829\n",
      "0.970\n",
      "0.569\n",
      "0.462\n",
      "0.411\n",
      "0.863\n",
      "0.574\n",
      "0.973\n",
      "0.574\n",
      "0.792\n",
      "0.692\n",
      "0.352\n",
      "0.226\n",
      "0.342\n",
      "0.342\n",
      "0.357\n",
      "0.192\n",
      "0.181\n",
      "0.178\n",
      "0.303\n",
      "0.277\n",
      "0.448\n",
      "0.193\n",
      "0.238\n",
      "0.132\n",
      "0.329\n",
      "0.371\n",
      "0.300\n",
      "0.187\n",
      "0.599\n",
      "0.415\n",
      "0.349\n",
      "0.125\n",
      "0.131\n",
      "0.434\n",
      "0.192\n",
      "0.165\n",
      "0.334\n",
      "0.414\n",
      "0.462\n",
      "0.622\n",
      "0.305\n",
      "0.147\n",
      "0.924\n",
      "0.836\n",
      "0.105\n",
      "0.250\n",
      "0.625\n",
      "0.518\n",
      "0.305\n",
      "0.296\n",
      "0.973\n",
      "0.430\n",
      "0.248\n",
      "0.533\n",
      "0.661\n",
      "0.142\n",
      "0.719\n",
      "0.639\n",
      "0.238\n",
      "0.605\n",
      "0.659\n",
      "0.157\n",
      "0.285\n",
      "0.089\n",
      "0.310\n",
      "0.602\n",
      "0.256\n",
      "0.335\n",
      "0.772\n",
      "0.361\n",
      "0.106\n",
      "0.618\n",
      "0.237\n",
      "0.408\n",
      "0.090\n",
      "0.090\n",
      "0.486\n",
      "0.091\n",
      "0.394\n",
      "0.237\n",
      "0.142\n",
      "0.497\n",
      "0.099\n",
      "0.465\n",
      "0.106\n",
      "0.090\n",
      "0.538\n",
      "0.671\n",
      "0.256\n",
      "0.364\n",
      "0.146\n",
      "0.115\n",
      "0.718\n",
      "0.844\n",
      "0.239\n",
      "0.147\n",
      "0.203\n",
      "0.278\n",
      "0.557\n",
      "0.168\n",
      "0.307\n",
      "0.065\n",
      "0.133\n",
      "0.060\n",
      "0.063\n",
      "0.074\n",
      "0.094\n",
      "0.203\n",
      "0.203\n",
      "0.218\n",
      "0.088\n",
      "0.111\n",
      "0.488\n",
      "0.092\n",
      "0.228\n",
      "0.077\n",
      "0.235\n",
      "0.090\n",
      "0.349\n",
      "0.070\n",
      "0.323\n",
      "0.108\n",
      "0.103\n",
      "0.503\n",
      "0.627\n",
      "0.524\n",
      "0.234\n",
      "0.334\n",
      "0.071\n",
      "0.154\n",
      "0.279\n",
      "0.523\n",
      "0.290\n",
      "0.716\n",
      "0.519\n",
      "0.325\n",
      "0.474\n",
      "0.286\n",
      "0.342\n",
      "0.405\n",
      "0.608\n",
      "0.478\n",
      "0.247\n",
      "0.111\n",
      "0.308\n",
      "0.222\n",
      "0.423\n",
      "0.588\n",
      "0.524\n",
      "0.318\n",
      "0.206\n",
      "0.397\n",
      "0.193\n",
      "0.163\n",
      "0.184\n",
      "0.506\n",
      "0.082\n",
      "0.936\n",
      "0.551\n",
      "0.416\n",
      "0.948\n",
      "0.818\n",
      "0.321\n",
      "0.103\n",
      "0.642\n",
      "0.526\n",
      "0.259\n",
      "0.299\n",
      "0.811\n",
      "0.952\n",
      "0.552\n",
      "0.444\n",
      "0.393\n",
      "0.845\n",
      "0.556\n",
      "0.955\n",
      "0.556\n",
      "0.774\n",
      "0.674\n",
      "0.334\n",
      "0.208\n",
      "0.325\n",
      "0.324\n",
      "0.339\n",
      "0.174\n",
      "0.163\n",
      "0.160\n",
      "0.285\n",
      "0.259\n",
      "0.430\n",
      "0.175\n",
      "0.220\n",
      "0.115\n",
      "0.311\n",
      "0.354\n",
      "0.282\n",
      "0.169\n",
      "0.581\n",
      "0.398\n",
      "0.331\n",
      "0.107\n",
      "0.113\n",
      "0.416\n",
      "0.174\n",
      "0.148\n",
      "0.316\n",
      "0.397\n",
      "0.444\n",
      "0.604\n",
      "0.287\n",
      "0.130\n",
      "0.906\n",
      "0.818\n",
      "0.087\n",
      "0.232\n",
      "0.607\n",
      "0.501\n",
      "0.287\n",
      "0.278\n",
      "0.955\n",
      "0.412\n",
      "0.231\n",
      "0.516\n",
      "0.643\n",
      "0.124\n",
      "0.701\n",
      "0.622\n",
      "0.221\n",
      "0.587\n",
      "0.641\n",
      "0.140\n",
      "0.267\n",
      "0.071\n",
      "0.292\n",
      "0.584\n",
      "0.238\n",
      "0.317\n",
      "0.754\n",
      "0.343\n",
      "0.088\n",
      "0.601\n",
      "0.219\n",
      "0.390\n",
      "0.072\n",
      "0.072\n",
      "0.469\n",
      "0.074\n",
      "0.376\n",
      "0.219\n",
      "0.125\n",
      "0.479\n",
      "0.081\n",
      "0.447\n",
      "0.088\n",
      "0.072\n",
      "0.521\n",
      "0.654\n",
      "0.239\n",
      "0.346\n",
      "0.129\n",
      "0.107\n",
      "0.709\n",
      "0.835\n",
      "0.230\n",
      "0.139\n",
      "0.194\n",
      "0.269\n",
      "0.548\n",
      "0.159\n",
      "0.298\n",
      "0.056\n",
      "0.125\n",
      "0.051\n",
      "0.054\n",
      "0.065\n",
      "0.085\n",
      "0.194\n",
      "0.194\n",
      "0.210\n",
      "0.079\n",
      "0.102\n",
      "0.479\n",
      "0.083\n",
      "0.219\n",
      "0.069\n",
      "0.226\n",
      "0.081\n",
      "0.340\n",
      "0.061\n",
      "0.315\n",
      "0.099\n",
      "0.094\n",
      "0.494\n",
      "0.618\n",
      "0.515\n",
      "0.225\n",
      "0.326\n",
      "0.062\n",
      "0.146\n",
      "0.271\n",
      "0.514\n",
      "0.281\n",
      "0.707\n",
      "0.510\n",
      "0.316\n",
      "0.465\n",
      "0.277\n",
      "0.333\n",
      "0.396\n",
      "0.599\n",
      "0.469\n",
      "0.238\n",
      "0.102\n",
      "0.299\n",
      "0.213\n",
      "0.414\n",
      "0.579\n",
      "0.516\n",
      "0.309\n",
      "0.197\n",
      "0.388\n",
      "0.184\n",
      "0.154\n",
      "0.175\n",
      "0.497\n",
      "0.073\n",
      "0.927\n",
      "0.542\n",
      "0.407\n",
      "0.940\n",
      "0.809\n",
      "0.312\n",
      "0.094\n",
      "0.633\n",
      "0.517\n",
      "0.251\n",
      "0.290\n",
      "0.802\n",
      "0.943\n",
      "0.543\n",
      "0.435\n",
      "0.384\n",
      "0.836\n",
      "0.547\n",
      "0.946\n",
      "0.547\n",
      "0.765\n",
      "0.665\n",
      "0.325\n",
      "0.199\n",
      "0.316\n",
      "0.315\n",
      "0.330\n",
      "0.165\n",
      "0.154\n",
      "0.151\n",
      "0.276\n",
      "0.250\n",
      "0.421\n",
      "0.166\n",
      "0.211\n",
      "0.106\n",
      "0.302\n",
      "0.345\n",
      "0.273\n",
      "0.160\n",
      "0.572\n",
      "0.389\n",
      "0.322\n",
      "0.098\n",
      "0.105\n",
      "0.407\n",
      "0.165\n",
      "0.139\n",
      "0.307\n",
      "0.388\n",
      "0.435\n",
      "0.595\n",
      "0.278\n",
      "0.121\n",
      "0.897\n",
      "0.809\n",
      "0.078\n",
      "0.224\n",
      "0.598\n",
      "0.492\n",
      "0.278\n",
      "0.269\n",
      "0.946\n",
      "0.403\n",
      "0.222\n",
      "0.507\n",
      "0.634\n",
      "0.115\n",
      "0.692\n",
      "0.613\n",
      "0.212\n",
      "0.578\n",
      "0.632\n",
      "0.131\n",
      "0.259\n",
      "0.062\n",
      "0.283\n",
      "0.575\n",
      "0.229\n",
      "0.308\n",
      "0.745\n",
      "0.334\n",
      "0.079\n",
      "0.592\n",
      "0.210\n",
      "0.381\n",
      "0.063\n",
      "0.063\n",
      "0.460\n",
      "0.065\n",
      "0.368\n",
      "0.210\n",
      "0.116\n",
      "0.470\n",
      "0.073\n",
      "0.438\n",
      "0.079\n",
      "0.063\n",
      "0.512\n",
      "0.645\n",
      "0.230\n",
      "0.337\n",
      "0.120\n",
      "0.134\n",
      "0.737\n",
      "0.862\n",
      "0.258\n",
      "0.166\n",
      "0.222\n",
      "0.297\n",
      "0.576\n",
      "0.187\n",
      "0.325\n",
      "0.083\n",
      "0.152\n",
      "0.079\n",
      "0.082\n",
      "0.092\n",
      "0.112\n",
      "0.222\n",
      "0.222\n",
      "0.237\n",
      "0.107\n",
      "0.130\n",
      "0.507\n",
      "0.110\n",
      "0.246\n",
      "0.096\n",
      "0.254\n",
      "0.109\n",
      "0.368\n",
      "0.089\n",
      "0.342\n",
      "0.127\n",
      "0.121\n",
      "0.521\n",
      "0.646\n",
      "0.543\n",
      "0.252\n",
      "0.353\n",
      "0.090\n",
      "0.173\n",
      "0.298\n",
      "0.542\n",
      "0.309\n",
      "0.735\n",
      "0.537\n",
      "0.344\n",
      "0.492\n",
      "0.305\n",
      "0.360\n",
      "0.423\n",
      "0.627\n",
      "0.497\n",
      "0.266\n",
      "0.129\n",
      "0.327\n",
      "0.241\n",
      "0.441\n",
      "0.606\n",
      "0.543\n",
      "0.337\n",
      "0.224\n",
      "0.415\n",
      "0.211\n",
      "0.182\n",
      "0.203\n",
      "0.524\n",
      "0.100\n",
      "0.955\n",
      "0.570\n",
      "0.434\n",
      "0.967\n",
      "0.836\n",
      "0.340\n",
      "0.121\n",
      "0.661\n",
      "0.544\n",
      "0.278\n",
      "0.317\n",
      "0.830\n",
      "0.970\n",
      "0.570\n",
      "0.462\n",
      "0.412\n",
      "0.864\n",
      "0.575\n",
      "0.974\n",
      "0.575\n",
      "0.793\n",
      "0.692\n",
      "0.352\n",
      "0.227\n",
      "0.343\n",
      "0.342\n",
      "0.357\n",
      "0.193\n",
      "0.182\n",
      "0.179\n",
      "0.304\n",
      "0.278\n",
      "0.449\n",
      "0.193\n",
      "0.238\n",
      "0.133\n",
      "0.330\n",
      "0.372\n",
      "0.301\n",
      "0.187\n",
      "0.600\n",
      "0.416\n",
      "0.350\n",
      "0.126\n",
      "0.132\n",
      "0.435\n",
      "0.193\n",
      "0.166\n",
      "0.334\n",
      "0.415\n",
      "0.463\n",
      "0.622\n",
      "0.305\n",
      "0.148\n",
      "0.925\n",
      "0.837\n",
      "0.106\n",
      "0.251\n",
      "0.626\n",
      "0.519\n",
      "0.306\n",
      "0.296\n",
      "0.974\n",
      "0.430\n",
      "0.249\n",
      "0.534\n",
      "0.662\n",
      "0.143\n",
      "0.720\n",
      "0.640\n",
      "0.239\n",
      "0.606\n",
      "0.660\n",
      "0.158\n",
      "0.286\n",
      "0.090\n",
      "0.311\n",
      "0.603\n",
      "0.257\n",
      "0.336\n",
      "0.773\n",
      "0.361\n",
      "0.107\n",
      "0.619\n",
      "0.238\n",
      "0.409\n",
      "0.091\n",
      "0.091\n",
      "0.487\n",
      "0.092\n",
      "0.395\n",
      "0.238\n",
      "0.143\n",
      "0.497\n",
      "0.100\n",
      "0.466\n",
      "0.107\n",
      "0.091\n",
      "0.539\n",
      "0.672\n",
      "0.257\n",
      "0.365\n",
      "0.147\n",
      "0.122\n",
      "0.725\n",
      "0.850\n",
      "0.245\n",
      "0.154\n",
      "0.209\n",
      "0.284\n",
      "0.563\n",
      "0.174\n",
      "0.313\n",
      "0.071\n",
      "0.140\n",
      "0.066\n",
      "0.069\n",
      "0.080\n",
      "0.100\n",
      "0.209\n",
      "0.209\n",
      "0.225\n",
      "0.094\n",
      "0.117\n",
      "0.494\n",
      "0.098\n",
      "0.234\n",
      "0.084\n",
      "0.241\n",
      "0.096\n",
      "0.355\n",
      "0.076\n",
      "0.330\n",
      "0.114\n",
      "0.109\n",
      "0.509\n",
      "0.633\n",
      "0.530\n",
      "0.240\n",
      "0.341\n",
      "0.077\n",
      "0.161\n",
      "0.286\n",
      "0.529\n",
      "0.296\n",
      "0.722\n",
      "0.525\n",
      "0.331\n",
      "0.480\n",
      "0.292\n",
      "0.348\n",
      "0.411\n",
      "0.614\n",
      "0.484\n",
      "0.253\n",
      "0.117\n",
      "0.314\n",
      "0.228\n",
      "0.429\n",
      "0.594\n",
      "0.531\n",
      "0.324\n",
      "0.212\n",
      "0.403\n",
      "0.199\n",
      "0.169\n",
      "0.190\n",
      "0.512\n",
      "0.088\n",
      "0.942\n",
      "0.557\n",
      "0.422\n",
      "0.955\n",
      "0.824\n",
      "0.327\n",
      "0.109\n",
      "0.648\n",
      "0.532\n",
      "0.266\n",
      "0.305\n",
      "0.817\n",
      "0.958\n",
      "0.558\n",
      "0.450\n",
      "0.399\n",
      "0.851\n",
      "0.562\n",
      "0.961\n",
      "0.562\n",
      "0.780\n",
      "0.680\n",
      "0.340\n",
      "0.214\n",
      "0.331\n",
      "0.330\n",
      "0.345\n",
      "0.180\n",
      "0.169\n",
      "0.167\n",
      "0.291\n",
      "0.265\n",
      "0.436\n",
      "0.181\n",
      "0.226\n",
      "0.121\n",
      "0.317\n",
      "0.360\n",
      "0.288\n",
      "0.175\n",
      "0.587\n",
      "0.404\n",
      "0.337\n",
      "0.113\n",
      "0.120\n",
      "0.422\n",
      "0.180\n",
      "0.154\n",
      "0.322\n",
      "0.403\n",
      "0.450\n",
      "0.610\n",
      "0.293\n",
      "0.136\n",
      "0.912\n",
      "0.824\n",
      "0.093\n",
      "0.239\n",
      "0.613\n",
      "0.507\n",
      "0.293\n",
      "0.284\n",
      "0.961\n",
      "0.418\n",
      "0.237\n",
      "0.522\n",
      "0.649\n",
      "0.130\n",
      "0.707\n",
      "0.628\n",
      "0.227\n",
      "0.593\n",
      "0.647\n",
      "0.146\n",
      "0.274\n",
      "0.077\n",
      "0.298\n",
      "0.590\n",
      "0.244\n",
      "0.323\n",
      "0.760\n",
      "0.349\n",
      "0.094\n",
      "0.607\n",
      "0.225\n",
      "0.396\n",
      "0.078\n",
      "0.078\n",
      "0.475\n",
      "0.080\n",
      "0.383\n",
      "0.225\n",
      "0.131\n",
      "0.485\n",
      "0.088\n",
      "0.453\n",
      "0.094\n",
      "0.078\n",
      "0.527\n",
      "0.660\n",
      "0.245\n",
      "0.352\n",
      "0.135\n",
      "0.120\n",
      "0.723\n",
      "0.848\n",
      "0.244\n",
      "0.152\n",
      "0.207\n",
      "0.283\n",
      "0.562\n",
      "0.172\n",
      "0.311\n",
      "0.069\n",
      "0.138\n",
      "0.064\n",
      "0.067\n",
      "0.078\n",
      "0.098\n",
      "0.208\n",
      "0.208\n",
      "0.223\n",
      "0.093\n",
      "0.116\n",
      "0.493\n",
      "0.096\n",
      "0.232\n",
      "0.082\n",
      "0.239\n",
      "0.095\n",
      "0.354\n",
      "0.075\n",
      "0.328\n",
      "0.113\n",
      "0.107\n",
      "0.507\n",
      "0.632\n",
      "0.529\n",
      "0.238\n",
      "0.339\n",
      "0.076\n",
      "0.159\n",
      "0.284\n",
      "0.528\n",
      "0.295\n",
      "0.721\n",
      "0.523\n",
      "0.330\n",
      "0.478\n",
      "0.291\n",
      "0.346\n",
      "0.409\n",
      "0.613\n",
      "0.483\n",
      "0.252\n",
      "0.115\n",
      "0.312\n",
      "0.227\n",
      "0.427\n",
      "0.592\n",
      "0.529\n",
      "0.323\n",
      "0.210\n",
      "0.401\n",
      "0.197\n",
      "0.168\n",
      "0.189\n",
      "0.510\n",
      "0.086\n",
      "0.940\n",
      "0.555\n",
      "0.420\n",
      "0.953\n",
      "0.822\n",
      "0.326\n",
      "0.107\n",
      "0.647\n",
      "0.530\n",
      "0.264\n",
      "0.303\n",
      "0.816\n",
      "0.956\n",
      "0.556\n",
      "0.448\n",
      "0.397\n",
      "0.850\n",
      "0.561\n",
      "0.960\n",
      "0.561\n",
      "0.779\n",
      "0.678\n",
      "0.338\n",
      "0.213\n",
      "0.329\n",
      "0.328\n",
      "0.343\n",
      "0.179\n",
      "0.168\n",
      "0.165\n",
      "0.289\n",
      "0.263\n",
      "0.435\n",
      "0.179\n",
      "0.224\n",
      "0.119\n",
      "0.315\n",
      "0.358\n",
      "0.287\n",
      "0.173\n",
      "0.586\n",
      "0.402\n",
      "0.336\n",
      "0.112\n",
      "0.118\n",
      "0.421\n",
      "0.179\n",
      "0.152\n",
      "0.320\n",
      "0.401\n",
      "0.449\n",
      "0.608\n",
      "0.291\n",
      "0.134\n",
      "0.911\n",
      "0.823\n",
      "0.092\n",
      "0.237\n",
      "0.612\n",
      "0.505\n",
      "0.292\n",
      "0.282\n",
      "0.960\n",
      "0.416\n",
      "0.235\n",
      "0.520\n",
      "0.648\n",
      "0.128\n",
      "0.706\n",
      "0.626\n",
      "0.225\n",
      "0.592\n",
      "0.645\n",
      "0.144\n",
      "0.272\n",
      "0.076\n",
      "0.297\n",
      "0.589\n",
      "0.243\n",
      "0.321\n",
      "0.759\n",
      "0.347\n",
      "0.093\n",
      "0.605\n",
      "0.224\n",
      "0.395\n",
      "0.077\n",
      "0.077\n",
      "0.473\n",
      "0.078\n",
      "0.381\n",
      "0.224\n",
      "0.129\n",
      "0.483\n",
      "0.086\n",
      "0.452\n",
      "0.093\n",
      "0.077\n",
      "0.525\n",
      "0.658\n",
      "0.243\n",
      "0.350\n",
      "0.133\n",
      "0.138\n",
      "0.741\n",
      "0.867\n",
      "0.262\n",
      "0.170\n",
      "0.226\n",
      "0.301\n",
      "0.580\n",
      "0.191\n",
      "0.330\n",
      "0.088\n",
      "0.156\n",
      "0.083\n",
      "0.086\n",
      "0.097\n",
      "0.117\n",
      "0.226\n",
      "0.226\n",
      "0.241\n",
      "0.111\n",
      "0.134\n",
      "0.511\n",
      "0.115\n",
      "0.251\n",
      "0.100\n",
      "0.258\n",
      "0.113\n",
      "0.372\n",
      "0.093\n",
      "0.346\n",
      "0.131\n",
      "0.126\n",
      "0.526\n",
      "0.650\n",
      "0.547\n",
      "0.257\n",
      "0.357\n",
      "0.094\n",
      "0.177\n",
      "0.302\n",
      "0.546\n",
      "0.313\n",
      "0.739\n",
      "0.541\n",
      "0.348\n",
      "0.497\n",
      "0.309\n",
      "0.365\n",
      "0.427\n",
      "0.631\n",
      "0.501\n",
      "0.270\n",
      "0.134\n",
      "0.331\n",
      "0.245\n",
      "0.446\n",
      "0.611\n",
      "0.547\n",
      "0.341\n",
      "0.229\n",
      "0.420\n",
      "0.216\n",
      "0.186\n",
      "0.207\n",
      "0.529\n",
      "0.105\n",
      "0.959\n",
      "0.574\n",
      "0.439\n",
      "0.971\n",
      "0.841\n",
      "0.344\n",
      "0.126\n",
      "0.665\n",
      "0.549\n",
      "0.282\n",
      "0.322\n",
      "0.834\n",
      "0.975\n",
      "0.575\n",
      "0.467\n",
      "0.416\n",
      "0.868\n",
      "0.579\n",
      "0.978\n",
      "0.579\n",
      "0.797\n",
      "0.697\n",
      "0.357\n",
      "0.231\n",
      "0.348\n",
      "0.347\n",
      "0.362\n",
      "0.197\n",
      "0.186\n",
      "0.183\n",
      "0.308\n",
      "0.282\n",
      "0.453\n",
      "0.198\n",
      "0.243\n",
      "0.138\n",
      "0.334\n",
      "0.377\n",
      "0.305\n",
      "0.192\n",
      "0.604\n",
      "0.421\n",
      "0.354\n",
      "0.130\n",
      "0.136\n",
      "0.439\n",
      "0.197\n",
      "0.171\n",
      "0.339\n",
      "0.420\n",
      "0.467\n",
      "0.627\n",
      "0.310\n",
      "0.153\n",
      "0.929\n",
      "0.841\n",
      "0.110\n",
      "0.255\n",
      "0.630\n",
      "0.524\n",
      "0.310\n",
      "0.301\n",
      "0.978\n",
      "0.435\n",
      "0.254\n",
      "0.538\n",
      "0.666\n",
      "0.147\n",
      "0.724\n",
      "0.645\n",
      "0.244\n",
      "0.610\n",
      "0.664\n",
      "0.163\n",
      "0.290\n",
      "0.094\n",
      "0.315\n",
      "0.607\n",
      "0.261\n",
      "0.340\n",
      "0.777\n",
      "0.366\n",
      "0.111\n",
      "0.624\n",
      "0.242\n",
      "0.413\n",
      "0.095\n",
      "0.095\n",
      "0.492\n",
      "0.097\n",
      "0.399\n",
      "0.242\n",
      "0.148\n",
      "0.502\n",
      "0.104\n",
      "0.470\n",
      "0.111\n",
      "0.095\n",
      "0.544\n",
      "0.677\n",
      "0.262\n",
      "0.369\n",
      "0.152\n",
      "0.133\n",
      "0.736\n",
      "0.861\n",
      "0.257\n",
      "0.165\n",
      "0.220\n",
      "0.296\n",
      "0.575\n",
      "0.185\n",
      "0.324\n",
      "0.082\n",
      "0.151\n",
      "0.077\n",
      "0.080\n",
      "0.091\n",
      "0.111\n",
      "0.221\n",
      "0.221\n",
      "0.236\n",
      "0.106\n",
      "0.129\n",
      "0.506\n",
      "0.109\n",
      "0.245\n",
      "0.095\n",
      "0.252\n",
      "0.108\n",
      "0.367\n",
      "0.088\n",
      "0.341\n",
      "0.126\n",
      "0.120\n",
      "0.520\n",
      "0.645\n",
      "0.542\n",
      "0.251\n",
      "0.352\n",
      "0.089\n",
      "0.172\n",
      "0.297\n",
      "0.541\n",
      "0.308\n",
      "0.734\n",
      "0.536\n",
      "0.343\n",
      "0.491\n",
      "0.304\n",
      "0.359\n",
      "0.422\n",
      "0.626\n",
      "0.496\n",
      "0.265\n",
      "0.128\n",
      "0.325\n",
      "0.240\n",
      "0.440\n",
      "0.605\n",
      "0.542\n",
      "0.336\n",
      "0.223\n",
      "0.414\n",
      "0.210\n",
      "0.181\n",
      "0.202\n",
      "0.523\n",
      "0.099\n",
      "0.954\n",
      "0.568\n",
      "0.433\n",
      "0.966\n",
      "0.835\n",
      "0.339\n",
      "0.120\n",
      "0.660\n",
      "0.543\n",
      "0.277\n",
      "0.316\n",
      "0.829\n",
      "0.969\n",
      "0.569\n",
      "0.461\n",
      "0.410\n",
      "0.863\n",
      "0.574\n",
      "0.973\n",
      "0.574\n",
      "0.792\n",
      "0.691\n",
      "0.351\n",
      "0.226\n",
      "0.342\n",
      "0.341\n",
      "0.356\n",
      "0.192\n",
      "0.181\n",
      "0.178\n",
      "0.302\n",
      "0.276\n",
      "0.448\n",
      "0.192\n",
      "0.237\n",
      "0.132\n",
      "0.328\n",
      "0.371\n",
      "0.300\n",
      "0.186\n",
      "0.599\n",
      "0.415\n",
      "0.349\n",
      "0.125\n",
      "0.131\n",
      "0.434\n",
      "0.192\n",
      "0.165\n",
      "0.333\n",
      "0.414\n",
      "0.462\n",
      "0.621\n",
      "0.304\n",
      "0.147\n",
      "0.924\n",
      "0.836\n",
      "0.105\n",
      "0.250\n",
      "0.625\n",
      "0.518\n",
      "0.305\n",
      "0.295\n",
      "0.973\n",
      "0.429\n",
      "0.248\n",
      "0.533\n",
      "0.661\n",
      "0.141\n",
      "0.719\n",
      "0.639\n",
      "0.238\n",
      "0.605\n",
      "0.658\n",
      "0.157\n",
      "0.285\n",
      "0.089\n",
      "0.310\n",
      "0.602\n",
      "0.256\n",
      "0.334\n",
      "0.772\n",
      "0.360\n",
      "0.106\n",
      "0.618\n",
      "0.237\n",
      "0.408\n",
      "0.090\n",
      "0.090\n",
      "0.486\n",
      "0.091\n",
      "0.394\n",
      "0.237\n",
      "0.142\n",
      "0.496\n",
      "0.099\n",
      "0.465\n",
      "0.106\n",
      "0.090\n",
      "0.538\n",
      "0.671\n",
      "0.256\n",
      "0.363\n",
      "0.146\n",
      "0.134\n",
      "0.737\n",
      "0.863\n",
      "0.258\n",
      "0.166\n",
      "0.222\n",
      "0.297\n",
      "0.576\n",
      "0.187\n",
      "0.326\n",
      "0.083\n",
      "0.152\n",
      "0.079\n",
      "0.082\n",
      "0.092\n",
      "0.112\n",
      "0.222\n",
      "0.222\n",
      "0.237\n",
      "0.107\n",
      "0.130\n",
      "0.507\n",
      "0.111\n",
      "0.246\n",
      "0.096\n",
      "0.254\n",
      "0.109\n",
      "0.368\n",
      "0.089\n",
      "0.342\n",
      "0.127\n",
      "0.121\n",
      "0.521\n",
      "0.646\n",
      "0.543\n",
      "0.253\n",
      "0.353\n",
      "0.090\n",
      "0.173\n",
      "0.298\n",
      "0.542\n",
      "0.309\n",
      "0.735\n",
      "0.537\n",
      "0.344\n",
      "0.493\n",
      "0.305\n",
      "0.361\n",
      "0.423\n",
      "0.627\n",
      "0.497\n",
      "0.266\n",
      "0.129\n",
      "0.327\n",
      "0.241\n",
      "0.442\n",
      "0.607\n",
      "0.543\n",
      "0.337\n",
      "0.225\n",
      "0.416\n",
      "0.212\n",
      "0.182\n",
      "0.203\n",
      "0.524\n",
      "0.100\n",
      "0.955\n",
      "0.570\n",
      "0.435\n",
      "0.967\n",
      "0.836\n",
      "0.340\n",
      "0.122\n",
      "0.661\n",
      "0.544\n",
      "0.278\n",
      "0.318\n",
      "0.830\n",
      "0.971\n",
      "0.570\n",
      "0.463\n",
      "0.412\n",
      "0.864\n",
      "0.575\n",
      "0.974\n",
      "0.575\n",
      "0.793\n",
      "0.693\n",
      "0.353\n",
      "0.227\n",
      "0.343\n",
      "0.343\n",
      "0.358\n",
      "0.193\n",
      "0.182\n",
      "0.179\n",
      "0.304\n",
      "0.278\n",
      "0.449\n",
      "0.194\n",
      "0.239\n",
      "0.133\n",
      "0.330\n",
      "0.372\n",
      "0.301\n",
      "0.188\n",
      "0.600\n",
      "0.416\n",
      "0.350\n",
      "0.126\n",
      "0.132\n",
      "0.435\n",
      "0.193\n",
      "0.167\n",
      "0.335\n",
      "0.416\n",
      "0.463\n",
      "0.623\n",
      "0.306\n",
      "0.149\n",
      "0.925\n",
      "0.837\n",
      "0.106\n",
      "0.251\n",
      "0.626\n",
      "0.520\n",
      "0.306\n",
      "0.297\n",
      "0.974\n",
      "0.431\n",
      "0.249\n",
      "0.534\n",
      "0.662\n",
      "0.143\n",
      "0.720\n",
      "0.641\n",
      "0.240\n",
      "0.606\n",
      "0.660\n",
      "0.158\n",
      "0.286\n",
      "0.090\n",
      "0.311\n",
      "0.603\n",
      "0.257\n",
      "0.336\n",
      "0.773\n",
      "0.362\n",
      "0.107\n",
      "0.620\n",
      "0.238\n",
      "0.409\n",
      "0.091\n",
      "0.091\n",
      "0.488\n",
      "0.092\n",
      "0.395\n",
      "0.238\n",
      "0.144\n",
      "0.498\n",
      "0.100\n",
      "0.466\n",
      "0.107\n",
      "0.091\n",
      "0.539\n",
      "0.673\n",
      "0.258\n",
      "0.365\n",
      "0.147\n",
      "0.135\n",
      "0.738\n",
      "0.863\n",
      "0.259\n",
      "0.167\n",
      "0.223\n",
      "0.298\n",
      "0.577\n",
      "0.188\n",
      "0.327\n",
      "0.084\n",
      "0.153\n",
      "0.080\n",
      "0.083\n",
      "0.093\n",
      "0.113\n",
      "0.223\n",
      "0.223\n",
      "0.238\n",
      "0.108\n",
      "0.131\n",
      "0.508\n",
      "0.111\n",
      "0.247\n",
      "0.097\n",
      "0.255\n",
      "0.110\n",
      "0.369\n",
      "0.090\n",
      "0.343\n",
      "0.128\n",
      "0.122\n",
      "0.522\n",
      "0.647\n",
      "0.544\n",
      "0.254\n",
      "0.354\n",
      "0.091\n",
      "0.174\n",
      "0.299\n",
      "0.543\n",
      "0.310\n",
      "0.736\n",
      "0.538\n",
      "0.345\n",
      "0.494\n",
      "0.306\n",
      "0.362\n",
      "0.424\n",
      "0.628\n",
      "0.498\n",
      "0.267\n",
      "0.130\n",
      "0.328\n",
      "0.242\n",
      "0.443\n",
      "0.608\n",
      "0.544\n",
      "0.338\n",
      "0.225\n",
      "0.416\n",
      "0.213\n",
      "0.183\n",
      "0.204\n",
      "0.525\n",
      "0.101\n",
      "0.956\n",
      "0.571\n",
      "0.436\n",
      "0.968\n",
      "0.837\n",
      "0.341\n",
      "0.123\n",
      "0.662\n",
      "0.545\n",
      "0.279\n",
      "0.319\n",
      "0.831\n",
      "0.972\n",
      "0.571\n",
      "0.464\n",
      "0.413\n",
      "0.865\n",
      "0.576\n",
      "0.975\n",
      "0.576\n",
      "0.794\n",
      "0.694\n",
      "0.354\n",
      "0.228\n",
      "0.344\n",
      "0.344\n",
      "0.359\n",
      "0.194\n",
      "0.183\n",
      "0.180\n",
      "0.305\n",
      "0.279\n",
      "0.450\n",
      "0.195\n",
      "0.240\n",
      "0.134\n",
      "0.331\n",
      "0.373\n",
      "0.302\n",
      "0.189\n",
      "0.601\n",
      "0.417\n",
      "0.351\n",
      "0.127\n",
      "0.133\n",
      "0.436\n",
      "0.194\n",
      "0.167\n",
      "0.336\n",
      "0.416\n",
      "0.464\n",
      "0.624\n",
      "0.307\n",
      "0.149\n",
      "0.926\n",
      "0.838\n",
      "0.107\n",
      "0.252\n",
      "0.627\n",
      "0.520\n",
      "0.307\n",
      "0.298\n",
      "0.975\n",
      "0.432\n",
      "0.250\n",
      "0.535\n",
      "0.663\n",
      "0.144\n",
      "0.721\n",
      "0.641\n",
      "0.240\n",
      "0.607\n",
      "0.661\n",
      "0.159\n",
      "0.287\n",
      "0.091\n",
      "0.312\n",
      "0.604\n",
      "0.258\n",
      "0.337\n",
      "0.774\n",
      "0.363\n",
      "0.108\n",
      "0.620\n",
      "0.239\n",
      "0.410\n",
      "0.092\n",
      "0.092\n",
      "0.488\n",
      "0.093\n",
      "0.396\n",
      "0.239\n",
      "0.144\n",
      "0.499\n",
      "0.101\n",
      "0.467\n",
      "0.108\n",
      "0.092\n",
      "0.540\n",
      "0.673\n",
      "0.258\n",
      "0.366\n",
      "0.148\n",
      "0.139\n",
      "0.742\n",
      "0.867\n",
      "0.263\n",
      "0.171\n",
      "0.227\n",
      "0.302\n",
      "0.581\n",
      "0.192\n",
      "0.331\n",
      "0.088\n",
      "0.157\n",
      "0.084\n",
      "0.087\n",
      "0.097\n",
      "0.117\n",
      "0.227\n",
      "0.227\n",
      "0.242\n",
      "0.112\n",
      "0.135\n",
      "0.512\n",
      "0.115\n",
      "0.251\n",
      "0.101\n",
      "0.259\n",
      "0.114\n",
      "0.373\n",
      "0.094\n",
      "0.347\n",
      "0.132\n",
      "0.126\n",
      "0.526\n",
      "0.651\n",
      "0.548\n",
      "0.258\n",
      "0.358\n",
      "0.095\n",
      "0.178\n",
      "0.303\n",
      "0.547\n",
      "0.314\n",
      "0.740\n",
      "0.542\n",
      "0.349\n",
      "0.497\n",
      "0.310\n",
      "0.366\n",
      "0.428\n",
      "0.632\n",
      "0.502\n",
      "0.271\n",
      "0.134\n",
      "0.332\n",
      "0.246\n",
      "0.447\n",
      "0.611\n",
      "0.548\n",
      "0.342\n",
      "0.229\n",
      "0.420\n",
      "0.217\n",
      "0.187\n",
      "0.208\n",
      "0.529\n",
      "0.105\n",
      "0.960\n",
      "0.575\n",
      "0.439\n",
      "0.972\n",
      "0.841\n",
      "0.345\n",
      "0.126\n",
      "0.666\n",
      "0.549\n",
      "0.283\n",
      "0.322\n",
      "0.835\n",
      "0.976\n",
      "0.575\n",
      "0.468\n",
      "0.417\n",
      "0.869\n",
      "0.580\n",
      "0.979\n",
      "0.580\n",
      "0.798\n",
      "0.698\n",
      "0.357\n",
      "0.232\n",
      "0.348\n",
      "0.348\n",
      "0.363\n",
      "0.198\n",
      "0.187\n",
      "0.184\n",
      "0.309\n",
      "0.283\n",
      "0.454\n",
      "0.199\n",
      "0.243\n",
      "0.138\n",
      "0.335\n",
      "0.377\n",
      "0.306\n",
      "0.193\n",
      "0.605\n",
      "0.421\n",
      "0.355\n",
      "0.131\n",
      "0.137\n",
      "0.440\n",
      "0.198\n",
      "0.171\n",
      "0.339\n",
      "0.420\n",
      "0.468\n",
      "0.628\n",
      "0.310\n",
      "0.153\n",
      "0.930\n",
      "0.842\n",
      "0.111\n",
      "0.256\n",
      "0.631\n",
      "0.524\n",
      "0.311\n",
      "0.301\n",
      "0.979\n",
      "0.436\n",
      "0.254\n",
      "0.539\n",
      "0.667\n",
      "0.148\n",
      "0.725\n",
      "0.645\n",
      "0.244\n",
      "0.611\n",
      "0.665\n",
      "0.163\n",
      "0.291\n",
      "0.095\n",
      "0.316\n",
      "0.608\n",
      "0.262\n",
      "0.341\n",
      "0.778\n",
      "0.366\n",
      "0.112\n",
      "0.624\n",
      "0.243\n",
      "0.414\n",
      "0.096\n",
      "0.096\n",
      "0.492\n",
      "0.097\n",
      "0.400\n",
      "0.243\n",
      "0.148\n",
      "0.503\n",
      "0.105\n",
      "0.471\n",
      "0.112\n",
      "0.096\n",
      "0.544\n",
      "0.677\n",
      "0.262\n",
      "0.370\n",
      "0.152\n",
      "0.136\n",
      "0.739\n",
      "0.865\n",
      "0.260\n",
      "0.168\n",
      "0.224\n",
      "0.299\n",
      "0.578\n",
      "0.189\n",
      "0.328\n",
      "0.085\n",
      "0.154\n",
      "0.081\n",
      "0.084\n",
      "0.094\n",
      "0.114\n",
      "0.224\n",
      "0.224\n",
      "0.239\n",
      "0.109\n",
      "0.132\n",
      "0.509\n",
      "0.113\n",
      "0.248\n",
      "0.098\n",
      "0.256\n",
      "0.111\n",
      "0.370\n",
      "0.091\n",
      "0.344\n",
      "0.129\n",
      "0.123\n",
      "0.523\n",
      "0.648\n",
      "0.545\n",
      "0.255\n",
      "0.355\n",
      "0.092\n",
      "0.175\n",
      "0.300\n",
      "0.544\n",
      "0.311\n",
      "0.737\n",
      "0.539\n",
      "0.346\n",
      "0.495\n",
      "0.307\n",
      "0.363\n",
      "0.425\n",
      "0.629\n",
      "0.499\n",
      "0.268\n",
      "0.131\n",
      "0.329\n",
      "0.243\n",
      "0.444\n",
      "0.609\n",
      "0.545\n",
      "0.339\n",
      "0.227\n",
      "0.418\n",
      "0.214\n",
      "0.184\n",
      "0.205\n",
      "0.526\n",
      "0.102\n",
      "0.957\n",
      "0.572\n",
      "0.437\n",
      "0.969\n",
      "0.838\n",
      "0.342\n",
      "0.124\n",
      "0.663\n",
      "0.546\n",
      "0.280\n",
      "0.320\n",
      "0.832\n",
      "0.973\n",
      "0.572\n",
      "0.465\n",
      "0.414\n",
      "0.866\n",
      "0.577\n",
      "0.976\n",
      "0.577\n",
      "0.795\n",
      "0.695\n",
      "0.355\n",
      "0.229\n",
      "0.345\n",
      "0.345\n",
      "0.360\n",
      "0.195\n",
      "0.184\n",
      "0.181\n",
      "0.306\n",
      "0.280\n",
      "0.451\n",
      "0.196\n",
      "0.241\n",
      "0.135\n",
      "0.332\n",
      "0.374\n",
      "0.303\n",
      "0.190\n",
      "0.602\n",
      "0.418\n",
      "0.352\n",
      "0.128\n",
      "0.134\n",
      "0.437\n",
      "0.195\n",
      "0.169\n",
      "0.337\n",
      "0.418\n",
      "0.465\n",
      "0.625\n",
      "0.308\n",
      "0.151\n",
      "0.927\n",
      "0.839\n",
      "0.108\n",
      "0.253\n",
      "0.628\n",
      "0.522\n",
      "0.308\n",
      "0.299\n",
      "0.976\n",
      "0.433\n",
      "0.251\n",
      "0.536\n",
      "0.664\n",
      "0.145\n",
      "0.722\n",
      "0.642\n",
      "0.242\n",
      "0.608\n",
      "0.662\n",
      "0.160\n",
      "0.288\n",
      "0.092\n",
      "0.313\n",
      "0.605\n",
      "0.259\n",
      "0.338\n",
      "0.775\n",
      "0.364\n",
      "0.109\n",
      "0.622\n",
      "0.240\n",
      "0.411\n",
      "0.093\n",
      "0.093\n",
      "0.490\n",
      "0.094\n",
      "0.397\n",
      "0.240\n",
      "0.146\n",
      "0.500\n",
      "0.102\n",
      "0.468\n",
      "0.109\n",
      "0.093\n",
      "0.541\n",
      "0.675\n",
      "0.260\n",
      "0.367\n",
      "0.149\n",
      "0.107\n",
      "0.710\n",
      "0.835\n",
      "0.231\n",
      "0.139\n",
      "0.194\n",
      "0.270\n",
      "0.549\n",
      "0.159\n",
      "0.298\n",
      "0.056\n",
      "0.125\n",
      "0.051\n",
      "0.054\n",
      "0.065\n",
      "0.085\n",
      "0.195\n",
      "0.195\n",
      "0.210\n",
      "0.080\n",
      "0.103\n",
      "0.480\n",
      "0.083\n",
      "0.219\n",
      "0.069\n",
      "0.226\n",
      "0.082\n",
      "0.341\n",
      "0.062\n",
      "0.315\n",
      "0.100\n",
      "0.094\n",
      "0.494\n",
      "0.619\n",
      "0.516\n",
      "0.225\n",
      "0.326\n",
      "0.063\n",
      "0.146\n",
      "0.271\n",
      "0.515\n",
      "0.282\n",
      "0.708\n",
      "0.510\n",
      "0.317\n",
      "0.465\n",
      "0.278\n",
      "0.333\n",
      "0.396\n",
      "0.600\n",
      "0.470\n",
      "0.239\n",
      "0.102\n",
      "0.299\n",
      "0.214\n",
      "0.414\n",
      "0.579\n",
      "0.516\n",
      "0.310\n",
      "0.197\n",
      "0.388\n",
      "0.184\n",
      "0.155\n",
      "0.176\n",
      "0.497\n",
      "0.073\n",
      "0.927\n",
      "0.542\n",
      "0.407\n",
      "0.940\n",
      "0.809\n",
      "0.313\n",
      "0.094\n",
      "0.634\n",
      "0.517\n",
      "0.251\n",
      "0.290\n",
      "0.803\n",
      "0.943\n",
      "0.543\n",
      "0.435\n",
      "0.384\n",
      "0.837\n",
      "0.547\n",
      "0.947\n",
      "0.548\n",
      "0.766\n",
      "0.665\n",
      "0.325\n",
      "0.200\n",
      "0.316\n",
      "0.315\n",
      "0.330\n",
      "0.166\n",
      "0.155\n",
      "0.152\n",
      "0.276\n",
      "0.250\n",
      "0.422\n",
      "0.166\n",
      "0.211\n",
      "0.106\n",
      "0.302\n",
      "0.345\n",
      "0.274\n",
      "0.160\n",
      "0.573\n",
      "0.389\n",
      "0.323\n",
      "0.099\n",
      "0.105\n",
      "0.408\n",
      "0.166\n",
      "0.139\n",
      "0.307\n",
      "0.388\n",
      "0.436\n",
      "0.595\n",
      "0.278\n",
      "0.121\n",
      "0.898\n",
      "0.810\n",
      "0.079\n",
      "0.224\n",
      "0.599\n",
      "0.492\n",
      "0.279\n",
      "0.269\n",
      "0.947\n",
      "0.403\n",
      "0.222\n",
      "0.507\n",
      "0.635\n",
      "0.115\n",
      "0.693\n",
      "0.613\n",
      "0.212\n",
      "0.579\n",
      "0.632\n",
      "0.131\n",
      "0.259\n",
      "0.063\n",
      "0.284\n",
      "0.576\n",
      "0.230\n",
      "0.308\n",
      "0.746\n",
      "0.334\n",
      "0.080\n",
      "0.592\n",
      "0.211\n",
      "0.382\n",
      "0.064\n",
      "0.064\n",
      "0.460\n",
      "0.065\n",
      "0.368\n",
      "0.211\n",
      "0.116\n",
      "0.470\n",
      "0.073\n",
      "0.439\n",
      "0.080\n",
      "0.064\n",
      "0.512\n",
      "0.645\n",
      "0.230\n",
      "0.337\n",
      "0.120\n",
      "0.111\n",
      "0.713\n",
      "0.839\n",
      "0.234\n",
      "0.143\n",
      "0.198\n",
      "0.273\n",
      "0.552\n",
      "0.163\n",
      "0.302\n",
      "0.060\n",
      "0.129\n",
      "0.055\n",
      "0.058\n",
      "0.069\n",
      "0.089\n",
      "0.198\n",
      "0.198\n",
      "0.213\n",
      "0.083\n",
      "0.106\n",
      "0.483\n",
      "0.087\n",
      "0.223\n",
      "0.073\n",
      "0.230\n",
      "0.085\n",
      "0.344\n",
      "0.065\n",
      "0.318\n",
      "0.103\n",
      "0.098\n",
      "0.498\n",
      "0.622\n",
      "0.519\n",
      "0.229\n",
      "0.330\n",
      "0.066\n",
      "0.149\n",
      "0.275\n",
      "0.518\n",
      "0.285\n",
      "0.711\n",
      "0.514\n",
      "0.320\n",
      "0.469\n",
      "0.281\n",
      "0.337\n",
      "0.400\n",
      "0.603\n",
      "0.473\n",
      "0.242\n",
      "0.106\n",
      "0.303\n",
      "0.217\n",
      "0.418\n",
      "0.583\n",
      "0.520\n",
      "0.313\n",
      "0.201\n",
      "0.392\n",
      "0.188\n",
      "0.158\n",
      "0.179\n",
      "0.501\n",
      "0.077\n",
      "0.931\n",
      "0.546\n",
      "0.411\n",
      "0.944\n",
      "0.813\n",
      "0.316\n",
      "0.098\n",
      "0.637\n",
      "0.521\n",
      "0.254\n",
      "0.294\n",
      "0.806\n",
      "0.947\n",
      "0.547\n",
      "0.439\n",
      "0.388\n",
      "0.840\n",
      "0.551\n",
      "0.950\n",
      "0.551\n",
      "0.769\n",
      "0.669\n",
      "0.329\n",
      "0.203\n",
      "0.320\n",
      "0.319\n",
      "0.334\n",
      "0.169\n",
      "0.158\n",
      "0.155\n",
      "0.280\n",
      "0.254\n",
      "0.425\n",
      "0.170\n",
      "0.215\n",
      "0.110\n",
      "0.306\n",
      "0.349\n",
      "0.277\n",
      "0.164\n",
      "0.576\n",
      "0.393\n",
      "0.326\n",
      "0.102\n",
      "0.108\n",
      "0.411\n",
      "0.169\n",
      "0.143\n",
      "0.311\n",
      "0.392\n",
      "0.439\n",
      "0.599\n",
      "0.282\n",
      "0.125\n",
      "0.901\n",
      "0.813\n",
      "0.082\n",
      "0.228\n",
      "0.602\n",
      "0.496\n",
      "0.282\n",
      "0.273\n",
      "0.950\n",
      "0.407\n",
      "0.226\n",
      "0.511\n",
      "0.638\n",
      "0.119\n",
      "0.696\n",
      "0.617\n",
      "0.216\n",
      "0.582\n",
      "0.636\n",
      "0.135\n",
      "0.263\n",
      "0.066\n",
      "0.287\n",
      "0.579\n",
      "0.233\n",
      "0.312\n",
      "0.749\n",
      "0.338\n",
      "0.083\n",
      "0.596\n",
      "0.214\n",
      "0.385\n",
      "0.067\n",
      "0.067\n",
      "0.464\n",
      "0.069\n",
      "0.371\n",
      "0.214\n",
      "0.120\n",
      "0.474\n",
      "0.076\n",
      "0.442\n",
      "0.083\n",
      "0.067\n",
      "0.516\n",
      "0.649\n",
      "0.234\n",
      "0.341\n",
      "0.124\n",
      "0.095\n",
      "0.698\n",
      "0.824\n",
      "0.219\n",
      "0.127\n",
      "0.183\n",
      "0.258\n",
      "0.537\n",
      "0.148\n",
      "0.287\n",
      "0.044\n",
      "0.113\n",
      "0.040\n",
      "0.043\n",
      "0.053\n",
      "0.073\n",
      "0.183\n",
      "0.183\n",
      "0.198\n",
      "0.068\n",
      "0.091\n",
      "0.468\n",
      "0.072\n",
      "0.208\n",
      "0.057\n",
      "0.215\n",
      "0.070\n",
      "0.329\n",
      "0.050\n",
      "0.303\n",
      "0.088\n",
      "0.082\n",
      "0.482\n",
      "0.607\n",
      "0.504\n",
      "0.214\n",
      "0.314\n",
      "0.051\n",
      "0.134\n",
      "0.259\n",
      "0.503\n",
      "0.270\n",
      "0.696\n",
      "0.498\n",
      "0.305\n",
      "0.454\n",
      "0.266\n",
      "0.322\n",
      "0.384\n",
      "0.588\n",
      "0.458\n",
      "0.227\n",
      "0.091\n",
      "0.288\n",
      "0.202\n",
      "0.403\n",
      "0.568\n",
      "0.504\n",
      "0.298\n",
      "0.186\n",
      "0.377\n",
      "0.173\n",
      "0.143\n",
      "0.164\n",
      "0.485\n",
      "0.061\n",
      "0.916\n",
      "0.531\n",
      "0.396\n",
      "0.928\n",
      "0.798\n",
      "0.301\n",
      "0.083\n",
      "0.622\n",
      "0.506\n",
      "0.239\n",
      "0.279\n",
      "0.791\n",
      "0.932\n",
      "0.532\n",
      "0.424\n",
      "0.373\n",
      "0.825\n",
      "0.536\n",
      "0.935\n",
      "0.536\n",
      "0.754\n",
      "0.654\n",
      "0.314\n",
      "0.188\n",
      "0.304\n",
      "0.304\n",
      "0.319\n",
      "0.154\n",
      "0.143\n",
      "0.140\n",
      "0.265\n",
      "0.239\n",
      "0.410\n",
      "0.155\n",
      "0.200\n",
      "0.094\n",
      "0.291\n",
      "0.333\n",
      "0.262\n",
      "0.149\n",
      "0.561\n",
      "0.377\n",
      "0.311\n",
      "0.087\n",
      "0.093\n",
      "0.396\n",
      "0.154\n",
      "0.128\n",
      "0.296\n",
      "0.377\n",
      "0.424\n",
      "0.584\n",
      "0.267\n",
      "0.110\n",
      "0.886\n",
      "0.798\n",
      "0.067\n",
      "0.212\n",
      "0.587\n",
      "0.481\n",
      "0.267\n",
      "0.258\n",
      "0.935\n",
      "0.392\n",
      "0.210\n",
      "0.495\n",
      "0.623\n",
      "0.104\n",
      "0.681\n",
      "0.602\n",
      "0.201\n",
      "0.567\n",
      "0.621\n",
      "0.120\n",
      "0.247\n",
      "0.051\n",
      "0.272\n",
      "0.564\n",
      "0.218\n",
      "0.297\n",
      "0.734\n",
      "0.323\n",
      "0.068\n",
      "0.581\n",
      "0.199\n",
      "0.370\n",
      "0.052\n",
      "0.052\n",
      "0.449\n",
      "0.053\n",
      "0.356\n",
      "0.199\n",
      "0.105\n",
      "0.459\n",
      "0.061\n",
      "0.427\n",
      "0.068\n",
      "0.052\n",
      "0.500\n",
      "0.634\n",
      "0.219\n",
      "0.326\n",
      "0.108\n",
      "0.083\n",
      "0.686\n",
      "0.811\n",
      "0.207\n",
      "0.115\n",
      "0.171\n",
      "0.246\n",
      "0.525\n",
      "0.136\n",
      "0.275\n",
      "0.032\n",
      "0.101\n",
      "0.028\n",
      "0.031\n",
      "0.041\n",
      "0.061\n",
      "0.171\n",
      "0.171\n",
      "0.186\n",
      "0.056\n",
      "0.079\n",
      "0.456\n",
      "0.060\n",
      "0.195\n",
      "0.045\n",
      "0.203\n",
      "0.058\n",
      "0.317\n",
      "0.038\n",
      "0.291\n",
      "0.076\n",
      "0.070\n",
      "0.470\n",
      "0.595\n",
      "0.492\n",
      "0.202\n",
      "0.302\n",
      "0.039\n",
      "0.122\n",
      "0.247\n",
      "0.491\n",
      "0.258\n",
      "0.684\n",
      "0.486\n",
      "0.293\n",
      "0.442\n",
      "0.254\n",
      "0.310\n",
      "0.372\n",
      "0.576\n",
      "0.446\n",
      "0.215\n",
      "0.078\n",
      "0.276\n",
      "0.190\n",
      "0.391\n",
      "0.556\n",
      "0.492\n",
      "0.286\n",
      "0.174\n",
      "0.364\n",
      "0.161\n",
      "0.131\n",
      "0.152\n",
      "0.473\n",
      "0.049\n",
      "0.904\n",
      "0.519\n",
      "0.384\n",
      "0.916\n",
      "0.785\n",
      "0.289\n",
      "0.071\n",
      "0.610\n",
      "0.493\n",
      "0.227\n",
      "0.267\n",
      "0.779\n",
      "0.920\n",
      "0.519\n",
      "0.412\n",
      "0.361\n",
      "0.813\n",
      "0.524\n",
      "0.923\n",
      "0.524\n",
      "0.742\n",
      "0.642\n",
      "0.302\n",
      "0.176\n",
      "0.292\n",
      "0.292\n",
      "0.307\n",
      "0.142\n",
      "0.131\n",
      "0.128\n",
      "0.253\n",
      "0.227\n",
      "0.398\n",
      "0.143\n",
      "0.188\n",
      "0.082\n",
      "0.279\n",
      "0.321\n",
      "0.250\n",
      "0.137\n",
      "0.549\n",
      "0.365\n",
      "0.299\n",
      "0.075\n",
      "0.081\n",
      "0.384\n",
      "0.142\n",
      "0.116\n",
      "0.284\n",
      "0.364\n",
      "0.412\n",
      "0.572\n",
      "0.255\n",
      "0.098\n",
      "0.874\n",
      "0.786\n",
      "0.055\n",
      "0.200\n",
      "0.575\n",
      "0.469\n",
      "0.255\n",
      "0.246\n",
      "0.923\n",
      "0.380\n",
      "0.198\n",
      "0.483\n",
      "0.611\n",
      "0.092\n",
      "0.669\n",
      "0.589\n",
      "0.189\n",
      "0.555\n",
      "0.609\n",
      "0.107\n",
      "0.235\n",
      "0.039\n",
      "0.260\n",
      "0.552\n",
      "0.206\n",
      "0.285\n",
      "0.722\n",
      "0.311\n",
      "0.056\n",
      "0.569\n",
      "0.187\n",
      "0.358\n",
      "0.040\n",
      "0.040\n",
      "0.437\n",
      "0.041\n",
      "0.344\n",
      "0.187\n",
      "0.093\n",
      "0.447\n",
      "0.049\n",
      "0.415\n",
      "0.056\n",
      "0.040\n",
      "0.488\n",
      "0.621\n",
      "0.207\n",
      "0.314\n",
      "0.096\n",
      "0.107\n",
      "0.710\n",
      "0.836\n",
      "0.231\n",
      "0.139\n",
      "0.195\n",
      "0.270\n",
      "0.549\n",
      "0.160\n",
      "0.299\n",
      "0.056\n",
      "0.125\n",
      "0.052\n",
      "0.055\n",
      "0.065\n",
      "0.085\n",
      "0.195\n",
      "0.195\n",
      "0.210\n",
      "0.080\n",
      "0.103\n",
      "0.480\n",
      "0.084\n",
      "0.219\n",
      "0.069\n",
      "0.227\n",
      "0.082\n",
      "0.341\n",
      "0.062\n",
      "0.315\n",
      "0.100\n",
      "0.094\n",
      "0.494\n",
      "0.619\n",
      "0.516\n",
      "0.226\n",
      "0.326\n",
      "0.063\n",
      "0.146\n",
      "0.271\n",
      "0.515\n",
      "0.282\n",
      "0.708\n",
      "0.510\n",
      "0.317\n",
      "0.466\n",
      "0.278\n",
      "0.334\n",
      "0.396\n",
      "0.600\n",
      "0.470\n",
      "0.239\n",
      "0.102\n",
      "0.300\n",
      "0.214\n",
      "0.415\n",
      "0.580\n",
      "0.516\n",
      "0.310\n",
      "0.198\n",
      "0.389\n",
      "0.185\n",
      "0.155\n",
      "0.176\n",
      "0.497\n",
      "0.073\n",
      "0.928\n",
      "0.543\n",
      "0.408\n",
      "0.940\n",
      "0.809\n",
      "0.313\n",
      "0.095\n",
      "0.634\n",
      "0.517\n",
      "0.251\n",
      "0.291\n",
      "0.803\n",
      "0.944\n",
      "0.543\n",
      "0.436\n",
      "0.385\n",
      "0.837\n",
      "0.548\n",
      "0.947\n",
      "0.548\n",
      "0.766\n",
      "0.666\n",
      "0.326\n",
      "0.200\n",
      "0.316\n",
      "0.316\n",
      "0.331\n",
      "0.166\n",
      "0.155\n",
      "0.152\n",
      "0.277\n",
      "0.251\n",
      "0.422\n",
      "0.167\n",
      "0.212\n",
      "0.106\n",
      "0.303\n",
      "0.345\n",
      "0.274\n",
      "0.161\n",
      "0.573\n",
      "0.389\n",
      "0.323\n",
      "0.099\n",
      "0.105\n",
      "0.408\n",
      "0.166\n",
      "0.140\n",
      "0.308\n",
      "0.389\n",
      "0.436\n",
      "0.596\n",
      "0.279\n",
      "0.122\n",
      "0.898\n",
      "0.810\n",
      "0.079\n",
      "0.224\n",
      "0.599\n",
      "0.493\n",
      "0.279\n",
      "0.270\n",
      "0.947\n",
      "0.404\n",
      "0.222\n",
      "0.507\n",
      "0.635\n",
      "0.116\n",
      "0.693\n",
      "0.613\n",
      "0.213\n",
      "0.579\n",
      "0.633\n",
      "0.131\n",
      "0.259\n",
      "0.063\n",
      "0.284\n",
      "0.576\n",
      "0.230\n",
      "0.309\n",
      "0.746\n",
      "0.335\n",
      "0.080\n",
      "0.593\n",
      "0.211\n",
      "0.382\n",
      "0.064\n",
      "0.064\n",
      "0.461\n",
      "0.065\n",
      "0.368\n",
      "0.211\n",
      "0.117\n",
      "0.471\n",
      "0.073\n",
      "0.439\n",
      "0.080\n",
      "0.064\n",
      "0.512\n",
      "0.646\n",
      "0.231\n",
      "0.338\n",
      "0.120\n",
      "0.087\n",
      "0.689\n",
      "0.815\n",
      "0.210\n",
      "0.119\n",
      "0.174\n",
      "0.249\n",
      "0.528\n",
      "0.139\n",
      "0.278\n",
      "0.036\n",
      "0.104\n",
      "0.031\n",
      "0.034\n",
      "0.045\n",
      "0.065\n",
      "0.174\n",
      "0.174\n",
      "0.189\n",
      "0.059\n",
      "0.082\n",
      "0.459\n",
      "0.063\n",
      "0.199\n",
      "0.049\n",
      "0.206\n",
      "0.061\n",
      "0.320\n",
      "0.041\n",
      "0.294\n",
      "0.079\n",
      "0.074\n",
      "0.474\n",
      "0.598\n",
      "0.495\n",
      "0.205\n",
      "0.306\n",
      "0.042\n",
      "0.125\n",
      "0.250\n",
      "0.494\n",
      "0.261\n",
      "0.687\n",
      "0.490\n",
      "0.296\n",
      "0.445\n",
      "0.257\n",
      "0.313\n",
      "0.376\n",
      "0.579\n",
      "0.449\n",
      "0.218\n",
      "0.082\n",
      "0.279\n",
      "0.193\n",
      "0.394\n",
      "0.559\n",
      "0.496\n",
      "0.289\n",
      "0.177\n",
      "0.368\n",
      "0.164\n",
      "0.134\n",
      "0.155\n",
      "0.477\n",
      "0.053\n",
      "0.907\n",
      "0.522\n",
      "0.387\n",
      "0.919\n",
      "0.789\n",
      "0.292\n",
      "0.074\n",
      "0.613\n",
      "0.497\n",
      "0.230\n",
      "0.270\n",
      "0.782\n",
      "0.923\n",
      "0.523\n",
      "0.415\n",
      "0.364\n",
      "0.816\n",
      "0.527\n",
      "0.926\n",
      "0.527\n",
      "0.745\n",
      "0.645\n",
      "0.305\n",
      "0.179\n",
      "0.296\n",
      "0.295\n",
      "0.310\n",
      "0.145\n",
      "0.134\n",
      "0.131\n",
      "0.256\n",
      "0.230\n",
      "0.401\n",
      "0.146\n",
      "0.191\n",
      "0.086\n",
      "0.282\n",
      "0.325\n",
      "0.253\n",
      "0.140\n",
      "0.552\n",
      "0.369\n",
      "0.302\n",
      "0.078\n",
      "0.084\n",
      "0.387\n",
      "0.145\n",
      "0.119\n",
      "0.287\n",
      "0.368\n",
      "0.415\n",
      "0.575\n",
      "0.258\n",
      "0.101\n",
      "0.877\n",
      "0.789\n",
      "0.058\n",
      "0.203\n",
      "0.578\n",
      "0.472\n",
      "0.258\n",
      "0.249\n",
      "0.926\n",
      "0.383\n",
      "0.202\n",
      "0.487\n",
      "0.614\n",
      "0.095\n",
      "0.672\n",
      "0.593\n",
      "0.192\n",
      "0.558\n",
      "0.612\n",
      "0.111\n",
      "0.239\n",
      "0.042\n",
      "0.263\n",
      "0.555\n",
      "0.209\n",
      "0.288\n",
      "0.725\n",
      "0.314\n",
      "0.059\n",
      "0.572\n",
      "0.190\n",
      "0.361\n",
      "0.043\n",
      "0.043\n",
      "0.440\n",
      "0.045\n",
      "0.347\n",
      "0.190\n",
      "0.096\n",
      "0.450\n",
      "0.052\n",
      "0.418\n",
      "0.059\n",
      "0.043\n",
      "0.492\n",
      "0.625\n",
      "0.210\n",
      "0.317\n",
      "0.100\n",
      "0.124\n",
      "0.727\n",
      "0.852\n",
      "0.248\n",
      "0.156\n",
      "0.212\n",
      "0.287\n",
      "0.566\n",
      "0.177\n",
      "0.316\n",
      "0.073\n",
      "0.142\n",
      "0.069\n",
      "0.072\n",
      "0.082\n",
      "0.102\n",
      "0.212\n",
      "0.212\n",
      "0.227\n",
      "0.097\n",
      "0.120\n",
      "0.497\n",
      "0.100\n",
      "0.236\n",
      "0.086\n",
      "0.244\n",
      "0.099\n",
      "0.358\n",
      "0.079\n",
      "0.332\n",
      "0.117\n",
      "0.111\n",
      "0.511\n",
      "0.636\n",
      "0.533\n",
      "0.243\n",
      "0.343\n",
      "0.080\n",
      "0.163\n",
      "0.288\n",
      "0.532\n",
      "0.299\n",
      "0.725\n",
      "0.527\n",
      "0.334\n",
      "0.483\n",
      "0.295\n",
      "0.351\n",
      "0.413\n",
      "0.617\n",
      "0.487\n",
      "0.256\n",
      "0.119\n",
      "0.317\n",
      "0.231\n",
      "0.432\n",
      "0.597\n",
      "0.533\n",
      "0.327\n",
      "0.214\n",
      "0.405\n",
      "0.202\n",
      "0.172\n",
      "0.193\n",
      "0.514\n",
      "0.090\n",
      "0.945\n",
      "0.560\n",
      "0.424\n",
      "0.957\n",
      "0.826\n",
      "0.330\n",
      "0.112\n",
      "0.651\n",
      "0.534\n",
      "0.268\n",
      "0.307\n",
      "0.820\n",
      "0.961\n",
      "0.560\n",
      "0.453\n",
      "0.402\n",
      "0.854\n",
      "0.565\n",
      "0.964\n",
      "0.565\n",
      "0.783\n",
      "0.683\n",
      "0.342\n",
      "0.217\n",
      "0.333\n",
      "0.333\n",
      "0.348\n",
      "0.183\n",
      "0.172\n",
      "0.169\n",
      "0.294\n",
      "0.268\n",
      "0.439\n",
      "0.184\n",
      "0.229\n",
      "0.123\n",
      "0.320\n",
      "0.362\n",
      "0.291\n",
      "0.178\n",
      "0.590\n",
      "0.406\n",
      "0.340\n",
      "0.116\n",
      "0.122\n",
      "0.425\n",
      "0.183\n",
      "0.156\n",
      "0.325\n",
      "0.405\n",
      "0.453\n",
      "0.613\n",
      "0.296\n",
      "0.138\n",
      "0.915\n",
      "0.827\n",
      "0.096\n",
      "0.241\n",
      "0.616\n",
      "0.509\n",
      "0.296\n",
      "0.287\n",
      "0.964\n",
      "0.421\n",
      "0.239\n",
      "0.524\n",
      "0.652\n",
      "0.133\n",
      "0.710\n",
      "0.630\n",
      "0.229\n",
      "0.596\n",
      "0.650\n",
      "0.148\n",
      "0.276\n",
      "0.080\n",
      "0.301\n",
      "0.593\n",
      "0.247\n",
      "0.326\n",
      "0.763\n",
      "0.351\n",
      "0.097\n",
      "0.609\n",
      "0.228\n",
      "0.399\n",
      "0.081\n",
      "0.081\n",
      "0.477\n",
      "0.082\n",
      "0.385\n",
      "0.228\n",
      "0.133\n",
      "0.488\n",
      "0.090\n",
      "0.456\n",
      "0.097\n",
      "0.081\n",
      "0.529\n",
      "0.662\n",
      "0.247\n",
      "0.355\n",
      "0.137\n",
      "0.106\n",
      "0.709\n",
      "0.835\n",
      "0.230\n",
      "0.138\n",
      "0.194\n",
      "0.269\n",
      "0.548\n",
      "0.159\n",
      "0.298\n",
      "0.055\n",
      "0.124\n",
      "0.051\n",
      "0.054\n",
      "0.064\n",
      "0.084\n",
      "0.194\n",
      "0.194\n",
      "0.209\n",
      "0.079\n",
      "0.102\n",
      "0.479\n",
      "0.083\n",
      "0.219\n",
      "0.068\n",
      "0.226\n",
      "0.081\n",
      "0.340\n",
      "0.061\n",
      "0.314\n",
      "0.099\n",
      "0.093\n",
      "0.493\n",
      "0.618\n",
      "0.515\n",
      "0.225\n",
      "0.325\n",
      "0.062\n",
      "0.145\n",
      "0.270\n",
      "0.514\n",
      "0.281\n",
      "0.707\n",
      "0.509\n",
      "0.316\n",
      "0.465\n",
      "0.277\n",
      "0.333\n",
      "0.395\n",
      "0.599\n",
      "0.469\n",
      "0.238\n",
      "0.102\n",
      "0.299\n",
      "0.213\n",
      "0.414\n",
      "0.579\n",
      "0.515\n",
      "0.309\n",
      "0.197\n",
      "0.388\n",
      "0.184\n",
      "0.154\n",
      "0.175\n",
      "0.496\n",
      "0.073\n",
      "0.927\n",
      "0.542\n",
      "0.407\n",
      "0.939\n",
      "0.809\n",
      "0.312\n",
      "0.094\n",
      "0.633\n",
      "0.517\n",
      "0.250\n",
      "0.290\n",
      "0.802\n",
      "0.943\n",
      "0.543\n",
      "0.435\n",
      "0.384\n",
      "0.836\n",
      "0.547\n",
      "0.946\n",
      "0.547\n",
      "0.765\n",
      "0.665\n",
      "0.325\n",
      "0.199\n",
      "0.315\n",
      "0.315\n",
      "0.330\n",
      "0.165\n",
      "0.154\n",
      "0.151\n",
      "0.276\n",
      "0.250\n",
      "0.421\n",
      "0.166\n",
      "0.211\n",
      "0.105\n",
      "0.302\n",
      "0.344\n",
      "0.273\n",
      "0.160\n",
      "0.572\n",
      "0.388\n",
      "0.322\n",
      "0.098\n",
      "0.104\n",
      "0.407\n",
      "0.165\n",
      "0.139\n",
      "0.307\n",
      "0.388\n",
      "0.435\n",
      "0.595\n",
      "0.278\n",
      "0.121\n",
      "0.897\n",
      "0.809\n",
      "0.078\n",
      "0.223\n",
      "0.598\n",
      "0.492\n",
      "0.278\n",
      "0.269\n",
      "0.946\n",
      "0.403\n",
      "0.222\n",
      "0.506\n",
      "0.634\n",
      "0.115\n",
      "0.692\n",
      "0.613\n",
      "0.212\n",
      "0.578\n",
      "0.632\n",
      "0.131\n",
      "0.258\n",
      "0.062\n",
      "0.283\n",
      "0.575\n",
      "0.229\n",
      "0.308\n",
      "0.745\n",
      "0.334\n",
      "0.079\n",
      "0.592\n",
      "0.210\n",
      "0.381\n",
      "0.063\n",
      "0.063\n",
      "0.460\n",
      "0.064\n",
      "0.367\n",
      "0.210\n",
      "0.116\n",
      "0.470\n",
      "0.072\n",
      "0.438\n",
      "0.079\n",
      "0.063\n",
      "0.511\n",
      "0.645\n",
      "0.230\n",
      "0.337\n",
      "0.119\n",
      "0.106\n",
      "0.709\n",
      "0.834\n",
      "0.230\n",
      "0.138\n",
      "0.194\n",
      "0.269\n",
      "0.548\n",
      "0.159\n",
      "0.297\n",
      "0.055\n",
      "0.124\n",
      "0.051\n",
      "0.054\n",
      "0.064\n",
      "0.084\n",
      "0.194\n",
      "0.194\n",
      "0.209\n",
      "0.079\n",
      "0.102\n",
      "0.479\n",
      "0.082\n",
      "0.218\n",
      "0.068\n",
      "0.226\n",
      "0.081\n",
      "0.340\n",
      "0.061\n",
      "0.314\n",
      "0.099\n",
      "0.093\n",
      "0.493\n",
      "0.618\n",
      "0.515\n",
      "0.224\n",
      "0.325\n",
      "0.062\n",
      "0.145\n",
      "0.270\n",
      "0.514\n",
      "0.281\n",
      "0.707\n",
      "0.509\n",
      "0.316\n",
      "0.464\n",
      "0.277\n",
      "0.332\n",
      "0.395\n",
      "0.599\n",
      "0.469\n",
      "0.238\n",
      "0.101\n",
      "0.299\n",
      "0.213\n",
      "0.414\n",
      "0.578\n",
      "0.515\n",
      "0.309\n",
      "0.196\n",
      "0.387\n",
      "0.183\n",
      "0.154\n",
      "0.175\n",
      "0.496\n",
      "0.072\n",
      "0.927\n",
      "0.542\n",
      "0.406\n",
      "0.939\n",
      "0.808\n",
      "0.312\n",
      "0.093\n",
      "0.633\n",
      "0.516\n",
      "0.250\n",
      "0.289\n",
      "0.802\n",
      "0.943\n",
      "0.542\n",
      "0.435\n",
      "0.384\n",
      "0.836\n",
      "0.547\n",
      "0.946\n",
      "0.547\n",
      "0.765\n",
      "0.665\n",
      "0.324\n",
      "0.199\n",
      "0.315\n",
      "0.315\n",
      "0.329\n",
      "0.165\n",
      "0.154\n",
      "0.151\n",
      "0.276\n",
      "0.250\n",
      "0.421\n",
      "0.166\n",
      "0.210\n",
      "0.105\n",
      "0.302\n",
      "0.344\n",
      "0.273\n",
      "0.160\n",
      "0.572\n",
      "0.388\n",
      "0.322\n",
      "0.098\n",
      "0.104\n",
      "0.407\n",
      "0.165\n",
      "0.138\n",
      "0.306\n",
      "0.387\n",
      "0.435\n",
      "0.595\n",
      "0.277\n",
      "0.120\n",
      "0.897\n",
      "0.809\n",
      "0.078\n",
      "0.223\n",
      "0.598\n",
      "0.491\n",
      "0.278\n",
      "0.268\n",
      "0.946\n",
      "0.402\n",
      "0.221\n",
      "0.506\n",
      "0.634\n",
      "0.115\n",
      "0.692\n",
      "0.612\n",
      "0.211\n",
      "0.578\n",
      "0.632\n",
      "0.130\n",
      "0.258\n",
      "0.062\n",
      "0.283\n",
      "0.575\n",
      "0.229\n",
      "0.308\n",
      "0.745\n",
      "0.333\n",
      "0.079\n",
      "0.591\n",
      "0.210\n",
      "0.381\n",
      "0.063\n",
      "0.063\n",
      "0.459\n",
      "0.064\n",
      "0.367\n",
      "0.210\n",
      "0.115\n",
      "0.470\n",
      "0.072\n",
      "0.438\n",
      "0.079\n",
      "0.063\n",
      "0.511\n",
      "0.644\n",
      "0.229\n",
      "0.337\n",
      "0.119\n",
      "0.130\n",
      "0.733\n",
      "0.858\n",
      "0.254\n",
      "0.162\n",
      "0.217\n",
      "0.293\n",
      "0.572\n",
      "0.182\n",
      "0.321\n",
      "0.079\n",
      "0.148\n",
      "0.074\n",
      "0.077\n",
      "0.088\n",
      "0.108\n",
      "0.218\n",
      "0.218\n",
      "0.233\n",
      "0.102\n",
      "0.126\n",
      "0.502\n",
      "0.106\n",
      "0.242\n",
      "0.092\n",
      "0.249\n",
      "0.104\n",
      "0.364\n",
      "0.084\n",
      "0.338\n",
      "0.122\n",
      "0.117\n",
      "0.517\n",
      "0.642\n",
      "0.539\n",
      "0.248\n",
      "0.349\n",
      "0.086\n",
      "0.169\n",
      "0.294\n",
      "0.537\n",
      "0.304\n",
      "0.730\n",
      "0.533\n",
      "0.340\n",
      "0.488\n",
      "0.300\n",
      "0.356\n",
      "0.419\n",
      "0.622\n",
      "0.493\n",
      "0.262\n",
      "0.125\n",
      "0.322\n",
      "0.236\n",
      "0.437\n",
      "0.602\n",
      "0.539\n",
      "0.332\n",
      "0.220\n",
      "0.411\n",
      "0.207\n",
      "0.177\n",
      "0.199\n",
      "0.520\n",
      "0.096\n",
      "0.950\n",
      "0.565\n",
      "0.430\n",
      "0.963\n",
      "0.832\n",
      "0.335\n",
      "0.117\n",
      "0.656\n",
      "0.540\n",
      "0.274\n",
      "0.313\n",
      "0.826\n",
      "0.966\n",
      "0.566\n",
      "0.458\n",
      "0.407\n",
      "0.860\n",
      "0.570\n",
      "0.970\n",
      "0.571\n",
      "0.789\n",
      "0.688\n",
      "0.348\n",
      "0.222\n",
      "0.339\n",
      "0.338\n",
      "0.353\n",
      "0.189\n",
      "0.177\n",
      "0.175\n",
      "0.299\n",
      "0.273\n",
      "0.445\n",
      "0.189\n",
      "0.234\n",
      "0.129\n",
      "0.325\n",
      "0.368\n",
      "0.297\n",
      "0.183\n",
      "0.595\n",
      "0.412\n",
      "0.345\n",
      "0.122\n",
      "0.128\n",
      "0.431\n",
      "0.189\n",
      "0.162\n",
      "0.330\n",
      "0.411\n",
      "0.459\n",
      "0.618\n",
      "0.301\n",
      "0.144\n",
      "0.921\n",
      "0.833\n",
      "0.101\n",
      "0.247\n",
      "0.621\n",
      "0.515\n",
      "0.302\n",
      "0.292\n",
      "0.969\n",
      "0.426\n",
      "0.245\n",
      "0.530\n",
      "0.657\n",
      "0.138\n",
      "0.715\n",
      "0.636\n",
      "0.235\n",
      "0.601\n",
      "0.655\n",
      "0.154\n",
      "0.282\n",
      "0.085\n",
      "0.306\n",
      "0.598\n",
      "0.253\n",
      "0.331\n",
      "0.769\n",
      "0.357\n",
      "0.103\n",
      "0.615\n",
      "0.233\n",
      "0.405\n",
      "0.087\n",
      "0.087\n",
      "0.483\n",
      "0.088\n",
      "0.391\n",
      "0.234\n",
      "0.139\n",
      "0.493\n",
      "0.096\n",
      "0.462\n",
      "0.103\n",
      "0.087\n",
      "0.535\n",
      "0.668\n",
      "0.253\n",
      "0.360\n",
      "0.143\n",
      "0.098\n",
      "0.701\n",
      "0.826\n",
      "0.222\n",
      "0.130\n",
      "0.186\n",
      "0.261\n",
      "0.540\n",
      "0.151\n",
      "0.289\n",
      "0.047\n",
      "0.116\n",
      "0.042\n",
      "0.045\n",
      "0.056\n",
      "0.076\n",
      "0.186\n",
      "0.186\n",
      "0.201\n",
      "0.071\n",
      "0.094\n",
      "0.471\n",
      "0.074\n",
      "0.210\n",
      "0.060\n",
      "0.218\n",
      "0.073\n",
      "0.332\n",
      "0.053\n",
      "0.306\n",
      "0.091\n",
      "0.085\n",
      "0.485\n",
      "0.610\n",
      "0.507\n",
      "0.216\n",
      "0.317\n",
      "0.054\n",
      "0.137\n",
      "0.262\n",
      "0.506\n",
      "0.273\n",
      "0.699\n",
      "0.501\n",
      "0.308\n",
      "0.456\n",
      "0.269\n",
      "0.324\n",
      "0.387\n",
      "0.591\n",
      "0.461\n",
      "0.230\n",
      "0.093\n",
      "0.291\n",
      "0.205\n",
      "0.405\n",
      "0.570\n",
      "0.507\n",
      "0.301\n",
      "0.188\n",
      "0.379\n",
      "0.175\n",
      "0.146\n",
      "0.167\n",
      "0.488\n",
      "0.064\n",
      "0.919\n",
      "0.533\n",
      "0.398\n",
      "0.931\n",
      "0.800\n",
      "0.304\n",
      "0.085\n",
      "0.625\n",
      "0.508\n",
      "0.242\n",
      "0.281\n",
      "0.794\n",
      "0.934\n",
      "0.534\n",
      "0.426\n",
      "0.376\n",
      "0.828\n",
      "0.539\n",
      "0.938\n",
      "0.539\n",
      "0.757\n",
      "0.656\n",
      "0.316\n",
      "0.191\n",
      "0.307\n",
      "0.306\n",
      "0.321\n",
      "0.157\n",
      "0.146\n",
      "0.143\n",
      "0.267\n",
      "0.241\n",
      "0.413\n",
      "0.157\n",
      "0.202\n",
      "0.097\n",
      "0.294\n",
      "0.336\n",
      "0.265\n",
      "0.151\n",
      "0.564\n",
      "0.380\n",
      "0.314\n",
      "0.090\n",
      "0.096\n",
      "0.399\n",
      "0.157\n",
      "0.130\n",
      "0.298\n",
      "0.379\n",
      "0.427\n",
      "0.586\n",
      "0.269\n",
      "0.112\n",
      "0.889\n",
      "0.801\n",
      "0.070\n",
      "0.215\n",
      "0.590\n",
      "0.483\n",
      "0.270\n",
      "0.260\n",
      "0.938\n",
      "0.394\n",
      "0.213\n",
      "0.498\n",
      "0.626\n",
      "0.107\n",
      "0.684\n",
      "0.604\n",
      "0.203\n",
      "0.570\n",
      "0.624\n",
      "0.122\n",
      "0.250\n",
      "0.054\n",
      "0.275\n",
      "0.567\n",
      "0.221\n",
      "0.300\n",
      "0.737\n",
      "0.325\n",
      "0.071\n",
      "0.583\n",
      "0.202\n",
      "0.373\n",
      "0.055\n",
      "0.055\n",
      "0.451\n",
      "0.056\n",
      "0.359\n",
      "0.202\n",
      "0.107\n",
      "0.461\n",
      "0.064\n",
      "0.430\n",
      "0.071\n",
      "0.055\n",
      "0.503\n",
      "0.636\n",
      "0.221\n",
      "0.329\n",
      "0.111\n",
      "0.116\n",
      "0.719\n",
      "0.844\n",
      "0.240\n",
      "0.148\n",
      "0.204\n",
      "0.279\n",
      "0.558\n",
      "0.169\n",
      "0.308\n",
      "0.065\n",
      "0.134\n",
      "0.061\n",
      "0.064\n",
      "0.074\n",
      "0.094\n",
      "0.204\n",
      "0.204\n",
      "0.219\n",
      "0.089\n",
      "0.112\n",
      "0.489\n",
      "0.092\n",
      "0.228\n",
      "0.078\n",
      "0.236\n",
      "0.091\n",
      "0.350\n",
      "0.071\n",
      "0.324\n",
      "0.109\n",
      "0.103\n",
      "0.503\n",
      "0.628\n",
      "0.525\n",
      "0.235\n",
      "0.335\n",
      "0.072\n",
      "0.155\n",
      "0.280\n",
      "0.524\n",
      "0.291\n",
      "0.717\n",
      "0.519\n",
      "0.326\n",
      "0.474\n",
      "0.287\n",
      "0.343\n",
      "0.405\n",
      "0.609\n",
      "0.479\n",
      "0.248\n",
      "0.111\n",
      "0.309\n",
      "0.223\n",
      "0.424\n",
      "0.588\n",
      "0.525\n",
      "0.319\n",
      "0.206\n",
      "0.397\n",
      "0.194\n",
      "0.164\n",
      "0.185\n",
      "0.506\n",
      "0.082\n",
      "0.937\n",
      "0.552\n",
      "0.416\n",
      "0.949\n",
      "0.818\n",
      "0.322\n",
      "0.103\n",
      "0.643\n",
      "0.526\n",
      "0.260\n",
      "0.299\n",
      "0.812\n",
      "0.953\n",
      "0.552\n",
      "0.445\n",
      "0.394\n",
      "0.846\n",
      "0.557\n",
      "0.956\n",
      "0.557\n",
      "0.775\n",
      "0.675\n",
      "0.334\n",
      "0.209\n",
      "0.325\n",
      "0.325\n",
      "0.340\n",
      "0.175\n",
      "0.164\n",
      "0.161\n",
      "0.286\n",
      "0.260\n",
      "0.431\n",
      "0.176\n",
      "0.220\n",
      "0.115\n",
      "0.312\n",
      "0.354\n",
      "0.283\n",
      "0.170\n",
      "0.582\n",
      "0.398\n",
      "0.332\n",
      "0.108\n",
      "0.114\n",
      "0.417\n",
      "0.175\n",
      "0.148\n",
      "0.316\n",
      "0.397\n",
      "0.445\n",
      "0.605\n",
      "0.287\n",
      "0.130\n",
      "0.907\n",
      "0.819\n",
      "0.088\n",
      "0.233\n",
      "0.608\n",
      "0.501\n",
      "0.288\n",
      "0.278\n",
      "0.956\n",
      "0.413\n",
      "0.231\n",
      "0.516\n",
      "0.644\n",
      "0.125\n",
      "0.702\n",
      "0.622\n",
      "0.221\n",
      "0.588\n",
      "0.642\n",
      "0.140\n",
      "0.268\n",
      "0.072\n",
      "0.293\n",
      "0.585\n",
      "0.239\n",
      "0.318\n",
      "0.755\n",
      "0.343\n",
      "0.089\n",
      "0.601\n",
      "0.220\n",
      "0.391\n",
      "0.073\n",
      "0.073\n",
      "0.469\n",
      "0.074\n",
      "0.377\n",
      "0.220\n",
      "0.125\n",
      "0.480\n",
      "0.082\n",
      "0.448\n",
      "0.089\n",
      "0.073\n",
      "0.521\n",
      "0.654\n",
      "0.239\n",
      "0.347\n",
      "0.129\n",
      "0.066\n",
      "0.669\n",
      "0.794\n",
      "0.190\n",
      "0.098\n",
      "0.153\n",
      "0.229\n",
      "0.507\n",
      "0.118\n",
      "0.257\n",
      "0.015\n",
      "0.084\n",
      "0.010\n",
      "0.013\n",
      "0.024\n",
      "0.044\n",
      "0.153\n",
      "0.153\n",
      "0.169\n",
      "0.038\n",
      "0.062\n",
      "0.438\n",
      "0.042\n",
      "0.178\n",
      "0.028\n",
      "0.185\n",
      "0.040\n",
      "0.299\n",
      "0.020\n",
      "0.274\n",
      "0.058\n",
      "0.053\n",
      "0.453\n",
      "0.577\n",
      "0.475\n",
      "0.184\n",
      "0.285\n",
      "0.022\n",
      "0.105\n",
      "0.230\n",
      "0.473\n",
      "0.240\n",
      "0.666\n",
      "0.469\n",
      "0.276\n",
      "0.424\n",
      "0.236\n",
      "0.292\n",
      "0.355\n",
      "0.558\n",
      "0.428\n",
      "0.197\n",
      "0.061\n",
      "0.258\n",
      "0.172\n",
      "0.373\n",
      "0.538\n",
      "0.475\n",
      "0.268\n",
      "0.156\n",
      "0.347\n",
      "0.143\n",
      "0.113\n",
      "0.135\n",
      "0.456\n",
      "0.032\n",
      "0.886\n",
      "0.501\n",
      "0.366\n",
      "0.899\n",
      "0.768\n",
      "0.271\n",
      "0.053\n",
      "0.592\n",
      "0.476\n",
      "0.210\n",
      "0.249\n",
      "0.761\n",
      "0.902\n",
      "0.502\n",
      "0.394\n",
      "0.343\n",
      "0.796\n",
      "0.506\n",
      "0.906\n",
      "0.507\n",
      "0.725\n",
      "0.624\n",
      "0.284\n",
      "0.158\n",
      "0.275\n",
      "0.274\n",
      "0.289\n",
      "0.124\n",
      "0.113\n",
      "0.111\n",
      "0.235\n",
      "0.209\n",
      "0.381\n",
      "0.125\n",
      "0.170\n",
      "0.065\n",
      "0.261\n",
      "0.304\n",
      "0.232\n",
      "0.119\n",
      "0.531\n",
      "0.348\n",
      "0.281\n",
      "0.057\n",
      "0.064\n",
      "0.366\n",
      "0.124\n",
      "0.098\n",
      "0.266\n",
      "0.347\n",
      "0.395\n",
      "0.554\n",
      "0.237\n",
      "0.080\n",
      "0.857\n",
      "0.769\n",
      "0.037\n",
      "0.183\n",
      "0.557\n",
      "0.451\n",
      "0.238\n",
      "0.228\n",
      "0.905\n",
      "0.362\n",
      "0.181\n",
      "0.466\n",
      "0.593\n",
      "0.074\n",
      "0.651\n",
      "0.572\n",
      "0.171\n",
      "0.537\n",
      "0.591\n",
      "0.090\n",
      "0.218\n",
      "0.021\n",
      "0.242\n",
      "0.534\n",
      "0.188\n",
      "0.267\n",
      "0.705\n",
      "0.293\n",
      "0.039\n",
      "0.551\n",
      "0.169\n",
      "0.340\n",
      "0.022\n",
      "0.022\n",
      "0.419\n",
      "0.024\n",
      "0.327\n",
      "0.170\n",
      "0.075\n",
      "0.429\n",
      "0.032\n",
      "0.398\n",
      "0.039\n",
      "0.022\n",
      "0.471\n",
      "0.604\n",
      "0.189\n",
      "0.296\n",
      "0.079\n",
      "0.075\n",
      "0.678\n",
      "0.803\n",
      "0.199\n",
      "0.107\n",
      "0.163\n",
      "0.238\n",
      "0.517\n",
      "0.128\n",
      "0.266\n",
      "0.024\n",
      "0.093\n",
      "0.020\n",
      "0.023\n",
      "0.033\n",
      "0.053\n",
      "0.163\n",
      "0.163\n",
      "0.178\n",
      "0.048\n",
      "0.071\n",
      "0.448\n",
      "0.051\n",
      "0.187\n",
      "0.037\n",
      "0.195\n",
      "0.050\n",
      "0.309\n",
      "0.030\n",
      "0.283\n",
      "0.068\n",
      "0.062\n",
      "0.462\n",
      "0.587\n",
      "0.484\n",
      "0.193\n",
      "0.294\n",
      "0.031\n",
      "0.114\n",
      "0.239\n",
      "0.483\n",
      "0.250\n",
      "0.676\n",
      "0.478\n",
      "0.285\n",
      "0.433\n",
      "0.246\n",
      "0.301\n",
      "0.364\n",
      "0.568\n",
      "0.438\n",
      "0.207\n",
      "0.070\n",
      "0.268\n",
      "0.182\n",
      "0.382\n",
      "0.547\n",
      "0.484\n",
      "0.278\n",
      "0.165\n",
      "0.356\n",
      "0.152\n",
      "0.123\n",
      "0.144\n",
      "0.465\n",
      "0.041\n",
      "0.896\n",
      "0.511\n",
      "0.375\n",
      "0.908\n",
      "0.777\n",
      "0.281\n",
      "0.062\n",
      "0.602\n",
      "0.485\n",
      "0.219\n",
      "0.258\n",
      "0.771\n",
      "0.911\n",
      "0.511\n",
      "0.403\n",
      "0.353\n",
      "0.805\n",
      "0.516\n",
      "0.915\n",
      "0.516\n",
      "0.734\n",
      "0.634\n",
      "0.293\n",
      "0.168\n",
      "0.284\n",
      "0.283\n",
      "0.298\n",
      "0.134\n",
      "0.123\n",
      "0.120\n",
      "0.245\n",
      "0.219\n",
      "0.390\n",
      "0.134\n",
      "0.179\n",
      "0.074\n",
      "0.271\n",
      "0.313\n",
      "0.242\n",
      "0.128\n",
      "0.541\n",
      "0.357\n",
      "0.291\n",
      "0.067\n",
      "0.073\n",
      "0.376\n",
      "0.134\n",
      "0.107\n",
      "0.275\n",
      "0.356\n",
      "0.404\n",
      "0.564\n",
      "0.246\n",
      "0.089\n",
      "0.866\n",
      "0.778\n",
      "0.047\n",
      "0.192\n",
      "0.567\n",
      "0.460\n",
      "0.247\n",
      "0.237\n",
      "0.915\n",
      "0.371\n",
      "0.190\n",
      "0.475\n",
      "0.603\n",
      "0.084\n",
      "0.661\n",
      "0.581\n",
      "0.180\n",
      "0.547\n",
      "0.601\n",
      "0.099\n",
      "0.227\n",
      "0.031\n",
      "0.252\n",
      "0.544\n",
      "0.198\n",
      "0.277\n",
      "0.714\n",
      "0.302\n",
      "0.048\n",
      "0.560\n",
      "0.179\n",
      "0.350\n",
      "0.032\n",
      "0.032\n",
      "0.428\n",
      "0.033\n",
      "0.336\n",
      "0.179\n",
      "0.084\n",
      "0.438\n",
      "0.041\n",
      "0.407\n",
      "0.048\n",
      "0.032\n",
      "0.480\n",
      "0.613\n",
      "0.198\n",
      "0.306\n",
      "0.088\n",
      "0.112\n",
      "0.715\n",
      "0.840\n",
      "0.236\n",
      "0.144\n",
      "0.199\n",
      "0.274\n",
      "0.553\n",
      "0.164\n",
      "0.303\n",
      "0.061\n",
      "0.130\n",
      "0.056\n",
      "0.059\n",
      "0.070\n",
      "0.090\n",
      "0.199\n",
      "0.199\n",
      "0.215\n",
      "0.084\n",
      "0.108\n",
      "0.484\n",
      "0.088\n",
      "0.224\n",
      "0.074\n",
      "0.231\n",
      "0.086\n",
      "0.345\n",
      "0.066\n",
      "0.320\n",
      "0.104\n",
      "0.099\n",
      "0.499\n",
      "0.623\n",
      "0.520\n",
      "0.230\n",
      "0.331\n",
      "0.067\n",
      "0.151\n",
      "0.276\n",
      "0.519\n",
      "0.286\n",
      "0.712\n",
      "0.515\n",
      "0.321\n",
      "0.470\n",
      "0.282\n",
      "0.338\n",
      "0.401\n",
      "0.604\n",
      "0.474\n",
      "0.243\n",
      "0.107\n",
      "0.304\n",
      "0.218\n",
      "0.419\n",
      "0.584\n",
      "0.521\n",
      "0.314\n",
      "0.202\n",
      "0.393\n",
      "0.189\n",
      "0.159\n",
      "0.181\n",
      "0.502\n",
      "0.078\n",
      "0.932\n",
      "0.547\n",
      "0.412\n",
      "0.945\n",
      "0.814\n",
      "0.317\n",
      "0.099\n",
      "0.638\n",
      "0.522\n",
      "0.256\n",
      "0.295\n",
      "0.807\n",
      "0.948\n",
      "0.548\n",
      "0.440\n",
      "0.389\n",
      "0.841\n",
      "0.552\n",
      "0.952\n",
      "0.552\n",
      "0.771\n",
      "0.670\n",
      "0.330\n",
      "0.204\n",
      "0.321\n",
      "0.320\n",
      "0.335\n",
      "0.170\n",
      "0.159\n",
      "0.157\n",
      "0.281\n",
      "0.255\n",
      "0.426\n",
      "0.171\n",
      "0.216\n",
      "0.111\n",
      "0.307\n",
      "0.350\n",
      "0.278\n",
      "0.165\n",
      "0.577\n",
      "0.394\n",
      "0.327\n",
      "0.103\n",
      "0.110\n",
      "0.412\n",
      "0.170\n",
      "0.144\n",
      "0.312\n",
      "0.393\n",
      "0.441\n",
      "0.600\n",
      "0.283\n",
      "0.126\n",
      "0.902\n",
      "0.815\n",
      "0.083\n",
      "0.229\n",
      "0.603\n",
      "0.497\n",
      "0.283\n",
      "0.274\n",
      "0.951\n",
      "0.408\n",
      "0.227\n",
      "0.512\n",
      "0.639\n",
      "0.120\n",
      "0.697\n",
      "0.618\n",
      "0.217\n",
      "0.583\n",
      "0.637\n",
      "0.136\n",
      "0.264\n",
      "0.067\n",
      "0.288\n",
      "0.580\n",
      "0.234\n",
      "0.313\n",
      "0.751\n",
      "0.339\n",
      "0.084\n",
      "0.597\n",
      "0.215\n",
      "0.386\n",
      "0.068\n",
      "0.068\n",
      "0.465\n",
      "0.070\n",
      "0.373\n",
      "0.216\n",
      "0.121\n",
      "0.475\n",
      "0.078\n",
      "0.444\n",
      "0.084\n",
      "0.068\n",
      "0.517\n",
      "0.650\n",
      "0.235\n",
      "0.342\n",
      "0.125\n",
      "0.121\n",
      "0.724\n",
      "0.849\n",
      "0.245\n",
      "0.153\n",
      "0.209\n",
      "0.284\n",
      "0.563\n",
      "0.174\n",
      "0.313\n",
      "0.070\n",
      "0.139\n",
      "0.066\n",
      "0.069\n",
      "0.079\n",
      "0.099\n",
      "0.209\n",
      "0.209\n",
      "0.224\n",
      "0.094\n",
      "0.117\n",
      "0.494\n",
      "0.097\n",
      "0.233\n",
      "0.083\n",
      "0.241\n",
      "0.096\n",
      "0.355\n",
      "0.076\n",
      "0.329\n",
      "0.114\n",
      "0.108\n",
      "0.508\n",
      "0.633\n",
      "0.530\n",
      "0.240\n",
      "0.340\n",
      "0.077\n",
      "0.160\n",
      "0.285\n",
      "0.529\n",
      "0.296\n",
      "0.722\n",
      "0.524\n",
      "0.331\n",
      "0.480\n",
      "0.292\n",
      "0.348\n",
      "0.410\n",
      "0.614\n",
      "0.484\n",
      "0.253\n",
      "0.116\n",
      "0.314\n",
      "0.228\n",
      "0.429\n",
      "0.594\n",
      "0.530\n",
      "0.324\n",
      "0.211\n",
      "0.402\n",
      "0.199\n",
      "0.169\n",
      "0.190\n",
      "0.511\n",
      "0.087\n",
      "0.942\n",
      "0.557\n",
      "0.422\n",
      "0.954\n",
      "0.823\n",
      "0.327\n",
      "0.109\n",
      "0.648\n",
      "0.531\n",
      "0.265\n",
      "0.305\n",
      "0.817\n",
      "0.958\n",
      "0.557\n",
      "0.450\n",
      "0.399\n",
      "0.851\n",
      "0.562\n",
      "0.961\n",
      "0.562\n",
      "0.780\n",
      "0.680\n",
      "0.340\n",
      "0.214\n",
      "0.330\n",
      "0.330\n",
      "0.345\n",
      "0.180\n",
      "0.169\n",
      "0.166\n",
      "0.291\n",
      "0.265\n",
      "0.436\n",
      "0.181\n",
      "0.226\n",
      "0.120\n",
      "0.317\n",
      "0.359\n",
      "0.288\n",
      "0.175\n",
      "0.587\n",
      "0.403\n",
      "0.337\n",
      "0.113\n",
      "0.119\n",
      "0.422\n",
      "0.180\n",
      "0.153\n",
      "0.322\n",
      "0.402\n",
      "0.450\n",
      "0.610\n",
      "0.293\n",
      "0.135\n",
      "0.912\n",
      "0.824\n",
      "0.093\n",
      "0.238\n",
      "0.613\n",
      "0.506\n",
      "0.293\n",
      "0.284\n",
      "0.961\n",
      "0.418\n",
      "0.236\n",
      "0.521\n",
      "0.649\n",
      "0.130\n",
      "0.707\n",
      "0.627\n",
      "0.226\n",
      "0.593\n",
      "0.647\n",
      "0.145\n",
      "0.273\n",
      "0.077\n",
      "0.298\n",
      "0.590\n",
      "0.244\n",
      "0.323\n",
      "0.760\n",
      "0.349\n",
      "0.094\n",
      "0.606\n",
      "0.225\n",
      "0.396\n",
      "0.078\n",
      "0.078\n",
      "0.474\n",
      "0.079\n",
      "0.382\n",
      "0.225\n",
      "0.130\n",
      "0.485\n",
      "0.087\n",
      "0.453\n",
      "0.094\n",
      "0.078\n",
      "0.526\n",
      "0.659\n",
      "0.244\n",
      "0.352\n",
      "0.134\n",
      "0.130\n",
      "0.733\n",
      "0.858\n",
      "0.254\n",
      "0.162\n",
      "0.217\n",
      "0.292\n",
      "0.571\n",
      "0.182\n",
      "0.321\n",
      "0.079\n",
      "0.148\n",
      "0.074\n",
      "0.077\n",
      "0.088\n",
      "0.108\n",
      "0.217\n",
      "0.217\n",
      "0.233\n",
      "0.102\n",
      "0.125\n",
      "0.502\n",
      "0.106\n",
      "0.242\n",
      "0.092\n",
      "0.249\n",
      "0.104\n",
      "0.363\n",
      "0.084\n",
      "0.338\n",
      "0.122\n",
      "0.117\n",
      "0.517\n",
      "0.641\n",
      "0.538\n",
      "0.248\n",
      "0.349\n",
      "0.085\n",
      "0.169\n",
      "0.294\n",
      "0.537\n",
      "0.304\n",
      "0.730\n",
      "0.533\n",
      "0.339\n",
      "0.488\n",
      "0.300\n",
      "0.356\n",
      "0.419\n",
      "0.622\n",
      "0.492\n",
      "0.261\n",
      "0.125\n",
      "0.322\n",
      "0.236\n",
      "0.437\n",
      "0.602\n",
      "0.539\n",
      "0.332\n",
      "0.220\n",
      "0.411\n",
      "0.207\n",
      "0.177\n",
      "0.198\n",
      "0.520\n",
      "0.096\n",
      "0.950\n",
      "0.565\n",
      "0.430\n",
      "0.963\n",
      "0.832\n",
      "0.335\n",
      "0.117\n",
      "0.656\n",
      "0.540\n",
      "0.274\n",
      "0.313\n",
      "0.825\n",
      "0.966\n",
      "0.566\n",
      "0.458\n",
      "0.407\n",
      "0.859\n",
      "0.570\n",
      "0.969\n",
      "0.570\n",
      "0.788\n",
      "0.688\n",
      "0.348\n",
      "0.222\n",
      "0.339\n",
      "0.338\n",
      "0.353\n",
      "0.188\n",
      "0.177\n",
      "0.175\n",
      "0.299\n",
      "0.273\n",
      "0.444\n",
      "0.189\n",
      "0.234\n",
      "0.129\n",
      "0.325\n",
      "0.368\n",
      "0.296\n",
      "0.183\n",
      "0.595\n",
      "0.412\n",
      "0.345\n",
      "0.121\n",
      "0.128\n",
      "0.430\n",
      "0.188\n",
      "0.162\n",
      "0.330\n",
      "0.411\n",
      "0.458\n",
      "0.618\n",
      "0.301\n",
      "0.144\n",
      "0.920\n",
      "0.832\n",
      "0.101\n",
      "0.247\n",
      "0.621\n",
      "0.515\n",
      "0.301\n",
      "0.292\n",
      "0.969\n",
      "0.426\n",
      "0.245\n",
      "0.530\n",
      "0.657\n",
      "0.138\n",
      "0.715\n",
      "0.636\n",
      "0.235\n",
      "0.601\n",
      "0.655\n",
      "0.154\n",
      "0.282\n",
      "0.085\n",
      "0.306\n",
      "0.598\n",
      "0.252\n",
      "0.331\n",
      "0.768\n",
      "0.357\n",
      "0.102\n",
      "0.615\n",
      "0.233\n",
      "0.404\n",
      "0.086\n",
      "0.086\n",
      "0.483\n",
      "0.088\n",
      "0.391\n",
      "0.233\n",
      "0.139\n",
      "0.493\n",
      "0.096\n",
      "0.461\n",
      "0.102\n",
      "0.086\n",
      "0.535\n",
      "0.668\n",
      "0.253\n",
      "0.360\n",
      "0.143\n",
      "0.124\n",
      "0.727\n",
      "0.852\n",
      "0.248\n",
      "0.156\n",
      "0.212\n",
      "0.287\n",
      "0.566\n",
      "0.177\n",
      "0.316\n",
      "0.073\n",
      "0.142\n",
      "0.069\n",
      "0.072\n",
      "0.082\n",
      "0.102\n",
      "0.212\n",
      "0.212\n",
      "0.227\n",
      "0.097\n",
      "0.120\n",
      "0.497\n",
      "0.101\n",
      "0.236\n",
      "0.086\n",
      "0.244\n",
      "0.099\n",
      "0.358\n",
      "0.079\n",
      "0.332\n",
      "0.117\n",
      "0.111\n",
      "0.511\n",
      "0.636\n",
      "0.533\n",
      "0.243\n",
      "0.343\n",
      "0.080\n",
      "0.163\n",
      "0.288\n",
      "0.532\n",
      "0.299\n",
      "0.725\n",
      "0.527\n",
      "0.334\n",
      "0.483\n",
      "0.295\n",
      "0.351\n",
      "0.413\n",
      "0.617\n",
      "0.487\n",
      "0.256\n",
      "0.119\n",
      "0.317\n",
      "0.231\n",
      "0.432\n",
      "0.597\n",
      "0.533\n",
      "0.327\n",
      "0.215\n",
      "0.405\n",
      "0.202\n",
      "0.172\n",
      "0.193\n",
      "0.514\n",
      "0.090\n",
      "0.945\n",
      "0.560\n",
      "0.425\n",
      "0.957\n",
      "0.826\n",
      "0.330\n",
      "0.112\n",
      "0.651\n",
      "0.534\n",
      "0.268\n",
      "0.308\n",
      "0.820\n",
      "0.961\n",
      "0.560\n",
      "0.453\n",
      "0.402\n",
      "0.854\n",
      "0.565\n",
      "0.964\n",
      "0.565\n",
      "0.783\n",
      "0.683\n",
      "0.343\n",
      "0.217\n",
      "0.333\n",
      "0.333\n",
      "0.348\n",
      "0.183\n",
      "0.172\n",
      "0.169\n",
      "0.294\n",
      "0.268\n",
      "0.439\n",
      "0.184\n",
      "0.229\n",
      "0.123\n",
      "0.320\n",
      "0.362\n",
      "0.291\n",
      "0.178\n",
      "0.590\n",
      "0.406\n",
      "0.340\n",
      "0.116\n",
      "0.122\n",
      "0.425\n",
      "0.183\n",
      "0.157\n",
      "0.325\n",
      "0.405\n",
      "0.453\n",
      "0.613\n",
      "0.296\n",
      "0.139\n",
      "0.915\n",
      "0.827\n",
      "0.096\n",
      "0.241\n",
      "0.616\n",
      "0.510\n",
      "0.296\n",
      "0.287\n",
      "0.964\n",
      "0.421\n",
      "0.239\n",
      "0.524\n",
      "0.652\n",
      "0.133\n",
      "0.710\n",
      "0.630\n",
      "0.230\n",
      "0.596\n",
      "0.650\n",
      "0.148\n",
      "0.276\n",
      "0.080\n",
      "0.301\n",
      "0.593\n",
      "0.247\n",
      "0.326\n",
      "0.763\n",
      "0.352\n",
      "0.097\n",
      "0.610\n",
      "0.228\n",
      "0.399\n",
      "0.081\n",
      "0.081\n",
      "0.478\n",
      "0.082\n",
      "0.385\n",
      "0.228\n",
      "0.134\n",
      "0.488\n",
      "0.090\n",
      "0.456\n",
      "0.097\n",
      "0.081\n",
      "0.529\n",
      "0.662\n",
      "0.247\n",
      "0.355\n",
      "0.137\n",
      "0.133\n",
      "0.736\n",
      "0.861\n",
      "0.257\n",
      "0.165\n",
      "0.221\n",
      "0.296\n",
      "0.575\n",
      "0.186\n",
      "0.324\n",
      "0.082\n",
      "0.151\n",
      "0.078\n",
      "0.081\n",
      "0.091\n",
      "0.111\n",
      "0.221\n",
      "0.221\n",
      "0.236\n",
      "0.106\n",
      "0.129\n",
      "0.506\n",
      "0.109\n",
      "0.245\n",
      "0.095\n",
      "0.253\n",
      "0.108\n",
      "0.367\n",
      "0.088\n",
      "0.341\n",
      "0.126\n",
      "0.120\n",
      "0.520\n",
      "0.645\n",
      "0.542\n",
      "0.251\n",
      "0.352\n",
      "0.089\n",
      "0.172\n",
      "0.297\n",
      "0.541\n",
      "0.308\n",
      "0.734\n",
      "0.536\n",
      "0.343\n",
      "0.491\n",
      "0.304\n",
      "0.359\n",
      "0.422\n",
      "0.626\n",
      "0.496\n",
      "0.265\n",
      "0.128\n",
      "0.326\n",
      "0.240\n",
      "0.440\n",
      "0.605\n",
      "0.542\n",
      "0.336\n",
      "0.223\n",
      "0.414\n",
      "0.210\n",
      "0.181\n",
      "0.202\n",
      "0.523\n",
      "0.099\n",
      "0.954\n",
      "0.569\n",
      "0.433\n",
      "0.966\n",
      "0.835\n",
      "0.339\n",
      "0.120\n",
      "0.660\n",
      "0.543\n",
      "0.277\n",
      "0.316\n",
      "0.829\n",
      "0.969\n",
      "0.569\n",
      "0.461\n",
      "0.411\n",
      "0.863\n",
      "0.574\n",
      "0.973\n",
      "0.574\n",
      "0.792\n",
      "0.691\n",
      "0.351\n",
      "0.226\n",
      "0.342\n",
      "0.341\n",
      "0.356\n",
      "0.192\n",
      "0.181\n",
      "0.178\n",
      "0.303\n",
      "0.277\n",
      "0.448\n",
      "0.192\n",
      "0.237\n",
      "0.132\n",
      "0.329\n",
      "0.371\n",
      "0.300\n",
      "0.186\n",
      "0.599\n",
      "0.415\n",
      "0.349\n",
      "0.125\n",
      "0.131\n",
      "0.434\n",
      "0.192\n",
      "0.165\n",
      "0.333\n",
      "0.414\n",
      "0.462\n",
      "0.621\n",
      "0.304\n",
      "0.147\n",
      "0.924\n",
      "0.836\n",
      "0.105\n",
      "0.250\n",
      "0.625\n",
      "0.518\n",
      "0.305\n",
      "0.295\n",
      "0.973\n",
      "0.429\n",
      "0.248\n",
      "0.533\n",
      "0.661\n",
      "0.142\n",
      "0.719\n",
      "0.639\n",
      "0.238\n",
      "0.605\n",
      "0.659\n",
      "0.157\n",
      "0.285\n",
      "0.089\n",
      "0.310\n",
      "0.602\n",
      "0.256\n",
      "0.335\n",
      "0.772\n",
      "0.360\n",
      "0.106\n",
      "0.618\n",
      "0.237\n",
      "0.408\n",
      "0.090\n",
      "0.090\n",
      "0.486\n",
      "0.091\n",
      "0.394\n",
      "0.237\n",
      "0.142\n",
      "0.496\n",
      "0.099\n",
      "0.465\n",
      "0.106\n",
      "0.090\n",
      "0.538\n",
      "0.671\n",
      "0.256\n",
      "0.364\n",
      "0.146\n",
      "0.127\n",
      "0.730\n",
      "0.855\n",
      "0.251\n",
      "0.159\n",
      "0.214\n",
      "0.289\n",
      "0.568\n",
      "0.179\n",
      "0.318\n",
      "0.076\n",
      "0.145\n",
      "0.071\n",
      "0.074\n",
      "0.085\n",
      "0.105\n",
      "0.214\n",
      "0.214\n",
      "0.230\n",
      "0.099\n",
      "0.123\n",
      "0.499\n",
      "0.103\n",
      "0.239\n",
      "0.089\n",
      "0.246\n",
      "0.101\n",
      "0.360\n",
      "0.081\n",
      "0.335\n",
      "0.119\n",
      "0.114\n",
      "0.514\n",
      "0.638\n",
      "0.535\n",
      "0.245\n",
      "0.346\n",
      "0.082\n",
      "0.166\n",
      "0.291\n",
      "0.534\n",
      "0.301\n",
      "0.727\n",
      "0.530\n",
      "0.336\n",
      "0.485\n",
      "0.297\n",
      "0.353\n",
      "0.416\n",
      "0.619\n",
      "0.489\n",
      "0.258\n",
      "0.122\n",
      "0.319\n",
      "0.233\n",
      "0.434\n",
      "0.599\n",
      "0.536\n",
      "0.329\n",
      "0.217\n",
      "0.408\n",
      "0.204\n",
      "0.174\n",
      "0.196\n",
      "0.517\n",
      "0.093\n",
      "0.947\n",
      "0.562\n",
      "0.427\n",
      "0.960\n",
      "0.829\n",
      "0.332\n",
      "0.114\n",
      "0.653\n",
      "0.537\n",
      "0.271\n",
      "0.310\n",
      "0.822\n",
      "0.963\n",
      "0.563\n",
      "0.455\n",
      "0.404\n",
      "0.856\n",
      "0.567\n",
      "0.967\n",
      "0.567\n",
      "0.786\n",
      "0.685\n",
      "0.345\n",
      "0.219\n",
      "0.336\n",
      "0.335\n",
      "0.350\n",
      "0.185\n",
      "0.174\n",
      "0.172\n",
      "0.296\n",
      "0.270\n",
      "0.441\n",
      "0.186\n",
      "0.231\n",
      "0.126\n",
      "0.322\n",
      "0.365\n",
      "0.293\n",
      "0.180\n",
      "0.592\n",
      "0.409\n",
      "0.342\n",
      "0.118\n",
      "0.125\n",
      "0.427\n",
      "0.185\n",
      "0.159\n",
      "0.327\n",
      "0.408\n",
      "0.456\n",
      "0.615\n",
      "0.298\n",
      "0.141\n",
      "0.918\n",
      "0.830\n",
      "0.098\n",
      "0.244\n",
      "0.618\n",
      "0.512\n",
      "0.298\n",
      "0.289\n",
      "0.966\n",
      "0.423\n",
      "0.242\n",
      "0.527\n",
      "0.654\n",
      "0.135\n",
      "0.712\n",
      "0.633\n",
      "0.232\n",
      "0.598\n",
      "0.652\n",
      "0.151\n",
      "0.279\n",
      "0.082\n",
      "0.303\n",
      "0.595\n",
      "0.249\n",
      "0.328\n",
      "0.766\n",
      "0.354\n",
      "0.100\n",
      "0.612\n",
      "0.230\n",
      "0.401\n",
      "0.083\n",
      "0.083\n",
      "0.480\n",
      "0.085\n",
      "0.388\n",
      "0.231\n",
      "0.136\n",
      "0.490\n",
      "0.093\n",
      "0.459\n",
      "0.100\n",
      "0.083\n",
      "0.532\n",
      "0.665\n",
      "0.250\n",
      "0.357\n",
      "0.140\n",
      "0.132\n",
      "0.735\n",
      "0.860\n",
      "0.256\n",
      "0.164\n",
      "0.219\n",
      "0.295\n",
      "0.574\n",
      "0.184\n",
      "0.323\n",
      "0.081\n",
      "0.150\n",
      "0.076\n",
      "0.079\n",
      "0.090\n",
      "0.110\n",
      "0.220\n",
      "0.220\n",
      "0.235\n",
      "0.104\n",
      "0.128\n",
      "0.504\n",
      "0.108\n",
      "0.244\n",
      "0.094\n",
      "0.251\n",
      "0.107\n",
      "0.366\n",
      "0.086\n",
      "0.340\n",
      "0.124\n",
      "0.119\n",
      "0.519\n",
      "0.644\n",
      "0.541\n",
      "0.250\n",
      "0.351\n",
      "0.088\n",
      "0.171\n",
      "0.296\n",
      "0.539\n",
      "0.306\n",
      "0.732\n",
      "0.535\n",
      "0.342\n",
      "0.490\n",
      "0.303\n",
      "0.358\n",
      "0.421\n",
      "0.624\n",
      "0.495\n",
      "0.264\n",
      "0.127\n",
      "0.324\n",
      "0.238\n",
      "0.439\n",
      "0.604\n",
      "0.541\n",
      "0.335\n",
      "0.222\n",
      "0.413\n",
      "0.209\n",
      "0.180\n",
      "0.201\n",
      "0.522\n",
      "0.098\n",
      "0.952\n",
      "0.567\n",
      "0.432\n",
      "0.965\n",
      "0.834\n",
      "0.338\n",
      "0.119\n",
      "0.659\n",
      "0.542\n",
      "0.276\n",
      "0.315\n",
      "0.828\n",
      "0.968\n",
      "0.568\n",
      "0.460\n",
      "0.409\n",
      "0.862\n",
      "0.572\n",
      "0.972\n",
      "0.573\n",
      "0.791\n",
      "0.690\n",
      "0.350\n",
      "0.224\n",
      "0.341\n",
      "0.340\n",
      "0.355\n",
      "0.191\n",
      "0.180\n",
      "0.177\n",
      "0.301\n",
      "0.275\n",
      "0.447\n",
      "0.191\n",
      "0.236\n",
      "0.131\n",
      "0.327\n",
      "0.370\n",
      "0.299\n",
      "0.185\n",
      "0.598\n",
      "0.414\n",
      "0.347\n",
      "0.124\n",
      "0.130\n",
      "0.433\n",
      "0.191\n",
      "0.164\n",
      "0.332\n",
      "0.413\n",
      "0.461\n",
      "0.620\n",
      "0.303\n",
      "0.146\n",
      "0.923\n",
      "0.835\n",
      "0.104\n",
      "0.249\n",
      "0.624\n",
      "0.517\n",
      "0.304\n",
      "0.294\n",
      "0.972\n",
      "0.428\n",
      "0.247\n",
      "0.532\n",
      "0.659\n",
      "0.140\n",
      "0.717\n",
      "0.638\n",
      "0.237\n",
      "0.603\n",
      "0.657\n",
      "0.156\n",
      "0.284\n",
      "0.087\n",
      "0.308\n",
      "0.601\n",
      "0.255\n",
      "0.333\n",
      "0.771\n",
      "0.359\n",
      "0.105\n",
      "0.617\n",
      "0.235\n",
      "0.407\n",
      "0.089\n",
      "0.089\n",
      "0.485\n",
      "0.090\n",
      "0.393\n",
      "0.236\n",
      "0.141\n",
      "0.495\n",
      "0.098\n",
      "0.464\n",
      "0.105\n",
      "0.089\n",
      "0.537\n",
      "0.670\n",
      "0.255\n",
      "0.362\n",
      "0.145\n",
      "0.124\n",
      "0.727\n",
      "0.852\n",
      "0.248\n",
      "0.156\n",
      "0.211\n",
      "0.287\n",
      "0.566\n",
      "0.176\n",
      "0.315\n",
      "0.073\n",
      "0.142\n",
      "0.068\n",
      "0.071\n",
      "0.082\n",
      "0.102\n",
      "0.212\n",
      "0.212\n",
      "0.227\n",
      "0.096\n",
      "0.120\n",
      "0.496\n",
      "0.100\n",
      "0.236\n",
      "0.086\n",
      "0.243\n",
      "0.099\n",
      "0.358\n",
      "0.078\n",
      "0.332\n",
      "0.116\n",
      "0.111\n",
      "0.511\n",
      "0.636\n",
      "0.533\n",
      "0.242\n",
      "0.343\n",
      "0.080\n",
      "0.163\n",
      "0.288\n",
      "0.531\n",
      "0.298\n",
      "0.724\n",
      "0.527\n",
      "0.334\n",
      "0.482\n",
      "0.294\n",
      "0.350\n",
      "0.413\n",
      "0.616\n",
      "0.487\n",
      "0.256\n",
      "0.119\n",
      "0.316\n",
      "0.230\n",
      "0.431\n",
      "0.596\n",
      "0.533\n",
      "0.327\n",
      "0.214\n",
      "0.405\n",
      "0.201\n",
      "0.172\n",
      "0.193\n",
      "0.514\n",
      "0.090\n",
      "0.944\n",
      "0.559\n",
      "0.424\n",
      "0.957\n",
      "0.826\n",
      "0.329\n",
      "0.111\n",
      "0.651\n",
      "0.534\n",
      "0.268\n",
      "0.307\n",
      "0.820\n",
      "0.960\n",
      "0.560\n",
      "0.452\n",
      "0.401\n",
      "0.854\n",
      "0.564\n",
      "0.964\n",
      "0.565\n",
      "0.783\n",
      "0.682\n",
      "0.342\n",
      "0.216\n",
      "0.333\n",
      "0.332\n",
      "0.347\n",
      "0.183\n",
      "0.172\n",
      "0.169\n",
      "0.293\n",
      "0.267\n",
      "0.439\n",
      "0.183\n",
      "0.228\n",
      "0.123\n",
      "0.319\n",
      "0.362\n",
      "0.291\n",
      "0.177\n",
      "0.589\n",
      "0.406\n",
      "0.339\n",
      "0.116\n",
      "0.122\n",
      "0.425\n",
      "0.183\n",
      "0.156\n",
      "0.324\n",
      "0.405\n",
      "0.453\n",
      "0.612\n",
      "0.295\n",
      "0.138\n",
      "0.915\n",
      "0.827\n",
      "0.096\n",
      "0.241\n",
      "0.616\n",
      "0.509\n",
      "0.296\n",
      "0.286\n",
      "0.963\n",
      "0.420\n",
      "0.239\n",
      "0.524\n",
      "0.651\n",
      "0.132\n",
      "0.709\n",
      "0.630\n",
      "0.229\n",
      "0.595\n",
      "0.649\n",
      "0.148\n",
      "0.276\n",
      "0.079\n",
      "0.300\n",
      "0.592\n",
      "0.247\n",
      "0.325\n",
      "0.763\n",
      "0.351\n",
      "0.097\n",
      "0.609\n",
      "0.227\n",
      "0.399\n",
      "0.081\n",
      "0.081\n",
      "0.477\n",
      "0.082\n",
      "0.385\n",
      "0.228\n",
      "0.133\n",
      "0.487\n",
      "0.090\n",
      "0.456\n",
      "0.097\n",
      "0.081\n",
      "0.529\n",
      "0.662\n",
      "0.247\n",
      "0.354\n",
      "0.137\n",
      "0.108\n",
      "0.710\n",
      "0.836\n",
      "0.231\n",
      "0.140\n",
      "0.195\n",
      "0.270\n",
      "0.549\n",
      "0.160\n",
      "0.299\n",
      "0.057\n",
      "0.125\n",
      "0.052\n",
      "0.055\n",
      "0.066\n",
      "0.086\n",
      "0.195\n",
      "0.195\n",
      "0.210\n",
      "0.080\n",
      "0.103\n",
      "0.480\n",
      "0.084\n",
      "0.220\n",
      "0.070\n",
      "0.227\n",
      "0.082\n",
      "0.341\n",
      "0.062\n",
      "0.315\n",
      "0.100\n",
      "0.095\n",
      "0.495\n",
      "0.619\n",
      "0.516\n",
      "0.226\n",
      "0.327\n",
      "0.063\n",
      "0.146\n",
      "0.272\n",
      "0.515\n",
      "0.282\n",
      "0.708\n",
      "0.511\n",
      "0.317\n",
      "0.466\n",
      "0.278\n",
      "0.334\n",
      "0.397\n",
      "0.600\n",
      "0.470\n",
      "0.239\n",
      "0.103\n",
      "0.300\n",
      "0.214\n",
      "0.415\n",
      "0.580\n",
      "0.517\n",
      "0.310\n",
      "0.198\n",
      "0.389\n",
      "0.185\n",
      "0.155\n",
      "0.176\n",
      "0.498\n",
      "0.074\n",
      "0.928\n",
      "0.543\n",
      "0.408\n",
      "0.941\n",
      "0.810\n",
      "0.313\n",
      "0.095\n",
      "0.634\n",
      "0.518\n",
      "0.251\n",
      "0.291\n",
      "0.803\n",
      "0.944\n",
      "0.544\n",
      "0.436\n",
      "0.385\n",
      "0.837\n",
      "0.548\n",
      "0.947\n",
      "0.548\n",
      "0.766\n",
      "0.666\n",
      "0.326\n",
      "0.200\n",
      "0.317\n",
      "0.316\n",
      "0.331\n",
      "0.166\n",
      "0.155\n",
      "0.152\n",
      "0.277\n",
      "0.251\n",
      "0.422\n",
      "0.167\n",
      "0.212\n",
      "0.107\n",
      "0.303\n",
      "0.346\n",
      "0.274\n",
      "0.161\n",
      "0.573\n",
      "0.390\n",
      "0.323\n",
      "0.099\n",
      "0.105\n",
      "0.408\n",
      "0.166\n",
      "0.140\n",
      "0.308\n",
      "0.389\n",
      "0.436\n",
      "0.596\n",
      "0.279\n",
      "0.122\n",
      "0.898\n",
      "0.810\n",
      "0.079\n",
      "0.225\n",
      "0.599\n",
      "0.493\n",
      "0.279\n",
      "0.270\n",
      "0.947\n",
      "0.404\n",
      "0.223\n",
      "0.508\n",
      "0.635\n",
      "0.116\n",
      "0.693\n",
      "0.614\n",
      "0.213\n",
      "0.579\n",
      "0.633\n",
      "0.132\n",
      "0.260\n",
      "0.063\n",
      "0.284\n",
      "0.576\n",
      "0.230\n",
      "0.309\n",
      "0.746\n",
      "0.335\n",
      "0.080\n",
      "0.593\n",
      "0.211\n",
      "0.382\n",
      "0.064\n",
      "0.064\n",
      "0.461\n",
      "0.066\n",
      "0.368\n",
      "0.211\n",
      "0.117\n",
      "0.471\n",
      "0.073\n",
      "0.439\n",
      "0.080\n",
      "0.064\n",
      "0.513\n",
      "0.646\n",
      "0.231\n",
      "0.338\n",
      "0.121\n",
      "0.077\n",
      "0.680\n",
      "0.805\n",
      "0.201\n",
      "0.109\n",
      "0.164\n",
      "0.240\n",
      "0.519\n",
      "0.129\n",
      "0.268\n",
      "0.026\n",
      "0.095\n",
      "0.021\n",
      "0.024\n",
      "0.035\n",
      "0.055\n",
      "0.165\n",
      "0.165\n",
      "0.180\n",
      "0.050\n",
      "0.073\n",
      "0.450\n",
      "0.053\n",
      "0.189\n",
      "0.039\n",
      "0.196\n",
      "0.052\n",
      "0.311\n",
      "0.032\n",
      "0.285\n",
      "0.070\n",
      "0.064\n",
      "0.464\n",
      "0.589\n",
      "0.486\n",
      "0.195\n",
      "0.296\n",
      "0.033\n",
      "0.116\n",
      "0.241\n",
      "0.485\n",
      "0.252\n",
      "0.678\n",
      "0.480\n",
      "0.287\n",
      "0.435\n",
      "0.248\n",
      "0.303\n",
      "0.366\n",
      "0.570\n",
      "0.440\n",
      "0.209\n",
      "0.072\n",
      "0.270\n",
      "0.184\n",
      "0.384\n",
      "0.549\n",
      "0.486\n",
      "0.280\n",
      "0.167\n",
      "0.358\n",
      "0.154\n",
      "0.125\n",
      "0.146\n",
      "0.467\n",
      "0.043\n",
      "0.898\n",
      "0.512\n",
      "0.377\n",
      "0.910\n",
      "0.779\n",
      "0.283\n",
      "0.064\n",
      "0.604\n",
      "0.487\n",
      "0.221\n",
      "0.260\n",
      "0.773\n",
      "0.913\n",
      "0.513\n",
      "0.405\n",
      "0.354\n",
      "0.807\n",
      "0.518\n",
      "0.917\n",
      "0.518\n",
      "0.736\n",
      "0.635\n",
      "0.295\n",
      "0.170\n",
      "0.286\n",
      "0.285\n",
      "0.300\n",
      "0.136\n",
      "0.125\n",
      "0.122\n",
      "0.246\n",
      "0.220\n",
      "0.392\n",
      "0.136\n",
      "0.181\n",
      "0.076\n",
      "0.272\n",
      "0.315\n",
      "0.244\n",
      "0.130\n",
      "0.543\n",
      "0.359\n",
      "0.293\n",
      "0.069\n",
      "0.075\n",
      "0.378\n",
      "0.136\n",
      "0.109\n",
      "0.277\n",
      "0.358\n",
      "0.406\n",
      "0.565\n",
      "0.248\n",
      "0.091\n",
      "0.868\n",
      "0.780\n",
      "0.049\n",
      "0.194\n",
      "0.569\n",
      "0.462\n",
      "0.249\n",
      "0.239\n",
      "0.917\n",
      "0.373\n",
      "0.192\n",
      "0.477\n",
      "0.605\n",
      "0.085\n",
      "0.663\n",
      "0.583\n",
      "0.182\n",
      "0.549\n",
      "0.603\n",
      "0.101\n",
      "0.229\n",
      "0.033\n",
      "0.254\n",
      "0.546\n",
      "0.200\n",
      "0.278\n",
      "0.716\n",
      "0.304\n",
      "0.050\n",
      "0.562\n",
      "0.181\n",
      "0.352\n",
      "0.034\n",
      "0.034\n",
      "0.430\n",
      "0.035\n",
      "0.338\n",
      "0.181\n",
      "0.086\n",
      "0.440\n",
      "0.043\n",
      "0.409\n",
      "0.050\n",
      "0.034\n",
      "0.482\n",
      "0.615\n",
      "0.200\n",
      "0.308\n",
      "0.090\n",
      "0.122\n",
      "0.725\n",
      "0.850\n",
      "0.246\n",
      "0.154\n",
      "0.209\n",
      "0.284\n",
      "0.563\n",
      "0.174\n",
      "0.313\n",
      "0.071\n",
      "0.140\n",
      "0.066\n",
      "0.069\n",
      "0.080\n",
      "0.100\n",
      "0.209\n",
      "0.209\n",
      "0.225\n",
      "0.094\n",
      "0.117\n",
      "0.494\n",
      "0.098\n",
      "0.234\n",
      "0.084\n",
      "0.241\n",
      "0.096\n",
      "0.355\n",
      "0.076\n",
      "0.330\n",
      "0.114\n",
      "0.109\n",
      "0.509\n",
      "0.633\n",
      "0.530\n",
      "0.240\n",
      "0.341\n",
      "0.077\n",
      "0.161\n",
      "0.286\n",
      "0.529\n",
      "0.296\n",
      "0.722\n",
      "0.525\n",
      "0.331\n",
      "0.480\n",
      "0.292\n",
      "0.348\n",
      "0.411\n",
      "0.614\n",
      "0.484\n",
      "0.253\n",
      "0.117\n",
      "0.314\n",
      "0.228\n",
      "0.429\n",
      "0.594\n",
      "0.531\n",
      "0.324\n",
      "0.212\n",
      "0.403\n",
      "0.199\n",
      "0.169\n",
      "0.190\n",
      "0.512\n",
      "0.088\n",
      "0.942\n",
      "0.557\n",
      "0.422\n",
      "0.955\n",
      "0.824\n",
      "0.327\n",
      "0.109\n",
      "0.648\n",
      "0.532\n",
      "0.266\n",
      "0.305\n",
      "0.817\n",
      "0.958\n",
      "0.558\n",
      "0.450\n",
      "0.399\n",
      "0.851\n",
      "0.562\n",
      "0.962\n",
      "0.562\n",
      "0.781\n",
      "0.680\n",
      "0.340\n",
      "0.214\n",
      "0.331\n",
      "0.330\n",
      "0.345\n",
      "0.180\n",
      "0.169\n",
      "0.167\n",
      "0.291\n",
      "0.265\n",
      "0.436\n",
      "0.181\n",
      "0.226\n",
      "0.121\n",
      "0.317\n",
      "0.360\n",
      "0.288\n",
      "0.175\n",
      "0.587\n",
      "0.404\n",
      "0.337\n",
      "0.113\n",
      "0.120\n",
      "0.422\n",
      "0.180\n",
      "0.154\n",
      "0.322\n",
      "0.403\n",
      "0.451\n",
      "0.610\n",
      "0.293\n",
      "0.136\n",
      "0.912\n",
      "0.824\n",
      "0.093\n",
      "0.239\n",
      "0.613\n",
      "0.507\n",
      "0.293\n",
      "0.284\n",
      "0.961\n",
      "0.418\n",
      "0.237\n",
      "0.522\n",
      "0.649\n",
      "0.130\n",
      "0.707\n",
      "0.628\n",
      "0.227\n",
      "0.593\n",
      "0.647\n",
      "0.146\n",
      "0.274\n",
      "0.077\n",
      "0.298\n",
      "0.590\n",
      "0.244\n",
      "0.323\n",
      "0.760\n",
      "0.349\n",
      "0.094\n",
      "0.607\n",
      "0.225\n",
      "0.396\n",
      "0.078\n",
      "0.078\n",
      "0.475\n",
      "0.080\n",
      "0.383\n",
      "0.226\n",
      "0.131\n",
      "0.485\n",
      "0.088\n",
      "0.453\n",
      "0.094\n",
      "0.078\n",
      "0.527\n",
      "0.660\n",
      "0.245\n",
      "0.352\n",
      "0.135\n",
      "0.122\n",
      "0.725\n",
      "0.850\n",
      "0.246\n",
      "0.154\n",
      "0.210\n",
      "0.285\n",
      "0.564\n",
      "0.175\n",
      "0.314\n",
      "0.071\n",
      "0.140\n",
      "0.067\n",
      "0.070\n",
      "0.080\n",
      "0.100\n",
      "0.210\n",
      "0.210\n",
      "0.225\n",
      "0.095\n",
      "0.118\n",
      "0.495\n",
      "0.099\n",
      "0.234\n",
      "0.084\n",
      "0.242\n",
      "0.097\n",
      "0.356\n",
      "0.077\n",
      "0.330\n",
      "0.115\n",
      "0.109\n",
      "0.509\n",
      "0.634\n",
      "0.531\n",
      "0.241\n",
      "0.341\n",
      "0.078\n",
      "0.161\n",
      "0.286\n",
      "0.530\n",
      "0.297\n",
      "0.723\n",
      "0.525\n",
      "0.332\n",
      "0.481\n",
      "0.293\n",
      "0.349\n",
      "0.411\n",
      "0.615\n",
      "0.485\n",
      "0.254\n",
      "0.117\n",
      "0.315\n",
      "0.229\n",
      "0.430\n",
      "0.595\n",
      "0.531\n",
      "0.325\n",
      "0.213\n",
      "0.403\n",
      "0.200\n",
      "0.170\n",
      "0.191\n",
      "0.512\n",
      "0.088\n",
      "0.943\n",
      "0.558\n",
      "0.423\n",
      "0.955\n",
      "0.824\n",
      "0.328\n",
      "0.110\n",
      "0.649\n",
      "0.532\n",
      "0.266\n",
      "0.306\n",
      "0.818\n",
      "0.959\n",
      "0.558\n",
      "0.451\n",
      "0.400\n",
      "0.852\n",
      "0.563\n",
      "0.962\n",
      "0.563\n",
      "0.781\n",
      "0.681\n",
      "0.341\n",
      "0.215\n",
      "0.331\n",
      "0.331\n",
      "0.346\n",
      "0.181\n",
      "0.170\n",
      "0.167\n",
      "0.292\n",
      "0.266\n",
      "0.437\n",
      "0.182\n",
      "0.227\n",
      "0.121\n",
      "0.318\n",
      "0.360\n",
      "0.289\n",
      "0.176\n",
      "0.588\n",
      "0.404\n",
      "0.338\n",
      "0.114\n",
      "0.120\n",
      "0.423\n",
      "0.181\n",
      "0.154\n",
      "0.323\n",
      "0.403\n",
      "0.451\n",
      "0.611\n",
      "0.294\n",
      "0.137\n",
      "0.913\n",
      "0.825\n",
      "0.094\n",
      "0.239\n",
      "0.614\n",
      "0.508\n",
      "0.294\n",
      "0.285\n",
      "0.962\n",
      "0.419\n",
      "0.237\n",
      "0.522\n",
      "0.650\n",
      "0.131\n",
      "0.708\n",
      "0.628\n",
      "0.228\n",
      "0.594\n",
      "0.648\n",
      "0.146\n",
      "0.274\n",
      "0.078\n",
      "0.299\n",
      "0.591\n",
      "0.245\n",
      "0.324\n",
      "0.761\n",
      "0.350\n",
      "0.095\n",
      "0.607\n",
      "0.226\n",
      "0.397\n",
      "0.079\n",
      "0.079\n",
      "0.476\n",
      "0.080\n",
      "0.383\n",
      "0.226\n",
      "0.131\n",
      "0.486\n",
      "0.088\n",
      "0.454\n",
      "0.095\n",
      "0.079\n",
      "0.527\n",
      "0.660\n",
      "0.245\n",
      "0.353\n",
      "0.135\n",
      "0.125\n",
      "0.727\n",
      "0.853\n",
      "0.248\n",
      "0.157\n",
      "0.212\n",
      "0.287\n",
      "0.566\n",
      "0.177\n",
      "0.316\n",
      "0.074\n",
      "0.143\n",
      "0.069\n",
      "0.072\n",
      "0.083\n",
      "0.103\n",
      "0.212\n",
      "0.212\n",
      "0.227\n",
      "0.097\n",
      "0.120\n",
      "0.497\n",
      "0.101\n",
      "0.237\n",
      "0.087\n",
      "0.244\n",
      "0.099\n",
      "0.358\n",
      "0.079\n",
      "0.332\n",
      "0.117\n",
      "0.112\n",
      "0.512\n",
      "0.636\n",
      "0.533\n",
      "0.243\n",
      "0.344\n",
      "0.080\n",
      "0.163\n",
      "0.289\n",
      "0.532\n",
      "0.299\n",
      "0.725\n",
      "0.528\n",
      "0.334\n",
      "0.483\n",
      "0.295\n",
      "0.351\n",
      "0.414\n",
      "0.617\n",
      "0.487\n",
      "0.256\n",
      "0.120\n",
      "0.317\n",
      "0.231\n",
      "0.432\n",
      "0.597\n",
      "0.534\n",
      "0.327\n",
      "0.215\n",
      "0.406\n",
      "0.202\n",
      "0.172\n",
      "0.193\n",
      "0.515\n",
      "0.091\n",
      "0.945\n",
      "0.560\n",
      "0.425\n",
      "0.958\n",
      "0.827\n",
      "0.330\n",
      "0.112\n",
      "0.651\n",
      "0.535\n",
      "0.268\n",
      "0.308\n",
      "0.820\n",
      "0.961\n",
      "0.561\n",
      "0.453\n",
      "0.402\n",
      "0.854\n",
      "0.565\n",
      "0.964\n",
      "0.565\n",
      "0.783\n",
      "0.683\n",
      "0.343\n",
      "0.217\n",
      "0.334\n",
      "0.333\n",
      "0.348\n",
      "0.183\n",
      "0.172\n",
      "0.169\n",
      "0.294\n",
      "0.268\n",
      "0.439\n",
      "0.184\n",
      "0.229\n",
      "0.124\n",
      "0.320\n",
      "0.363\n",
      "0.291\n",
      "0.178\n",
      "0.590\n",
      "0.407\n",
      "0.340\n",
      "0.116\n",
      "0.122\n",
      "0.425\n",
      "0.183\n",
      "0.157\n",
      "0.325\n",
      "0.406\n",
      "0.453\n",
      "0.613\n",
      "0.296\n",
      "0.139\n",
      "0.915\n",
      "0.827\n",
      "0.096\n",
      "0.242\n",
      "0.616\n",
      "0.510\n",
      "0.296\n",
      "0.287\n",
      "0.964\n",
      "0.421\n",
      "0.240\n",
      "0.525\n",
      "0.652\n",
      "0.133\n",
      "0.710\n",
      "0.631\n",
      "0.230\n",
      "0.596\n",
      "0.650\n",
      "0.149\n",
      "0.277\n",
      "0.080\n",
      "0.301\n",
      "0.593\n",
      "0.247\n",
      "0.326\n",
      "0.763\n",
      "0.352\n",
      "0.097\n",
      "0.610\n",
      "0.228\n",
      "0.399\n",
      "0.081\n",
      "0.081\n",
      "0.478\n",
      "0.083\n",
      "0.385\n",
      "0.228\n",
      "0.134\n",
      "0.488\n",
      "0.090\n",
      "0.456\n",
      "0.097\n",
      "0.081\n",
      "0.530\n",
      "0.663\n",
      "0.248\n",
      "0.355\n",
      "0.138\n",
      "0.127\n",
      "0.730\n",
      "0.855\n",
      "0.251\n",
      "0.159\n",
      "0.215\n",
      "0.290\n",
      "0.569\n",
      "0.180\n",
      "0.319\n",
      "0.076\n",
      "0.145\n",
      "0.072\n",
      "0.075\n",
      "0.085\n",
      "0.105\n",
      "0.215\n",
      "0.215\n",
      "0.230\n",
      "0.100\n",
      "0.123\n",
      "0.500\n",
      "0.103\n",
      "0.239\n",
      "0.089\n",
      "0.247\n",
      "0.102\n",
      "0.361\n",
      "0.082\n",
      "0.335\n",
      "0.120\n",
      "0.114\n",
      "0.514\n",
      "0.639\n",
      "0.536\n",
      "0.246\n",
      "0.346\n",
      "0.083\n",
      "0.166\n",
      "0.291\n",
      "0.535\n",
      "0.302\n",
      "0.728\n",
      "0.530\n",
      "0.337\n",
      "0.486\n",
      "0.298\n",
      "0.354\n",
      "0.416\n",
      "0.620\n",
      "0.490\n",
      "0.259\n",
      "0.122\n",
      "0.320\n",
      "0.234\n",
      "0.435\n",
      "0.600\n",
      "0.536\n",
      "0.330\n",
      "0.217\n",
      "0.408\n",
      "0.205\n",
      "0.175\n",
      "0.196\n",
      "0.517\n",
      "0.093\n",
      "0.948\n",
      "0.563\n",
      "0.427\n",
      "0.960\n",
      "0.829\n",
      "0.333\n",
      "0.115\n",
      "0.654\n",
      "0.537\n",
      "0.271\n",
      "0.310\n",
      "0.823\n",
      "0.964\n",
      "0.563\n",
      "0.456\n",
      "0.405\n",
      "0.857\n",
      "0.568\n",
      "0.967\n",
      "0.568\n",
      "0.786\n",
      "0.686\n",
      "0.345\n",
      "0.220\n",
      "0.336\n",
      "0.336\n",
      "0.351\n",
      "0.186\n",
      "0.175\n",
      "0.172\n",
      "0.297\n",
      "0.271\n",
      "0.442\n",
      "0.187\n",
      "0.232\n",
      "0.126\n",
      "0.323\n",
      "0.365\n",
      "0.294\n",
      "0.181\n",
      "0.593\n",
      "0.409\n",
      "0.343\n",
      "0.119\n",
      "0.125\n",
      "0.428\n",
      "0.186\n",
      "0.159\n",
      "0.328\n",
      "0.408\n",
      "0.456\n",
      "0.616\n",
      "0.299\n",
      "0.141\n",
      "0.918\n",
      "0.830\n",
      "0.099\n",
      "0.244\n",
      "0.619\n",
      "0.512\n",
      "0.299\n",
      "0.290\n",
      "0.967\n",
      "0.424\n",
      "0.242\n",
      "0.527\n",
      "0.655\n",
      "0.136\n",
      "0.713\n",
      "0.633\n",
      "0.232\n",
      "0.599\n",
      "0.653\n",
      "0.151\n",
      "0.279\n",
      "0.083\n",
      "0.304\n",
      "0.596\n",
      "0.250\n",
      "0.329\n",
      "0.766\n",
      "0.354\n",
      "0.100\n",
      "0.612\n",
      "0.231\n",
      "0.402\n",
      "0.084\n",
      "0.084\n",
      "0.480\n",
      "0.085\n",
      "0.388\n",
      "0.231\n",
      "0.136\n",
      "0.491\n",
      "0.093\n",
      "0.459\n",
      "0.100\n",
      "0.084\n",
      "0.532\n",
      "0.665\n",
      "0.250\n",
      "0.358\n",
      "0.140\n",
      "0.124\n",
      "0.727\n",
      "0.852\n",
      "0.248\n",
      "0.156\n",
      "0.212\n",
      "0.287\n",
      "0.566\n",
      "0.177\n",
      "0.316\n",
      "0.073\n",
      "0.142\n",
      "0.069\n",
      "0.072\n",
      "0.082\n",
      "0.102\n",
      "0.212\n",
      "0.212\n",
      "0.227\n",
      "0.097\n",
      "0.120\n",
      "0.497\n",
      "0.101\n",
      "0.236\n",
      "0.086\n",
      "0.244\n",
      "0.099\n",
      "0.358\n",
      "0.079\n",
      "0.332\n",
      "0.117\n",
      "0.111\n",
      "0.511\n",
      "0.636\n",
      "0.533\n",
      "0.243\n",
      "0.343\n",
      "0.080\n",
      "0.163\n",
      "0.288\n",
      "0.532\n",
      "0.299\n",
      "0.725\n",
      "0.527\n",
      "0.334\n",
      "0.483\n",
      "0.295\n",
      "0.351\n",
      "0.413\n",
      "0.617\n",
      "0.487\n",
      "0.256\n",
      "0.119\n",
      "0.317\n",
      "0.231\n",
      "0.432\n",
      "0.597\n",
      "0.533\n",
      "0.327\n",
      "0.215\n",
      "0.405\n",
      "0.202\n",
      "0.172\n",
      "0.193\n",
      "0.514\n",
      "0.090\n",
      "0.945\n",
      "0.560\n",
      "0.425\n",
      "0.957\n",
      "0.826\n",
      "0.330\n",
      "0.112\n",
      "0.651\n",
      "0.534\n",
      "0.268\n",
      "0.308\n",
      "0.820\n",
      "0.961\n",
      "0.560\n",
      "0.453\n",
      "0.402\n",
      "0.854\n",
      "0.565\n",
      "0.964\n",
      "0.565\n",
      "0.783\n",
      "0.683\n",
      "0.343\n",
      "0.217\n",
      "0.333\n",
      "0.333\n",
      "0.348\n",
      "0.183\n",
      "0.172\n",
      "0.169\n",
      "0.294\n",
      "0.268\n",
      "0.439\n",
      "0.184\n",
      "0.229\n",
      "0.123\n",
      "0.320\n",
      "0.362\n",
      "0.291\n",
      "0.178\n",
      "0.590\n",
      "0.406\n",
      "0.340\n",
      "0.116\n",
      "0.122\n",
      "0.425\n",
      "0.183\n",
      "0.157\n",
      "0.325\n",
      "0.405\n",
      "0.453\n",
      "0.613\n",
      "0.296\n",
      "0.139\n",
      "0.915\n",
      "0.827\n",
      "0.096\n",
      "0.241\n",
      "0.616\n",
      "0.510\n",
      "0.296\n",
      "0.287\n",
      "0.964\n",
      "0.421\n",
      "0.239\n",
      "0.524\n",
      "0.652\n",
      "0.133\n",
      "0.710\n",
      "0.630\n",
      "0.230\n",
      "0.596\n",
      "0.650\n",
      "0.148\n",
      "0.276\n",
      "0.080\n",
      "0.301\n",
      "0.593\n",
      "0.247\n",
      "0.326\n",
      "0.763\n",
      "0.352\n",
      "0.097\n",
      "0.610\n",
      "0.228\n",
      "0.399\n",
      "0.081\n",
      "0.081\n",
      "0.478\n",
      "0.082\n",
      "0.385\n",
      "0.228\n",
      "0.134\n",
      "0.488\n",
      "0.090\n",
      "0.456\n",
      "0.097\n",
      "0.081\n",
      "0.529\n",
      "0.662\n",
      "0.248\n",
      "0.355\n",
      "0.137\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not isinstance(diff_score_1btk_normalized, torch.Tensor):\n",
    "    diff_score_1btk_normalized = torch.tensor(diff_score_1btk_normalized)\n",
    "\n",
    "print(\"Elements of diff_score_1btk_normalized:\")\n",
    "for element in diff_score_1btk_normalized.flatten():\n",
    "    print(f\"{element.item():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdc78cf-89e4-42c3-b03c-b8d03779e660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
