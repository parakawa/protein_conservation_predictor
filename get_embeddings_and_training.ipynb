{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76a910d1-a49d-4a65-8ee5-3a62370a1fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "def reduce_data(fasta_file, csv_file, reduced_amount, reduced_fasta_file, reduced_csv_file):\n",
    "    # Read the FASTA file and select a random subset of sequences\n",
    "    fasta_sequences = {}\n",
    "    selected_identifiers = []\n",
    "    with open(fasta_file, \"r\") as fasta:\n",
    "        records = list(SeqIO.parse(fasta, \"fasta\"))\n",
    "        random.shuffle(records)\n",
    "        selected_records = records[:reduced_amount]\n",
    "        for record in selected_records:\n",
    "            fasta_sequences[record.id] = str(record.seq)\n",
    "            selected_identifiers.append(record.id)\n",
    "\n",
    "    # Read the CSV file and store conservation scores for matching identifiers\n",
    "    csv_data = pd.read_csv(csv_file, delimiter='\\t', index_col=0)\n",
    "    reduced_csv_data = pd.DataFrame(\n",
    "        columns=csv_data.columns)  # Create an empty DataFrame\n",
    "    for identifier in selected_identifiers:\n",
    "        # Search for partial matches in the index\n",
    "        matching_index = csv_data.index[csv_data.index.str.contains(\n",
    "            identifier)]\n",
    "        if len(matching_index) > 0:\n",
    "            reduced_csv_data = pd.concat(\n",
    "                [reduced_csv_data, csv_data.loc[matching_index]])\n",
    "\n",
    "    # Write reduced data to new files\n",
    "    with open(reduced_fasta_file, \"w\") as fasta_reduced:\n",
    "        with open(reduced_csv_file, \"w\") as csv_reduced:\n",
    "            for identifier, sequence in fasta_sequences.items():\n",
    "                fasta_reduced.write(f\">{identifier}\\n{sequence}\\n\")\n",
    "            reduced_csv_data.to_csv(csv_reduced, sep='\\t')\n",
    "\n",
    "\n",
    "# reduce_data(\"curated_dataset/sequences.fasta\", \"curated_dataset/conservation_scores_formated.csv\", 1000,\"curated_dataset/reduced_input.fasta\", \"curated_dataset/reduced_input.csv\")\n",
    "\n",
    "# esm-extract esm2_t6_8M_UR50D curated_dataset/reduced_input.fasta curated_dataset/example_embeddings_esm2_reduced_input --repr_layers 0 5 6 --include mean per_tok\n",
    "\n",
    "def get_embeddings_vectors_sample_data(folder_path):\n",
    "\n",
    "    # Get the list of files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    # Filter the files to only include .pt files\n",
    "    pt_files = [file for file in files if file.endswith('.pt')]\n",
    "\n",
    "    # Initialize a list to store the vectors\n",
    "    vectors = []\n",
    "\n",
    "    # Load the vectors from each .pt file\n",
    "    for file in pt_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        embeddings = torch.load(file_path)[\"representations\"][6]\n",
    "        #embeddings = torch.load(file_path)[\"representations\"][6]\n",
    "        float_vector = embeddings.numpy().astype(float)\n",
    "        vectors.append(float_vector)\n",
    "    return vectors\n",
    "\n",
    "\n",
    "vectors = get_embeddings_vectors_sample_data('sample_data/example_embeddings_esm2')\n",
    "print(\"vectors\", len(vectors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bdc1b25-3248-4b24-a359-5392e6ef3a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(659, 320)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "557bffc9-de2e-4c87-9f2f-a1195cd0615a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings len torch.Size([59, 320])\n",
      "embeddings {'label': 'A0A1X7AIY7.1/282-340', 'representations': tensor([[-0.6685, -0.0708, -0.5033,  ...,  0.8954,  0.4106, -0.5340],\n",
      "        [-0.6899, -0.1052,  0.0013,  ...,  0.5112, -0.0517, -0.3438],\n",
      "        [-0.5972, -0.1812,  0.3029,  ...,  0.4339,  0.3076, -0.0928],\n",
      "        ...,\n",
      "        [-0.2558, -0.0050,  0.2232,  ...,  0.4575, -0.0603, -0.1484],\n",
      "        [-0.3865, -0.1068,  0.3723,  ...,  0.4398, -0.3131, -0.0656],\n",
      "        [-0.1832,  0.3298,  0.3563,  ..., -0.0673, -0.4823, -0.1598]])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_embeddings_vectors_curated_data(folder_path):\n",
    "    # Initialize a list to store the vectors\n",
    "    vectors = []\n",
    "    embeddings = []\n",
    "\n",
    "    # Traverse through each folder in the specified directory\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            # Check if the file is a .pt file\n",
    "            if file.endswith('.pt'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                embedding = torch.load(file_path)\n",
    "                selected_embedding = {\"label\": embedding[\"label\"], \"representations\": embedding[\"representations\"][6]}\n",
    "                #float_vector = embeddings.numpy().astype(float)\n",
    "                #vectors.append(float_vector)\n",
    "                embeddings.append(selected_embedding)\n",
    "\n",
    "    return vectors, embeddings\n",
    "\n",
    "vectors, embeddings = get_embeddings_vectors_curated_data('curated_dataset/example_embeddings_esm2_reduced_input')\n",
    "#print(\"Vectors:\", len(vectors[0]))\n",
    "print(\"embeddings len\", (embeddings[2][\"representations\"]).shape)\n",
    "print(\"embeddings\", embeddings[2])\n",
    "len(\"STPIRIFANGRRRVEVLRDNRLIYATSVNAGSQEIDTSSFPQGSYQLTIRIFNGSTLEQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7663a67f-94c0-41de-9de1-81014ea69328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('QIGGEDKADIAPILKEGFVGPGMQINNLLQERGEIVATVICGDNYFNENLDEATDTILGMIGQFNPDIVIAGPSFNAGRYGMACGAVCKAVSEKFNIPTLTGMYIESPGVDGYRKYTYIVETANSAVGMRTALPAMVKLALKLVDGVELGDPKEEGYIARGVRRNYFHAVRGSKRAVDMLIAKINDQPFTTEYPMPTFDRVAPNPHIVDMSKATIALVTSGGIVPKGNPDHIESSSASKFGKYDIEGFTNLTEKTHETAHGGYDPVYANLDADRVLPVDVLRELEAEGVIGKLHRYFYTTVGNGTSVANAKKFAAAIGKELVEAKVDAVILTST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb20a973-f6eb-4ef9-a932-8fab31851a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectors[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d83e63b8-9c03-4d21-8574-ba67b0f1b417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31696/4249312868.py:19: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  x = torch.tensor(embeddings_vectors, dtype=torch.float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 102720 at dim 1 (got 112960)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 53\u001b[0m\n\u001b[1;32m     48\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconservation_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Supongamos que tienes un array llamado \"vectors\" que contiene los embeddings vectors\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# y quieres entrenar el modelo con un tamaño de capa oculta de 64, una tasa de aprendizaje de 0.001\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# y durante 10 épocas.\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m \u001b[43mcalculate_conservation_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m, in \u001b[0;36mcalculate_conservation_scores\u001b[0;34m(embeddings_vectors, hidden_size, learning_rate, num_epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_conservation_scores\u001b[39m(embeddings_vectors, hidden_size, learning_rate, num_epochs):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Convertimos los vectores de embeddings en un tensor de PyTorch\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Normalizamos los datos de entrada\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     x \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m-\u001b[39m x\u001b[38;5;241m.\u001b[39mmin()) \u001b[38;5;241m/\u001b[39m (x\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m x\u001b[38;5;241m.\u001b[39mmin())\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 102720 at dim 1 (got 112960)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConservationModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(ConservationModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)  # Salida unidimensional para el score de conservación\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "def calculate_conservation_scores(embeddings_vectors, hidden_size, learning_rate, num_epochs):\n",
    "    # Convertimos los vectores de embeddings en un tensor de PyTorch\n",
    "    x = torch.tensor(embeddings_vectors, dtype=torch.float32)\n",
    "\n",
    "    # Normalizamos los datos de entrada\n",
    "    x = (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "    # Creamos el modelo\n",
    "    model = ConservationModel(input_size=x.shape[1], hidden_size=hidden_size)\n",
    "\n",
    "    # Definimos la función de pérdida y el optimizador\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Entrenamiento del modelo\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        outputs = model(x)\n",
    "\n",
    "        # Calculamos la pérdida\n",
    "        loss = criterion(outputs, x)  # Usamos los mismos datos como entrada y objetivo para el autoencoder\n",
    "\n",
    "        # Backward y optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Mostramos la pérdida\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Guardamos el modelo entrenado si es necesario\n",
    "    torch.save(model.state_dict(), 'conservation_model.pth')\n",
    "\n",
    "# Supongamos que tienes un array llamado \"vectors\" que contiene los embeddings vectors\n",
    "# y quieres entrenar el modelo con un tamaño de capa oculta de 64, una tasa de aprendizaje de 0.001\n",
    "# y durante 10 épocas.\n",
    "calculate_conservation_scores(vectors, hidden_size=64, learning_rate=0.001, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b700689-2533-452f-a28b-ecd7c0abfc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Iterar sobre cada lista de puntajes de conservación\n",
    "for i in range(len(conservation_scores)):\n",
    "    # Obtener la lista de puntajes de conservación actual\n",
    "    current_score = conservation_scores[i]\n",
    "    # Reemplazar los valores NaN por un valor específico, por ejemplo, 0\n",
    "    current_score = [0 if np.isnan(score) else score for score in current_score]\n",
    "    # Asignar la lista modificada de puntajes de conservación de nuevo al array original\n",
    "    conservation_scores[i] = current_score\n",
    "\n",
    "print(\"conservation_scores (después de tratar los NaN):\", len(conservation_scores[3]))\n",
    "print(conservation_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdcc001-4689-416a-aeea-774054ecec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "# Define the model\n",
    "class LinearRegressionModel(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Modificar la función de entrenamiento para ajustar las etiquetas\n",
    "def train_one_epoch(epoch_index, model, training_loader, optimizer, loss_fn, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    for i, data in enumerate(training_loader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Reducir las etiquetas a una sola dimensión (sumando)\n",
    "        labels = torch.sum(labels, dim=1, keepdim=True)\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "        # Imprimir las salidas del modelo\n",
    "        print('Sample outputs:', outputs)\n",
    "\n",
    "    return last_loss\n",
    "\n",
    "# Prepare your data\n",
    "# Rellenar las listas más cortas con ceros para que todas tengan la misma longitud\n",
    "max_length = max(len(score) for score in conservation_scores)\n",
    "conservation_scores = [score + [0] * (max_length - len(score)) for score in conservation_scores]\n",
    "\n",
    "X_train = torch.tensor(vectors, dtype=torch.float32)\n",
    "if isinstance(conservation_scores, np.ndarray):\n",
    "    # If conservation_scores is a NumPy array, convert it to a list first\n",
    "    conservation_scores = conservation_scores.tolist()\n",
    "y_train = torch.tensor(conservation_scores, dtype=torch.float32)\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 32\n",
    "training_data = TensorDataset(X_train, y_train)\n",
    "training_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "input_size = X_train.shape[1]\n",
    "model = LinearRegressionModel(input_size=input_size)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Initialize TensorBoard writer\n",
    "tb_writer = SummaryWriter()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}:\")\n",
    "    last_loss = train_one_epoch(epoch, model, training_loader, optimizer, loss_fn, tb_writer)\n",
    "    print(f\"  Epoch loss: {last_loss}\")\n",
    "\n",
    "# Close TensorBoard writer\n",
    "tb_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e49aebf-5094-4e45-93cc-e84c40009bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mi_entorno",
   "language": "python",
   "name": "mi_entorno"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
